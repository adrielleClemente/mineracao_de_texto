{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e54b9b-9d76-497d-b068-fd76eedf5252",
   "metadata": {},
   "source": [
    "# Análise de texto do livro Data Science do Zero\n",
    "\n",
    "Primeiro, fiz um script para converter o livro em pdf para txt, em outro notebook. A ideia é fazer a *mineração de texto*.\n",
    "\n",
    "**Fonte:** [Introdução a Mineração de textos com Python](https://www.ufsm.br/pet/sistemas-de-informacao/2021/07/12/introducao-a-mineracao-de-textos-com-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7cf502-350d-4416-9ed8-37288b8ec816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar as bibliotecas\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e286757-74d4-4433-80c9-65ba5160a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('livro_data.txt', mode = 'r', encoding = 'utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b38da234-7b60-4b36-af36-e627a1cba5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passando texto para minúscula\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d163bc04-8fe3-4be3-b6ae-e625265b2172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tcompra\tdeste\tconteúdo\tnão\tprevê\tatendimento\te\tfornecimento\tde\tsuporte\ttécnico\toperacional,\tinstalação\n",
      "ou\tconfiguração\tdo\tsistema\tde\tleitor\tde\tebooks.\tem\talguns\tcasos,\te\tdependendo\tda\tplataforma,\to\tsuporte\n",
      "poderá\tser\tobtido\tcom\to\tfabricante\tdo\tequipamento\te/ou\tloja\tde\tcomércio\tde\tebooks.data\tscience\tdo\tzero\n",
      "copyright\t©\t2016\tda\tstarlin\talta\teditora\te\tconsultoria\teireli.\tisbn:\t978-85-508-0387-6\n",
      "translated\tfrom\toriginal\tdata\tscience\tfrom\tscratch\tby\tjoel\tgrus.\tcopyright\t©\t2015\tby\to’reilly\tmedia.\n",
      "isbn\t978-1-491-90142-7.\tthis\ttranslation\tis\tpublished\tand\tsold\tby\tpermission\tof\to’reilly\tmedia,\tinc.,\tthe\n",
      "owner\tof\tall\trights\tto\tpublish\tand\tsell\tthe\tsame.\tportuguese\tlanguage\tedition\tpublished\tby\tstarlin\talta\n",
      "editora\te\tconsultoria\teireli,\tcopyright\t©\t2016\tby\tstarlin\talta\teditora\te\tconsultoria\teireli\n",
      ".\n",
      "todos\tos\tdireitos\testão\treservados\te\tprotegidos\tpor\tlei.\tnenhuma\tparte\tdeste\tlivro,\tsem\tautorização\tprévia\n",
      "por\tescrito\tda\teditora,\tpoderá\tser\treproduzida\tou\ttransmitida.\ta\tviolação\tdos\tdireitos\tautorais\té\tcrime\n",
      "estabelecido\tna\tlei\tnº\t9.610/98\te\tcom\tpunição\tde\tacordo\tcom\to\tartigo\t184\tdo\tcódigo\tpenal.\n",
      "a\teditora\tnão\tse\tresponsabiliza\tpelo\tconteúdo\tda\tobra,\tformulada\texclusivamente\tpelo(s)\tautor(es).\n",
      "marcas\tregistradas:\n",
      "\ttodos\tos\ttermos\tmencionados\te\treconhecidos\tcomo\tmarca\tregistrada\te/ou\n",
      "comercial\tsão\tde\tresponsabilidade\tde\tseus\tproprietários.\ta\teditora\tinforma\tnão\testar\tassociada\ta\tnenhum\n",
      "produto\te/ou\tfornecedor\tapresentado\tno\tlivro.\n",
      "edição\trevisada\tconforme\to\tacordo\tortográfico\tda\tlíngua\tportuguesa\tde\t2009.\n",
      "obra\tdisponível\tpara\tvenda\tcorporativa\te/ou\tpersonalizada.\tpara\tmais\tinformações,\tfale\tcom\n",
      "projetos@altabooks.com.br\n",
      "produção\teditorial\n",
      "editora\talta\tbooks\n",
      "produtor\teditorial\n",
      "claudia\tbraga\n",
      "thiê\talves\n",
      "produtor\teditorial\t(design)\n",
      "aurélio\tcorrêa\n",
      "gerência\teditorial\n",
      "anderson\tvieira\n",
      "supervisão\tde\tqualidade\teditorial\n",
      "sergio\tde\tsouza\n",
      "assistente\teditorial\n",
      "carolina\tgiannini\n",
      "marketing\teditorial\n",
      "silas\tamaro\n",
      "marketing@altabooks.com.br\n",
      "gerência\tde\tcaptação\te\tcontratação\tde\tobras\n",
      "j.\ta.\trugeri\n",
      "autoria@altabooks.com.br\n",
      "vendas\tatacado\te\tvarejo\n",
      "daniele\tfonseca\n",
      "viviane\tpaiva\n",
      "comercial@altabooks.com.brouvidoria\n",
      "ouvidoria@altabooks.com.br\n",
      "equipe\teditorial\n",
      "bianca\tteodoro\n",
      "christian\tdanniel\n",
      "izabelli\tcarvalho\n",
      "jessica\tcarvalho\n",
      "juliana\tde\toliveira\n",
      "renan\tcastro\n",
      "tradução\n",
      "welington\tnascimento\n",
      "copidesque\n",
      "vivian\tsbravatti\n",
      "revisão\tgramatical\n",
      "ana\tpaula\tda\tfonseca\n",
      "revisão\ttécnica\n",
      "ronaldo\td’avila\troenick\n",
      "engenheiro\tde\teletrônica\tpelo\tinstituto\tmilitar\tde\tengenharia\n",
      "(ime)\n",
      "diagramação\n",
      "cláudio\tfrota\n",
      "erratas\te\tarquivos\tde\tapoio:\n",
      "\tno\tsite\tda\teditora\trelatamos,\tcom\ta\tdevida\tcorreção,\tqualquer\terro\n",
      "encontrado\tem\tnossos\tlivros,\tbem\tcomo\tdisponibilizamos\tarquivos\tde\tapoio\tse\taplicáveis\tà\tobra\tem\n",
      "questão.\n",
      "acesse\to\tsite\t\n",
      "www.altabooks.com.br\n",
      "\te\tprocure\tpelo\ttítulo\tdo\tlivro\tdesejado\tpara\tter\tacesso\tàs\terratas,\n",
      "aos\tarquivos\tde\tapoio\te/ou\ta\toutros\tconteúdos\taplicáveis\tà\tobra.\n",
      "suporte\ttécnico:\n",
      "\ta\tobra\té\tcomercializada\tna\tforma\tem\tque\testá,\tsem\tdireito\ta\tsuporte\ttécnico\tou\n",
      "orientação\tpessoal/exclusiva\tao\tleitor.\n",
      "dados\tinternacionais\tde\tcatalogação\tna\tpublicação\t(cip)\n",
      "vagner\trodolfo\tcrb-8/9410\n",
      "g885d\t\t\t\t\tgrus,\tjoel\n",
      "data\tscience\tdo\tzero\t[\trecurso\teletrônico\t]\t/\tjoel\tgrus;\ttraduzido\tpor\n",
      "welington\tnascimento.\t-\trio\tde\tjaneiro\t:\talta\tbooks,\t2016.\n",
      "336\tp.\t:\til.\t;\t3,8\tmb.\n",
      "tradução\tde:\tdata\tscience\tfrom\tscratch:\tfirst\tprinciples\twith\n",
      "python\n",
      "inclui\tíndice.\n",
      "isbn:\t978-85-508-0387-6\t(ebook)1.\tmatemática.\t2.\tprogramação.\t3.\tanálise\tde\tdados.\ti.\tnascimento,\n",
      "welington.\tii.\ttítulo.\n",
      "cdd\t005.13\t\t\t\t\t\n",
      "cdu\t004.655.3\n",
      "rua\tviúva\tcláudio,\t291\t-\tbairro\tindustrial\tdo\tjacaré\n",
      "cep:\t20.970-031\t-\trio\tde\tjaneiro\t(rj)\n",
      "tels.:\t(21)\t3278-8069\t/\t3278-8419\n",
      "www.altabooks.com.br\n",
      "\t—\t\n",
      "altabooks@altabooks.com.br\n",
      "www.facebook.com/altabooks\n",
      "\t—\t\n",
      "www.instagram.com/altabooks1.\n",
      "2.\n",
      "sumário\n",
      "prefácio\n",
      "introdução\n",
      "a\tascensão\tdos\tdados\n",
      "o\tque\té\tdata\tscience?\n",
      "motivação\thipotética:\tdatasciencester\n",
      "encontrando\tconectores-chave\n",
      "cientistas\tde\tdados\tque\tvocê\ttalvez\tconheça\n",
      "salários\te\texperiência\n",
      "contas\tpagas\n",
      "tópicos\tde\tinteresse\n",
      "em\tdiante\n",
      "curso\trelâmpago\tde\tpython\n",
      "o\tbásico\n",
      "iniciando\tem\tpython\n",
      "python\tzen\n",
      "formatação\tde\tespaço\tem\tbranco\n",
      "módulos\n",
      "aritmética\n",
      "funções\n",
      "strings\t(cadeias\tde\tcaracteres)\n",
      "exceções\n",
      "listas\n",
      "tuplas\n",
      "dicionários\n",
      "conjuntos\n",
      "controle\tde\tfluxo3.\n",
      "4.\n",
      "5.\n",
      "veracidade\n",
      "não\ttão\tbásico\n",
      "ordenação\n",
      "compreensões\tde\tlista\n",
      "geradores\te\titeradores\n",
      "aleatoriedade\n",
      "expressões\tregulares\n",
      "programação\torientada\ta\tobjeto\n",
      "ferramentas\tfuncionais\n",
      "enumeração\t(enumerate)\n",
      "descompactação\tde\tzip\te\targumentos\n",
      "args\te\tkwargs\n",
      "bem-vindo\tà\tdatasciencester!\n",
      "para\tmais\tesclarecimentos\n",
      "visualizando\tdados\n",
      "matplotlib\n",
      "gráficos\tde\tbarra\n",
      "gráficos\tde\tlinhas\n",
      "gráficos\tde\tdispersão\n",
      "para\tmais\tesclarecimentos\n",
      "álgebra\tlinear\n",
      "vetores\n",
      "matrizes\n",
      "para\tmais\tesclarecimentos\n",
      "estatística\n",
      "descrevendo\tum\tconjunto\túnico\tde\tdados\n",
      "tendências\tcentrais\n",
      "dispersão\n",
      "correlação\n",
      "paradoxo\tde\tsimpson\n",
      "alguns\toutros\tpontos\tde\tatenção\tsobre\tcorrelação\n",
      "correlação\te\tcausalidade\n",
      "para\tmais\tesclarecimentos6.\n",
      "7.\n",
      "8.\n",
      "9.\n",
      "probabilidade\n",
      "dependência\te\tindependência\n",
      "probabilidade\tcondicional\n",
      "teorema\tde\tbayes\n",
      "variáveis\taleatórias\n",
      "distribuições\tcontínuas\n",
      "a\tdistribuição\tnormal\n",
      "o\tteorema\tdo\tlimite\tcentral\n",
      "para\tmais\tesclarecimentos\n",
      "hipótese\te\tinferência\n",
      "teste\testatístico\tde\thipótese\n",
      "exemplo:\tlançar\tuma\tmoeda\n",
      "p\n",
      "-values\n",
      "intervalos\tde\tconfiança\n",
      "p-hacking\n",
      "exemplo:\texecutando\tum\tteste\ta/b\n",
      "inferência\tbayesiana\n",
      "para\tmais\tesclarecimentos\n",
      "gradiente\tdescendente\n",
      "a\tideia\tpor\ttrás\tdo\tgradiente\tdescendente\n",
      "estimando\to\tgradiente\n",
      "usando\to\tgradiente\n",
      "escolhendo\to\ttamanho\tdo\tpróximo\tpasso\n",
      "juntando\ttudo\n",
      "gradiente\tdescendente\testocástico\n",
      "para\tmais\tesclarecimentos\n",
      "obtendo\tdados\n",
      "stdin\te\tstdout\n",
      "lendo\tarquivos\n",
      "o\tbásico\tde\tarquivos\ttexto\n",
      "arquivos\tdelimitados\n",
      "extraindo\tdados\tda\tinternet\n",
      "html\te\tsua\tsubsequente\tpesquisa10.\n",
      "11.\n",
      "12.\n",
      "13.\n",
      "exemplo:\tlivros\to’reilly\tsobre\tdados\n",
      "usando\tapis\n",
      "json\t(e\txml)\n",
      "usando\tuma\tapi\tnão\tautenticada\n",
      "encontrando\tapis\n",
      "exemplo:\tusando\tas\tapis\tdo\ttwitter\n",
      "obtendo\tcredenciais\n",
      "para\tmais\tesclarecimentos\n",
      "trabalhando\tcom\tdados\n",
      "explorando\tseus\tdados\n",
      "explorando\tdados\tunidimensionais\n",
      "duas\tdimensões\n",
      "muitas\tdimensões\n",
      "limpando\te\ttransformando\n",
      "manipulando\tdados\n",
      "redimensionando\n",
      "redução\tda\tdimensionalidade\n",
      "para\tmais\tesclarecimentos\n",
      "aprendizado\tde\tmáquina\n",
      "modelagem\n",
      "o\tque\té\taprendizado\tde\tmáquina?\n",
      "sobreajuste\te\tsub-ajuste\n",
      "precisão\n",
      "compromisso\tentre\tpolarização\te\tvariância\n",
      "recursos\textração\te\tseleção\tde\tcaracterística\n",
      "para\tmais\tesclarecimentos\n",
      "k–vizinhos\tmais\tpróximos\n",
      "o\tmodelo\n",
      "exemplo:\tlinguagens\tfavoritas\n",
      "a\tmaldição\tda\tdimensionalidade\n",
      "para\tmais\tesclarecimentos\n",
      "naive\tbayes\n",
      "um\tfiltro\tde\tspam\tmuito\testúpido14.\n",
      "15.\n",
      "16.\n",
      "17.\n",
      "um\tfiltro\tde\tspam\tmais\tsofisticado\n",
      "implementação\n",
      "testando\tnosso\tmodelo\n",
      "para\tmais\tesclarecimentos\n",
      "regressão\tlinear\tsimples\n",
      "o\tmodelo\n",
      "usando\to\tgradiente\tdescendente\n",
      "estimativa\tmáxima\tda\tprobabilidade\n",
      "para\tmais\tesclarecimentos\n",
      "regressão\tmúltipla\n",
      "o\tmodelo\n",
      "mais\tsuposições\tdo\tmodelo\tdos\tmínimos\tquadrados\n",
      "ajustando\to\tmodelo\n",
      "interpretando\to\tmodelo\n",
      "o\tbenefício\tdo\tajuste\n",
      "digressão:\ta\tinicialização\n",
      "erros\tpadrões\tde\tcoeficientes\tde\tregressão\n",
      "regularização\n",
      "para\tmais\tesclarecimentos\n",
      "regressão\tlogística\n",
      "o\tproblema\n",
      "a\tfunção\tlogística\n",
      "aplicando\to\tmodelo\n",
      "o\tbenefício\tdo\tajuste\n",
      "máquina\tde\tvetor\tde\tsuporte\n",
      "para\tmais\tesclarecimentos\n",
      "árvores\tde\tdecisão\n",
      "o\tque\té\tuma\tárvore\tde\tdecisão?\n",
      "entropia\n",
      "a\tentropia\tde\tuma\tpartição\n",
      "criando\tuma\tárvore\tde\tdecisão\n",
      "juntando\ttudo\n",
      "florestas\taleatórias18.\n",
      "19.\n",
      "20.\n",
      "21.\n",
      "22.\n",
      "para\tmaiores\tesclarecimentos\n",
      "redes\tneurais\n",
      "perceptrons\n",
      "redes\tneurais\tfeed-forward\n",
      "backpropagation\n",
      "exemplo:\tderrotando\tum\tcaptcha\n",
      "para\tmais\tesclarecimentos\n",
      "agrupamento\n",
      "a\tideia\n",
      "o\tmodelo\n",
      "exemplo:\tencontros\n",
      "escolhendo\tk\n",
      "exemplo:\tagrupando\tcores\n",
      "agrupamento\thierárquico\tbottom-up\n",
      "para\tmais\tesclarecimentos\n",
      "processamento\tde\tlinguagem\tnatural\n",
      "nuvens\tde\tpalavras\n",
      "modelos\tn-gramas\n",
      "gramáticas\n",
      "um\tadendo:\tamostragem\tde\tgibbs\n",
      "modelagem\tde\ttópicos\n",
      "para\tmais\tesclarecimentos\n",
      "análise\tde\trede\n",
      "centralidade\tde\tintermediação\n",
      "centralidade\tde\tvetor\tpróprio\n",
      "multiplicação\tde\tmatrizes\n",
      "centralidade\n",
      "gráficos\tdirecionados\te\tpagerank\n",
      "para\tmais\tesclarecimentos\n",
      "sistemas\trecomendadores\n",
      "curadoria\tmanual\n",
      "recomendando\to\tque\té\tpopular23.\n",
      "24.\n",
      "25.\n",
      "filtragem\tcolaborativa\tbaseada\tno\tusuário\n",
      "filtragem\tcolaborativa\tbaseada\tem\titens\n",
      "para\tmais\tesclarecimentos\n",
      "bases\tde\tdados\te\tsql\n",
      "create\ttable\te\tinsert\n",
      "update\n",
      "delete\n",
      "select\n",
      "group\tby\n",
      "order\tby\n",
      "join\n",
      "subconsultas\n",
      "índices\n",
      "otimização\tde\tconsulta\n",
      "nosql\n",
      "para\tmais\tesclarecimentos\n",
      "mapreduce\n",
      "exemplo:\tcontagem\tde\tpalavras\n",
      "por\tque\tmapreduce?\n",
      "mapreduce\tmais\tgeneralizado\n",
      "exemplo:\tanalisando\tatualizações\tde\tstatus\n",
      "exemplo:\tmultiplicação\tde\tmatriz\n",
      "um\tadendo:\tcombinadores\n",
      "para\tmais\tesclarecimentos\n",
      "vá\tem\tfrente\te\tpratique\tdata\tscience\n",
      "ipython\n",
      "matemática\n",
      "não\tdo\tzero\n",
      "numpy\n",
      "pandas\n",
      "scikit-learn\n",
      "visualização\n",
      "rencontre\tdados\n",
      "pratique\tdata\tscience\n",
      "hacker\tnews\n",
      "carros\tde\tbombeiros\n",
      "camisetas\n",
      "e\tvocê?•\n",
      "•\n",
      "•\n",
      "prefácio\n",
      "data\tscience\n",
      "data\tscience\ttem\tsido\tchamada\tde\t“o\temprego\tmais\tsexy\tdo\tséculo\t21”\n",
      "(\n",
      "http://bit.ly/1bqe-1wy\n",
      ")\n",
      ",\tprovavelmente\tpor\talguém\tque\tnunca\ttenha\tvisitado\n",
      "um\tquartel\tdo\tcorpo\tde\tbombeiros.\tde\tqualquer\tforma,\tdata\tscience\té\tum\tcampo\n",
      "em\tevidência\te\testá\tem\talta;\tnão\trequer\tmuita\tinvestigação\tpara\tencontrar\n",
      "prognósticos\tde\tanalistas\tde\tque,\tnos\tpróximos\tdez\tanos,\tprecisaremos\tde\n",
      "bilhões\te\tbilhões\tde\tcientistas\tde\tdados\ta\tmais\tdo\tque\tpossuímos\tatualmente.\n",
      "mas\to\tque\té\tdata\tscience?\tafinal\tde\tcontas,\tnão\tconseguimos\tproduzir\tcientistas\n",
      "de\tdados\tse\tnão\tsoubermos\to\tque\trealmente\té.\tde\tacordo\tcom\to\tdiagrama\tde\n",
      "venn\t\n",
      "(\n",
      "http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagr\n",
      ")\n",
      ",\tum\n",
      "tanto\tfamoso\tnesta\tárea,\tdata\tscience\tse\tencontra\tna\tinterseção\tde:\n",
      "habilidades\tde\thacker\n",
      "conhecimento\tde\testatística\te\tmatemática\n",
      "competência\tsignificativa\n",
      "originalmente,\tplanejei\tescrever\tum\tlivro\tabordando\tos\ttrês,\tmas\teu\trapidamente\n",
      "percebi\tque\tuma\tabordagem\tcompleta\tde\t“competência\tsignificativa”\texigiria\n",
      "dezenas\tde\tmilhares\tde\tpáginas.\tassim,\teu\tdecidi\tfocar\tnos\tdois\tprimeiros.\tmeu\n",
      "objetivo\té\tajudá-lo\ta\tdesenvolver\thabilidades\tde\thacker,\tas\tquais\tvocê\tprecisará\n",
      "para\tiniciar\ta\tprática\tem\tdata\tscience.\tmeu\toutro\tobjetivo\té\tfazer\tvocê\tse\tsentir\n",
      "confortável\tcom\tmatemática\te\testatística,\tque\tsão\ta\tbase\tde\tdata\tscience.\n",
      "de\talguma\tforma,\teste\tlivro\té\tuma\tgrande\tambição.\ta\tmelhor\tmaneira\tde\n",
      "aprender\ta\thackear\té\thackeando\tcoisas.\tao\tler\teste\tlivro,\tvocê\tterá\tum\tbom\n",
      "entendimento\tde\tcomo\teu\thackeio\tas\tcoisas,\tque\ttalvez\tnão\tseja\ta\tmelhor\tforma\n",
      "para\tvocê.\tvocê\tentenderá\tquais\tferramentas\teu\tuso\tque\ttalvez\tnão\tsejam\tasmelhores\tpara\tvocê.\tvocê\tverá\tcomo\teu\tabordo\tos\tproblemas\tcom\tdados,\tque\n",
      "talvez\tnão\tseja\ta\tmelhor\tabordagem\tpara\tvocê.\ta\tintenção\t(e\ta\t\n",
      "esperança)\té\tque\n",
      "meus\texemplos\tinspirarão\tvocê\ta\texperimentar\tas\tcoisas\tdo\tseu\tjeito.\ttodo\to\n",
      "código\te\tdados\tdeste\tlivro\testão\tdisponíveis\tno\tgithub\n",
      "(\n",
      "https://github.com/joelgrus/data-science-from-scratch\n",
      ")\n",
      "\tpara\tajudar.\n",
      "do\tmesmo\tmodo,\ta\tmelhor\tmaneira\tde\taprender\tmatemática\té\tpraticando.\tna\n",
      "verdade,\teste\tnão\té\tum\tlivro\tde\tmatemática\te,\tna\tmaior\tparte,\tnós\tnão\n",
      "“praticaremos\tmatemática”.\tno\tentanto,\tvocê\tnão\tpode\tpraticar\tdata\tscience\tsem\n",
      "ter\t\n",
      "algum\n",
      "\tentendimento\tde\tprobabilidade,\testatística\te\tálgebra\tlinear.\tisso\n",
      "significa\tque,\tquando\tnecessário,\tvamos\ta\tfundo\tnas\tequações\tmatemáticas,\n",
      "intuições\tmatemáticas,\taxiomas\tmatemáticos\te\tversões\tcartunescas\tde\tgrandes\n",
      "ideias\tmatemáticas.\tespero\tque\tvocê\tnão\ttenha\tmedo\tde\tir\tfundo\tcomigo.\n",
      "durante\ttodo\to\tlivro,\ttambém\tespero\tque\tvocê\tveja\tque\tbrincar\tcom\tdados\té\n",
      "divertido,\tporque,\tbem,\tbrincar\tcom\tdados\té\tdivertido!\t‘especialmente\tse\n",
      "comparado\ta\talgumas\talternativas,\tcomo\tdeclaração\tde\timpostos\tou\texploração\n",
      "de\tcarvão.’•\n",
      "•\n",
      "•\n",
      "do\tzero\n",
      "existem\tvárias\te\tvárias\tbibliotecas,\testruturas,\tmódulos\te\tkits\tde\tferramentas\tde\n",
      "data\tscience\tque\timplementam\tde\tmodo\teficiente\tos\tmais\tcomuns\t(e\ttambém\tos\n",
      "menos\tcomuns)\talgoritmos\te\ttécnicas.\tse\tvocê\tse\ttornar\tum\tcientista\tde\tdados,\n",
      "será\tíntimo\tde\tnumpy,\tde\tscikit-learn,\tde\tpandas\te\tde\tdiversas\toutras\tbibliotecas.\n",
      "elas\tsão\tótimas\tpara\tpraticar\tdata\tscience\te\ttambém\tótimas\tpara\tcomeçar\ta\n",
      "praticar\tsem\tentender\tde\tfato\to\tque\té\tdata\tscience.\n",
      "neste\tlivro,\tabordaremos\tdata\tscience\tdo\tzero.\tisso\tsignifica\tque\tconstruiremos\n",
      "ferramentas\te\timplementaremos\talgoritmos\tà\tmão,\ta\tfim\tde\tentendê-los\tmelhor.\n",
      "eu\tme\tempenhei\tbastante\tem\tcriar\timplementações\te\texemplos\tque\tsão\tclaros,\n",
      "bem\tcomentados\te\tlegíveis.\tna\tmaioria\tdos\tcasos,\tas\tferramentas\tque\n",
      "construiremos\tserão\tesclarecedoras,\tmas\tpouco\tpráticas.\telas\tfuncionarão\tbem\n",
      "em\tpequenos\tconjuntos\tde\tdados,\tmas\tfracassarão\tnas\tescalas\tencontradas\tna\n",
      "web.\n",
      "no\tdecorrer\tdo\tlivro,\teu\tindicarei\tbibliotecas\tque\tvocê\ttalvez\tuse\tpara\taplicar\n",
      "tais\ttécnicas\tpara\taumentar\tos\tconjuntos\tde\tdados.\tporém,\tnão\tas\tusaremos\taqui.\n",
      "há\tum\tsólido\tdebate\tsobre\tqual\ta\tmelhor\tlinguagem\tpara\taprender\tdata\tscience.\n",
      "muitos\tacreditam\tque\té\ta\tlinguagem\tde\tprogramação\testatística\tr.\t(achamos\n",
      "que\tessas\tpessoas\testão\t\n",
      "erradas\n",
      ".)\tpoucos\tsugerem\tjava\tou\tscala.\tcontudo,\n",
      "python\té\ta\tescolha\tevidente.\n",
      "python\tpossui\tdiversos\trecursos\tque\to\ttornam\tmais\tadequado\tpara\to\taprendizado\n",
      "(e\tprática)\tde\tdata\tscience:\n",
      "é\tgratuito.\n",
      "é\trelativamente\tsimples\tde\tcodificar\t(e,\to\tprincipal,\tde\tentender).\n",
      "possui\tmuitas\tbibliotecas\túteis\trelacionadas\tao\tdata\tscience.\n",
      "fico\treceoso\tao\tdizer\tque\tpython\té\tminha\tlinguagem\tde\tprogramação\tfavorita.\n",
      "há\toutras\tlinguagens\tque\tconsidero\tmais\tagradáveis,\tmais\tbem\tprojetadas,\tou\n",
      "apenas\tmais\tdivertidas\tde\ttrabalhar.\te,\tainda\tassim,\ttoda\tvez\tque\teu\tcomeço\tum\n",
      "projeto\tnovo\tde\tdata\tscience,\teu\tacabo\tusando\tpython.\ttoda\tvez\tque\tprecisofazer\tum\tprotótipo\trápido\tque\tfuncione,\teu\tacabo\tusando\tpython.\te\ttoda\tvez\tque\n",
      "quero\tdemonstrar\tconceitos\tprecisos\tde\tdata\tscience,\tde\tmaneira\tfácil\tde\n",
      "entender,\tacabo\tusando\tpython.\tdesta\tforma,\to\tlivro\tusa\tpython.\n",
      "o\tobjetivo\tdeste\tlivro\tnão\té\tensinar\tpython.\t(apesar\tde\tser\tbem\tóbvio\tque,\tao\n",
      "ler\teste\tlivro,\tvocê\taprenderá\tum\tpouco\tde\tpython.)\tirei\tlevá-lo\tem\tum\tcurso\n",
      "intensivo\tpelo\tcapítulo\tque\tdestaca\tos\trecursos\tmais\timportantes\tpara\tos\tnossos\n",
      "propósitos,\tmas\tse\tvocê\tnão\tsabe\tnada\tsobre\tprogramar\tem\tpython\t(ou\tsobre\n",
      "programação\tno\tgeral),\ttalvez\tvocê\tqueira\tturbinar\teste\tlivro\tcom\talgo\tcomo\tum\n",
      "tutorial\t“python\tpara\tiniciantes”.\n",
      "o\trestante\tdesta\tintrodução\tao\tdata\tscience\tterá\ta\tmesma\tabordagem\t—\tentrando\n",
      "em\tdetalhes\tquando\tparecer\tessencial\tou\tesclarecedor,\toutras\tvezes\tdeixando\tos\n",
      "detalhes\tpara\tvocê\tdescobrir\tpor\tsi\tsó\t(ou\tprocurar\tna\twikipédia).\n",
      "ao\tlongo\tdos\tanos,\ttreinei\tum\tgrande\tnúmero\tde\tcientistas\tde\tdados.\tapesar\tde\n",
      "que\tnem\ttodos\teles\tseguiram\to\tcaminho\tde\tse\ttornarem\tcientistas\tde\tdados\n",
      "ninjas\trockstars,\tos\tdeixei\tmelhores\tdo\tque\tquando\tos\tencontrei.\tvim\ta\tacreditar\n",
      "que\tqualquer\tpessoa\tque\ttenha\talguma\taptidão\tpara\ta\tmatemática\te\talguma\n",
      "habilidade\tpara\tprogramação\ttem\to\tque\té\tnecessário\tpara\tpraticar\tdata\tscience.\n",
      "tudo\to\tque\tprecisa\té\tde\tuma\tmente\tcuriosa,\tvontade\ttrabalhar\tbastante\te\teste\n",
      "livro.\tportanto,\teste\tlivro.convenções\tusadas\tneste\tlivro\n",
      "as\tseguintes\tconvenções\ttipográficas\tsão\tusadas\tneste\tlivro:\n",
      "itálico\n",
      "indica\ttermos\tnovos,\turls,\tendereços\tde\te-mail,\tnomes\te\textensões\tde\tarquivos.\n",
      "monoespaçada\n",
      "usada\tpara\tlistagens\tde\tprogramas,\te,\ttambém,\tdentro\tdo\ttexto\tse\treferindo\taos\telementos\tdos\n",
      "programas\tcomo\tvariáveis\tou\tnomes\tde\tfunções,\tbancos\tde\tdados,\ttipos\tde\tdados,\tvariáveis\tde\n",
      "ambiente,\tdeclarações\te\tpalavras-chave.\n",
      "monoespaçada\tcom\tbold\n",
      "mostra\tcomandos\tou\toutro\ttexto\tque\tdeve\tser\tliteralmente\tdigitado\tpelo\tusuário.\n",
      "monoespaçada\tcom\titálico\n",
      "mostra\ttexto\tque\tdeve\tser\tsubstituído\tcom\tvalores\tfornecidos\tpelo\tusuário\tou\tpor\tvalores\n",
      "determinados\tpelo\tcontexto.\n",
      "este\tícone\tsignifica\tuma\tdica\tou\tsugestão.\n",
      "este\tícone\tsignifica\tuma\tobservação\tgeral.\n",
      "este\tícone\tsignifica\tum\taviso\tou\tprecaução.usando\texemplos\tde\tcódigo\n",
      "você\tpode\tbaixar\to\tmaterial\tcomplementar\t(exemplos\tde\tcódigo,\texercícios,\n",
      "etc.)\tno\tsite\tda\teditora\talta\tbooks.\tprocure\tpelo\ttítulo\tou\tisbn\tdo\tlivro.\teste\n",
      "conteúdo\ttambém\testá\tdisponível\tem\t\n",
      "https://github.com/joelgrus/data-science-\n",
      "from-scratch\n",
      ".\ttodos\tos\toutros\tsites\tmencionados\tnesta\tobra\testão\tem\tinglês\te\ta\n",
      "editora\tnão\tse\tresponsabiliza\tpela\tmanutenção\tou\tconteúdo\tde\tsites\tde\tterceiros.\n",
      "este\tlivro\testá\taqui\tpara\tajudar\ta\trealizar\to\ttrabalho.\tde\tmodo\tgeral,\tse\to\n",
      "exemplo\tde\tcódigo\té\toferecido\tcom\tele,\tvocê\tpode\tusá-lo\tem\tseus\tprogramas\te\n",
      "documentações.\tvocê\tnão\tprecisa\tnos\tcontatar\tpara\tpermissão\ta\tmenos\tque\tvocê\n",
      "esteja\treproduzindo\tuma\tporção\tsignificativa\tdo\tcódigo.\tpor\texemplo,\tescrever\n",
      "um\tprograma\tque\tusa\tvários\tpedações\tdo\tcódigo\tdeste\tlivro\tnão\tprecisa\tde\n",
      "permissão.\tvender\tou\tdistribuir\tum\tcd-rom\tcom\tos\texemplos\tdos\tlivros\tda\n",
      "alta\tbooks\tprecisa\tde\tpermissão.\tresponder\ta\tuma\tpergunta\tcitando\teste\tlivro\n",
      "ou\tum\texemplo\tnão\tprecisa\tde\tpermissão.\tincorporar\tuma\tquantidade\n",
      "significativa\tde\texemplos\tde\tcódigo\tdeste\tlivro\tna\tdocumentação\tdo\tseu\tproduto\n",
      "precisa\tde\tpermissão.agradecimentos\n",
      "primeiramente,\teu\tgostaria\tde\tagradecer\ta\tmike\tloukides\tpor\taceitar\tminha\n",
      "proposta\tpara\teste\tlivro\t(e\tpor\tinsistir\tque\teu\to\tdiminuísse\tpara\tum\ttamanho\n",
      "razoável).\tseria\tmuito\tmais\tfácil\tpara\tele\tter\tdito\t“quem\té\testa\tpessoa\tque\tvive\n",
      "me\tenviando\te-mails\tcom\tamostras\tde\tcapítulos\te\tcomo\tfaço\tpara\tela\tir\n",
      "embora?”\tfico\tagradecido\tpor\tele\tnão\tter\tfeito\tisso.\ttambém\tgostaria\tde\n",
      "agradecer\ta\tminha\teditora,\tmarie\tbeaugureau,\tpor\tme\tguiar\tpelo\tprocesso\tde\n",
      "publicação\te\tter\tum\tlivro\tem\tum\testado\tmuito\tmelhor\tdo\tque\teu\tteria\tse\n",
      "estivesse\tsozinho.\n",
      "eu\tnão\tpoderia\tter\tescrito\teste\tlivro\tse\teu\tnunca\ttivesse\taprendido\tdata\tscience\te,\n",
      "provavelmente,\tnão\tteria\taprendido\tse\tnão\tfosse\tpela\tinfluência\tde\tdave\thsu,\n",
      "igor\ttatarinov,\tjohn\trauser\te\to\trestante\tda\tturma\tfarecast.\t(há\ttanto\ttempo\tque\n",
      "nem\tse\tusava\to\tnome\tdata\tscience!)\ta\tgalera\tlegal\tda\tcoursera\ttambém\tmerece\n",
      "bastante\tcrédito.\n",
      "também\tsou\tmuito\tagradecido\tpelos\tmeus\tleitores\te\trevisores.\tjay\tfundling\n",
      "encontrou\ttoneladas\tde\terros\te\tapontou\tmuitas\texplicações\tque\tnão\testavam\n",
      "claras,\te\to\tlivro\testá\tmuito\tmelhor\t(e\tmuito\tmais\tcorreto)\tgraças\ta\tele.\tdebashis\n",
      "ghosh\té\tum\therói\tpor\tchecar\ttodas\tas\tminhas\testatísticas.\tandrew\tmusselman\n",
      "sugeriu\tdiminuir\tos\taspectos\tdo\ttipo\t“pessoas\tque\tpreferem\tr\tao\tpython\tsão\n",
      "moralmente\tresponsáveis”\tdo\tlivro,\tque\tacabei\tachando\tum\tótimo\tconselho.\n",
      "trey\tcausey,\tryan\tmatthew\tbalfanz,\tloris\tmularoni,\tnúria\tpujol,\trob\n",
      "jefferson,\tmary\tpat\tcampbell,\tzach\tgeary\te\twendy\tgrus\ttambém\tforneceram\n",
      "valiosas\topiniões.\tquaisquer\terros\tremanescentes\tsão\tde\tminha\texclusiva\n",
      "responsabilidade.\n",
      "devo\tmuito\tà\tcomunidade\tdo\ttwitter\t#datascience,\tpor\tme\texpor\ta\ttoneladas\tde\n",
      "novos\tconceitos,\tme\tapresentar\tpara\tmuitas\tpessoas\te\tparar\tde\tme\tsentir\tum\n",
      "fracassado,\ttanto\tque\teu\tme\tsuperei\te\tescrevi\tum\tlivro\tpara\tcompensar.\tum\n",
      "agradecimento\tespecial\tpara\ttrey\tcausey\t(novamente)\tpor\t(inadvertidamente)\n",
      "me\tlembrar\tde\tincluir\tum\tcapítulo\tsobre\tálgebra\tlinear,\te\tpara\tscan\tj.\ttaylor\tpor\n",
      "(inadvertidamente)\tapontar\talgumas\tlacunas\tno\tcapítulo\t“trabalhando\tcom\n",
      "dados”.acima\tde\ttudo,\teu\tdevo\tum\timenso\tagradecimento\tpara\tganga\te\tmadeline.\ta\n",
      "única\tcoisa\tmais\tdifícil\tdo\tque\tescrever\tum\tlivro\té\tmorar\tcom\talguém\tque\testeja\n",
      "escrevendo\tum.\teu\tnão\tteria\tconseguido\tsem\to\tapoio\tdeles.capítulo\t1\n",
      "introdução\n",
      "“\n",
      "dados!\tdados!\tdados!”\tele\tgritou\timpacientemente.\t“não\tposso\tfabricar\ttijolos\tsem\tbarro.”\n",
      "—arthur\tconan\tdoylea\tascensão\tdos\tdados\n",
      "vivemos\tem\tum\tmundo\tque\testá\tsoterrado\tpor\tdados.\tos\twebsites\trastreiam\n",
      "todos\tos\tcliques\tde\ttodos\tos\tusuários.\tseu\tsmartphone\testá\tfazendo\tum\tregistro\n",
      "da\tsua\tlocalização\te\tsua\tvelocidade\ta\tcada\tsegundo\tdiariamente.\tatletas\n",
      "avaliados\tusam\tpedômetros\tcom\testeroides\tque\testão\tsempre\tregistrando\tsuas\n",
      "batidas\tdo\tcoração,\thábitos\tde\tmovimentos,\tdieta\te\tpadrões\tdo\tsono.\tcarros\n",
      "inteligentes\tcoletam\thábitos\tde\tdireção,\tcasas\tinteligentes\tcoletam\thábitos\tde\n",
      "moradia\te\tmarqueteiros\tinteligentes\tcoletam\thábitos\tde\tcompra.\ta\tprópria\n",
      "internet\trepresenta\tum\tdiagrama\tgrande\tde\tconhecimento\tque\tcontém\t(entre\n",
      "outras\tcoisas)\tuma\tenorme\tenciclopédia\tde\treferências\tcruzadas:\tbases\tde\tdados\n",
      "específicos\tde\tdomínio\tsobre\tfilmes,\tmúsica,\tresultados\tde\tesportes,\tmáquinas\n",
      "de\tpinball,\tmemes\te\tcoquetéis;\te\tmuitas\testatísticas\tdo\tgoverno\t(algumas\tdelas\n",
      "são\tverdades!)\tsobre\ttantos\tgovernos\tque\tcausariam\tum\tnó\tna\tsua\tcabeça.\n",
      "soterrados\tsob\tesses\tdados\testão\tas\trespostas\tpara\tas\tinúmeras\tquestões\tque\n",
      "ninguém\tnunca\tpensou\tem\tperguntar.\tneste\tlivro,\taprenderemos\tcomo\tencontrá-\n",
      "las.o\tque\té\tdata\tscience?\n",
      "há\tuma\tpiada\tque\tdiz\tque\tum\tcientista\tde\tdados\té\talguém\tque\tsabe\tmais\tsobre\n",
      "estatística\tdo\tque\tum\tcientista\tda\tcomputação\te\tmais\tsobre\tciência\tda\n",
      "computação\tdo\tque\tum\testatístico\t(eu\tnão\tdisse\tque\ta\tpiada\tera\tboa).\tna\n",
      "verdade,\talguns\tcientistas\tde\tdados\tsão\t—\tpara\ttodos\tos\tpropósitos\tpráticos\t—\n",
      "estatísticos,\tenquanto\toutros\tsão\tquase\tindistinguíveis\tdos\tengenheiros\tde\n",
      "software.\talguns\tsão\texperts\tem\taprendizado\tde\tmáquina,\tenquanto\toutros\tnão\n",
      "conseguiram\taprender\tmuita\tcoisa\tsobre\to\tassunto.\talguns\tsão\tphds\tcom\tum\n",
      "impressionante\tregistro\tde\tpublicações,\tenquanto\toutros\tnunca\tleram\tum\n",
      "trabalho\tacadêmico\t(apesar\t\n",
      "de\tser\tuma\tvergonha).\tresumindo,\tbasicamente\tnão\n",
      "importa\tcomo\tvocê\tdefine\tdata\tscience,\tpois\tvocê\tencontrará\tpraticantes\tpara\n",
      "quem\ta\tdefinição\testá\ttotal\te\tabsolutamente\terrada.\n",
      "de\tqualquer\tforma,\tnão\tpermitiremos\tque\tisso\tnos\timpeça\tde\ttentar.\tdigamos\n",
      "que\tum\tcientista\tde\tdados\tseja\talguém\tque\textrai\tconhecimento\tde\tdados\n",
      "desorganizados.\to\tmundo\tde\thoje\testá\tcheio\tde\tpessoas\ttentando\ttransformar\n",
      "dados\tem\tconhecimento.\n",
      "por\texemplo,\to\tsite\tde\tnamoro\tokcupid\tpede\tque\tseus\tmembros\trespondam\n",
      "milhares\tde\tperguntas\ta\tfim\tde\tencontrar\tas\tcombinações\tmais\tadequadas\tpara\n",
      "eles.\tmas\ttambém\tanalisa\ttais\tresultados\tpara\tdescobrir\tperguntas\taparentemente\n",
      "inócuas\tas\tquais\tvocê\tpoderia\tperguntar\tpara\talguém\te\tdescobrir\tqual\ta\n",
      "possibilidade\tde\tessa\tpessoa\tdormir\tcom\tvocê\tno\tprimeiro\tencontro\n",
      "(\n",
      "http://bit.ly/1equ0hi\n",
      ").\n",
      "o\tfacebook\tpede\tque\tvocê\tadicione\tsua\tcidade\tnatal\te\tsua\tlocalização\tatual,\n",
      "supostamente\tpara\tfacilitar\tque\tseus\tamigos\to\tencontrem\te\tse\tconectem\tcom\n",
      "você.\tporém,\tele\ttambém\tanalisa\tessas\tlocalizações\tpara\tidentificar\tpadrões\tde\n",
      "migração\tglobal\t(\n",
      "http://on.fb.me/1eqtq3a\n",
      ")\te\tonde\tvivem\tos\tfã-clubes\tdos\ttimes\n",
      "de\tfutebol\t(\n",
      "http://on.fb.me/1eqtvno\n",
      ").\n",
      "como\tuma\tgrande\tempresa,\ta\ttarget\trastreia\tsuas\tencomendas\te\tinterações,\n",
      "tanto\tonline\tcomo\tna\tloja\tfísica.\tela\tusa\tos\tdados\tem\tum\tmodelo\tpreditivo\n",
      "(\n",
      "http://nyti.ms/1eqtznl\n",
      ")\tpara\tsaber\tquais\tclientes\testão\tgrávidas\ta\tfim\tde\n",
      "melhorar\tsua\toferta\tde\tartigos\trelacionados\ta\tbebês.em\t2012,\ta\tcampanha\tdo\tobama\tempregou\tmuitos\tcientistas\tde\tdados\tque\n",
      "mineraram\tos\tdados\te\texperimentaram\tuma\tforma\tde\tidentificar\tos\teleitores\tque\n",
      "precisavam\tde\tuma\tatenção\textra,\totimizar\tprogramas\te\trecursos\tpara\ta\tcaptação\n",
      "de\tfundos\tde\tdoadores\tespecíficos\te\tfocando\tesforços\tpara\tvotos\tonde\n",
      "provavelmente\teles\tteriam\tsido\túteis.\tnormalmente,\té\tde\tcomum\tacordo\tpensar\n",
      "que\tesses\tesforços\ttiveram\tum\tpapel\timportante\tna\treeleição\tdo\tpresidente,\to\n",
      "que\tsignifica\tque\té\tseguro\tapostar\tque\tas\tcampanhas\tpolíticas\tdo\tfuturo\tse\n",
      "tornarão\tcada\tvez\tmais\tdependentes\tde\tdados,\tresultando\tem\tuma\tcorrida\n",
      "armamentista\tsem\tfim\tde\tdata\tscience\te\tcoleta\tde\tdados.\n",
      "agora,\tantes\tque\tvocê\tse\tsinta\tmuito\texausto:\talguns\tcientistas\tde\tdados\ttambém\n",
      "usam\tsuas\thabilidades\tpara\to\tbem,\tocasionalmente\t—\tusar\tos\tdados\tpara\ttornar\n",
      "o\tgoverno\tmais\teficiente\t(\n",
      "http://bit.ly/1eqtgiw\n",
      "),\tajudar\tos\tdesabrigados\n",
      "(\n",
      "http://bit.ly/1eqtiyl\n",
      "),\te\tmelhorar\ta\tsaúde\tpública\t(\n",
      "http://bit.ly/1eqtptv\n",
      ").\tmas,\n",
      "certamente,\tnão\tafetará\tsua\tcarreira\tse\tvocê\tgosta\tde\tencontrar\ta\tmelhor\tmaneira\n",
      "de\tfazer\to\tpúblico\tclicar\tem\tseus\tanúncios.motivação\thipotética:\tdatasciencester\n",
      "parabéns!\tvocê\tacabou\tde\tser\tcontratado\tpara\tliderar\tos\tesforços\tde\tdata\tscience\n",
      "na\tdatasciencester,\t\n",
      "a\n",
      "\trede\tsocial\tpara\tcientistas\tde\tdados.\n",
      "apesar\tde\tser\t\n",
      "para\n",
      "\tos\tcientistas\tde\tdados,\ta\tdatasciencester\tnunca\tinvestiu\tem\n",
      "construir\tsua\tprópria\tatividade\tde\tdata\tscience\t(na\tverdade,\ta\tdatasciencester\n",
      "nunca\tinvestiu\tem\tconstruir\tseu\tpróprio\tproduto).\tesse\tserá\tseu\ttrabalho!\tno\n",
      "decorrer\tdo\tlivro,\taprenderemos\tsobre\tos\tconceitos\tde\tdata\tscience\tao\tresolver\n",
      "problemas\tcom\tos\tquais\tvocê\tse\tdepara\tno\ttrabalho.\talgumas\tvezes,\tolharemos\n",
      "para\tos\tdados\texplicitamente\tfornecidos\tpelo\tusuário,\toutras\t\n",
      "vezes\tolharemos\n",
      "para\tos\tgerados\tpor\tsuas\tinterações\tcom\tum\tsite\te,\tàs\tvezes,\tolharemos\tpara\tos\n",
      "dados\tdos\texperimentos\tque\tprojetaremos.\n",
      "e,\tdevido\tà\tdatasciencester\tpossuir\tuma\tforte\tmentalidade\tde\t“não-foi-\n",
      "inventado-aqui”,\tnós\tconstruiremos\tnossas\tpróprias\tferramentas\tdo\tzero.\tno\n",
      "final,\tvocê\tterá\tum\tsólido\tentendimento\tdos\tfundamentos\tde\tdata\tscience.\tvocê\n",
      "estará\tpronto\tpara\taplicar\tsuas\thabilidades\tem\tsua\tempresa\tcom\tuma\tpremissa\n",
      "menos\tduvidosa,\tou\tem\tqualquer\toutro\tproblema\tque\tvier\ta\tdespertar\tseu\n",
      "interesse.\n",
      "bem-vindo\ta\tbordo\te\tboa\tsorte!\t‘você\tpode\tusar\tjeans\tàs\tsextas\te\to\ttoalete\té\tno\n",
      "final\tdo\tcorredor\tà\tdireita.’\n",
      "encontrando\tconectores-chave\n",
      "é\tseu\tprimeiro\tdia\tde\ttrabalho\tna\tdatasciencester\te\to\tvice-presidente\tde\trede\n",
      "(networking)\testá\tcheio\tde\tperguntas\tsobre\tseus\tusuários.\taté\tagora,\tele\tnão\tteve\n",
      "ninguém\tpara\tperguntar,\tentão\tele\testá\tmuito\tempolgado\tem\tter\tvocê\taqui.\n",
      "particularmente,\tele\tquer\tque\tvocê\tidentifique\tquem\tsão\tos\t“conectores-chave”\n",
      "entre\tos\tcientistas\tde\tdados.\tpara\tisso,\tele\tlhe\tdá\tuma\tparte\tde\ttoda\ta\trede\tda\n",
      "datasciencester.\tna\tvida\treal,\tvocê\tgeralmente\tnão\trecebe\tos\tdados\tde\tque\n",
      "precisa.\to\t\n",
      "capítulo\t9\n",
      "\té\tvoltado\tpara\ta\tobtenção\tde\tdados.\n",
      "com\to\tque\tse\tparece\tessa\tparte\tdos\tdados?\tela\tconsiste\tem\tuma\tlista\tde\n",
      "usuários,\tcada\tum\trepresentado\tpor\tum\t\n",
      "dict\n",
      "\tque\tcontém\tum\t\n",
      "id\n",
      "\t(um\tnúmero)\tparacada\tusuário\tou\tusuária\te\tum\t\n",
      "name\n",
      "\t(que\tpor\tuma\tdas\tgrandes\tcoincidências\n",
      "cósmicas\tque\trima\tcom\to\t\n",
      "id\n",
      "\tdo\tusuário):\n",
      "users\t=\t[\n",
      "{\t\"id\":\t0,\t\"name\":\t\"hero\"\t},\n",
      "{\t\"id\":\t1,\t\"name\":\t\"dunn\"\t},\n",
      "{\t\"id\":\t2,\t\"name\":\t\"sue\"\t},\n",
      "{\t\"id\":\t3,\t\"name\":\t\"chi\"\t},\n",
      "{\t\"id\":\t4,\t\"name\":\t\"thor\"\t},\n",
      "{\t\"id\":\t5,\t\"name\":\t\"clive\"\t},\n",
      "{\t\"id\":\t6,\t\"name\":\t\"hicks\"\t},\n",
      "{\t\"id\":\t7,\t\"name\":\t\"devin\"\t},\n",
      "{\t\"id\":\t8,\t\"name\":\t\"kate\"\t},\n",
      "{\t\"id\":\t9,\t\"name\":\t\"klein\"\t}\n",
      "]\n",
      "ele\ttambém\tfornece\tdados\t“amigáveis”,\trepresentados\tpor\tuma\tlista\tde\tpares\tde\n",
      "ids:\n",
      "friendships\t=\t[(0,\t1),\t(0,\t2),\t(1,\t2),\t(1,\t3),\t(2,\t3),\t(3,\t4),\n",
      "\t\t\t\t(4,\t5),\t(5,\t6),\t(5,\t7),\t(6,\t8),\t(7,\t8),\t(8,\t9)]\n",
      "por\texemplo,\ta\ttupla\t\n",
      "(0,1)\n",
      "\tindica\tque\to\tcientista\tde\tdados\tcom\ta\t\n",
      "id\n",
      "\t0\t(hero)\te\to\n",
      "cientista\tde\tdados\tcom\ta\t\n",
      "id\n",
      "\t1\t(dunn)\tsão\tamigos.\ta\trede\té\tilustrada\tna\t\n",
      "figura\t1-\n",
      "1\n",
      ".\n",
      "figura\t1-1.\ta\trede\tda\tdatasciencester\n",
      "já\tque\trepresentamos\tnossos\tusuários\tcomo\t\n",
      "dict\n",
      "s,\té\tfácil\tde\taumentá-los\tcom\n",
      "dados\textras.\n",
      "não\tfique\tpreso\taos\tdetalhes\tdo\tcódigo\tagora.\tno\t\n",
      "capítulo\t2\n",
      ",\tvamos\tlevá-lo\ta\tum\n",
      "curso\tintensivo\tde\tpython.\tpor\tenquanto,\ttente\tpegar\to\tsentido\tgeral\tdo\tque\testamosfazendo.\n",
      "por\texemplo,\ttalvez\tnós\tqueiramos\tadicionar\tuma\tlista\tde\tamigos\tpara\tcada\n",
      "usuário.\tprimeiro\tnós\tconfiguramos\ta\tpropriedade\t\n",
      "friends\n",
      "\tde\tcada\tusuário\tem\tuma\n",
      "lista\tvazia:\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "user[\"friends\"]\t=\t[]\n",
      "então,\tnós\tpovoamos\ta\tlista\tcom\tos\tdados\tde\t\n",
      "friendships\n",
      ":\n",
      "for\n",
      "\ti,\tj\t\n",
      "in\n",
      "\tfriendships:\n",
      "#\tisso\tfunciona\tporque\tusers[i]\té\to\tusuário\tcuja\tid\té\ti\n",
      "users[i][\"friends\"].append(users[j])\t\n",
      "#\tadiciona\ti\tcomo\tum\tamigo\tde\tj\n",
      "users[j][\"friends\"].append(users[i])\t\n",
      "#\tadiciona\tj\tcomo\tum\tamigo\tde\ti\n",
      "uma\tvez\tque\to\t\n",
      "dict\n",
      "\tde\tcada\tusuário\tcontenha\tuma\tlista\tde\tamigos,\tpodemos\n",
      "facilmente\tperguntar\tsobre\tnosso\tgráfico,\tcomo\t“qual\té\to\tnúmero\tmédio\tde\n",
      "conexões?”\n",
      "primeiro,\tencontramos\tum\tnúmero\t\n",
      "total\n",
      "\tde\tconexões,\tresumindo\tos\ttamanhos\tde\n",
      "todas\tas\tlistas\tde\t\n",
      "friends\n",
      ":\n",
      "def\tnumber_of_friends(user):\n",
      "\"\"\"quantos\tamigos\to\tusuário\ttem?\"\"\"\n",
      "return\tlen(user[\"friends\"])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttamanho\tda\tlista\tfriend_ids\n",
      "total_connections\t=\tsum(number_of_friends(user)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor\tuser\tin\tusers)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t24\n",
      "então,\tapenas\tdividimos\tpelo\tnúmero\tde\tusuários:\n",
      "from\t__future__import\n",
      "\tdivision\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdivisão\tinteira\testá\tincompleta\n",
      "num_users\t=\tlen(users)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttamanho\tda\tlista\tde\tusuários\n",
      "avg_connections\t=\ttotal_connections\t/\tnum_users\t\t\t\t\t\n",
      "#\t2.4\n",
      "também\té\tfácil\tde\tencontrar\tas\tpessoas\tmais\tconectadas\t—\tsão\tas\tque\tpossuem\n",
      "o\tmaior\tnúmero\tde\tamigos.\n",
      "como\tnão\thá\tmuitos\tusuários,\tpodemos\tordená-los\tde\t“muito\tamigos”\tpara\n",
      "“menos\tamigos”:\n",
      "#\tcria\tuma\tlista\t(user_id,\tnumber_of_friends)\n",
      "num_friends_by_id\t=\t[(user[\"id\"],\tnumber_of_friends(user))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers]\n",
      "sorted(num_friends_by_id,\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tordenado\n",
      "key=\n",
      "lambda\n",
      "\t(user_id,\tnum_friends):\tnum_friends,\t\t\t\t\t\n",
      "#\tpor\tnum_friends\n",
      "reverse=true)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdo\tmaior\tpara\to\tmenor\n",
      "#\tcada\tpar\té\t(user_id,\tnum_friends)\n",
      "#\t[(1,\t3),\t(2,\t3),\t(3,\t3),\t(5,\t3),\t(8,\t3)\n",
      ",\n",
      "#\t\t(0,\t2),\t(4,\t2),\t(6,\t2),\t(7,\t2),\t(9,\t1)]\n",
      "uma\tmaneira\tde\tpensar\tsobre\to\tque\tnós\tfizemos\té\tuma\tmaneira\tde\tidentificar\tas\n",
      "pessoas\tque\tsão,\tde\talguma\tforma,\tcentrais\tpara\ta\trede.\tna\tverdade,\to\tque\n",
      "acabamos\tde\tcomputar\té\tuma\trede\tmétrica\tde\t\n",
      "grau\tde\tcentralidade\n",
      "\t(\n",
      "figura\t1-2\n",
      ").\n",
      "figura\t1-2.\ta\trede\tdatasciencester\tordenada\tpelo\tgrau\n",
      "essa\tfigura\ttem\ta\tvantagem\tde\tser\tfácil\tde\tcalcular,\tmas\tnem\tsempre\tlhe\tdá\tos\n",
      "resultados\tque\tvocê\tqueria\tou\tesperaria.\tpor\texemplo,\ta\trede\tthor\tda\n",
      "datasciencester\t(\n",
      "id\n",
      "\t4)\tpossui\tsomente\tduas\tconexões\tenquanto\tque\tdunn\t(\n",
      "id\n",
      "\t1)\n",
      "possui\ttrês.\tainda\tolhando\tpara\ta\trede,\tparece\tque\tthor\tdeveria\tser\tmais\n",
      "centralizado.\tno\t\n",
      "capítulo\t21\n",
      ",\tinvestigaremos\tas\tredes\tcom\tmais\tdetalhe,\te\n",
      "veremos\tnoções\tde\tcentralidade\tmais\tcomplexas\tque\tpodem\tou\tnão\tcorresponder\n",
      "melhor\tà\tnossa\tintuição.\n",
      "cientistas\tde\tdados\tque\tvocê\ttalvez\tconheça\n",
      "enquanto\tvocê\testá\tpreenchendo\tos\tpapéis\tde\tadmissão,\ta\tvice-presidente\tda\n",
      "fraternidade\tchega\ta\tsua\tmesa.\tela\tquer\testimular\tmais\tconexões\tentre\tos\tseus\n",
      "membros,\te\tpede\tque\tvocê\tdesenvolva\tsugestões\tde\t“cientistas\tde\tdados\tque\n",
      "você\ttalvez\tconheça”.seu\tprimeiro\tinstinto\té\tsugerir\tum\tusuário\tque\tpossa\tconhecer\tamigos\tde\n",
      "amigos.\tsão\tfáceis\tde\tcomputar:\tpara\tcada\tamigo\tde\tum\tusuário,\titera\tsobre\tos\n",
      "amigos\tdaquela\tpessoa,\te\tcoleta\ttodos\tos\tresultados:\n",
      "def\n",
      "\tfriends_of_friend_ids_bad(user):\n",
      "#\t“foaf”\té\tabreviação\tde\t“friend\tof\ta\tfriend”\n",
      "return\n",
      "\t[foaf[\"id\"]\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tuser[\"friends\"]\t\t\t\t\t\t\n",
      "#\tpara\tcada\tamigo\tde\tusuário\n",
      "for\n",
      "\tfoaf\t\n",
      "in\n",
      "\tfriend[\"friends\"]]\t\t\t\t\t\n",
      "#\tpega\tcada\t_their_friends\n",
      "quando\tchamamos\t\n",
      "users[0]\n",
      "\t(hero),\tele\tproduz:\n",
      "[0,\t2,\t3,\t0,\t1,\t3]\n",
      "isso\tinclui\to\tusuário\t0\t(duas\tvezes),\tuma\tvez\tque\thero\té,\tde\tfato,\tamigo\tde\n",
      "ambos\tos\tseus\tamigos.\tinclui\tos\tusuários\t1\te\t2,\tapesar\tde\teles\tjá\tserem\tamigos\n",
      "do\thero.\te\tinclui\to\tusuário\t3\tduas\tvezes,\tjá\tque\tchi\té\talcançável\tpor\tmeio\tde\n",
      "dois\tamigos\tdiferentes:\n",
      "print\n",
      "\t[friend[\"id\"]\t\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tusers[0][\"friends\"]]\t\t\t\n",
      "#\t[1,\t2]\n",
      "print\n",
      "\t[friend[\"id\"]\t\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tusers[1][\"friends\"]]\t\t\t\n",
      "#\t[0,\t2,\t3]\n",
      "print\n",
      "\t[friend[\"id\"]\t\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tusers[2][\"friends\"]]\t\t\t\n",
      "#\t[0,\t1,\t3]\n",
      "saber\tque\tas\tpessoas\tsão\tamigas-de-amigas\tde\tdiversas\tmaneiras\tparece\tuma\n",
      "informação\tinteressante,\tentão\ttalvez\tnós\tdevêssemos\tproduzir\tuma\t\n",
      "contagem\n",
      "\tde\n",
      "amigos\tem\tcomum.\tdefinitivamente,\tdevemos\tusar\tuma\tfunção\tde\tajuda\tpara\n",
      "excluir\tas\tpessoas\tque\tjá\tsão\tconhecidas\tdo\tusuário:\n",
      "from\tcollections\timport\tcounter\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnão\tcarregado\tpor\tpadrão\n",
      "def\tnot_the_same(user,\tother_user):\n",
      "\"\"\"dois\tusuários\tnão\tsão\tos\tmesmos\tse\tpossuem\tids\tdiferentes\"\"\"\n",
      "return\tuser[\"id\"]\t!=\tother_user[\"id\"]\n",
      "def\tnot_friends(user,\tother_user):\n",
      "\"\"\"other_user\tnão\té\tum\tamigo\tse\tnão\testá\tem\tuser[“friends”];\n",
      "isso\té,\tse\té\tnot_the_same\tcom\ttodas\tas\tpessoas\tem\tuser[“friends”]\"\"\"\n",
      "return\tall(not_the_same(friend,\tother_user)\n",
      "\tfor\tfriend\tin\tuser[\"friends\"])\n",
      "def\tfriends_of_friend_ids(user):\n",
      "return\tcounter(foaf[\"id\"]\n",
      "\t\t\tfor\tfriend\tin\tuser[\"friends\"]\t\t\t\t\t\t\t\t\n",
      "#\tpara\tcada\tum\tdos\tmeus\tamigos\n",
      "\tfor\tfoaf\tin\tfriend[\"friends\"]\t\t\t\t\t\t\t\t\t\t\n",
      "#\tque\tcontam\t*their*\tamigos\n",
      "\t\t\tif\tnot_the_same(user,\tfoaf)\t\t\t\t\t\t\t\t\t\t\n",
      "#\tque\tnão\tsejam\teu\n",
      "\t\t\tand\tnot_friends(user,\tfoaf))\t\t\t\t\t\t\t\t\t\n",
      "#\te\tque\tnão\tsão\tmeus\tamigos\n",
      "print\tfriends_of_friend_ids(users[3])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcounter({0:\t2,\t5:\t1})isso\tdiz\tsobre\tchi\t(\n",
      "id\n",
      "\t3)\tque\tela\tpossui\tdois\tamigos\tem\tcomum\tcom\thero\t(\n",
      "id\n",
      "\t0)\n",
      "mas\tsomente\tum\tamigo\tem\tcomum\tcom\tclive\t(\n",
      "id\n",
      "\t5).\n",
      "como\tum\tcientista\tde\tdados,\tvocê\tsabe\tque\tvocê\tpode\tgostar\tde\tencontrar\n",
      "usuários\tcom\tinteresses\tsimilares\t(esse\té\tum\tbom\texemplo\tdo\taspecto\n",
      "“competência\tsignificativa”\tde\tdata\tscience).\tdepois\tde\tperguntar\tpor\taí,\tvocê\n",
      "consegue\tpôr\tas\tmãos\tnesse\tdado,\tcomo\tuma\tlista\tde\tpares\t\n",
      "(user_id,\tinterest)\n",
      ":\n",
      "interests\t=\t[\n",
      "(0,\t\"hadoop\"),\t(0,\t\"big\tdata\"),\t(0,\t\"hbase\"),\t(0,\t\"java\"),\n",
      "(0,\t\"spark\"),\t(0,\t\"storm\"),\t(0,\t\"cassandra\"),\n",
      "(1,\t\"nosql\"),\t(1,\t\"mongodb\"),\t(1,\t\"cassandra\"),\t(1,\t\"hbase\"),\n",
      "(1,\t\"postgres\"),\t(2,\t\"python\"),\t(2,\t\"scikit-learn\"),\t(2,\t\"scipy\"),\n",
      "(2,\t\"numpy\"),\t(2,\t\"statsmodels\"),\t(2,\t\"pandas\"),\t(3,\t\"r\"),\t(3,\t\"python\"),\n",
      "(3,\t\"statistics\"),\t(3,\t\"regression\"),\t(3,\t\"probability\"),\n",
      "(4,\t\"machine\tlearning\"),\t(4,\t\"regression\"),\t(4,\t\"decision\ttrees\"),\n",
      "(4,\t\"libsvm\"),\t(5,\t\"python\"),\t(5,\t\"r\"),\t(5,\t\"java\"),\t(5,\t\"c++\"),\n",
      "(5,\t\"haskell\"),\t(5,\t\"programming\tlanguages\"),\t(6,\t\"statistics\"),\n",
      "(6,\t\"probability\"),\t(6,\t\"mathematics\"),\t(6,\t\"theory\"),\n",
      "(7,\t\"machine\tlearning\"),\t(7,\t\"scikit-learn\"),\t(7,\t\"mahout\"),\n",
      "(7,\t\"neural\tnetworks\"),\t(8,\t\"neural\tnetworks\"),\t(8,\t\"deep\tlearning\"),\n",
      "(8,\t\"big\tdata\"),\t(8,\t\"artificial\tintelligence\"),\t(9,\t\"hadoop\"),\n",
      "(9,\t\"java\"),\t(9,\t\"mapreduce\"),\t(9,\t\"big\tdata\")\n",
      "]\n",
      "por\texemplo,\tthor\t(\n",
      "id\n",
      "\t4)\tnão\tpossui\tamigos\tem\tcomum\tcom\tdevin\t(\n",
      "id\n",
      "\t7),\tmas\n",
      "compartilham\tdo\tinteresse\tem\taprendizado\tde\tmáquina.\n",
      "é\tfácil\tconstruir\tuma\tfunção\tque\tencontre\tusuários\tcom\to\tmesmo\tinteresse:\n",
      "def\n",
      "\tdata_scientists_who_like(target_interest):\n",
      "return\n",
      "\t[user_id\n",
      "for\n",
      "\tuser_id,\tuser_interest\t\n",
      "in\n",
      "\tinterests\n",
      "if\n",
      "\tuser_interest\t==\ttarget_interest]\n",
      "funciona,\tmas\ta\tlista\tinteira\tde\tinteresses\tdeve\tser\texaminada\tpara\tcada\tbusca.\n",
      "se\ttivermos\tmuitos\tusuários\te\tinteresses\t(ou\tse\tquisermos\tfazer\tmuitas\tbuscas),\n",
      "seria\tmelhor\tconstruir\tum\tíndice\tde\tinteresses\tpara\tusuários:\n",
      "from\tcollections\timport\tdefaultdict\n",
      "#\tas\tchaves\tsão\tinteresses,\tos\tvalores\tsão\tlistas\tde\tuser_ids\tcom\tinterests\n",
      "user_ids_by_interest\t=\tdefaultdict(list)\n",
      "for\tuser_id,\tinterest\tin\tinterests:\n",
      "user_ids_by_interest[interest].append(user_id)•\n",
      "•\n",
      "•\n",
      "e\toutro\tde\tusuários\tpara\tinteresses:\n",
      "#\tas\tchaves\tsão\tuser_ids,\tos\tvalores\tsão\tas\tlistas\tde\tinterests\tpara\taquele\tuser_id\n",
      "interests_by_user_id\t=\tdefaultdict(list)\n",
      "for\n",
      "\tuser_id,\tinterest\t\n",
      "in\n",
      "\tinterests:\n",
      "interests_by_user_id[user_id].append(interest)\n",
      "agora\tfica\tfácil\tdescobrir\tquem\tpossui\tos\tmaiores\tinteresses\tem\tcomum\tcom\tum\n",
      "certo\tusuário:\n",
      "itera\tsobre\tos\tinteresses\tdo\tusuário.\n",
      "para\tcada\tinteresse,\titera\tsobre\tos\toutros\tusuários\tcom\taquele\tinteresse.\n",
      "mantém\ta\tcontagem\tde\tquantas\tvezes\tvemos\tcada\toutro\tusuário.\n",
      "def\n",
      "\tmost_common_interests_with(user):\n",
      "return\n",
      "\tcounter(interested_user_id\n",
      "for\n",
      "\tinterest\t\n",
      "in\n",
      "\tinterests_by_user_id[user[\"id\"]]\n",
      "for\n",
      "\tinterested_user_id\t\n",
      "in\n",
      "\tuser_ids_by_interest[interest]\n",
      "if\n",
      "\tinterested_user_id\t!=\tuser[\"id\"])\n",
      "poderíamos\tusar\tesse\texemplo\tpara\tconstruir\tum\trecurso\tmais\trico\tde\n",
      "“cientistas\tde\tdados\tque\tvocê\tdeveria\tconhecer”\tbaseado\tem\tuma\tcombinação\n",
      "de\tamigos\te\tinteresses\tem\tcomum.\texploraremos\tesses\ttipos\tde\taplicações\tno\n",
      "capítulo\t22\n",
      ".\n",
      "salários\te\texperiência\n",
      "na\thora\tem\tque\tvocê\testá\tsaindo\tpara\to\talmoço,\to\tvice-presidente\tde\trelações\n",
      "públicas\tpergunta\tse\tvocê\tpode\tfornecer\talguns\tfatos\tcuriosos\tsobre\tquanto\tos\n",
      "cientistas\tde\tdados\trecebem.\tdados\tde\tsalário\té,\tde\tfato,\tum\ttópico\tsensível,\tmas\n",
      "ele\tconsegue\tfornecer\tum\tconjunto\tde\tdados\tanônimos\tcontendo\to\t\n",
      "salary\n",
      "\t(salário)\n",
      "de\tcada\tusuário\t(em\tdólares)\te\t\n",
      "tenure\n",
      "\t(experiência)\tcomo\tum\tcientista\tde\tdados\n",
      "(em\tanos):\n",
      "salaries_and_tenures\t=\t[(83000,\t8.7),\t(88000,\t8.1),\n",
      "\t\t\t\t\t\t\t\t(48000,\t0.7),\t(76000,\t6),\n",
      "\t\t\t\t\t\t\t\t(69000,\t6.5),\t(76000,\t7.5),\n",
      "\t\t\t\t\t\t\t\t(60000,\t2.5),\t(83000,\t10),\n",
      "\t\t\t\t\t\t\t\t(48000,\t1.9),\t(63000,\t4.2)]\n",
      "naturalmente,\to\tprimeiro\tpasso\té\ttraçar\tos\tdados\t(veremos\tcomo\tfazê-lo\tno\n",
      "capítulo\t3\n",
      ").\tos\tresultados\tse\tencontram\tna\t\n",
      "figura\t1-3\n",
      ".figura\t1-3.\tsalário\tpor\tanos\tde\texperiência\n",
      "fica\tbem\tclaro\tque\tos\tque\tpossuem\tmais\texperiência\ttendem\ta\treceber\tmais.\n",
      "como\tvocê\tpode\ttransformar\tisso\tem\tum\tfato\tcurioso?\ta\tprimeira\tideia\té\n",
      "analisar\ta\tmédia\tsalarial\tpara\tcada\tano:\n",
      "#\tas\tchaves\tsão\tos\tanos,\tos\tvalores\tsão\tas\tlistas\tdos\tsalários\tpara\tcada\tano\n",
      "salary_by_tenure\t=\tdefaultdict(list)\n",
      "for\n",
      "\tsalary,\ttenure\t\n",
      "in\n",
      "\tsalaries_and_tenures:\n",
      "salary_by_tenure[tenure].append(salary)\n",
      "#\tas\tchaves\tsão\tos\tanos,\tcada\tvalor\té\ta\tmédia\tsalarial\tpara\taquele\tano\n",
      "average_salary_by_tenure\t=\t{\n",
      "tenure\t:\tsum(salaries)\t/\tlen(salaries)\n",
      "for\n",
      "\ttenure,\tsalaries\t\n",
      "in\n",
      "\tsalary_by_tenure.items()\n",
      "}\n",
      "não\té\tmuito\tútil,\tjá\tque\tnenhum\tdos\tusuários\tpossui\to\tmesmo\tcaso,\to\tque\n",
      "significa\tque\testamos\treportando\tapenas\tos\tsalários\tindividuais\tdos\tusuários:{0.7:\t48000.0,\n",
      "\t1.9:\t48000.0,\n",
      "\t2.5:\t60000.0,\n",
      "\t4.2:\t63000.0,\n",
      "\t6:\t76000.0,\n",
      "\t6.5:\t69000.0,\n",
      "\t7.5:\t76000.0,\n",
      "\t8.1:\t88000.0,\n",
      "\t8.7:\t83000.0,\n",
      "\t10:\t83000.0}\n",
      "talvez\tfosse\tmais\tproveitoso\tagrupar\tos\tcasos:\n",
      "def\n",
      "\ttenure_bucket(tenure):\n",
      "if\n",
      "\ttenure\t<\t2:\n",
      "return\n",
      "\t\"less\tthan\ttwo\"\n",
      "elif\n",
      "\ttenure\t<\t5:\n",
      "return\n",
      "\t\"between\ttwo\tand\tfive\"\n",
      "else\n",
      ":\n",
      "return\n",
      "\t\"more\tthan\tfive\"\n",
      "então,\to\tgrupo\tjunta\tos\tsalários\tcorrespondentes\tpara\tcada\tagrupamento:\n",
      "#\tas\tchaves\tsão\tagrupamentos\tdos\tcasos,\tos\tvalores\tsão\tas\tlistas\n",
      "#\tdos\tsalários\tpara\taquele\tagrupamento\n",
      "salary_by_tenure_bucket\t=\tdefaultdict(list)\n",
      "for\tsalary,\ttenure\tin\tsalaries_and_tenures:\n",
      "bucket\t=\ttenure_bucket(tenure)\n",
      "salary_by_tenure_bucket[bucket].append(salary)\n",
      "e,\tfinalmente,\tcomputar\ta\tmédia\tsalarial\tpara\tcada\tgrupo:\n",
      "#\tas\tchaves\tsão\tagrupamentos\tdos\tcasos,\tos\tvalores\tsão\n",
      "#\ta\tmédia\tsalarial\tpara\taquele\tagrupamento\n",
      "average_salary_by_bucket\t=\t{\n",
      "tenure_bucket\t:\tsum(salaries)\t/\tlen(salaries)\n",
      "for\ttenure_bucket,\tsalaries\tin\tsalary_by_tenure_bucket.iteritems()\n",
      "}\n",
      "que\té\tmais\tinteressante:\n",
      "{'between\ttwo\tand\tfive':\t61500.0,\n",
      "\t'less\tthan\ttwo':\t48000.0,\n",
      "\t'more\tthan\tfive':\t79166.66666666667}\n",
      "e\tvocê\ttem\tum\tclichê:\t“os\tcientistas\tde\tdados\tcom\tmais\tde\tcinco\tanos\tde\n",
      "experiência\trecebem\t65%\ta\tmais\tdo\tque\tos\tque\tpossuem\tpouca\tou\tnenhuma\n",
      "experiência!”no\tentanto,\tnós\tescolhemos\tos\tcasos\tde\tforma\taleatória.\to\tque\trealmente\n",
      "queríamos\tfazer\tera\torganizar\tum\ttipo\tde\tafirmação\tsobre\to\tefeito\tdo\tsalário\t—\n",
      "em\tmédia\t—\tde\tter\tum\tano\tadicional\tde\texperiência.\talém\tde\ttornar\to\tfato\tmais\n",
      "intrigante,\tainda\tpermite\tque\t\n",
      "façamos\tprevisões\n",
      "\tsobre\tsalários\tque\tnão\n",
      "conhecemos.\texploraremos\tmais\tessa\tideia\tno\t\n",
      "capítulo\t14\n",
      ".\n",
      "contas\tpagas\n",
      "ao\tvoltar\tpara\ta\tsua\tmesa,\ta\tvice-presidente\tda\treceita\testá\tesperando\tpor\tvocê.\n",
      "ela\tquer\tentender\tmelhor\tquais\tsão\tos\tusuários\tque\tpagam\tpor\tcontas\te\tquais\n",
      "que\tnão\tpagam\t(ela\tsabe\tseus\tnomes,\tmas\tessa\tinformação\tnão\té\tessencial).\n",
      "você\tpercebe\tque\tparece\thaver\tuma\tcorrespondência\tentre\tos\tanos\tde\n",
      "experiência\te\tas\tcontas\tpagas:\n",
      "0.7\tpaid\n",
      "1.9\tunpaid\n",
      "2.5\tpaid\n",
      "4.2\tunpaid\n",
      "6\t\t\tunpaid\n",
      "6.5\tunpaid\n",
      "7.5\tunpaid\n",
      "8.1\tunpaid\n",
      "8.7\tpaid\n",
      "10\t\tpaid\n",
      "os\tusuários\tcom\tpoucos\te\tmuitos\tanos\tde\texperiência\ttendem\ta\tpagar;\tos\n",
      "usuários\tcom\tuma\tquantidade\tmediana\tde\texperiência\tnão.\n",
      "logo,\tse\tvocê\tquisesse\tcriar\tum\tmodelo\t—\tapesar\tde\tnão\thaver\tdados\to\n",
      "suficiente\tpara\tservir\tde\tbase\tpara\tum\t—\tvocê\ttalvez\ttentasse\tprever\t“paid”\tpara\n",
      "os\tusuários\tcom\tpoucos\te\tmuitos\tanos\tde\texperiência,\te\t“unpaid”\tpara\tos\n",
      "usuários\tcom\tquantidade\tmediana\tde\texperiência:\n",
      "def\n",
      "\tpredict_paid_or_unpaid(years_experience):\n",
      "if\n",
      "\tyears_experience\t<\t3.0:\n",
      "\t\t\t\n",
      "return\n",
      "\t\"paid\"\n",
      "elif\n",
      "\tyears_experience\t<\t8.5:\n",
      "\t\t\t\n",
      "return\n",
      "\t\"unpaid\"\n",
      "else\n",
      ":\n",
      "\t\t\t\n",
      "return\n",
      "\t\"paid\"\n",
      "certamente,\tnós\tdefinimos\tvisualmente\tos\tcortes.1.\n",
      "2.\n",
      "3.\n",
      "com\tmais\tdados\t(e\tmais\tmatemática),\tnós\tpoderíamos\tconstruir\tum\tmodelo\n",
      "prevendo\ta\tprobabilidade\tde\tque\tum\tusuário\tpagaria,\tbaseado\tem\tseus\tanos\tde\n",
      "experiência.\tinvestigaremos\tesse\ttipo\tde\tproblema\tno\t\n",
      "capítulo\t16\n",
      ".\n",
      "tópicos\tde\tinteresse\n",
      "quando\tseu\tdia\testá\tterminando,\ta\tvice-presidente\tda\testratégia\tde\tconteúdo\n",
      "pede\tdados\tsobre\tem\tquais\ttópicos\tos\tusuários\testão\tmais\tinteressados,\tpara\tque\n",
      "ela\tpossa\tplanejar\to\tcalendário\tdo\tseu\tblog\tde\tacordo.\tvocê\tjá\tpossui\tos\tdados\n",
      "brutos\tpara\to\tprojeto\tsugerido:\n",
      "interests\t=\t[\n",
      "(0,\t\"hadoop\"),\t(0,\t\"big\tdata\"),\t(0,\t\"hbase\"),\t(0,\t\"java\"),\n",
      "(0,\t\"spark\"),\t(0,\t\"storm\"),\t(0,\t\"cassandra\"),\n",
      "(1,\t“nosql”),\t(1,\t“mongodb”),\t(1,\t“cassandra”),\t(1,\t“hbase”),\n",
      "(1,\t“postgres”),\t(2,\t“python”),\t(2,\t“scikit-learn”),\t(2,\t“scipy”),\n",
      "(2,\t“numpy”),\t(2,\t“statsmodels”),\t(2,\t“pandas”),\t(3,\t“r”),\t(3,\t“python”),\n",
      "(3,\t“statistics”),\t(3,\t“regression”),\t(3,\t“probability”),\n",
      "(4,\t“machine\tlearning”),\t(4,\t“regression”),\t(4,\t“decision\ttrees”),\n",
      "(4,\t“libsvm”),\t(5,\t“python”),\t(5,\t“r”),\t(5,\t“java”),\t(5,\t“c++”),\n",
      "(5,\t“haskell”),\t(5,\t“programming\tlanguages”),\t(6,\t“statistics”),\n",
      "(6,\t“probability”),\t(6,\t“mathematics”),\t(6,\t“theory”),\n",
      "(7,\t“machine\tlearning”),\t(7,\t“scikit-learn”),\t(7,\t“mahout”),\n",
      "(7,\t“neural\tnetworks”),\t(8,\t“neural\tnetworks”),\t(8,\t“deep\tlearning”),\n",
      "(8,\t“big\tdata”),\t(8,\t“artificial\tintelligence”),\t(9,\t“hadoop”),\n",
      "(9,\t“java”),\t(9,\t“mapreduce”),\t(9,\t“big\tdata”)\n",
      "]\n",
      "uma\tsimples\tforma\t(e\ttambém\tfascinante)\tde\tencontrar\tos\tinteresses\tmais\n",
      "populares\té\tfazer\tuma\tsimples\tcontagem\tde\tpalavras:\n",
      "coloque\tcada\tum\tem\tletras\tminúsculas\t(já\tque\tusuários\tdiferentes\tpodem\n",
      "ou\tnão\tescrever\tseus\tinteresses\tem\tletras\tmaiúsculas).\n",
      "divida\tem\tpalavras.\n",
      "conte\tos\tresultados.\n",
      "no\tcódigo:\n",
      "words_and_counts\t=\tcounter(word\n",
      "\t\t\t\n",
      "for\n",
      "\tuser,\tinterest\t\n",
      "in\n",
      "\tinterests\n",
      "\t\t\t\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tinterest.lower().split())\n",
      "isso\tfacilita\tlistar\tas\tpalavras\tque\tocorrem\tmais\tde\tuma\tvez:\n",
      "for\n",
      "\tword,\tcount\t\n",
      "in\n",
      "\twords_and_counts.most_common():if\n",
      "\tcount\t>\t1:\n",
      "print\n",
      "\tword,\tcount\n",
      "o\tque\tfornece\to\tresultado\tesperado\t(a\tmenos\tque\tvocê\tespere\tque\t“scikit-learn”\n",
      "possa\tser\tdividido\tem\tduas\tpalavras,\to\tque\tnão\tfornecerá\to\tresultado\tesperado):\n",
      "learning\t3\n",
      "java\t3\n",
      "python\t3\n",
      "big\t3\n",
      "data\t3\n",
      "hbase\t2\n",
      "regression\t2\n",
      "cassandra\t2\n",
      "statistics\t2\n",
      "probability\t2\n",
      "hadoop\t2\n",
      "networks\t2\n",
      "machine\t2\n",
      "neural\t2\n",
      "scikit-learn\t2\n",
      "r\t2\n",
      "veremos\tformas\tmais\taprimoradas\tde\textrair\ttópicos\tdos\tdados\tno\t\n",
      "capítulo\t20\n",
      ".\n",
      "em\tdiante\n",
      "foi\tum\tprimeiro\tdia\tbem\tproveitoso!\texausto,\tvocê\tsai\tdo\tprédio\tantes\tque\n",
      "alguém\tpeça\talgo\tmais.\ttenha\tuma\tboa\tnoite\tde\tsono,\tporque\tamanhã\tserá\tdia\tde\n",
      "treinamento\tpara\tnovos\tfuncionários.\tsim,\tvocê\ttrabalhou\tum\tdia\tinteiro\t\n",
      "antes\n",
      "do\ttreinamento.\tculpa\tdo\trh.capítulo\t2\n",
      "curso\trelâmpago\tde\tpython\n",
      "as\tpessoas\tainda\tsão\tloucas\tpelo\tpython\tmesmo\tdepois\tde\tvinte\te\tcinco\tanos,\n",
      "o\tque\té\tdifícil\tde\tacreditar\n",
      ".\n",
      "—michael\tpalin\n",
      "todos\tos\tfuncionários\tnovos\tna\tdatasciencester\tsão\tobrigados\ta\tpassar\tpelo\n",
      "treinamento\tdos\tfuncionários\tnovos,\ta\tparte\tmais\tinteressante\té\tque\tcontém\tum\n",
      "curso\tintensivo\tde\tpython.\n",
      "mas\tnão\té\tum\ttutorial\tcompreensível\tsobre\tpython,\té\tdirecionado\ta\tdestacar\tas\n",
      "partes\tda\tlinguagem\tque\tserão\tmais\timportantes\tpara\tnós\t(algumas\tdelas,\tem\n",
      "geral,\tnão\tsão\to\tfoco\tdos\ttutoriais\tpython).o\tbásico\n",
      "iniciando\tem\tpython\n",
      "você\tpode\tbaixar\to\tpython\tem\tpython.org\t(\n",
      "https://www.python.org\n",
      "/\n",
      ").\tmas\tse\n",
      "você\tainda\tnão\to\ttiver,\trecomendo\ta\tinstalação\tda\tdistribuição\tanaconda\n",
      "(\n",
      "https://store.continuum.io/cshop/anaconda\n",
      "/\n",
      "),\tque\tjá\tcontém\ta\tmaioria\tdas\n",
      "bibliotecas\tque\tvocê\tprecisa\tpara\tpraticar\tdata\tscience.\n",
      "no\tmomento\tda\tescrita\tdeste\tlivro,\ta\tversão\tmais\trecente\tdo\tpython\té\ta\t3.4.\n",
      "porém,\tna\tdatasciencester,\tusamos\to\tantigo\te\tconfiável\tpython\t2.7.\to\tpython\t3\n",
      "não\té\tcompatível\tcom\ta\tversão\tanterior\tdo\tpython\t2\te\tmuitas\tbibliotecas\n",
      "importantes\tsomente\tfuncionam\tbem\tcom\t2.7.\ta\tcomunidade\tdo\tdata\tscience\n",
      "ainda\testá\tpresa\tao\t2.7,\to\tque\tsignifica\tque\tnós\testaremos\ttambém.\tcertifique-se\n",
      "de\tter\tessa\tversão.\n",
      "se\tvocê\tnão\tconseguir\tanaconda,\tinstale\tpip\t(\n",
      "https://pypi.python.org/pypi/pip\n",
      "),\n",
      "que\té\tum\tgerenciador\tde\tpacote\tpython\tque\tpermite\tque\tvocê\tfacilmente\tinstale\n",
      "pacotes\tde\tterceiros\t(precisaremos\tde\talguns).\ttambém\tvale\ta\tpena\tobter\n",
      "ipython\t(\n",
      "http://ipython.org\n",
      "/\n",
      "),\to\tqual\té\tum\tshell\tpython\tmuito\tmelhor\tde\tse\n",
      "trabalhar.\n",
      "se\tvocê\tinstalou\tanaconda,\tjá\tdeve\tvir\tcom\tpip\te\tipython.\n",
      "apenas\texecute:\n",
      "pip\tinstall\tipython\n",
      "e\tentão\tprocure\tna\tinternet\tpor\tsoluções\tpara\tquaisquer\tmensagens\tde\terros\n",
      "enigmáticas\tque\thouver.\n",
      "python\tzen\n",
      "python\tpossui\tuma\tdescrição\tzen\tde\tseus\tprincípios\tde\tdesign\n",
      "(\n",
      "http://legacy.python.org/dev/peps/pep-0020\n",
      "/\n",
      "),\tque\tvocê\tencontrar\tdentro\tdo\n",
      "próprio\tinterpretador\tpython\tao\tdigitar\t\n",
      "import\tthis\n",
      ".\n",
      "o\tmais\tdiscutido\tdeles\té:\n",
      "deveria\thaver\tum\t—\tde\tpreferência\tapenas\tum\t—\tmodo\tóbvio\tde\tfazê-lo.\n",
      "o\tcódigo\tescrito\tde\tacordo\tcom\tesse\tmodo\t“óbvio”(que\ttalvez\tnão\tseja\ttão\n",
      "óbvio\tpara\tum\tnovato)\tfrequentemente\té\tdescrito\tcomo\t“pythonic”.\tapesar\tde\n",
      "este\tnão\tser\tum\tlivro\tsobre\tpython,\tde\tvez\tem\tquando\tcontrastaremos\tmodos\n",
      "pythonic\te\tnão-pythonic\tde\trealizar\tos\tmesmos\tprocessos,\te\tfavoreceremos\n",
      "soluções\tpythonic\tpara\tos\tnossos\tproblemas.\n",
      "formatação\tde\tespaço\tem\tbranco\n",
      "muitas\tlinguagens\tusam\tchaves\tpara\tdelimitar\tblocos\tde\tcódigo.\tpython\tusa\n",
      "indentação:\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\t[1,\t2,\t3,\t4,\t5]:\n",
      "print\n",
      "\ti\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tprimeira\tlinha\tpara\to\tbloco\t“for\ti”\n",
      "for\n",
      "\tj\t\n",
      "in\n",
      "\t[1,\t2,\t3,\t4,\t5]:\n",
      "print\n",
      "\tj\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tprimeira\tlinha\tpara\to\tbloco\t“for\tj”\n",
      "print\n",
      "\ti\t+\tj\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\túltima\tlinha\tpara\to\tbloco\t“for\tj”\n",
      "print\n",
      "\ti\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\túltima\tlinha\tpara\to\tbloco\t“for\ti”\n",
      "print\n",
      "\t\"done\tlooping\"\n",
      "isso\tfaz\tcom\tque\to\tcódigo\tpython\tseja\tbem\tlegível,\tmas\ttambém\tsignifica\tque\n",
      "você\ttem\tque\tser\tmuito\tcuidadoso\tcom\ta\tsua\tformatação.\to\tespaço\tem\tbranco\té\n",
      "ignorado\tdentro\tdos\tparênteses\te\tcolchetes,\to\tque\tpoder\tser\tmuito\tútil\tem\n",
      "computações\tintermináveis:\n",
      "long_winded_computation\t=\t(1\t+\t2\t+\t3\t+\t4\t+\t5\t+\t6\t+\t7\t+\t8\t+\t9\t+\t10\t+\t11\t+\t12\t+\n",
      "\t\t13\t+\t14\t+\t15\t+\t16\t+\t17\t+\t18\t+\t19\t+\t20)\n",
      "e\tpara\tfacilitar\ta\tleitura:\n",
      "list_of_lists\t=\t[[1,\t2,\t3],\t[4,\t5,\t6],\t[7,\t8,\t9]]\n",
      "easier_to_read_list_of_lists\t=\t[\t[1,\t2,\t3],\n",
      "[4,\t5,\t6],\n",
      "[7,\t8,\t9]\t]\n",
      "você\ttambém\tpode\tusar\tuma\tbarra\tinvertida\tpara\tindicar\tque\tuma\tdeclaração\n",
      "continua\tna\tpróxima\tlinha,\tapesar\tde\traramente\tfazermos\tisso:\n",
      "two_plus_three\t=\t2\t+\t\\\n",
      "\t\t\t\t\t\t\t3\n",
      "uma\tconsequência\tda\tformatação\tdo\tespaço\tem\tbranco\té\tque\tpode\tser\tdifícil\n",
      "copiar\te\tcolar\to\tcódigo\tno\tpython\tshell.\tpor\texemplo,\tse\tvocê\ttentasse\tcolar\teste\n",
      "código:for\n",
      "\ti\t\n",
      "in\n",
      "\t[1,\t2,\t3,\t4,\t5]:\n",
      "#\tnote\ta\tlinha\tem\tbranco\n",
      "print\n",
      "\ti\n",
      "na\tpython\tshell\tcomum,\tvocê\tteria:\n",
      "indentationerror\n",
      ":\texpected\tan\tindented\tblock\n",
      "porque\to\tinterpretador\tpensa\tque\ta\tlinha\tem\tbranco\tdetermina\to\tfinal\tdo\tbloco\n",
      "do\tloop\tfor.\n",
      "ipython\ttem\ta\tfunção\tmágica\t\n",
      "%paste\n",
      ",\tque\tcopia\tcorretamente\to\tque\tquer\tque\n",
      "esteja\tna\tárea\tde\ttransferência,\tespaço\tem\tbranco\te\ttudo\to\tmais.\tapenas\tisso\tjá\té\n",
      "uma\tboa\trazão\tpara\tusar\tipython.\n",
      "módulos\n",
      "alguns\trecursos\tde\tpython\tnão\tsão\tcarregados\tpor\tpadrão.\tisto\tinclui\ttanto\n",
      "recursos\tcomo\tparte\tda\tlinguagem\tassim\tcomo\trecursos\tde\tterceiros,\tque\tvocê\n",
      "baixa\tpor\tconta\tprópria.\tpara\tusar\tesses\trecursos,\tvocê\tprecisará\t\n",
      "import\n",
      "\t(importar)\n",
      "os\tmódulos\tque\tos\tcontêm.\n",
      "uma\tabordagem\té\tsimplesmente\timportar\to\tpróprio\tmódulo:\n",
      "import\tre\n",
      "my_regex\t=\tre.compile(\"[0-9]+\",\tre.i)\n",
      "aqui,\t\n",
      "re\n",
      "\té\to\tmódulo\tque\tcontém\tas\tfunções\te\tconstantes\tpara\ttrabalhar\tcom\n",
      "expressões\tregulares.\tapós\tesse\ttipo\tde\t\n",
      "import\n",
      ",\tvocê\tsomente\tpode\tacessar\ttais\n",
      "funções\tusando\to\tprefixo\t\n",
      "re\n",
      "…\n",
      "se\tvocê\tjá\ttiver\tum\t\n",
      "re\n",
      "\tdiferente\tno\tseu\tcódigo\tvocê\tpoderia\tusar\tum\talias:\n",
      "import\tre\tas\tregex\n",
      "my_regex\t=\tregex.compile(\"[0-9]+\",\tregex.i)\n",
      "você\ttalvez\tqueira\tfazer\tisso\tse\to\tseu\tmódulo\ttem\tum\tnome\tcomplicado\tou\tse\n",
      "você\tvai\tdigitar\tbastante.\tpor\texemplo,\tao\tvisualizar\tdados\tcom\t\n",
      "matplotlib\n",
      ",\tuma\n",
      "convenção\tpadrão\té:\n",
      "import\tmatplotlib.pyplot\tas\tplt\n",
      "se\tvocê\tprecisar\tde\talguns\tvalores\tespecíficos\tde\tum\tmódulo,\tpode\timportá-los\n",
      "explicitamente\te\tusá-los\tsem\tqualificação:from\tcollections\timport\n",
      "\tdefaultdict,\tcounter\n",
      "lookup\t=\tdefaultdict(int)\n",
      "my_counter\t=\tcounter()\n",
      "se\tvocê\tfosse\tuma\tpessoa\tmá,\tvocê\tpoderia\timportar\to\tconteúdo\tinteiro\tde\tum\n",
      "módulo\tdentro\tdo\tseu\tconjunto\tde\tnomes,\to\tque\ttalvez\tpudesse\tsobrescrever\n",
      "variáveis\tque\tvocê\tjá\ttinha\tdefinido:\n",
      "match\t=\t10\n",
      "from\tre\timport\n",
      "\t*\t\t\t\t\t\t\n",
      "#\tih\tnão,\tre\ttem\tuma\tfunção\tque\tcombinação\n",
      "print\n",
      "\tmatch\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t\"<function\tre.match>\"\n",
      "no\tentanto,\tjá\tque\tvocê\tnão\té\tuma\tpessoa\tmá,\tvocê\tnunca\tfará\tisso.\n",
      "aritmética\n",
      "python\t2.7\tusa\ta\tdivisão\tde\tinteiros\tpor\tpadrão,\tportanto\t\n",
      "5/2\n",
      "\té\tigual\ta\t\n",
      "2\n",
      ".\tquase\n",
      "sempre\tisso\tnão\té\to\tque\tqueremos,\tentão\tsempre\tcomeçaremos\tnossos\tarquivos\n",
      "com:\n",
      "from\t__future__\timport\n",
      "\tdivision\n",
      "depois\tdisso,\t\n",
      "5/2\n",
      "\té\tigual\ta\t\n",
      "2.5.\n",
      "\ttodo\texemplo\tde\tcódigo\tneste\tlivro\tusa\tesse\tnovo\n",
      "estilo\tde\tdivisão.\tna\tgrande\tmaioria\tdos\tcasos\tem\tque\tprecisaremos\tde\tdivisão\n",
      "de\tinteiros,\tpoderemos\tobtê-la\tcom\tuma\tbarra\tdupla\t\n",
      "5\t//\t2\n",
      ".\n",
      "funções\n",
      "uma\tfunção\té\tuma\tregra\tpara\tpegar\tzero\te\tmais\tentradas\te\tretornar\tuma\tsaída\n",
      "correspondente.\tem\tpython,\tdefinimos\tas\tfunções\tusando\t\n",
      "def\n",
      ":\n",
      "def\tdouble(x):\n",
      "\"\"\"aqui\té\tonde\tvocê\tcoloca\tum\tdocstring\t(cadeia\tde\tcaracteres\tde\tdocumentação)\topcional\n",
      "que\texplica\to\tque\ta\tfunção\tfaz\n",
      ".\n",
      "por\texemplo,\testa\tfunção\tmultiplica\tsua\tentrada\tpor\t2\"\"\"\n",
      "return\tx\t*\t2\n",
      "as\tfunções\tde\tpython\tsão\tde\t\n",
      "primeira\tclasse\n",
      ",\tque\tsignifica\tque\tpodemos\tatribuí-\n",
      "las\ta\tvariáveis\te\tpassá-las\tpara\tas\tfunções\tcomo\tquaisquer\toutros\targumentos:\n",
      "def\n",
      "\tapply_to_one(f):\n",
      "\"\"\"chama\ta\tfunção\tf\tcom\t1\tcomo\tseu\targumento\"\"\"\n",
      "return\n",
      "\tf(1)\n",
      "my_double\t=\tdouble\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\trefere-se\tà\tfunção\tdefinida\tanteriormente\n",
      "x\t=\tapply_to_one(my_double)\t\t\t\t\t\n",
      "#\té\tigual\ta\t2também\té\tfácil\tcriar\tpequenas\tfunções\tanônimas,\tou\tlambdas:\n",
      "y\t=\tapply_to_one(\n",
      "lambda\n",
      "\tx:\tx\t+\t4)\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t5\n",
      "você\tpode\tatribuir\tlambdas\ta\tvariáveis,\tapesar\tde\tque\tmaioria\tdas\tpessoas\tlhe\n",
      "dirão\tpara\tusar\t\n",
      "def\n",
      ":\n",
      "another_double\t=\t\n",
      "lambda\n",
      "\tx:\t2\t*\tx\t\t\t\t\t\t\t\t\n",
      "#\tnão\tfaça\tisso\n",
      "def\n",
      "\tanother_double(x):\t\n",
      "return\n",
      "\t2\t*\tx\t\t\t\t\t\n",
      "#\tfaça\tisso\n",
      "os\tparâmetros\tde\tfunção\ttambém\tpodem\treceber\targumentos\tpadrões,\tque\tsó\n",
      "precisam\tser\tespecificados\tquando\tvocê\tquiser\tum\tvalor\talém\tdo\tpadrão:\n",
      "def\n",
      "\tmy_print(message=\"my\tdefault\tmessage\"):\n",
      "print\n",
      "\tmessage\n",
      "my_print(\"hello\")\t\t\t\t\n",
      "#\texibe\t'hello'\n",
      "my_print()\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\texibe\t'my\tdefault\tmessage'\n",
      "às\tvezes\té\tútil\tespecificar\targumentos\tpelo\tnome:\n",
      "def\n",
      "\tsubtract(a=0,\tb=0):\n",
      "return\n",
      "\ta\t-\tb\n",
      "subtract(10,\t5)\t\t\n",
      "#\tretorna\ts\n",
      "subtract(0,\t5)\t\t\t\n",
      "#\tretorna\t-s\n",
      "subtract(b=5)\t\t\t\t\n",
      "#\tmesmo\tque\to\tanterior\n",
      "criaremos\tmuitas,\tmuitas\tfunções.\n",
      "strings\t(cadeias\tde\tcaracteres)\n",
      "as\tstrings\tpodem\tser\tdelimitadas\tpor\taspas\tsimples\tou\tduplas\t(mas\telas\tdevem\n",
      "combinar):\n",
      "single_quoted_string\t=\t'data\tscience'\n",
      "double_quoted_string\t=\t\"data\tscience\"\n",
      "o\tpython\tusa\ta\tbarra\tinvertida\tpara\tcodificar\tcaracteres\tespeciais.\tpor\texemplo:\n",
      "tab_string\t=\t\"\n",
      "\\t\n",
      "\"\t\t\t\t\t\t\t\n",
      "#\trepresenta\to\tcaractere\ttab\n",
      "len(tab_string)\t\t\t\t\t\t\t\t\t\n",
      "#\té\t1\n",
      "se\tvocê\tquiser\tbarras\tinvertidas\tcomo\tbarras\tinvertidas\t(que\tvocê\tvê\tnos\tnomes\n",
      "dos\tdiretórios\tou\texpressões\tregulares\tno\twindows),\tvocê\tpode\tcriar\tuma\tstring\n",
      "bruta\n",
      "\tusando\t\n",
      "r\"\"\n",
      ":\n",
      "not_tab_string\t=\tr\"\\t\"\t\t\n",
      "#\trepresenta\tos\tcaracteres\t'\\'\te\t't'\n",
      "len(not_tab_string)\t\t\t\t\t\n",
      "#\té\t2você\tpode\tcriar\tstrings\tmúltiplas\tusando\taspas\ttriplas\tou\tduplas:\n",
      "multi_line_string\t=\t\"\"\"esta\té\ta\tprimeira\tlinha.\n",
      "e\testa\té\ta\tsegunda\n",
      "e\testa\té\ta\tterceira\"\"\"\n",
      "exceções\n",
      "quando\talgo\tdá\terrado,\to\tpython\texibe\tuma\t\n",
      "exceção\n",
      ".\tse\tnão\tfor\tmanipulada,\to\n",
      "programa\ttravará.\tvocê\tpode\tmanipulá-las\tusando\t\n",
      "try\n",
      "\te\t\n",
      "except\n",
      ":\n",
      "try\n",
      ":\n",
      "print\n",
      "\t0\t/\t0\n",
      "except\tzerodivisionerror\n",
      ":\n",
      "print\n",
      "\t\"cannot\tdivide\tby\tzero\"\n",
      "apesar\tde\tserem\tconsideradas\truins\tem\tmuitas\tlinguagens,\tas\texceções\tsão\n",
      "usadas\tlivremente\tno\tpython\tpara\tdar\tuma\tlimpeza\tno\tcódigo\te,\tocasionalmente,\n",
      "faremos\to\tmesmo.\n",
      "listas\n",
      "provavelmente,\ta\testrutura\tde\tdados\tmais\tbásica\tem\tpython\té\ta\t\n",
      "list\n",
      ".\tuma\tlista\té\n",
      "apenas\tuma\tcoleção\tordenada.\t(é\tparecida\tcom\to\tarray\tdas\toutras\tlinguagens,\n",
      "mas\tcom\talgumas\tfuncionalidades\ta\tmais.)\n",
      "integer_list\t=\t[1,\t2,\t3]\n",
      "heterogeneous_list\t=\t[\"string\",\t0.1,\ttrue]\n",
      "list_of_lists\t=\t[\tinteger_list,\theterogeneous_list,\t[]\t]\n",
      "list_length\t=\tlen(integer_list)\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t3\n",
      "list_sum\t\t\t\t=\tsum(integer_list)\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t6\n",
      "você\tpode\tter\tou\tconfigurar\to\telemento\t\n",
      "n\n",
      "-ésimo\tde\tuma\tlista\tcom\tcolchetes:\n",
      "x\t=\trange(10)\n",
      "\t\t\t\t\t\t\n",
      "#\té\ta\tlista\t[0,\t1,\t...,\t9]\n",
      "zero\t=\tx[0]\n",
      "\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t0,\tas\tlistas\tsão\tindexadas\ta\tpartir\tde\t0\n",
      "one\t=\tx[1]\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t1\n",
      "nine\t=\tx[-1]\n",
      "\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t9,\t'pythonic'\tpara\to\túltimo\telemento\n",
      "eight\t=\tx[-2]\n",
      "\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t8,\t'pythonic'\tpara\to\tanterior\tao\túltimo\telemento\n",
      "x[0]\t=\t-1\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "#\tagora\tx\té\t[-1,\t1,\t2,\t3,\t...,\t9]\n",
      "você\ttambém\tpode\tusar\tos\tcolchetes\tpara\trepartir\tas\tlistas:\n",
      "first_three\t=\tx[:3]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[-1,\t1,\t2]\n",
      "three_to_end\t=\tx[3:];\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[3,\t4,\t...,\t9]\n",
      "one_to_four\t=\tx[1:5]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[1,\t2,\t3,\t4]last_three\t=\tx[-3:]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[7,\t8,\t9]\n",
      "without_first_and_last\t=\tx[1:-1];\t\t\t\t\t\n",
      "#\t[1,\t2,\t...,\t8]\n",
      "copy_of_x\t=\tx[:]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[-1,\t1,\t2,\t...,\t9]\n",
      "o\tpython\tpossui\to\toperador\t\n",
      "in\n",
      "\tpara\tverificar\ta\tassociação\tà\tlista:\n",
      "1\t\n",
      "in\n",
      "\t[1,\t2,\t3]\t\t\t\t\t\t\n",
      "#\tverdadeiro\n",
      "0\t\n",
      "in\n",
      "\t[1,\t2,\t3]\t\t\t\t\t\t\n",
      "#\tfalso\n",
      "essa\tverificação\tenvolve\texaminar\tos\telementos\tde\tuma\tlista\tum\tde\tcada\tvez,\to\n",
      "que\tsignifica\tque\tvocê\tprovavelmente\tnão\tdeveria\tusá-la\ta\tmenos\tque\tvocê\tsaiba\n",
      "que\tsua\tlista\té\tpequena\t(ou\ta\tmenos\tque\tvocê\tnão\tse\timporte\tem\tquanto\ttempo\ta\n",
      "verificação\tdurará).\n",
      "é\tfácil\tconcatenar\tas\tlistas\tjuntas:\n",
      "x\t=\t[1,\t2,\t3]\n",
      "x.extend([4,\t5,\t6])\t\t\t\t\t\t\t\t\t\n",
      "#\tx\tagora\té\t[1,2,3,4,5,6]\n",
      "se\tvocê\tnão\tquiser\tmodificar\t\n",
      "x\n",
      "\tvocê\tpode\tusar\tuma\tadição\tna\tlista:\n",
      "x\t=\t[1,\t2,\t3]\n",
      "y\t=\tx\t+\t[4,\t5,\t6]\t\t\t\t\t\t\t\t\t\t\n",
      "#\ty\té[1,\t2,\t3,\t4,\t5,\t6];\tx\tnão\tmudou\n",
      "com\tmais\tfrequência,\tanexaremos\tum\titem\tde\tcada\tvez\tnas\tlistas:\n",
      "x\t=\t[1,\t2,\t3]\n",
      "x.append(0)\t\t\t\t\t\t\t\t\t\t\n",
      "#\tx\tagora\té\t[1,\t2,\t3,\t0]\n",
      "y\t=\tx[-1]\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t0\n",
      "z\t=\tlen(x)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t4\n",
      "às\tvezes\té\tconveniente\t\n",
      "desfazer\n",
      "\tas\tlistas\tse\tvocê\tsabe\tquantos\telementos\telas\n",
      "possuem:\n",
      "x,\ty\t=\t[1,\t2]\t\t\t\t\t\t\t\t\n",
      "#\tagora\tx\té\t1,\ty\té\t2\n",
      "apesar\tde\tque\tvocê\treceberá\tum\t\n",
      "valueerror\n",
      "\tse\tnão\ttiver\tos\tmesmos\tnúmeros\tde\n",
      "elementos\tdos\tdois\tlados.\n",
      "é\tcomum\tusar\tum\tsublinhado\tpara\tum\tvalor\tque\tvocê\tdescartará:\n",
      "_,\ty\t=\t[1,\t2]\t\t\t\t\t\t\t\t\n",
      "#\tagora\ty\t==\t2,\tnão\tse\tpreocupou\tcom\to\tprimeiro\telemento\n",
      "tuplas\n",
      "são\tas\tprimas\timutáveis\tdas\tlistas.\tquase\ttudo\tque\tvocê\tpode\tfazer\tcom\tuma\n",
      "lista,\tque\tnão\tenvolva\tmodificá-la,\té\tpossível\tser\tfeito\tem\tuma\ttupla.\tvocê\n",
      "especifica\tuma\ttupla\tao\tusar\tparênteses\t(ou\tnada)\tem\tvez\tde\tcolchetes:my_list\t=\t[1,\t2]\n",
      "my_tuple\t=\t(1,\t2)\n",
      "other_tuple\t=\t3,\t4\n",
      "my_list[1]\t=\t3\t\t\t\t\t\t\n",
      "#\tmy_list\tagora\té\t[1,\t3]\n",
      "try\n",
      ":\n",
      "my_tuple[1]\t=\t3\n",
      "except\ttypeerror\n",
      ":\n",
      "print\n",
      "\t\"cannot\tmodify\ta\ttuple\"\n",
      "as\ttuplas\tsão\tuma\tmaneira\teficaz\tde\tretornar\tmúltiplos\tvalores\ta\tpartir\tdas\n",
      "funções:\n",
      "def\n",
      "\tsum_and_product(x,\ty):\n",
      "return\n",
      "\t(x\t+\ty),(x\t*\ty)\n",
      "sp\t=\tsum_and_product(2,\t3)\t\t\t\t\t\n",
      "#\té\tigual\t(5,\t6)\n",
      "s,\tp\t=\tsum_and_product(5,\t10)\t\t\n",
      "#\ts\té\t15,\tp\té\t50\n",
      "as\ttuplas\t(e\tlistas)\ttambém\tpodem\tser\tusadas\tpara\t\n",
      "atribuições\tmúltiplas\n",
      ":\n",
      "x,\ty\t=\t1,\t2\t\t\t\t\t\t\t\n",
      "#\tagora\tx\té\t1,\ty\té\t2\n",
      "x,\ty\t=\ty,\tx\t\t\t\t\t\t\t\n",
      "#\tmodo\tpythonic\tde\ttrocar\tas\tvariáveis;\tagora\tx\té\t2,\ty\té\t1\n",
      "dicionários\n",
      "outra\testrutura\tfundamental\té\tum\tdicionário,\tque\tassocia\t\n",
      "valores\n",
      "\tcom\t\n",
      "chaves\n",
      "\te\n",
      "permite\tque\tvocê\trecupere\to\tvalor\tcorrespondente\tde\tuma\tdada\tchave\n",
      "rapidamente:\n",
      "empty_dict\t=\t{}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpythonic\n",
      "empty_dict2\t=\tdict();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tmenos\tpythonic\n",
      "grades\t=\t{\t\"joel\"\t:\t80,\t\"tim\"\t:\t95\t}\t\t\t\t\t\t\n",
      "#\tdicionário\tliteral\n",
      "você\tpode\tprocurar\to\tvalor\tpara\tuma\tchave\tusando\tcolchetes:\n",
      "joels_grade\t=\tgrades[\"joel\"]\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t80\n",
      "mas\tvocê\treceberá\tum\t\n",
      "keyerror\n",
      "\tse\tperguntar\tpor\tuma\tchave\tque\tnão\testeja\tno\n",
      "dicionário:\n",
      "try\n",
      ":\n",
      "kates_grade\t=\tgrades[\"kate\"]\n",
      "except\tkeyerror\n",
      ":\n",
      "print\n",
      "\t\"no\tgrade\tfor\tkate!\"\n",
      "você\tpode\tverificar\ta\texistência\tde\tuma\tchave\tusando\t\n",
      "in\n",
      ":\n",
      "joel_has_grade\t=\t\"joel\"\t\n",
      "in\n",
      "\tgrades\t\t\t\t\t\t\t\n",
      "#\tverdadeiro\n",
      "kate_has_grade\t=\t\"kate\"\t\n",
      "in\n",
      "\tgrades\t\t\t\t\t\t\t\n",
      "#\tfalsoos\tdicionários\tpossuem\to\tmétodo\t\n",
      "get\n",
      "\tque\tretorna\tum\tvalor\tpadrão\t(em\tvez\tde\n",
      "levantar\tuma\texceção)\tquando\tvocê\tprocura\tpor\tuma\tchave\tque\tnão\testeja\tno\n",
      "dicionário:\n",
      "joels_grade\t=\tgrades.get(\"joel\",\t0)\t\t\t\t\n",
      "#\té\tigual\ta\t80\n",
      "kates_grade\t=\tgrades.get(\"kate\",\t0)\t\t\t\t\n",
      "#\té\tigual\ta\t0\n",
      "no_ones_grade\t=\tgrades.get(\"no\tone\")\t\t\t\n",
      "#\tpadrão\tpara\tpadrão\té\tnone\n",
      "você\tatribui\tpares\tde\tvalores-chave\tusando\tos\tmesmos\tcolchetes:\n",
      "grades[\"tim\"]\t=\t99\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tsubstitui\to\tvalor\tantigo\n",
      "grades[\"kate\"]\t=\t100\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tadiciona\tuma\tterceira\tentrada\n",
      "num_students\t=\tlen(grades)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t3\n",
      "frequentemente\tusaremos\tdicionários\tcomo\tuma\tsimples\tmaneira\tde\trepresentar\n",
      "dados\testruturados:\n",
      "tweet\t=\t{\n",
      "\"user\"\t:\t\"joelgrus\",\n",
      "\"text\"\t:\t\"data\tscience\tis\tawesome\",\n",
      "\"retweet_count\"\t:\t100,\n",
      "\"hashtags\"\t:\t[\"#data\",\t\"#science\",\t\"#datascience\",\t\"#awesome\",\t\"#yolo\"]\n",
      "}\n",
      "além\tde\tprocurar\tpor\tchaves\tespecíficas,\tpodemos\tolhar\tpara\ttodas\telas:\n",
      "tweet_keys\t\t\t=\ttweet.keys()\t\t\t\t\t\t\t\t\n",
      "#\tlista\tde\tchaves\n",
      "tweet_values\t=\ttweet.values()\t\t\t\t\t\t\n",
      "#\tlista\tde\tvalores-chave\n",
      "tweet_items\t\t=\ttweet.items()\t\t\t\t\t\t\t\n",
      "#\tlista\tde\t(chave,\tvalor)\ttuplas\n",
      "\"user\"\tin\ttweet_keys\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tverdadeiro,\tmas\tusa\tlist\tin,\tmais\tlento\n",
      "\"user\"\tin\ttweet\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tmais\tpythonic,\tusa\tdict\tin,\tmais\trápido\n",
      "\"joelgrus\"\tin\ttweet_values\t\t\t\t\t\t\t\t\t\n",
      "#\tverdadeiro\n",
      "as\tchaves\tdos\tdicionários\tdevem\tser\timutáveis;\tparticularmente,\tvocê\tnão\tpode\n",
      "usar\t\n",
      "list\n",
      "s\tcomo\tchaves.\tse\tvocê\tprecisar\tde\tuma\tchave\tmultipart,\tvocê\tdeveria\n",
      "usar\tuma\t\n",
      "tuple\n",
      "\tou\tdescobrir\tuma\tforma\tde\ttransformar\tuma\tchave\tem\tuma\tstring.\n",
      "defaultdict\n",
      "imagine\tque\tvocê\testeja\ttentando\tcontar\tas\tpalavras\tem\tum\tdocumento.\tum\n",
      "método\tclaro\té\tcriar\tum\tdicionário\tno\tqual\tas\tchaves\tsão\tpalavras\te\tos\tvalores\n",
      "são\tcontagens.\tconforme\t\n",
      "você\tvai\tverificando\tcada\tpalavra,\tvocê\tpode\n",
      "incrementar\tsua\tcontagem\tse\tela\tjá\testiver\tno\tdicionário\te\tadicioná-la\tno\n",
      "dicionário\tse\tnão\testiver:\n",
      "word_counts\t=\t{}for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument:\n",
      "if\n",
      "\tword\t\n",
      "in\n",
      "\tword_counts:\n",
      "word_counts[word]\t+=\t1\n",
      "else\n",
      ":\n",
      "word_counts[word]\t=\t1\n",
      "você\ttambém\tpoderia\tusar\to\tmétodo\t“perdão\té\tmelhor\tdo\tque\tpermissão”\te\n",
      "apenas\tmanipular\ta\texceção\ta\tpartir\tda\ttentativa\tde\tprocurar\tpela\tchave\tperdida:\n",
      "word_counts\t=\t{}\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument:\n",
      "try\n",
      ":\n",
      "word_counts[word]\t+=\t1\n",
      "except\tkeyerror\n",
      ":\n",
      "word_counts[word]\t=\t1\n",
      "uma\tterceira\tabordagem\té\tusar\t\n",
      "get\n",
      ",\tque\tse\tcomporta\tmuito\tbem\tcom\tas\tchaves\n",
      "perdidas:\n",
      "word_counts\t=\t{}\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument:\n",
      "previous_count\t=\tword_counts.get(word,\t0)\n",
      "word_counts[word]\t=\tprevious_count\t+\t1\n",
      "tudo\tisso\té\tlevemente\tcomplicado,\tpor\tisso\to\t\n",
      "defaultdict\n",
      "\té\tútil.\tum\t\n",
      "defaultdict\n",
      "\té\n",
      "como\tum\tdicionário\tcomum,\texceto\tque,\tquando\tvocê\ttenta\tprocurar\tpor\tuma\n",
      "chave\tque\tele\tnão\tpossui,\tele\tprimeiro\tadiciona\tum\tvalor\tpara\tela\tusando\ta\n",
      "função\tde\targumento\tzero\tque\tvocê\tforneceu\tao\tcriá-lo.\tpara\tusar\t\n",
      "defaultdict\n",
      "s,\tvocê\n",
      "tem\tque\timportá-los\tdas\t\n",
      "collection\n",
      "s:\n",
      "from\tcollections\timport\n",
      "\tdefaultdict\n",
      "word_counts\t=\tdefaultdict(int)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tint()\tproduz\t0\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument:\n",
      "word_counts[word]\t+=\t1\n",
      "eles\ttambém\tpodem\tser\túteis\tcom\t\n",
      "list\n",
      "\tou\t\n",
      "dict\n",
      "\tou\taté\tmesmo\tcom\tsuas\tpróprias\n",
      "funções:\n",
      "dd_list\t=\tdefaultdict(list)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tlist()\tproduz\tuma\tlista\tvazia\n",
      "dd_list[2].append(1)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tagora\tdd_list\tcontém\t{2:\t[1]}\n",
      "dd_dict\t=\tdefaultdict(dict)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdict()\tproduz\tum\tdict\tvazio\n",
      "dd_dict[\"joel\"][\"city\"]\t=\t\"seattle\"\t\t\t\t\t\t\t\t\t\n",
      "#\t{\t\"joel\"\t:\t{\t\"city\"\t:\tseattle\"}}\n",
      "dd_pair\t=\tdefaultdict(\n",
      "lambda\n",
      ":\t[0,\t0])\n",
      "dd_pair[2][1]\t=\t1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tagora\tdd_pair\tcontêm\t{2:\t[0,1]}\n",
      "isso\tserá\tútil\tquando\tvocê\tusar\tdicionários\tpara\t“coletar”\tresultados\tpor\talgumachave\te\tnão\tquiser\tverificar\ttoda\tvez\tpara\tver\tse\tela\tainda\texiste.\n",
      "contador\n",
      "um\t\n",
      "counter\n",
      "\t(contador)\ttransforma\tuma\tsequência\tde\tvalores\tem\talgo\tparecido\n",
      "com\to\tobjeto\t\n",
      "defaultdict(int)\n",
      "\tmapeando\tas\tchaves\tpara\tas\tcontagens.\tprimeiramente,\n",
      "o\tusaremos\tpara\tcriar\thistogramas:\n",
      "from\tcollections\timport\n",
      "\tcounter\n",
      "c\t=\tcounter([0,\t1,\t2,\t0])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tc\té\t(basicamente)\t{\t0\t:\t2,\t1\t:\t1,\t2\t:\t1\t}\n",
      "isso\tnos\tmostra\tuma\tforma\tsimples\tde\tresolver\tnosso\tproblema\tde\t\n",
      "word_counts\n",
      ":\n",
      "word_counts\t=\tcounter(document)\n",
      "uma\tinstância\t\n",
      "counter\n",
      "\tpossui\tum\tmétodo\t\n",
      "most_common\n",
      "\tque\té\tfrequentemente\tútil:\n",
      "#\timprime\tas\tdez\tpalavas\tmais\tcomuns\te\tsuas\tcontas\n",
      "for\n",
      "\tword,\tcount\t\n",
      "in\n",
      "\tword_counts.most_common(10):\n",
      "print\n",
      "\tword,\tcount\n",
      "conjuntos\n",
      "outra\testrutura\tde\tdados\té\to\t\n",
      "set\n",
      "\t(conjunto),\tque\trepresenta\tuma\tcoleção\tde\n",
      "elementos\t\n",
      "distintos\n",
      ":\n",
      "s\t=\tset()\n",
      "s.add(1)\t\t\t\t\t\t\t\t\t\t\n",
      "#\ts\tagora\té\t{\t1\t}\n",
      "s.add(2)\t\t\t\t\t\t\t\t\t\t\n",
      "#\ts\tagora\té\t{\t1,\t2\t}\n",
      "s.add(2)\t\t\t\t\t\t\t\t\t\t\n",
      "#\ts\tainda\té\t{\t1,\t2\t}\n",
      "x\t=\tlen(s)\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\t2\n",
      "y\t=\t2\t\n",
      "in\n",
      "\ts\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\ttrue\n",
      "z\t=\t3\t\n",
      "in\n",
      "\ts\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\tfalse\n",
      "usaremos\tos\tconjuntos\tpor\tduas\trazões\tprincipais.\ta\tprimeira\té\tque\t\n",
      "in\n",
      "\té\tuma\n",
      "operação\tmuito\trápida\tem\tconjuntos.\tse\ttivermos\tuma\tgrande\tcoleção\tde\titens\n",
      "que\tqueiramos\tusar\tpara\tum\tteste\tde\tsociedade,\tum\tconjunto\té\tmais\tadequado\tdo\n",
      "que\tuma\tlista:\n",
      "stopwords_list\t=\t[\"a\",\"an\",\"at\"]\t+\thundreds_of_other_words\t+\t[\"yet\",\t\"you\"]\n",
      "\"zip\"\t\n",
      "in\n",
      "\tstopwords_list\t\t\t\t\t\t\t\n",
      "#\tfalso,\tmas\ttem\tque\tverificar\ttodos\tos\telementos\n",
      "stopwords_set\t=\tset(stopwords_list)\n",
      "\"zip\"\t\n",
      "in\n",
      "\tstopwords_set\t\t\t\t\t\t\t\t\n",
      "#\tmuito\trápido\tpara\tverificar\n",
      "a\tsegunda\trazão\té\tencontrar\tos\titens\t\n",
      "distintos\n",
      "\tem\tuma\tcoleção:item_list\t=\t[1,\t2,\t3,\t1,\t2,\t3]\n",
      "num_items\t=\tlen(item_list)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t6\n",
      "item_set\t=\tset(item_list)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t{1,\t2,\t3}\n",
      "num_distinct_items\t=\tlen(item_set)\t\t\t\t\t\t\t\t\t\t\n",
      "#\t3\n",
      "distinct_item_list\t=\tlist(item_set)\t\t\t\t\t\t\t\t\t\n",
      "#\t[1,\t2,\t3]\n",
      "usaremos\t\n",
      "set\n",
      "s\tcom\tmenos\tfrequência\tdo\tque\t\n",
      "dict\n",
      "s\te\t\n",
      "list\n",
      "s.\n",
      "controle\tde\tfluxo\n",
      "como\tna\tmaioria\tdas\tlinguagens\tde\tprogramação,\tvocê\tpode\tdesempenhar\tuma\n",
      "ação\tcondicionalmente\tusando\t\n",
      "if\n",
      ":\n",
      "if\n",
      "\t1\t>\t2:\n",
      "message\t=\t\"if\tonly\t1\twere\tgreater\tthan\ttwo...\"\n",
      "elif\n",
      "\t1\t>\t3:\n",
      "message\t=\t\"elif\tstands\tfor\t'else\tif'\"\n",
      "else\n",
      ":\n",
      "message\t=\t\"when\tall\telse\tfails\tuse\telse\t(if\tyou\twant\tto)\"\n",
      "você\ttambém\tpode\tescrever\tum\t\n",
      "ternário\n",
      "\tif-then-else\tem\tuma\tlinha,\to\tque\n",
      "faremos\tocasionalmente:\n",
      "parity\t=\t\"even\"\t\n",
      "if\n",
      "\tx\t%\t2\t==\t0\t\n",
      "else\n",
      "\t\"odd\"\n",
      "python\tpossui\tum\tloop\twhile:\n",
      "x\t=\t0\n",
      "while\n",
      "\tx\t<\t10:\n",
      "print\n",
      "\tx,\t\"is\tless\tthan\t10\"\n",
      "x\t+=\t1\n",
      "embora\tusaremos\tmais\t\n",
      "for\n",
      "\te\t\n",
      "in\n",
      ":\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(10):\n",
      "print\n",
      "\tx,\t\"is\tless\tthan\t10\"\n",
      "se\tvocê\tprecisar\tde\tuma\tlógica\tmais\tcomplexa,\tpode\tusar\t\n",
      "continue\n",
      "\te\t\n",
      "break\n",
      ":\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(10):\n",
      "if\n",
      "\tx\t==\t3:\n",
      "continue\n",
      "\t\t\t\t\n",
      "#\tvai\tpara\ta\tpróxima\titeração\timediatamente\n",
      "if\n",
      "\tx\t==\t5:\n",
      "break\n",
      "\t\t\t\t\t\t\t\n",
      "#\tsai\tdo\tloop\tcompletamente\n",
      "print\n",
      "\tx\n",
      "essa\tsaída\tserá\t0,\t1,\t2\te\t4.•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "veracidade\n",
      "os\tbooleanos\tem\tpython\tfuncionam\tcomo\tna\tmaioria\tdas\tlinguagens,\texceto\n",
      "que\teles\tsão\tiniciados\tpor\tletras\tmaiúsculas:\n",
      "one_is_less_than_two\t=\t1\t<\t2\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\té\tigual\ta\ttrue\n",
      "true_equals_false\t=\ttrue\t==\tfalse\t\t\t\t\t\t\n",
      "#\té\tigual\ta\tfalse\n",
      "python\tusa\to\tvalor\t\n",
      "none\n",
      "\tpara\tindicar\tum\tvalor\tnão-existente.\té\tparecido\tcom\to\n",
      "null\n",
      "\tdas\toutras\tlinguagens:\n",
      "x\t=\tnone\n",
      "print\n",
      "\tx\t==\tnone\t\t\t\t\t\n",
      "#\timprime\ttrue\tmas\tnão\té\tpythonic\n",
      "print\n",
      "\tx\t\n",
      "is\n",
      "\tnone\t\t\t\t\t\n",
      "#\timprime\ttrue\te\té\tpythonic\n",
      "o\tpython\tpermite\tque\tvocê\tuse\tqualquer\tvalor\tque\tespera\tpor\tum\tbooleano.\n",
      "todos\tos\texemplos\ta\tseguir\tsão\t“\n",
      "falsos\n",
      "”:\n",
      "false\n",
      "none\n",
      "[]\t(uma\tlist\tvazia)\n",
      "{}\t(um\tdict\tvazio)\n",
      "\"\"\n",
      "set()\n",
      "0\n",
      "0.0\n",
      "quase\ttodo\to\trestante\tpode\tser\ttratado\tcomo\t\n",
      "true\n",
      ".\tisso\tpermite\tque\tvocê\tuse\n",
      "declarações\t\n",
      "if\n",
      "\tpara\ttestar\tlistas,\tstrings\tou\tdicionários\tvazios\te\tassim\tpor\tdiante.\n",
      "às\tvezes\tisso\tcausa\talguns\tpequenos\tbugs\tse\tvocê\testiver\tesperando\tpor\teste\n",
      "comportamento:\n",
      "s\t=\tsome_function_that_returns_a_string()\n",
      "if\n",
      "\ts:\n",
      "first_char\t=\ts[0]\n",
      "else\n",
      ":\n",
      "first_char\t=\t\"\"\n",
      "uma\tforma\tmais\tsimples\tde\tfazer\to\tmesmo\té:\n",
      "first_char\t=\ts\t\n",
      "and\n",
      "\ts[0]\n",
      "já\tque\t\n",
      "and\n",
      "\tretorna\tseu\tsegundo\tvalor\tquando\to\tprimeiro\té\t“\n",
      "verdadeiro\n",
      "”,\tou\to\n",
      "primeiro\tvalor\tquando\tnão\té.\tda\tmesma\tforma,\tse\t\n",
      "x\n",
      "\té\tum\tnúmero\tou,possivelmente,\t\n",
      "none\n",
      ":\n",
      "safe_x\t=\tx\t\n",
      "or\n",
      "\t0\n",
      "definitivamente\té\tum\tnúmero.\n",
      "python\tpossui\tuma\tfunção\t\n",
      "all\n",
      ",\tque\tpega\tuma\tlista\te\tretorna\t\n",
      "true\n",
      "\tprecisamente\n",
      "quando\ttodos\tos\telementos\tforem\tverdadeiros,\te\tuma\tfunção\t\n",
      "any\n",
      ",\tque\tretorna\t\n",
      "true\n",
      "quando\tpelo\tmenos\tum\telemento\té\tverdadeiro:\n",
      "all([true,\t1,\t{\t3\t}])\t\t\t\t\t\n",
      "#\ttrue\n",
      "all([true,\t1,\t{}])\t\t\t\t\t\t\t\t\n",
      "#\tfalse,\t{}\té\tfalso\n",
      "any([true,\t1,\t{}])\t\t\t\t\t\t\t\t\n",
      "#\ttrue,\ttrue\té\tverdadeiro\n",
      "all([])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttrue,\tsem\telementos\tfalsos\tna\tlista\n",
      "any([])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tfalse,\tsem\telementos\tverdadeiros\tna\tlistanão\ttão\tbásico\n",
      "aqui,\tveremos\talguns\tdos\tmais\tavançados\trecursos\tdo\tpython\tque\tserão\túteis\n",
      "para\ttrabalhar\tcom\tdados.\n",
      "ordenação\n",
      "toda\tlista\tde\tpython\tpossui\tum\tmétodo\t\n",
      "sort\n",
      "\tque\tordena\tseu\tespaço.\tse\tvocê\tnão\n",
      "quer\tbagunçar\tsua\tlista,\tvocê\tpode\tusar\ta\tfunção\t\n",
      "sort\n",
      "ed,\tque\tretornam\tuma\tlista\n",
      "nova:\n",
      "x\t=\t[4,1,2,3]\n",
      "y\t=\tsorted(x)\t\t\t\t\t\t\n",
      "#\té\t[1,2,3,4],\tx\tnão\tmudou\n",
      "x.sort()\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tagora\tx\té\t[1,2,3,4]\n",
      "por\tpadrão,\t\n",
      "sort\n",
      "\t(e\t\n",
      "sort\n",
      "ed)\torganizam\tuma\tlista\tda\tmenor\tpara\ta\tmaior\tbaseada\tem\n",
      "uma\tcomparação\tingênua\tde\telementos\tuns\tcom\tos\toutros.\n",
      "se\tvocê\tquer\tque\tos\telementos\tsejam\torganizados\tdo\tmaior\tpara\to\tmenor,\tvocê\n",
      "pode\tespecificar\to\tparâmetro\t\n",
      "reverse=true\n",
      ".\te,\tem\tvez\tde\tcomparar\tos\telementos\n",
      "com\teles\tmesmos,\tcompare\tos\tresultados\tda\tfunção\tque\tvocê\tespecificar\tcom\n",
      "key\n",
      ":\n",
      "#\torganiza\ta\tlista\tpelo\tvalor\tabsoluto\tdo\tmaior\tpara\to\tmenor\n",
      "x\t=\tsorted([-4,1,-2,3],\tkey=abs,\treverse=true)\t\n",
      "#\tis\t[-4,3,-2,1]\n",
      "#\torganiza\tas\tpalavras\te\tcontagens\tda\tmais\talta\tpara\ta\tmais\tbaixa\n",
      "wc\t=\tsorted(word_counts.items(),\n",
      "key=lambda\t(word,\tcount):\tcount,\n",
      "reverse=true)\n",
      "compreensões\tde\tlista\n",
      "com\tfrequência,\tvocê\tvai\tquerer\ttransformar\tuma\tlista\tem\toutra,\tescolhendo\n",
      "apenas\talguns\telementos,\ttransformando\ttais\telementos\tou\tambos.\to\tmodo\n",
      "pythonic\tde\tfazer\tisso\tsão\tas\t\n",
      "compreensões\tde\tlista\n",
      ":\n",
      "even_numbers\t=\t[x\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(5)\t\n",
      "if\n",
      "\tx\t%\t2\t==\t0]\t\t\t\t\n",
      "#\t[0,\t2,\t4]\n",
      "squares\t=\t[x\t*\tx\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(5)]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t[0,\t1,\t4,\t9,\t16]\n",
      "even_squares\t=\t[x\t*\tx\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\teven_numbers]\t\t\t\t\t\t\t\t\t\n",
      "#\t[0,\t4,\t16]\n",
      "você\tpode\ttransformar\tdicionários\tem\tconjuntos\tda\tmesma\tforma:square_dict\t=\t{\tx\t:\tx\t*\tx\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(5)\t}\t\t\t\n",
      "#\t{\t0:0,\t1:1,\t2:4,\t3:9,\t4:16\t}\n",
      "square_set\t=\t{\tx\t*\tx\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\t[1,\t-1]\t}\t\t\t\t\t\t\t\t\t\n",
      "#\t{\t1\t}\n",
      "se\tvocê\tnão\tprecisar\tdo\tvalor\tda\tlista,\té\tcomum\tusar\tum\tsublinhado\tcomo\n",
      "variável:\n",
      "zeroes\t=\t[0\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\teven_numbers]\t\t\t\t\t\t\n",
      "#\tpossui\to\tmesmo\ttamanho\tde\teven_numbers\n",
      "uma\tcompreensão\tde\tlista\tpode\tincluir\tmúltiplos\t\n",
      "for\n",
      ":\n",
      "pairs\t=\t[(x,\ty)\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(10)\n",
      "for\n",
      "\ty\t\n",
      "in\n",
      "\trange(10)]\t\t\t\t\n",
      "#\t100\tpairs\t(0,0)\t(0,1)\t...\t(9,8),\t(9,9)\n",
      "e\tos\tfor\tque\tvêm\tdepois\tpodem\tusar\tos\tresultados\tdos\tprimeiros:\n",
      "increasing_pairs\t=\t[(x,\ty)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tsomente\tpares\tcom\tx\t<\ty\n",
      ",\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trange(10)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\trange(lo,\thi)\té\tigual\ta\n",
      "for\n",
      "\ty\t\n",
      "in\n",
      "\trange(x\t+\t1,\t10)]\t\t\t\t\t\n",
      "#\t[lo,\tlo\t+\t1,\t...,\thi\t-\t1]\n",
      "usaremos\tbastantes\tcompreensões\tde\tlista.\n",
      "geradores\te\titeradores\n",
      "um\tproblema\tcom\tas\tlistas\té\tque\telas\tpodem\tcrescer\tsem\tparar\tfacilmente.\n",
      "range(1000000)\n",
      "\tcria\tuma\tlista\tcom\tum\tmilhão\tde\telementos.\tse\tvocê\tapenas\tprecisa\n",
      "lidar\tcom\teles\tum\tde\tcada\tvez,\tisso\tpode\tser\tuma\tfonte\tinfinita\tde\tineficiência\n",
      "(ou\tesgotamento\tde\tmemória).\tse\tvocê\tprecisar\tde\tpoucos\tvalores,\tcalcular\n",
      "todos\tseria\tuma\tperda\tde\ttempo.\n",
      "um\t\n",
      "gerador\n",
      "\té\talgo\tsobre\to\tqual\tvocê\tpode\titerar\t(para\tnós,\tgeralmente\tusando\n",
      "for\n",
      ")\tmas\tcujos\tvalores\tsão\tproduzidos\tapenas\tquando\tnecessários\n",
      "(\n",
      "preguiçosamente\n",
      ").\n",
      "uma\tforma\tde\tcriar\tgeradores\té\tcom\tfunções\te\to\toperador\t\n",
      "yield\n",
      ":\n",
      "def\n",
      "\tlazy_range(n):\n",
      "\"\"\"uma\tversão\tpreguiçosa\tde\trange\"\"\"\n",
      "i\t=\t0\n",
      "while\n",
      "\ti\t<\tn:\n",
      "yield\n",
      "\ti\n",
      "i\t+=\t1\n",
      "o\tloop\ta\tseguir\tconsumirá\tos\tvalores\t\n",
      "yield\n",
      "\tum\tde\tcada\tvez\taté\tnão\tsobrar\tmais\n",
      "nenhum:\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\tlazy_range(10):do_something_with(i)\n",
      "(o\tpython\tgeralmente\tvem\tcom\tuma\tfunção\t\n",
      "lazy_range\n",
      "\tchamada\t\n",
      "xrange\n",
      "\te,\tem\n",
      "python\t3,\t\n",
      "range\n",
      "\té,\tem\tsi,\tpreguiçoso\t(lazy).)\tisso\tsignifica\tque\tvocê\tpoderia\tcriar\n",
      "uma\tsequência\tinfinita:\n",
      "def\tnatural_numbers():\n",
      "\"\"\"retorna\t1,\t2,\t3,\t...\"\"\"\n",
      "n\t=\t1\n",
      "while\ttrue:\n",
      "yield\tn\n",
      "n\t+=\t1\n",
      "embora\tvocê\tnão\tdeveria\titerar\tsobre\tela\tsem\tusar\talgum\ttipo\tde\tlógica\t\n",
      "break\n",
      ".\n",
      "o\toutro\tlado\tda\tpreguiça\té\tque\tvocê\tsomente\tpode\titerar\tcom\tum\tgerador\tuma\tvez.\tse\n",
      "você\tprecisar\titerar\tmúltiplas\tvezes,\tvocê\tterá\tque\trecriar\tum\tgerador\ttodas\tas\tvezes\tou\n",
      "usar\tuma\tlista.\n",
      "uma\tsegunda\tforma\tde\tcriar\tgeradores\té\tusar\tcompreensões\tde\t\n",
      "for\n",
      "\tdentro\tde\n",
      "parênteses:\n",
      "lazy_evens_below_20\t=\t(i\t\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\tlazy_range(20)\t\n",
      "if\n",
      "\ti\t%\t2\t==\t0)\n",
      "lembre-se\tde\tque\tcada\t\n",
      "dict\n",
      "\tpossui\tum\tmétodo\t\n",
      "items()\n",
      "\tque\tretorna\tuma\tlista\tde\tseus\n",
      "pares\tvalores-chave.\tveremos\tcom\tmais\tfrequência\to\tmétodo\t\n",
      "iteritems()\n",
      ",\tque\n",
      "preguiçosamente\t\n",
      "yield\n",
      "s\t(chama)\tos\tpares\tde\tvalor-chave\tum\tde\tcada\tvez\n",
      "conforme\titeramos\tsobre\tele.\n",
      "aleatoriedade\n",
      "conforme\taprendemos\tdata\tscience,\tprecisaremos\tgerar\tnúmeros\taleatórios\tcom\n",
      "uma\tcerta\tfrequência,\to\tque\tpode\tser\tfeito\tcom\to\tmódulo\t\n",
      "random\n",
      ":\n",
      "import\trandom\n",
      "four_uniform_randoms\t=\t[random.random()\tfor\t_\tin\trange(4)]\n",
      "#\t[0.8444218515250481,\t\t\t\t\t\t#\trandom.random()\tproduz\tnúmeros\n",
      "#\t\t0.7579544029403025,\t\t\t\t\t\t#\tuniformemente\tentre\t0\te\t1\n",
      "#\t\t0.420571580830845,\t\t\t\t\t\t\t#\té\ta\tfunção\taleatória\tque\tusaremos\n",
      "#\t\t0.25891675029296335]\t\t\t\t\t#\tcom\tmais\tfrequênciao\tmódulo\t\n",
      "random\n",
      "\tde\tfato\tproduz\tnúmeros\tpseudoaleatórios\t(ou\tseja,\n",
      "determinísticos)\tbaseado\tem\tum\testado\tinterno\tque\tvocê\tpode\tconfigurar\tcom\n",
      "random.seed\n",
      "\tse\tquiser\tobter\tresultados\treproduzíveis:\n",
      "random.seed(10)\t\t\t\t\t\t\t\t\t\t\n",
      "#\tconfigura\tseed\tpara\t10\n",
      "print\n",
      "\trandom.random()\t\t\t\t\n",
      "#\t0.57140259469\n",
      "random.seed(10)\t\t\t\t\t\t\t\t\t\t\n",
      "#\treinicia\tseed\tpara\t10\n",
      "print\n",
      "\trandom.random()\t\t\t\t\n",
      "#\t0.57140259469\tnovamente\n",
      "às\tvezes\tusaremos\t\n",
      "random.randrange\n",
      ",\tque\tleva\tum\tou\tdois\targumentos\te\tretorna\tum\n",
      "elemento\tescolhido\taleatoriamente\tdo\t\n",
      "range()\n",
      "\tcorrespondente:\n",
      "random.randrange(10)\t\t\t\t\n",
      "#\tescolhe\taleatoriamente\tde\trange(10)\t=\t[0,\t1,\t...,\t9]\n",
      "random.randrange(3,\t6)\t\t\n",
      "#\tescolhe\taleatoriamente\tde\trange(3,\t6)\t=\t[3,\t4,\t5]\n",
      "existem\tmais\talguns\tmétodos\tque\tachamos\tconvenientes\tem\tcertas\tocasiões.\n",
      "random.shuffle\n",
      "\treordena\tos\telementos\tde\tuma\tlista\taleatoriamente:\n",
      "up_to_ten\t=\trange(10)\n",
      "random.shuffle(up_to_ten)\n",
      "print\n",
      "\tup_to_ten\n",
      "#\t[2,\t5,\t1,\t9,\t7,\t3,\t8,\t6,\t4,\t0]\t\t\t(seus\tresultados\tpodem\tser\tdiferentes)\n",
      "se\tvocê\tprecisar\tescolher\tum\telemento\trandomicamente\tde\tuma\tlista,\tvocê\tpode\n",
      "usar\t\n",
      "random.choice\n",
      ":\n",
      "my_best_friend\t=\trandom.choice([\"alice\",\t\"bob\",\t\"charlie\"])\t\t\t\t\n",
      "#\t\"bob\"\tfor\tme\n",
      "e\tse\tvocê\tprecisar\tescolher\taleatoriamente\tuma\tamostra\tdos\telementos\tsem\n",
      "substituição\t(por\texemplo,\tsem\tduplicatas),\tvocê\tpode\tusar\t\n",
      "random.sample:\n",
      "lottery_numbers\t=\trange(60)\n",
      "winning_numbers\t=\trandom.sample(lottery_numbers,\t6)\t\t\n",
      "#\t[16,\t36,\t10,\t6,\t25,\t9]\n",
      "para\tescolher\tuma\tamostra\tde\telementos\tcom\tsubstituição\t(por\texemplo,\n",
      "permitindo\tduplicatas),\tvocê\tpode\tfazer\tmúltiplas\tchamadas\tpara\t\n",
      "random.choice\n",
      ":\n",
      "four_with_replacement\t=\t[random.choice(range(10))\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(4)]\n",
      "#\t[9,\t4,\t4,\t2]\n",
      "expressões\tregulares\n",
      "as\texpressões\tregulares\tfornecem\tuma\tmaneira\tde\tprocurar\tpor\ttexto.\tsão\n",
      "incrivelmente\túteis\tmas\tum\tpouco\tcomplicadas,\ttanto\tque\taté\texistem\tlivros\n",
      "sobre\telas.\texplicaremos\tmais\tdetalhes\tnas\tpoucas\tvezes\tque\tas\tencontrarmos;estes\tsão\talguns\texemplos\tde\tcomo\tusá-las\tem\tpython:\n",
      "import\tre\n",
      "print\n",
      "\tall([\t\t\t\t\n",
      "#\ttodos\tsão\tverdadeiros\tporque\n",
      "not\n",
      "\tre.match(\"a\",\t\"cat\"),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t*\t'cat'\tnão\tcomeça\tcom\t'a'\n",
      "re.search(\"a\",\t\"cat\"),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t*\t'cat'\tpossui\tum\t'a'\n",
      "not\n",
      "\tre.search(\"c\",\t\"dog\"),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t*\t'dog'\tnão\tpossui\tum\t'c'\n",
      "3\t==\tlen(re.split(\"[ab]\",\t\"carbs\")),\t\t\t\t\n",
      "#\t*\tdivide\tem\ta\tou\tb\tpara\t['c','r','s']\n",
      "\"r-d-\"\t==\tre.sub(\"[0-9]\",\t\"-\",\t\"r2d2\")\t\t\n",
      "#\t*\tsubstitui\tdígitos\tpor\ttraços\n",
      "])\t\n",
      "#\timprime\ttrue\n",
      "programação\torientada\ta\tobjeto\n",
      "como\tmuitas\tlinguagens,\to\tpython\tpermite\tque\tvocê\tdefina\t\n",
      "classes\n",
      "\tque\n",
      "encapsulam\tdados\te\tas\tfunções\tque\tas\toperam.\tas\tusaremos\talgumas\tvezes\tpara\n",
      "tornar\tnosso\tcódigo\tmais\tlimpo\te\tsimples.\tprovavelmente\té\tmais\tfácil\texplicá-\n",
      "las\tao\tconstruir\tum\texemplo\trepleto\tde\tanotações.\n",
      "imagine\tque\tnão\ttivéssemos\to\t\n",
      "set\n",
      "\tembutido\tem\tpython.\tportanto,\ttalvez\n",
      "quiséssemos\tcriar\tnossa\tprópria\tclasse\t\n",
      "set\n",
      ".\n",
      "qual\tcomportamento\tnossa\tclasse\tdeveria\tter?\tdado\tum\texemplo\tde\t\n",
      "set\n",
      ",\n",
      "deveremos\tser\tcapazes\tde\t\n",
      "add\n",
      "\t(adicionar)\titens\tnele,\t\n",
      "remove\n",
      "\t(remover)\titens\tdele\te\n",
      "verificar\tse\tele\t\n",
      "contains\n",
      "\t(contém)\tum\tdeterminado\tvalor.\tcriaremos\ttodos\teles\n",
      "como\t\n",
      "funções\tde\tmembro\n",
      ",\to\tque\tsignifica\tque\tos\tacessaremos\tcom\tum\tponto\n",
      "depois\tde\tum\tobjeto\t\n",
      "set\n",
      ":\n",
      "#\tpor\tconvenção,\tdamos\tnomes\tpascalcase\tàs\tclasses\n",
      "class\tset:\n",
      "#\testas\tsão\tas\tfunções\tde\tmembro\n",
      "#\tcada\tuma\tpega\tum\tparâmetro\t“self”\t(outra\tconvenção)\n",
      "#\tque\tse\trefere\tao\tobjeto\tset\tsendo\tusado\tem\tquestão\n",
      "def\t__init__(self,\tvalues=none):\n",
      "\"\"\"este\té\to\tconstrutor\n",
      ".\n",
      "ele\té\tchamado\tquando\tvocê\tcria\tum\tnovo\tset\n",
      ".\n",
      "você\tdeveria\tusá-lo\tcomo\n",
      "s1\t=\tset()\t\t\t\t\t\t\t\t\t\t#\tconjunto\tvazio\n",
      "s2\t=\tset([1,2,2,3])\t#\tinicializa\tcom\tvalores\"\"\"\n",
      "self.dict\t=\t{}\t\n",
      "#\tcada\tinstância\tde\tset\tpossui\tsua\tprópria\tpropriedade\tdict\n",
      "\t\t\t\t\t\t\n",
      "#\tque\té\to\tque\tusaremos\tpara\trastrear\tas\tassociações\n",
      "if\tvalues\tis\tnot\tnone:\n",
      "for\tvalue\tin\tvalues:self.add(value)\n",
      "def\t__repr__(self):\n",
      "\"\"\"esta\té\ta\trepresentação\tda\tstring\tde\tum\tobjeto\tset\n",
      "se\tvocê\tdigitá-la\tno\tprompt\tdo\tpython\tou\tpassá-la\tpara\tstr()\"\"\"\n",
      "return\t\"set:\t\"\t+\tstr(self.dict.keys())\n",
      "#\trepresentaremos\ta\tassociação\tcomo\tuma\tchave\tem\tself.dict\tcom\tvalor\ttrue\n",
      "def\tadd(self,\tvalue):\n",
      "self.dict[value]\t=\ttrue\n",
      "#\tvalor\testá\tno\tset\tse\tele\tfor\tuma\tchave\tno\tdicionário\n",
      "def\tcontains(self,\tvalue):\n",
      "return\tvalue\tin\tself.dict\n",
      "def\tremove(self,\tvalue):\n",
      "del\tself.dict[value]\n",
      "que\tpoderíamos\tusar\tdesta\tforma:\n",
      "s\t=\tset([1,2,3])\n",
      "s.add(4)\n",
      "print\n",
      "\ts.contains(4)\t\t\t\t\n",
      "#\ttrue\n",
      "s.remove(3)\n",
      "print\n",
      "\ts.contains(3)\t\t\t\t\n",
      "#\tfalse\n",
      "ferramentas\tfuncionais\n",
      "ao\tpassar\tas\tfunções,\talgumas\tvezes\tqueremos\taplicá-las\tparcialmente\tpara\tcriar\n",
      "funções\tnovas.\tem\tum\tsimples\texemplo,\timagine\tque\ttemos\tuma\tfunção\tcom\n",
      "duas\tvariáveis:\n",
      "def\n",
      "\texp(base,\tpower):\n",
      "return\n",
      "\tbase\t**\tpower\n",
      "e\tqueremos\tusá-la\tpara\tcriar\tuma\tfunção\tde\tuma\tvariável\t\n",
      "two_to_the\n",
      "\tcuja\tentrada\té\n",
      "um\t\n",
      "power\n",
      "\te\tcuja\tsaída\té\to\tresultado\tde\t\n",
      "exp(2,\tpower)\n",
      ".\n",
      "podemos,\té\tclaro,\tfazer\tisso\tcom\t\n",
      "def\n",
      ",\tmas\tpode\tser\tum\tpouco\tcomplicado:\n",
      "def\n",
      "\ttwo_to_the(power):\n",
      "return\n",
      "\texp(2,\tpower)\n",
      "uma\tabordagem\tdiferente\té\tusar\t\n",
      "functools.partial\n",
      ":\n",
      "from\tfunctools\timport\n",
      "\tpartial\n",
      "two_to_the\t=\tpartial(exp,\t2)\t\t\t\t\n",
      "#\tagora\té\tuma\tfunção\tde\tuma\tvariável\n",
      "print\n",
      "\ttwo_to_the(3)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t8\n",
      "você\ttambém\tpode\tusar\t\n",
      "partial\n",
      "\tpara\tpreencher\tos\targumentos\tque\tvirão\tdepois\tsevocê\tespecificar\tseus\tnomes:\n",
      "square_of\t=\tpartial(exp,\tpower=2)\n",
      "print\n",
      "\tsquare_of(3)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t9\n",
      "começa\ta\tficar\tbagunçado\tquando\tvocê\tadiciona\targumentos\tno\tmeio\tda\tfunção,\n",
      "portanto\ttentaremos\tevitar\tisso.\n",
      "ocasionalmente\tusaremos\t\n",
      "map\n",
      ",\t\n",
      "reduce\n",
      "\te\t\n",
      "filter\n",
      ",\tque\tfornecem\talternativas\tfuncionais\n",
      "para\tas\tcompreensões\tde\tlista:\n",
      "def\tdouble(x):\n",
      "return\t2\t*\tx\n",
      "xs\t=\t[1,\t2,\t3,\t4]\n",
      "twice_xs\t=\t[double(x)\tfor\tx\tin\txs]\t\t\t\t\t\t\t\t\t\n",
      "#\t[2,\t4,\t6,\t8]\n",
      "twice_xs\t=\tmap(double,\txs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tigual\tao\tde\tcima\n",
      "list_doubler\t=\tpartial(map,\tdouble)\t\t\t\t\t\t\t\t\n",
      "#\tfunção\tque\tduplica\ta\tlista\n",
      "twice_xs\t=\tlist_doubler(xs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnovamente\t[2,\t4,\t6,\t8]\n",
      "você\tpode\tusar\t\n",
      "map\n",
      "\tcom\tfunções\tde\tmúltiplos\targumentos\tse\tfornecer\tmúltiplas\n",
      "listas:\n",
      "def\n",
      "\tmultiply(x,\ty):\t\n",
      "return\n",
      "\tx\t*\ty\n",
      "products\t=\tmap(multiply,\t[1,\t2],\t[4,\t5])\t\n",
      "#\t[1\t*\t4,\t2\t*\t5]\t=\t[4,\t10]\n",
      "igualmente,\t\n",
      "filter\n",
      "\tfaz\to\ttrabalho\tde\tuma\tcompreensão\tde\tlista\t\n",
      "if\n",
      ":\n",
      "def\tis_even(x):\n",
      "\"\"\"true\tse\tx\tfor\tpar,\tfalse\tse\tx\tfor\tímpar\"\"\"\n",
      "return\tx\t%\t2\t==\t0\n",
      "x_evens\t=\t[x\tfor\tx\tin\txs\tif\tis_even(x)]\t\t\t\t\t\n",
      "#\t[2,\t4]\n",
      "x_evens\t=\tfilter(is_even,\txs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tigual\tao\tde\tcima\n",
      "list_evener\t=\tpartial(filter,\tis_even)\t\t\t\t\t\t\n",
      "#\tfunção\tque\tfiltra\ta\tlista\n",
      "x_evens\t=\tlist_evener(xs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnovamente\t[2,\t4]\n",
      "reduce\n",
      "\tcombina\tos\tdois\tprimeiros\telementos\tde\tuma\tlista,\tentão\tesse\tresultado\n",
      "com\to\tterceiro\te\tesse\tresultado\tcom\to\tquarto;\te\tassim\tpor\tdiante,\tproduzindo\tum\n",
      "único\tresultado:\n",
      "x_product\t=\treduce(multiply,\txs)\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t=\t1\t*\t2\t*\t3\t*\t4\t=\t24\n",
      "list_product\t=\tpartial(reduce,\tmultiply)\t\t\t\t\n",
      "#\tfunção\tque\treduz\tuma\tlista\n",
      "x_product\t=\tlist_product(xs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnovamente\t=\t24\n",
      "enumeração\t(enumerate)\n",
      "com\talguma\tfrequência,\tvocê\tvai\tquerer\titerar\tpor\tuma\tlista\te\tusar\tseuselementos\te\tseus\tíndices:\n",
      "#\tnão\té\tpythonic\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\trange(len(documents)):\n",
      "document\t=\tdocuments[i]\n",
      "do_something(i,\tdocument)\n",
      "#\ttambém\tnão\té\tpythonic\n",
      "i\t=\t0\n",
      "for\n",
      "\tdocument\t\n",
      "in\n",
      "\tdocuments:\n",
      "do_something(i,\tdocument)\n",
      "i\t+=\t1\n",
      "a\tsolução\tpythonic\té\t\n",
      "enumerate\n",
      "\t(enumerar),\tque\tproduz\ttuplas\t(\n",
      "index,\telement\n",
      "):\n",
      "for\n",
      "\ti,\tdocument\t\n",
      "in\n",
      "\tenumerate(documents):\n",
      "do_something(i,\tdocument)\n",
      "da\tmesma\tforma,\tse\tapenas\tquisermos\tos\tíndices:\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\trange(len(documents)):\tdo_something(i)\t\t\t\t\t\t\n",
      "#\tnão\té\tpythonic\n",
      "for\n",
      "\ti,\t_\t\n",
      "in\n",
      "\tenumerate(documents):\tdo_something(i)\t\t\t\t\n",
      "#\tpythonic\n",
      "usaremos\tisso\tbastante.\n",
      "descompactação\tde\tzip\te\targumentos\n",
      "com\tuma\tcerta\tfrequência,\tprecisaremos\t\n",
      "zip\n",
      "\t(compactar)\tduas\tou\tmais\tlistas\n",
      "juntas.\t\n",
      "zip\n",
      "\ttransforma\tlistas\tmúltiplas\tem\tuma\túnica\tlista\tde\ttuplas\tde\telementos\n",
      "correspondentes:\n",
      "list1\t=\t['a',\t'b',\t'c']\n",
      "list2\t=\t[1,\t2,\t3]\n",
      "zip(list1,\tlist2)\t\t\t\t\t\t\t\t\n",
      "#\té\t[('a',\t1),\t('b',\t2),\t('c',\t3)]\n",
      "se\tas\tlistas\tsão\tde\ttamanhos\tdiferentes,\t\n",
      "zip\n",
      "\tpara\tassim\tque\ta\tprimeira\tlista\tacaba.\n",
      "você\ttambém\tpode\tdescompactar\tuma\tlista\tusando\tum\ttruque\tcurioso:\n",
      "pairs\t=\t[('a',\t1),\t('b',\t2),\t('c',\t3)]\n",
      "letters,\tnumbers\t=\tzip(*pairs)\n",
      "o\tasterisco\tdesempenha\ta\t\n",
      "descompactação\tde\targumento\n",
      ",\tque\tusa\tos\telementos\n",
      "de\t\n",
      "pairs\n",
      "\tcomo\targumentos\tindividuais\tpara\t\n",
      "zip\n",
      ".\tdá\tno\tmesmo\tse\tvocê\tchamasse:\n",
      "zip(('a',\t1),\t('b',\t2),\t('c',\t3))\n",
      "que\tretorna\t\n",
      "[(‘a’,\t’b’,\t’c’),\t(‘1’,\t’2’,\t’3’)].\n",
      "você\tpode\tusar\ta\tdescompactação\tde\targumento\tcom\tqualquer\tfunção:def\n",
      "\tadd(a,\tb):\t\n",
      "return\n",
      "\ta\t+\tb\n",
      "add(1,\t2)\t\t\t\t\t\t\t\n",
      "#\tretorna\t3\n",
      "add([1,\t2])\t\t\t\t\t\n",
      "#\ttypeerror!\n",
      "add(*[1,\t2])\t\t\t\t\n",
      "#\tretorna\t3\n",
      "é\traro\tacharmos\tisso\tútil,\tmas\tquando\tfazemos\té\tum\ttruque\tengenhoso.\n",
      "args\te\tkwargs\n",
      "digamos\tque\tqueremos\tcriar\tuma\tfunção\tde\tordem\talta\tque\ttem\tcomo\tentrada\n",
      "uma\tfunção\t\n",
      "f\n",
      "\te\tretorna\tuma\tfunção\tnova\tque\tretorna\tduas\tvezes\to\tvalor\tde\t\n",
      "f\n",
      "\tpara\n",
      "qualquer\tentrada:\n",
      "def\n",
      "\tdoubler(f):\n",
      "def\n",
      "\tg(x):\n",
      "return\n",
      "\t2\t*\tf(x)\n",
      "return\n",
      "\tg\n",
      "isto\tfunciona\tem\talguns\tcasos:\n",
      "def\n",
      "\tf1(x):\n",
      "\t\t\n",
      "return\n",
      "\tx\t+\t1\n",
      "g\t=\tdoubler(f1)\n",
      "print\n",
      "\tg(3)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t8\t(==\t(\t3\t+\t1)\t*\t2)\n",
      "print\n",
      "\tg(-1)\t\t\t\t\t\t\t\t\t\t\n",
      "#\t0\t(==\t(-1\t+\t1)\t*\t2)\n",
      "no\tentanto,\tele\tfalha\tcom\tfunções\tque\tpossuem\tmais\tde\tum\túnico\targumento:\n",
      "def\n",
      "\tf2(x,\ty):\n",
      "return\n",
      "\tx\t+\ty\n",
      "g\t=\tdoubler(f2)\t\n",
      "print\n",
      "\tg(1,\t2)\t\t\t\t\n",
      "#\ttypeerror:\tg()\tpega\texatamente\t1\targumento\t(2\tdados)\n",
      "o\tque\tprecisamos\té\tde\talguma\tmaneira\tde\tespecificar\tuma\tfunção\tque\tleva\n",
      "argumentos\tarbitrários.\tpodemos\tfazer\tisso\tcom\ta\tdescompactação\tde\targumento\n",
      "e\tum\tpouco\tde\tmágica:\n",
      "def\tmagic(*args,\t**kwargs):\n",
      "print\t\"unnamed\targs:\",\targs\n",
      "print\t\"keyword\targs:\",\tkwargs\n",
      "magic(1,\t2,\tkey=\"word\",\tkey2=\"word2\")\n",
      "#\timprime\n",
      "#\tunnamed\targs:\t(1,\t2)\n",
      "#\tkeyword\targs:{'key2':\t'word2',\t'key':\t'word'}\n",
      "ou\tseja,\tquando\tdefinimos\tuma\tfunção\tcomo\tessa,\t\n",
      "args\n",
      "\té\tuma\ttupla\tdos\tseusargumentos\tsem\tnome\te\t\n",
      "kwargs\n",
      "\té\tum\t\n",
      "dict\n",
      "\tdos\tseus\targumentos\tcom\tnome.\n",
      "funciona\tda\tforma\tcontrária\ttambém,\tse\tvocê\tquiser\tusar\tuma\t\n",
      "list\n",
      "\t(ou\t\n",
      "tuple\n",
      ")\te\t\n",
      "dict\n",
      "para\t\n",
      "fornecer\n",
      "\targumentos\tpara\tuma\tfunção:\n",
      "def\n",
      "\tother_way_magic(x,\ty,\tz):\n",
      "return\n",
      "\tx\t+\ty\t+\tz\n",
      "x_y_list\t=\t[1,\t2]\n",
      "z_dict\t=\t{\t\"z\"\t:\t3\t}\n",
      "print\n",
      "\tother_way_magic(*x_y_list,\t**z_dict)\t\n",
      "#\t6\n",
      "você\tpoderia\tfazer\ttodos\tos\ttipos\tde\ttruques\tcom\tisso;\tapenas\tusaremos\tpara\n",
      "produzir\toutras\tfunções\tde\tordem\talta\tcujas\tentradas\tpodem\taceitar\targumentos\n",
      "arbitrários:\n",
      "def\tdoubler_correct(f):\n",
      "\"\"\"funciona\tnão\timporta\tque\ttipo\tde\tentradas\tf\tespera\"\"\"\n",
      "def\tg(*args,\t**kwargs):\n",
      "\"\"\"quaisquer\targumentos\tcom\tos\tquais\tg\té\tfornecido,\tos\tpassa\tpara\tf\"\"\"\n",
      "return\t2\t*\tf(*args,\t**kwargs)\n",
      "return\tg\n",
      "g\t=\tdoubler_correct(f2)\n",
      "print\tg(1,\t2)\t\n",
      "#\t6\n",
      "bem-vindo\tà\tdatasciencester!\n",
      "concluímos\taqui\to\ttreinamento\tdos\tfuncionários\tnovos.\tah,\te\ttambém,\ttente\tnão\n",
      "surrupiar\tnada.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "não\thá\tescassez\tde\ttutoriais\tde\tpython\tno\tmundo.\to\tsite\toficial\n",
      "(\n",
      "https://docs.python.org/2/tutorial/\n",
      ")\tnão\té\tum\tlugar\truim\tpara\tcomeçar.\n",
      "o\ttutorial\toficial\tipython\t(\n",
      "http://ipython.org/ipython-\n",
      "doc/2/interactive/tutorial.html\n",
      ")\tnão\té\ttão\tbom.\tvocê\ttalvez\tprefira\tassistir\n",
      "aos\tvídeos\te\tàs\tapresentações\t(\n",
      "http://ipython.org/videos.html\n",
      ").\tcomo\n",
      "alternativa,\t\n",
      "python\tfor\tdata\tanalysis\n",
      "\t(o'reilly)\tdo\twes\tmckinney\tpossui\n",
      "um\tótimo\tcapítulo\tsobre\tipython.•\n",
      "•\n",
      "capítulo\t3\n",
      "visualizando\tdados\n",
      "acredito\tque\ta\tvisualização\tseja\tum\tdos\tmeios\tmais\tpoderosos\tde\tatingir\tmetas\tpessoais\n",
      ".\n",
      "—harvey\tmackay\n",
      "uma\tparte\tfundamental\tdo\tkit\tde\tferramentas\tdo\tcientista\tde\tdados\té\ta\n",
      "visualização\tde\tdados.\tembora\tseja\tmuito\tfácil\tcriar\tvisualizações,\té\tbem\tmais\n",
      "difícil\tproduzir\talgumas\t\n",
      "boas\n",
      ".\n",
      "existem\tdois\tusos\tprimários\tpara\ta\tvisualização\tde\tdados:\n",
      "para\t\n",
      "explorar\n",
      "\tdados\n",
      "para\t\n",
      "comunicar\n",
      "\tdados\n",
      "neste\tcapítulo,\tnos\tconcentraremos\tem\tconstruir\thabilidades\tdas\tquais\tvocê\n",
      "precisará\tpara\tcomeçar\ta\texplorar\tseus\tpróprios\tdados\te\tproduzir\tas\n",
      "visualizações\tque\tusaremos\tno\tdecorrer\tdo\tlivro.\tcomo\ta\tmaioria\tdos\tnossos\n",
      "tópicos\tdo\tcapítulo,\ta\tvisualização\tde\tdados\té\tuma\trica\tárea\tde\testudos\tque\n",
      "merece\tseu\tpróprio\tlivro.\tmas,\tmesmo\tassim,\ttentaremos\tmostrar\to\tque\té\tpreciso\n",
      "e\to\tque\tnão\té\tpara\tuma\tboa\tvisualização.matplotlib\n",
      "existe\tuma\tgrande\tvariedade\tde\tferramentas\tpara\tvisualizar\tdados.\tusaremos\ta\n",
      "biblioteca\t\n",
      "matplotlib\n",
      "\t\n",
      "(\n",
      "http://matplotlib.org/\n",
      ")\n",
      ",\tque\té\taltamente\tusada\t(apesar\tde\tsua\n",
      "idade).\tse\tvocê\testiver\tinteressado\tem\tproduzir\telaboradas\tvisualizações\n",
      "interativas\tpara\ta\tweb,\tprovavelmente\tnão\tserá\ta\tmelhor\tescolha\tmas,\tpara\n",
      "simples\tgráficos\tde\tbarras,\tde\tlinhas\te\tde\tdispersão,\tfunciona\tmuito\tbem.\n",
      "na\tverdade,\tusaremos\to\tmódulo\t\n",
      "matplotlib.pyplot\n",
      ".\tem\tseu\tsimples\tuso,\t\n",
      "pyplot\n",
      "mantém\tum\testado\tinterno\tem\tque\tvocê\tconstrói\tuma\tvisualização\tpasso\ta\tpasso.\n",
      "ao\tterminar,\tvocê\tpode\tsalvá-la\t(com\t\n",
      "savefig()\n",
      ")\tou\texibi-la\t(com\t\n",
      "show()\n",
      ").\n",
      "por\texemplo,\tfazer\tum\tgráfico\tsimples\t(como\ta\t\n",
      "figura\t3-1\n",
      ")\té\tbem\tfácil:\n",
      "from\tmatplotlib\timport\tpyplot\tas\tplt\n",
      "years\t=\t[1950,\t1960,\t1970,\t1980,\t1990,\t2000,\t2010]\n",
      "gdp\t=\t[300.2,\t543.3,\t1075.9,\t2862.5,\t5979.6,\t10289.7,\t14958.3]\n",
      "#\tcria\tum\tgráfico\tde\tlinha,\tanos\tno\teixo\tx,\tgdp\tno\teixo\ty\n",
      "plt.plot(years,\tgdp,\tcolor='green',\tmarker='o',\tlinestyle='solid')\n",
      "#\tadiciona\tum\ttítulo\n",
      "plt.title(\"gdp\tnominal\")\n",
      "#\tadiciona\tum\tselo\tno\teixo\ty\n",
      "plt.ylabel(\"bilhões\tde\t$\")\n",
      "plt.show()figura\t3-1.\tum\tgráfico\tde\tlinha\tsimples\n",
      "construir\tgráficos\tque\tpossuam\tuma\tboa\tqualidade\tde\timagem\té\tmais\n",
      "complicado\te\testá\talém\tdo\tescopo\tdeste\tcapítulo.\texistem\tdiversas\tmaneiras\tde\n",
      "personalizar\tseus\tgráficos\tcom\trótulos\tde\teixos,\testilos\tde\tlinha\te\tmarcadores\tde\n",
      "ponto,\tpor\texemplo.\tem\tvez\tde\tpassar\tpor\tum\ttratamento\tde\tcompreensão\tcom\n",
      "essas\topções,\tapenas\tusaremos\t(e\tchamaremos\tà\tatenção)\talguns\tdeles\tem\n",
      "nossos\texemplos.\n",
      "embora\tnão\tusemos\tmuito\tdessa\tfuncionalidade,\t\n",
      "matplotlib\n",
      "\té\tcapaz\tde\tproduzir\n",
      "gráficos\tcomplicados\tdentro\tde\tgráficos,\tformatação\tsofisticada\te\tvisualizações\n",
      "interativas.\tverifique\tsua\tdocumentação\tcaso\tqueira\tse\taprofundar\tmais\tdo\tque\n",
      "apresentamos\tneste\tlivro.gráficos\tde\tbarra\n",
      "um\tgráfico\tde\tbarra\té\tuma\tboa\tescolha\tquando\tvocê\tquer\tmostrar\tcomo\talgumas\n",
      "quantidades\tvariam\tentre\tum\tconjunto\t\n",
      "particular\n",
      "\tde\titens.\tpor\texemplo,\ta\t\n",
      "figura\n",
      "3-2\n",
      "\tmostra\tquantas\tpremiações\tdo\toscar\tcada\tuma\tdas\tvariedades\tdos\tfilmes\n",
      "ganharam:\n",
      "movies\t=\t[\"annie\thall\",\t\"ben-hur\",\t\"casablanca\",\t\"gandhi\",\t\"west\tside\tstory\"]\n",
      "num_oscars\t=\t[5,\t11,\t3,\t8,\t10]\n",
      "#\tbarras\tpossuem\to\ttamanho\tpadrão\tde\t0.8,\tentão\tadicionaremos\t0.1\tàs\n",
      "#\tcoordenadas\tà\tesquerda\tpara\tque\tcada\tbarra\tseja\tcentralizada\n",
      "xs\t=\t[i\t+\t0.1\tfor\ti,\t_\tin\tenumerate(movies)]\n",
      "#\tas\tbarras\tdo\tgráfico\tcom\tas\tcoordenadas\tx\tà\tesquerda\t[xs],\talturas\t[num_oscars]\n",
      "plt.bar(xs,\tnum_oscars)\n",
      "plt.ylabel(\"#\tde\tpremiações\")\n",
      "plt.title(\"meus\tfilmes\tfavoritos\")\n",
      "#\tnomeia\to\teixo\tx\tcom\tnomes\tde\tfilmes\tna\tbarra\tcentral\n",
      "plt.xticks([i\t+\t0.5\tfor\ti,\t_\tin\tenumerate(movies)],\tmovies)\n",
      "plt.show()figura\t3-2.\tum\tgráfico\tde\tbarra\tsimples\n",
      "um\tgráfico\tde\tbarra\ttambém\tpode\tser\tuma\tboa\tescolha\tpara\tcriar\tgráficos\tde\n",
      "histogramas\tde\tvalores\tnuméricos\tcarregados,\ta\tfim\tde\texplorar\tvisualmente\n",
      "como\tos\tvalores\tsão\t\n",
      "distribuídos\n",
      ",\tcomo\tna\t\n",
      "figura\t3-3\n",
      ":\n",
      "grades\t=\t[83,95,91,87,70,0,85,82,100,67,73,77,0]\n",
      "decile\t=\tlambda\tgrade:\tgrade\t//\t10\t*\t10\n",
      "histogram\t=\tcounter(decile(grade)\tfor\tgrade\tin\tgrades)\n",
      "plt.bar([x\t-\t4\tfor\tx\tin\thistogram.keys()],\t\t\n",
      "#\tmove\tcada\tbarra\tpara\ta\tesquerda\tem\t4\n",
      "\thistogram.values(),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdá\tpara\tcada\tbarra\tsua\taltura\tcorreta\n",
      "\t8)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdá\tpara\tcada\tbarra\ta\tlargura\tde\t8\n",
      "plt.axis([-5,\t105,\t0,\t5])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\teixo\tx\tde\t–5\taté\t105\n",
      ",\n",
      "#\teixo\ty\tde\t0\taté\t5\n",
      "plt.xticks([10\t*\ti\tfor\ti\tin\trange(11)])\t\t\t\t\t\n",
      "#\trótulos\tdo\teixo\tx\tem\t0,\t10,\t…,\t100\n",
      "plt.xlabel(\"decil\")\n",
      "plt.ylabel(\"#\tde\talunos\")\n",
      "plt.title(\"distribuição\tdas\tnotas\tdo\tteste\t1\")\n",
      "plt.show()figura\t3-3.\tusando\tum\tgráfico\tde\tbarra\tpara\tum\thistograma\n",
      "o\tterceiro\targumento\tpara\t\n",
      "plt.bar\n",
      "\tespecifica\ta\tlargura\tda\tbarra.\taqui,\tescolhemos\n",
      "a\tlargura\t8\t(o\tque\tdeixa\tum\tespaço\tpequeno\tentre\tas\tbarras,\tjá\tque\tnosso\n",
      "agrupamento\tpossui\to\ttamanho\t10).\tandamos\tcom\ta\tbarra\tem\t4,\tpara\tque\t(por\n",
      "exemplo)\ta\tbarra\t“80”\ttenha\tseu\tlado\tesquerdo\te\tdireito\tem\t76\te\t84,\te\t(portanto)\n",
      "seu\tcentro\tem\t80.\n",
      "a\tchamada\tpara\t\n",
      "plt.axis\n",
      "\tindica\tque\tqueremos\tque\to\teixo\tx\tvarie\tentre\t–5\taté\t105\n",
      "(para\tque\tas\tbarras\t“0”\te\t“100”\tsejam\tmostradas\tpor\tcompleto),\te\tque\to\teixo\ty\n",
      "deveria\tvariar\tde\t0\taté\t5.\ta\tchamada\tpara\t\n",
      "plt.xticks\n",
      "\tcoloca\tos\trótulos\tdo\teixo\tx\tem\n",
      "0,\t10,\t20,\t…,\t100.\n",
      "seja\tcriterioso\tquando\tusar\t\n",
      "plt.axis()\n",
      ".\tao\tcriar\tgráficos\tde\tbarra,\tnão\tcomeçar\to\n",
      "eixo\ty\tem\t0\té\tconsiderado\truim,\tjá\tque\tessa\té\tuma\tmaneira\tfácil\tde\tenganar\tas\n",
      "pessoas\t(\n",
      "figura\t3-4\n",
      "):\n",
      "mentions\t=\t[500,\t505]years\t=\t[2013,\t2014]\n",
      "plt.bar([2012.6,\t2013.6],\tmentions,\t0.8)\n",
      "plt.xticks(years)\n",
      "plt.ylabel(\"#\tde\tvezes\tque\touvimos\talguém\tdizer\t'data\tscience'\")\n",
      "#\tse\tvocê\tnão\tfizer\tisso,\tmatplotlib\tnomeará\to\teixo\tx\tde\t0,\t1\n",
      "#\te\tentão\tadiciona\ta\t+2.013e3\tpara\tfora\tdo\tcanto\t(matplotlib\tfeio!)\n",
      "plt.ticklabel_format(useoffset=false)\n",
      "#\tenganar\to\teixo\ty\tmostra\tapenas\ta\tparte\tacima\tde\t500\n",
      "plt.axis([2012.5,2014.5,499,506])\n",
      "plt.title(\"olhe\to\t\"grande\"\taumento!\")\n",
      "plt.show()\n",
      "figura\t3-4.\tum\tgráfico\tcom\tum\teixo\ty\tenganador\n",
      "na\t\n",
      "figura\t3-5\n",
      ",\tusamos\teixos\tmais\tsensatos\te,\tagora,\tparece\tmenos\n",
      "impressionante:\n",
      "plt.axis([2012.5,2014.5,0,550])\n",
      "plt.title(\"não\ttão\tgrande\tagora\")\n",
      "plt.show()figura\t3-5.\to\tmesmo\tgráfico\tsem\tum\teixo\ty\tenganadorgráficos\tde\tlinhas\n",
      "como\tjá\thavíamos\tdito,\tpodemos\tconstruir\tgráficos\tde\tlinha\tusando\t\n",
      "plt.plot()\n",
      ".\teles\n",
      "são\tuma\tboa\tescolha\tao\tmostrar\ttendências,\tcomo\ta\t\n",
      "figura\t3-6\n",
      "\tilustra:\n",
      "variance\t\t\t\t\t=\t[1,\t2,\t4,\t8,\t16,\t32,\t64,\t128,\t256]\n",
      "bias_squared\t=\t[256,\t128,\t64,\t32,\t16,\t8,\t4,\t2,\t1]\n",
      "total_error\t\t=\t[x\t+\ty\tfor\tx,\ty\tin\tzip(variance,\tbias_squared)]\n",
      "xs\t=\t[i\tfor\ti,\t_\tin\tenumerate(variance)]\n",
      "#\tpodemos\tfazer\tmúltiplas\tchamadas\tpara\tplt.plot\n",
      "#\tpara\tmostrar\tmúltiplas\tséries\tno\tmesmo\tgráfico\n",
      "plt.plot(xs,\tvariance,\t'g-',\tlabel='variance')\t\t\t\t\t\t\t\n",
      "#\tlinha\tverde\tsólida\n",
      "plt.plot(xs,\tbias_squared,\t'r-.',\tlabel='bias^2')\t\t\t\t\n",
      "#\tlinha\tcom\tlinha\tde\tponto\ttracejado\tvermelho\n",
      "plt.plot(xs,\ttotal_error,\t'b:',\tlabel='total\terror')\t\n",
      "#\tlinha\tcom\tpontilhado\tazul\n",
      "#\tporque\tatribuímos\trótulos\tpara\tcada\tsérie\n",
      "#\tpodemos\tobter\tuma\tlegenda\tgratuita\n",
      "#\tloc=9\tsignifica\t“top\tcenter”\n",
      "plt.legend(loc=9)\n",
      "plt.xlabel(\"complexidade\tdo\tmodelo\")\n",
      "plt.title(\"compromisso\tentre\tpolarização\te\tvariância\")\n",
      "plt.show()figura\t3-6.\tvários\tgráficos\tde\tlinha\tcom\tuma\tlegendagráficos\tde\tdispersão\n",
      "um\tgráfico\tde\tdispersão\té\ta\tescolha\tcerta\tpara\tvisualizar\to\trelacionamento\tentre\n",
      "dois\tpares\tde\tconjuntos\tde\tdados.\tpor\texemplo,\ta\t\n",
      "figura\t3-7\n",
      "\tilustra\to\n",
      "relacionamento\tentre\to\tnúmero\tde\tamigos\tque\tseus\tusuários\ttêm\te\to\tnúmero\tde\n",
      "minutos\tque\teles\tpassam\tno\tsite\tpor\tdia:\n",
      "friends\t=\t[\t70,\t65,\t72,\t63,\t71,\t64,\t60,\t64,\t67]\n",
      "minutes\t=\t[175,\t170,\t205,\t120,\t220,\t130,\t105,\t145,\t190]\n",
      "labels\t=\t['a',\t'b',\t'c',\t'd',\t'e',\t'f',\t'g',\t'h',\t'i']\n",
      "plt.scatter(friends,\tminutes)\n",
      "#\tnomeia\tcada\tposição\n",
      "for\tlabel,\tfriend_count,\tminute_count\tin\tzip(labels,\tfriends,\tminutes):\n",
      "plt.annotate(label,\n",
      "xy=(friend_count,\tminute_count),\t\n",
      "#\tcoloca\to\trótulo\tcom\tsua\tposição\n",
      "xytext=(5,\t-5),\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tmas\tcompensa\tum\tpouco\n",
      "textcoords='offset\tpoints')\n",
      "plt.title(\"minutos\tdiários\tvs.\tnúmero\tde\tamigos\")\n",
      "plt.xlabel(\"#\tde\tamigos\")\n",
      "plt.ylabel(\"minutos\tdiários\tpassados\tno\tsite\")\n",
      "plt.show()figura\t3-7.\tuma\tdispersão\tde\tamigos\te\ttempo\tno\tsite\n",
      "se\tvocê\testá\tespalhando\tvariáveis\tcomparáveis,\ttalvez\tvocê\tobtenha\tuma\n",
      "imagem\tenganosa\tse\tdeixar\tmatplotlib\tescolher\ta\tescala,\tcomo\tna\t\n",
      "figura\t3-8\n",
      ":\n",
      "test_1_grades\t=\t[\t99,\t90,\t85,\t97,\t80]\n",
      "test_2_grades\t=\t[100,\t85,\t60,\t90,\t70]\n",
      "plt.scatter(test_1_grades,\ttest_2_grades)\n",
      "plt.title(\"os\teixos\tnão\tsão\tcompatíveis\")\n",
      "plt.xlabel(\"nota\tdo\tteste\t2\")\tplt.ylabel(\"nota\tdo\tteste\t1\")\n",
      "plt.show()figura\t3-8.\tum\tgráfico\tde\tdispersão\tcom\teixos\tincompatíveis\n",
      "se\tincluirmos\tuma\tchamada\tpara\t\n",
      "plt.axis\n",
      "(\n",
      "“equals”\n",
      "),\to\tgráfico\t(\n",
      "figura\t3-9\n",
      ")\tmais\n",
      "preciso\tmostra\tque\ta\tmaior\tparte\tda\tvariação\tacontece\tno\tteste\t2.\n",
      "é\to\tsuficiente\tpara\tvocê\tcomeçar\ta\tcriar\tvisualizações.\taprenderemos\tmuito\n",
      "mais\tsobre\tvisualização\tno\tdecorrer\tdo\tlivro.figura\t3-9.\to\tmesmo\tgráfico\tde\tdispersão\tcom\teixos\tiguais•\n",
      "•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "seaborn\t(\n",
      "http://stanford.io/1ycojdi\n",
      ")\té\tconstruído\tno\ttopo\tde\t\n",
      "matplotlib\n",
      "\te\n",
      "permite\tque\tvocê\tproduza\tfacilmente\tvisualizações\tmais\tbonitas\t(e\tmais\n",
      "complexas).\n",
      "d3.js\t(\n",
      "http://d3js.org\n",
      ")\té\tuma\tbiblioteca\tjavascript\tque\tproduz\n",
      "visualizações\tinterativas\tsofisticadas\tpara\ta\tweb.\tembora\tnão\testeja\tem\n",
      "python,\té\tuma\ttendência\te\tamplamente\tusada,\te\tvale\ta\tpena\tse\tfamiliarizar\n",
      "com\tela.\n",
      "bokeh\t(\n",
      "http://bokeh.pydata.org\n",
      ")\té\ta\tbiblioteca\tmais\tnova\tque\ttraz\to\testilo\n",
      "de\tvisualização\td3\tpara\tpython.\n",
      "ggplot\t(\n",
      "http://bit.ly/1ycok1u\n",
      ")\té\tuma\tportagem\tpython\tda\tpopular\n",
      "biblioteca\t\n",
      "ggplot2\n",
      ",\tque\té\tamplamente\tusada\tpara\tcriar\tgráficos\te\tdiagramas\n",
      "de\t“qualidade\tde\tpublicação”.\tprovavelmente,\té\tmais\tinteressante\tse\tvocê\n",
      "já\té\tum\tusuário\tvoraz\tde\t\n",
      "ggplot2\n",
      "\te\tum\tpouco\topaco\tse\tnão\té.capítulo\t4\n",
      "álgebra\tlinear\n",
      "existe\talgo\tmais\tinútil\tou\tmenos\tútil\tque\tálgebra?\n",
      "—billy\tconnolly\n",
      "a\tálgebra\tlinear\té\to\tramo\tda\tmatemática\tque\tlida\tcom\t\n",
      "espaços\tvetoriais\n",
      ".\n",
      "apesar\tde\teu\tnão\tachar\tque\tvou\tconseguir\tensinar\tálgebra\tlinear\tem\tum\tcapítulo,\n",
      "ela\tsustenta\tum\tgrande\tnúmero\tde\tconceitos\te\ttécnicas\tde\tdata\tscience,\to\tque\n",
      "significa\tque\teu\tdevo\ta\tvocê,\tao\tmenos,\tuma\ttentativa.\to\tque\taprenderemos\n",
      "neste\tcapítulo,\tusaremos\texcessivamente\tno\tdecorrer\tdo\tlivro.vetores\n",
      "abstratamente,\tos\t\n",
      "vetores\n",
      "\tsão\tobjetos\tque\tpodem\tser\tsomados\tjuntos\t(para\n",
      "formar\tvetores\tnovos)\te\tque\tpodem\tser\tmultiplicados\tpelos\t\n",
      "escalares\n",
      "\t(por\n",
      "exemplo,\tnúmeros),\ttambém\tpara\tformar\tvetores\tnovos.\n",
      "concretamente\t(para\tnós),\tos\tvetores\tsão\tpontos\tem\talgum\tespaço\tde\tdimensão\n",
      "finita.\tapesar\tde\tvocê\tnão\tpensar\tem\tseus\tdados\tcomo\tvetores,\teles\tsão\tuma\n",
      "ótima\tmaneira\tde\trepresentar\tdados\tnuméricos.\n",
      "por\texemplo,\tse\tvocê\ttiver\tas\talturas,\tpesos\te\tidades\tde\tuma\tgrande\tquantidade\n",
      "de\tpessoas,\tpode\ttratar\tseus\tdados\tcomo\tvetores\ttridimensionais\t(\n",
      "height\n",
      ",\t\n",
      "weight\n",
      ",\n",
      "age\n",
      ").\tse\tvocê\testiver\tensinando\tuma\tturma\tcom\tquatro\ttestes,\tpode\ttratar\tas\tnotas\n",
      "dos\talunos\tcomo\tvetores\tquadridimensionais\t(\n",
      "exam1\n",
      ",\t\n",
      "exam2\n",
      ",\t\n",
      "exam3\n",
      ",\t\n",
      "exam4\n",
      ").\n",
      "a\tabordagem\tinicial\tmais\tsimples\té\trepresentar\tvetores\tcomo\tlistas\tde\tnúmeros.\n",
      "uma\tlista\tde\ttrês\tnúmeros\tcorresponde\ta\tum\tvetor\tem\tum\tespaço\ttridimensional,\n",
      "e\tvice-versa:\n",
      "height_weight_age\t=\t[70,\t\t\t\n",
      "#\tpolegadas\n",
      ",\n",
      "\t\t\t\t\t\t170,\t\n",
      "#\tquilos\n",
      ",\n",
      "\t\t\t\t\t\t40\t]\t\n",
      "#\tanos\n",
      "grades\t=\t[95,\t\t\t\n",
      "#\tteste1\n",
      "\t\t\t80,\t\t\t\n",
      "#\tteste2\n",
      "\t\t\t75,\t\t\t\n",
      "#\tteste3\n",
      "\t\t\t62\t]\t\t\n",
      "#\tteste4\n",
      "um\tproblema\tcom\tessa\tabordagem\té\tque\tqueremos\trealizar\t\n",
      "aritmética\n",
      "\tnos\n",
      "vetores.\tcomo\tas\tlistas\tde\tpython\tnão\tsão\tvetores\t(e,\tportanto,\tnão\tfacilita\ta\n",
      "aritmética\tcom\to\tvetor),\tprecisaremos\tconstruir\tessas\tferramentas\taritméticas\tnós\n",
      "mesmos.\tentão,\tvamos\tcomeçar\tpor\taí.\n",
      "para\tcomeçar,\tfrequentemente\tprecisaremos\tde\tdois\tvetores.\tos\tvetores\tse\n",
      "adicionam\tcomponente\ta\tcomponente.\tisso\tsignifica\tque,\tse\tdois\tvetores\t\n",
      "v\n",
      "\te\t\n",
      "w\n",
      "possuem\to\tmesmo\ttamanho,\tsua\tsoma\té\tsomente\to\tvetor\tcujo\tprimeiro\telemento\n",
      "seja\t\n",
      "v[0]\t+\tw[0]\n",
      ",\tcujo\tsegundo\telemento\tseja\t\n",
      "v[1]\t+\tw[1]\n",
      ",\te\tassim\tpor\tdiante.\t(se\teles\n",
      "não\tpossuírem\to\tmesmo\ttamanho,\tentão\tnão\tpoderemos\tsomá-los.)\n",
      "por\texemplo,\tsomar\tos\tvetores\t\n",
      "[1,\t2]\n",
      "\te\t\n",
      "[2,\t1]\n",
      "\tresulta\tem\t\n",
      "[1\t+\t2,\t2\t+\t1]\n",
      "\tou\t\n",
      "[3,\t3]\n",
      ",\tcomomostra\ta\t\n",
      "figura\t4-1\n",
      ".\n",
      "figura\t4-1.\tsomando\tdois\tvetores\n",
      "podemos\tfacilmente\timplementar\tisso\tcom\tvetores\t\n",
      "zip\n",
      "\tjuntos\te\tusar\tuma\n",
      "compreensão\tde\tlista\tpara\tadicionar\tos\telementos\tcorrespondentes:\n",
      "def\n",
      "\tvector_add(v,\tw):\n",
      "\"\"\"soma\telementos\tcorrespondentes\"\"\"\n",
      "return\n",
      "\t[v_i\t+\tw_i\n",
      "\t\n",
      "for\n",
      "\tv_i,\tw_i\t\n",
      "in\n",
      "\tzip(v,\tw)]\n",
      "da\tmesma\tforma,\tpara\tsubtrair\tdois\tvetores,\tapenas\tsubtraia\tos\telementos\n",
      "correspondentes:\n",
      "def\n",
      "\tvector_subtract(v,\tw):\n",
      "\"\"\"subtrai\telementos\tcorrespondentes\"\"\"\n",
      "return\n",
      "\t[v_i\t-\tw_i\n",
      "\t\n",
      "for\n",
      "\tv_i,\tw_i\t\n",
      "in\n",
      "\tzip(v,\tw)]\n",
      "às\tvezes\tqueremos\tsomar\tuma\tlista\tde\tvetores.\tou\tseja,\tcriar\tum\tvetor\tnovo\n",
      "cujo\tprimeiro\telemento\tseja\ta\tsoma\tde\ttodos\tos\tprimeiros\telementos,\tcujosegundo\telemento\tseja\ta\tsoma\tde\ttodos\tos\tsegundos\telementos,\te\tassim\tpor\n",
      "diante.\ta\tmaneira\tmais\tfácil\tde\tfazer\tisso\té\tadicionar\tum\tvetor\tde\tcada\tvez:\n",
      "def\tvector_sum(vectors):\n",
      "\"\"\"soma\ttoda\tos\telementos\tcorrespondentes\"\"\"\n",
      "result\t=\tvectors[0]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcomeça\tcom\to\tprimeiro\tvetor\n",
      "for\tvector\tin\tvectors[1:]:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdepois\tpassa\tpor\ttodos\tos\toutros\n",
      "result\t=\tvector_add(result,\tvector)\t\t\t\t\t\t\n",
      "#\te\tos\tadiciona\tao\tresultado\n",
      "return\tresult\n",
      "se\tvocê\tpensar\ta\trespeito,\testamos\tapenas\treduzindo\t(\n",
      "reducing\n",
      ")\ta\tlista\tde\tvetores\n",
      "usando\t\n",
      "vector_\tadd\n",
      ",\to\tque\tsignifica\tque\tpodemos\treescrever\tde\tforma\treduzida\n",
      "usando\tfunções\tde\talta\tordem:\n",
      "def\n",
      "\tvector_sum(vectors):\n",
      "\t\n",
      "return\n",
      "\treduce(vector_add,\tvectors)\n",
      "ou\taté\tmesmo:\n",
      "vector_sum\t=\tpartial(reduce,\tvector_add)\n",
      "embora\tesse\túltimo\tseja\tmais\tesperto\tdo\tque\tútil.\n",
      "também\tprecisaremos\tser\tcapazes\tde\tmultiplicar\tum\tvetor\tpor\tum\tescalar,\tque\n",
      "simplesmente\tfazemos\tao\tmultiplicar\tcada\telemento\tdo\tvetor\tpor\taquele\tnúmero:\n",
      "def\n",
      "\tscalar_multiply(c,\tv):\n",
      "\"\"\"c\té\tum\tnúmero,\tv\té\tum\tvetor\"\"\"\n",
      "return\n",
      "\t[c\t*\tv_i\t\n",
      "for\n",
      "\tv_i\t\n",
      "in\n",
      "\tv]\n",
      "isso\tpermite\tque\tcomputemos\ta\tmédia\tde\tuma\tlista\tde\tvetores\t(do\tmesmo\n",
      "tamanho):\n",
      "def\tvector_mean(vectors):\n",
      "\"\"\"computar\to\tvetor\tcujo\ti-ésimo\telemento\tseja\ta\tmédia\tdos\n",
      "i-ésimos\telementos\tdos\tvetores\tinclusos\"\"\"\n",
      "n\t=\tlen(vectors)\n",
      "return\tscalar_multiply(1/n,\tvector_sum(vectors))\n",
      "uma\tferramenta\tmenos\tóbvia\té\to\t\n",
      "produto\tescalar\n",
      "\t(\n",
      "dot\tproduct\n",
      ").\to\tproduto\n",
      "escalar\tde\tdois\tvetores\té\ta\tsoma\tde\tseus\tprodutos\tcomponente\ta\tcomponente:\n",
      "def\n",
      "\tdot(v,\tw):\n",
      "\"\"\"v_1\t*\tw_1\t+\t...\t+\tv_n\t*\tw_n\"\"\"\n",
      "return\n",
      "\tsum(v_i\t*\tw_i\n",
      "for\n",
      "\tv_i,\tw_i\t\n",
      "in\n",
      "\tzip(v,\tw))o\tproduto\tescalar\tmede\ta\tdistância\ta\tqual\to\tvetor\t\n",
      "v\n",
      "\tse\testende\tna\tdireção\tde\t\n",
      "w\n",
      ".\n",
      "por\texemplo,\tse\t\n",
      "w\t=\t[1,\t0]\n",
      "\tentão\t\n",
      "dot(v,\tw)\n",
      "\té\to\tprimeiro\tcomponente\tde\t\n",
      "v\n",
      ".\toutra\tforma\n",
      "de\tdizer\tisso\té\tque\tesse\té\to\ttamanho\tdo\tvetor\tque\tvocê\tteria\tse\tprojetasse\t\n",
      "v\n",
      "\tem\t\n",
      "w\n",
      "(\n",
      "figura\t4-2\n",
      ").\n",
      "figura\t4-2.\to\tproduto\tescalar\tcomo\tprojeção\tde\tvetor\n",
      "assim,\té\tfácil\tcomputar\ta\t\n",
      "soma\tdos\tquadrados\n",
      "\tde\tum\tvetor:\n",
      "def\n",
      "\tsum_of_squares(v):\n",
      "\"\"\"v_1\t*\tv_1\t+\t...\t+\tv_n\t*\tv_n\"\"\"\n",
      "return\n",
      "\tdot(v,\tv)\n",
      "que\tpodemos\tusar\tpara\tcomputar\tsua\t\n",
      "magnitude\n",
      "\t(ou\ttamanho):\n",
      "import\tmath\n",
      "def\n",
      "\tmagnitude(v):\n",
      "return\n",
      "\tmath.sqrt(sum_of_squares(v))\t\t\t\n",
      "#\tmath.sqrt\té\ta\tfunção\tda\traiz\tquadrada\n",
      "agora\ttemos\ttodas\tas\tpeças\tdas\tquais\tprecisamos\tpara\tcomputar\ta\tdistância\tentredois\tvetores,\tdefinida\tcomo:\n",
      "def\n",
      "\tsquared_distance(v,\tw):\n",
      "\"\"\"(v_1\t-\tw_1)\t**\t2\t+\t...\t+\t(v_n\t-\tw_n)\t**\t2\"\"\"\n",
      "return\n",
      "\tsum_of_squares(vector_subtract(v,\tw))\n",
      "def\n",
      "\tdistance(v,\tw):\n",
      "return\n",
      "\tmath.sqrt(squared_distance(v,\tw))\n",
      "que\tfica\tmais\tclaro\tse\tescrevermos\tcomo\t(o\tequivalente):\n",
      "def\n",
      "\tdistance(v,\tw):\n",
      "return\n",
      "\tmagnitude(vector_subtract(v,\tw))\n",
      "isso\tdeve\tser\to\tsuficiente\tpara\tcomeçarmos;\tusaremos\tessas\tfunções\n",
      "constantemente\tno\tdecorrer\tdo\tlivro.\n",
      "usar\tlistas\tcomo\tvetores\té\tbom\tpara\ta\texposição,\tmas\tterrível\tpara\to\tdesempenho.\n",
      "na\tprodução\tde\tcódigo,\tvocê\tpode\tquerer\tusar\ta\tbiblioteca\tnumpy,\tque\tinclui\tuma\n",
      "classe\tde\tarray\tde\talta\tperformance\tcom\ttodos\tos\ttipos\tde\toperações\tmatemáticas\n",
      "inclusas.matrizes\n",
      "uma\t\n",
      "matriz\n",
      "\té\tuma\tcoleção\tde\tnúmeros\tbidimensional.\trepresentaremos\tas\n",
      "matrizes\tcomo\t\n",
      "list\n",
      "as\tde\t\n",
      "list\n",
      "as,\tcom\tcada\tlista\tinterior\tpossuindo\to\tmesmo\ttamanho\n",
      "e\trepresentando\tuma\t\n",
      "linha\n",
      "\tda\tmatriz.\tse\t\n",
      "a\n",
      "\té\tuma\tmatriz,\tlogo\t\n",
      "a[i][j]\n",
      "\té\to\telemento\n",
      "da\ti-ésima\tlinha\te\tj-ésima\tda\tcoluna.\tpor\tconvenção\tmatemática,\tgeralmente\n",
      "usaremos\tletras\tmaiúsculas\tpara\trepresentar\tmatrizes.\tpor\texemplo:\n",
      "a\t=\t[[1,\t2,\t3],\t\t\t\n",
      "#\ta\tpossui\tduas\tlinhas\te\ttrês\tcolunas\n",
      "\t[4,\t5,\t6]]\n",
      "b\t=\t[[1,\t2],\t\t\t\t\t\t\n",
      "#\tb\tpossui\ttrês\tlinhas\te\tduas\tcolunas\n",
      "\t[3,\t4],\n",
      "\t[5,\t6]]\n",
      "na\tmatemática,\tnormalmente\tnomearíamos\ta\tprimeira\tlinha\tda\tmatriz\tde\t“linha\t1”\te\n",
      "a\tprimeira\tcoluna\tde\t“coluna\t1”.\tjá\tque\testamos\trepresentando\tmatrizes\tcom\tas\t\n",
      "list\n",
      "as\n",
      "de\tpython,\tque\tsão\tindexadas\tem\tzero,\tchamaremos\ta\tprimeira\tlinha\tde\tuma\tmatriz\n",
      "de\t“linha\t0”\te\ta\tprimeira\tcoluna\tde\t“coluna\t0”.\n",
      "dada\testa\trepresentação\tde\tlista-das-listas,\ta\tmatriz\t\n",
      "a\n",
      "\tpossui\tas\tlinhas\t\n",
      "len(a)\n",
      "\te\n",
      "colunas\t\n",
      "len(a[0])\n",
      ",\tque\tconsideramos\tdesta\tforma\t(shape):\n",
      "def\n",
      "\tshape(a):\n",
      "\tnum_rows\t=\tlen(a)\n",
      "\tnum_cols\t=\tlen(a[0])\t\n",
      "if\n",
      "\ta\t\n",
      "else\n",
      "\t0\t\t\t\n",
      "#\tnúmero\tde\telementos\tna\tprimeira\tlinha\n",
      "\t\n",
      "return\n",
      "\tnum_rows,\tnum_cols\n",
      "se\tuma\tmatriz\tpossui\t\n",
      "n\n",
      "\tlinhas\te\t\n",
      "k\n",
      "\tcolunas,\tnos\treferiremos\ta\tela\tcomo\tuma\n",
      "matriz\t\n",
      "n\tx\tk\n",
      ".\tpodemos\t(e,\tàs\tvezes,\tiremos)\tpensar\tem\tcada\tlinha\tde\tuma\tmatriz\n",
      "n\tx\tk\n",
      "\tcomo\tum\tvetor\tde\ttamanho\t\n",
      "k\n",
      ",\te\tcada\tcoluna\tcomo\tum\tvetor\tde\ttamanho\t\n",
      "n\n",
      ":\n",
      "def\tget_row(a,\ti):\n",
      "return\ta[i]\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ta[i]\tjá\té\tda\tlinha\ta[i]\té\tlinha\ti-ésimo\n",
      "def\tget_column(a,\tj):\n",
      "return\t[a_i[j]\t\t\t\t\t\t\t\t\t\t\n",
      "#\tj-ésimo\telemento\tda\tlinha\ta_i\n",
      "\tfor\ta_i\tin\ta]\t\t\t\t\n",
      "#\tpara\tcada\tlinha\ta_i\n",
      "também\tqueremos\tsaber\tcomo\tcriar\tmatrizes\tdadas\tsua\tforma\te\tuma\tfunção\n",
      "para\tproduzir\tseus\telementos.\tpodemos\tfazer\tisso\tusando\tuma\tcompreensão\tdelista\taninhada:\n",
      "def\tmake_matrix(num_rows,\tnum_cols,\tentry_fn):\n",
      "\"\"\"retorna\ta\tmatriz\tnum_rows\tx\tnum_cols\n",
      "cuja\tentrada\t(i,j)th\té\tentry_fn(i,\tj)\"\"\"\n",
      "return\t[[entry_fn(i,\tj)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdado\ti,\tcria\tuma\tlista\n",
      "\tfor\tj\tin\trange(num_cols)]\t\t\t\n",
      "#\t\t\t[entry_fn(i,\t0),\t...\t]\n",
      "\tfor\ti\tin\trange(num_rows)]\t\t\t\n",
      "#\tcria\tuma\tlista\tpara\tcada\ti\n",
      "dada\testa\tfunção,\tvocê\tpoderia\tfazer\tuma\t\n",
      "matriz\tde\tidentidade\n",
      "\t5\t×\t5\t(com\t1s\tna\n",
      "diagonal\te\t0s\tnos\tdemais\tlugares)\tcom:\n",
      "def\n",
      "\tis_diagonal(i,\tj):\n",
      "\"\"\"1's\tna\tdiagonal,\t0's\tnos\tdemais\tlugares\"\"\"\n",
      "return\n",
      "\t1\t\n",
      "if\n",
      "\ti\t==\tj\t\n",
      "else\n",
      "\t0\n",
      "#\t[[1,\t0,\t0,\t0,\t0]\n",
      ",\n",
      "#\t[0,\t1,\t0,\t0,\t0]\n",
      ",\n",
      "#\t[0,\t0,\t1,\t0,\t0]\n",
      ",\n",
      "#\t[0,\t0,\t0,\t1,\t0]\n",
      ",\n",
      "#\t[0,\t0,\t0,\t0,\t1]]\n",
      "as\tmatrizes\tserão\timportantes\tpara\tnós\tde\tdiversas\tformas.\n",
      "primeiro,\tpodemos\tusar\tuma\tmatriz\tpara\trepresentar\tum\tconjunto\tde\tdados\n",
      "consistindo\tde\tmúltiplos\tvetores,\tsimplesmente\tconsiderando\tcada\tvetor\tcomo\n",
      "uma\tlinha\tda\tmatriz.\tpor\texemplo,\tse\tvocê\ttivesse\ta\taltura,\to\tpeso\te\ta\tidade\tde\n",
      "1000\tpessoas,\tvocê\tpoderia\tcolocá-los\tem\tuma\tmatriz\t1000\t×\t3:\n",
      "data\t=\t[[70,\t170,\t40],\n",
      "\t[65,\t120,\t26],\n",
      "\t[77,\t250,\t19],\n",
      "\t\n",
      "#\n",
      "\t....\n",
      "\t]\n",
      "segundo,\tcomo\tveremos\tmais\ttarde,\tpodemos\tusar\tuma\tmatriz\t\n",
      "n\n",
      "\t×\t\n",
      "k\n",
      "\tpara\n",
      "representar\tuma\tfunção\tlinear\tque\tmapeia\tvetores\tdimensionais\t\n",
      "k\n",
      "\tpara\tvetores\n",
      "dimensionais\t\n",
      "n\n",
      ".\tnossas\tvárias\ttécnicas\te\tconceitos\tenglobarão\ttais\tfunções.\n",
      "terceiro,\tas\tmatrizes\tpodem\tser\tusadas\tpara\trepresentar\trelações\tbinárias.\tno\n",
      "capítulo\t1,\trepresentamos\tas\textremidades\tde\tuma\trede\tcomo\tuma\tcoleção\tde\n",
      "pares\t\n",
      "(i,\tj)\n",
      ".\tuma\trepresentação\talternativa\tseria\tcriar\tuma\tmatriz\t\n",
      "a\n",
      "\ttal\tque\t\n",
      "a[i][j]\n",
      "seja\t1\tse\tos\tnodos\t\n",
      "i\n",
      "\te\t\n",
      "j\n",
      "\testejam\tconectados\te\t0\tde\toutra\tforma.lembre-se\tde\tque\ttínhamos\tantes:\n",
      "friendships\t=\t[(0,\t1),\t(0,\t2),\t(1,\t2),\t(1,\t3),\t(2,\t3),\t(3,\t4),\n",
      "(4,\t5),\t(5,\t6),\t(5,\t7),\t(6,\t8),\t(7,\t8),\t(8,\t9)]\n",
      "também\tpoderíamos\trepresentar\tdesta\tforma:\n",
      "#\t\t\t\t\t\tusuário\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\n",
      "#\n",
      "friendships\t=\t[[0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\t\n",
      "#\tuser\t0\n",
      "[1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0],\t\n",
      "#\tuser\t1\n",
      "[1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0],\t\n",
      "#\tuser\t2\n",
      "[0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0],\t\n",
      "#\tuser\t3\n",
      "[0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0],\t\n",
      "#\tuser\t4\n",
      "[0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0],\t\n",
      "#\tuser\t5\n",
      "[0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0],\t\n",
      "#\tuser\t6\n",
      "[0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0],\t\n",
      "#\tuser\t7\n",
      "[0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1],\t\n",
      "#\tuser\t8\n",
      "[0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0]]\t\n",
      "#\tuser\t9\n",
      "se\ttivermos\tpoucas\tconexões,\tessa\tserá\tuma\trepresentação\tmuto\tfraca\tjá\tque\n",
      "você\tterá\tque\tcompletar\to\tarmazenamento\tcom\tdiversos\tzeros.\tno\tentanto,\tcom\n",
      "a\trepresentação\tda\tmatriz\té\tbem\tmais\tfácil\tverificar\tse\tos\tdois\tnodos\testão\n",
      "conectados\t—\tvocê\tapenas\ttem\tque\tprocurar\tna\tmatriz\tem\tvez\tde\tprocurar\n",
      "(possivelmente)\tcada\textremidade:\n",
      "friendships[0][2]\t==\t1\t\t\t\n",
      "#\ttrue,\t0\te\t2\tsão\tamigos\n",
      "friendships[0][8]\t==\t1\t\t\t\n",
      "#\tfalse,\t0\te\t8\tnão\tsão\tamigos\n",
      "da\tmesma\tforma,\tpara\tencontrar\tas\tconexões\tque\tum\tnodo\tpossui,\tvocê\tprecisa\n",
      "apenas\tinspecionar\ta\tcoluna\t(ou\ta\tlinha)\tcorrespondente\tàquele\tnodo:\n",
      "friends_of_five\t=\t[i\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tsomente\tprecisamos\n",
      "\t\t\t\t\n",
      "for\n",
      "\ti,\tis_friend\t\n",
      "in\n",
      "\tenumerate(friendships[5])\t\t\t\n",
      "#\tolhar\tpara\n",
      "\t\t\t\t\t\n",
      "if\n",
      "\tis_friend]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tuma\tlinha\n",
      "anteriormente,\tadicionamos\tuma\tlista\tde\tconexões\tpara\tcada\tobjeto\tde\tnodo\n",
      "para\taumentar\tsua\tvelocidade\tde\tprocesso,\tmas\tpara\tum\tgráfico\tgrande\te\tem\n",
      "evolução,\tseria\tmuito\tcaro\te\tde\tdifícil\tmanutenção.\n",
      "veremos\tmatrizes\tnovamente\tno\tdecorrer\tdo\tlivro.•\n",
      "—\n",
      "—\n",
      "—\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "a\tálgebra\tlinear\té\tamplamente\tusada\tpor\tcientistas\tde\tdados\t(implícita\n",
      "com\tfrequência,\te\tnão\traramente\tpor\tpessoas\tque\tnão\ta\tentendem).\tnão\n",
      "seria\tuma\tmá\tideia\tler\tum\tlivro\tdidático.\tvocê\tpode\tencontrar\tvários\n",
      "disponíveis\tonline:\n",
      "linear\talgebra\n",
      ",\tda\tuc\tdavis\t(\n",
      "http://bit.ly/1ycoq96\n",
      ")\n",
      "linear\talgebra\n",
      ",\tdo\tsaint\tmichael’s\tcollege\t(\n",
      "http://bit.ly/1ycopsf\n",
      ")\n",
      "se\tgostar\tde\taventuras,\t\n",
      "linear\talgebra\tdone\twrong\n",
      "(\n",
      "http://bit.ly/1ycot4w\n",
      ")\n",
      "\té\tum\tlivro\tcom\tuma\tintrodução\tmais\tavançada\n",
      "todos\tos\texemplos\tconstruídos\taqui\tvocê\tpode\tter\tgratuitamente\tse\tusar\n",
      "numpy\t(\n",
      "http://www.numpy.org\n",
      ").\t(e\tmais\texemplos\ttambém.)capítulo\t5\n",
      "estatística\n",
      "os\tfatos\tsão\tteimosos,\tmas\tas\testatísticas\tsão\tmais\tmaleáveis\n",
      ".\n",
      "—mark\ttwain\n",
      "a\t\n",
      "estatística\n",
      "\tse\trefere\tà\tmatemática\te\tàs\ttécnicas\tcom\tas\tquais\tentendemos\tos\n",
      "dados.\té\tum\tcampo\trico,\tamplo,\tmais\tadequado\ta\tuma\tprateleira\t(ou\tsala)\tem\n",
      "uma\tbiblioteca\tem\tvez\tde\tum\tcapítulo\tem\tum\tlivro,\tportanto,\tnossa\tabordagem\n",
      "não\tserá\tmuito\tprofunda.\tem\tvez\tdisso,\ttentarei\texplicar\tapenas\to\tsuficiente\tpara\n",
      "ensinar\ta\tser\taventureiro\te\tcaptar\tseu\tinteresse\tpara\tque\tvocê\tdê\tcontinuidade\te\n",
      "aprenda\tmais.descrevendo\tum\tconjunto\túnico\tde\tdados\n",
      "por\tmeio\tde\tuma\tcombinação\tde\tdiscurso\toral\te\tsorte,\ta\tdatasciencester\n",
      "ampliou\tpara\tdúzias\tde\tmembros\te\to\tvice-presidente\tda\tcaptação\tde\trecursos\n",
      "solicita\tum\trelatório\tde\tquantos\tamigos\tseus\tmembros\tpossuem\ta\tfim\tde\tincluí-\n",
      "los\tem\tseus\tdiscursos\tno\televador.\n",
      "ao\tusar\tas\ttécnicas\tdo\t\n",
      "capítulo\t1\n",
      ",\tvocê\té\tplenamente\tcapaz\tde\tproduzir\tdados.\n",
      "mas,\tagora,\tvocê\testá\tdiante\tdo\tproblema\tde\tcomo\t\n",
      "descrevê-los\n",
      ".\n",
      "uma\tdescrição\tevidente\tde\tqualquer\tdado\té\tsimplesmente\to\tdado\tem\tsi:\n",
      "num_friends\t=\t[100,\t49,\t41,\t40,\t25,\n",
      "#\t…\te\tmuitos\tmais\n",
      "]\n",
      "para\tum\tconjunto\tpequeno\tde\tdados,\tessa\tpode\taté\tser\ta\tmelhor\trepresentação.\n",
      "mas,\tpara\tum\tconjunto\tmaior,\tela\té\tcomplicada\te\tconfusa.\t(imagine\tolhar\tpara\n",
      "uma\tlista\tde\tum\tmilhão\tde\tnúmeros.)\tpor\tessa\trazão,\tusamos\ta\testatística\tpara\n",
      "destilar\te\tcomunicar\tos\taspectos\trelevantes\tdos\tnossos\tdados.\n",
      "na\tprimeira\tabordagem,\tcolocamos\ta\tcontagem\tde\tamigos\tem\tum\thistograma\n",
      "usando\t\n",
      "counter\n",
      "\te\t\n",
      "plt.bar()\n",
      "\t(\n",
      "figura\t5-1\n",
      "):\n",
      "friend_counts\t=\tcounter(num_friends)\n",
      "xs\t=\trange(101)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\to\tvalor\tmaior\té\t100\n",
      "ys\t=\t[friend_counts[x]\tfor\tx\tin\txs]\t\t\t\t\t\t\n",
      "#\ta\taltura\té\tsomente\t#\tde\tamigos\n",
      "plt.bar(xs,\tys)\n",
      "plt.axis([0,\t101,\t0,\t25])\n",
      "plt.title(\"histograma\tda\tcontagem\tde\tamigos\")\n",
      "plt.xlabel(\"#\tde\tamigos\")\n",
      "plt.ylabel(\"#\tde\tpessoas\")\n",
      "plt.show()figura\t5-1.\tum\thistograma\tda\tcontagem\tde\tamigos\n",
      "infelizmente,\tesse\tgráfico\tainda\té\tmuito\tdifícil\tpara\tinserir\tem\tdiscussões.\n",
      "portanto,\té\tmelhor\tcomeçar\ta\tgerar\talgumas\testatísticas.\tprovavelmente,\ta\n",
      "estatística\tmais\tsimples\té\to\tnúmero\tde\tpontos\tnos\tdados:\n",
      "num_points\t=\tlen(num_friends)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t204\n",
      "possivelmente,\tvocê\ttambém\testá\tinteressado\tnos\tmaiores\te\tmenores\tvalores:\n",
      "largest_value\t=\tmax(num_friends)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t100\n",
      "smallest_value\t=\tmin(num_friends)\t\t\t\t\t\t\t\t\t\t\n",
      "#\t1\n",
      "que\tsão\tapenas\tcasos\tespeciais\tde\tquerer\tsaber\tos\tvalores\tem\tposições\n",
      "específicas:\n",
      "sorted_values\t=\tsorted(num_friends)\n",
      "smallest_value\t=\tsorted_values[0]\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t1\n",
      "second_smallest_value\t=\tsorted_values[1]\t\t\t\t\t\n",
      "#\t1\n",
      "second_largest_value\t=\tsorted_values[-2]\t\t\t\t\t\n",
      "#\t49mas\testamos\tapenas\tcomeçando.\n",
      "tendências\tcentrais\n",
      "geralmente,\tqueremos\tter\talguma\tnoção\tde\tonde\tnossos\tdados\testão\tcentrados.\n",
      "a\t\n",
      "média\n",
      "\tserá\tmais\tutilizada\tpois\tela\té\tsoma\tdos\tdados\tdividido\tpela\tsua\n",
      "contagem:\n",
      "#\tnão\testá\tcerto\tse\tvocê\tnão\timportar\ta\tdivisão\tde\t__future__\n",
      "def\n",
      "\tmean(x):\n",
      "\t\n",
      "return\n",
      "\tsum(x)\t/\tlen(x)\n",
      "mean(num_friends)\t\t\t\n",
      "#\t7.333333\n",
      "se\tvocê\tpossui\tdois\tpontos\tde\tdados,\ta\tmédia\té\to\tponto\tno\tmeio\tdo\tcaminho\n",
      "entres\teles.\tconforme\tvocê\tacrescenta\tmais\tpontos,\ta\tmédia\tse\tmove,\tmas\n",
      "sempre\tdepende\tdo\tvalor\tde\tcada\tponto.\n",
      "algumas\tvezes\ttambém\tnos\tinteressaremos\tpela\t\n",
      "mediana\n",
      ",\tque\té\to\tvalor\tmaior\n",
      "do\tmeio\t(se\to\tnúmero\tde\tpontos\tde\tdados\tfor\tímpar)\tou\ta\tmédia\tdos\tdois\tvalores\n",
      "que\testiverem\tbem\tno\tmeio\t(se\to\tnúmero\tde\tpontos\tde\tdados\tfor\tpar).\n",
      "por\texemplo,\tse\ttivermos\tcinco\tpontos\tde\tdados\tem\tum\tvetor\tvariado\t\n",
      "x\n",
      ",\ta\n",
      "mediana\té\t\n",
      "x[5//2]\n",
      "\tou\t\n",
      "x[2]\n",
      ".\tse\ttivermos\tseis\tpontos\tde\tdados,\tqueremos\ta\tmédia\tde\n",
      "x[2]\n",
      "\t(o\tterceiro\tponto)\te\t\n",
      "x[3]\n",
      "\t(o\tquarto\tponto).\n",
      "repare\tque\t—\tdiferente\tda\tmédia\t—\ta\tmediana\tnão\tdepende\tde\tcada\tvalor\tnos\n",
      "seus\tdados.\tpor\texemplo,\tse\tvocê\taumentar\to\tmaior\tponto\t(ou\tdiminuir\to\tmenor\n",
      "ponto),\tos\tpontos\tdo\tmeio\tpermanecem\tintactos,\tlogo,\ta\tmediana\ttambém.\n",
      "a\tfunção\t\n",
      "median\n",
      "\té\tum\tpouco\tmais\tcomplicada\tdo\tque\tvocê\tpensa,\tprincipalmente\n",
      "por\tcausa\tdo\tcaso\t“par”:\n",
      "def\tmedian(v):\n",
      "\"\"\"encontra\to\tvalor\tmais\tao\tmeio\tde\tv\"\"\"\n",
      "n\t=\tlen(v)\n",
      "sorted_v\t=\tsorted(v)\n",
      "midpoint\t=\tn\t//\t2\n",
      "if\tn\t%\t2\t==\t1:\n",
      "\t\n",
      "#\tse\tfor\tímpar,\tretorna\to\tvalor\tdo\tmeio\n",
      "\treturn\tsorted_v[midpoint]\n",
      "else:#\tse\tfor\tpar,\tretorna\ta\tmédia\tdos\tvalores\tdo\tmeio\n",
      "lo\t=\tmidpoint\t-\t1\n",
      "hi\t=\tmidpoint\n",
      "return\t(sorted_v[lo]\t+\tsorted_v[hi])\t/\t2\n",
      "median(num_friends)\t#\t6.0\n",
      "evidentemente,\ta\tmédia\té\tmais\tfácil\tde\tcomputar\te\tvaria\tde\tmodo\tmais\tsuave\n",
      "conforme\tos\tdados\tmudam.\tse\ttivermos\t\n",
      "n\n",
      "\tpontos\tde\tdados\te\tum\tdeles\tcrescer\n",
      "em\tuma\tquantidade\t\n",
      "e\n",
      ",\tlogo,\tnecessariamente,\ta\tmédia\taumentará\tde\t\n",
      "e\t/\tn\n",
      ".\t(isso\n",
      "faz\tda\tmédia\ta\tresponsável\tpor\ttodos\tos\ttruques\tde\tcálculo.)\tmas,\tpara\tencontrar\n",
      "a\tmediana,\ttemos\tque\torganizar\tnossos\tdados.\te,\tao\tmudar\tum\tdos\tpontos\tde\n",
      "dados\tem\tuma\tpequena\tquantidade\t\n",
      "e\n",
      ",\ttalvez\ta\tmediana\taumente\tde\t\n",
      "e\n",
      ",\tou\talgum\n",
      "número\tmenor\tque\t\n",
      "e\n",
      ",\tou\tnenhum\tdeles\t(dependendo\tdo\tnúmero\tde\tdados).\n",
      "há,\tna\tverdade,\talguns\ttruques\tnão\ttão\tóbvios\tpara\tcomputar\tmedianas\n",
      "(\n",
      "http://en.wikipedia.org/wiki/quickselect\n",
      ")\tsem\tsem\torganizar\tos\tdados.\tno\tentanto,\n",
      "eles\testão\talém\tdo\tescopo\tdeste\tlivro,\tentão\t\n",
      "temos\n",
      "\tque\torganizá-los.\n",
      "ao\tmesmo\ttempo,\ta\tmédia\té\tmuito\tsensível\taos\tvalores\tdiscrepantes\tem\tnossos\n",
      "dados.\tse\tnosso\tusuário\tmais\tamigável\tpossui\tduzentos\tamigos\t(em\tvez\tde\tcem),\n",
      "então\ta\tmédia\tsubiria\tpara\t7.82,\tenquanto\ta\tmediana\tpermaneceria\ta\tmesma.\tse\n",
      "os\tvalores\tdiscrepantes\ttêm\ta\tpossibilidade\tde\tserem\tdados\truins\t(ou,\tde\toutro\n",
      "modo,\tnão\trepresentativos\tde\tqualquer\tfenômeno\tque\testejamos\ttentando\n",
      "entender),\tentão\ta\tmédia\tpode\tnos\tlevar\ta\tum\tengano.\tpor\texemplo,\tconta-se\n",
      "que,\tem\tmeados\tda\tdécada\tde\t1980,\ta\tgraduação\tda\tuniversidade\tda\tcarolina\tdo\n",
      "norte\tcom\ta\tmaior\tmédia\tde\tsalário\tinicial\tera\tgeografia,\tprincipalmente\tpor\n",
      "causa\tda\testrela\tdo\tnba\t(e\tum\tvalor\tdiscrepante)\tmichael\tjordan.\n",
      "uma\tgeneralização\tda\tmédia\té\to\t\n",
      "quantil\n",
      ",\tque\trepresenta\to\tvalor\tabaixo\tdo\tqual\ta\n",
      "uma\tcerta\tporcentagem\tdos\tdados\tse\tencontra\t(a\tmediana\trepresenta\to\tvalor\n",
      "abaixo\tdo\tqual\t50%\tdos\tdados\tse\tencontram).\n",
      "def\tquantile(x,\tp):\n",
      "\"\"\"retorna\to\tvalor\tpercentual\tp-ésimo\tem\tx\"\"\"\n",
      "p_index\t=\tint(p\t*\tlen(x))\n",
      "return\tsorted(x)[p_index]\n",
      "quantile(num_friends,\t0.10)\t\n",
      "#\t1\n",
      "quantile(num_friends,\t0.25)\t\n",
      "#\t3quantile(num_friends,\t0.75)\t\n",
      "#\t9\n",
      "quantile(num_friends,\t0.90)\t\n",
      "#\t13\n",
      "de\tmodo\tmenos\tcomum,\tvocê\ttalvez\tqueira\tolhar\tpara\ta\t\n",
      "moda\n",
      "\tou\tos\tvalores\n",
      "mais\tcomuns:\n",
      "def\tmode(x):\n",
      "\"\"\"retorna\tuma\tlista,\tpode\thaver\tmais\tde\tuma\tmoda\"\"\"\n",
      "counts\t=\tcounter(x)\n",
      "max_count\t=\tmax(counts.values())\n",
      "return\t[x_i\tfor\tx_i,\tcount\tin\tcounts.iteritems()\n",
      "\tif\tcount\t==\tmax_count]\n",
      "mode(num_friends)\t\t\t\t\t\t\n",
      "#\t1\tand\t6\n",
      "mas\tusaremos\ta\tmédia\tcom\tmais\tfrequência.\n",
      "dispersão\n",
      "a\t\n",
      "dispersão\n",
      "\tse\trefere\tà\tmedida\tde\tcomo\tos\tnossos\tdados\testão\tespalhados.\n",
      "tipicamente,\teles\tsão\testatísticas\tem\tque\tvalores\tperto\tde\tzero\tsignificam\t\n",
      "não\n",
      "estão\tespalhados\tde\tforma\talguma\n",
      "\te\tpara\tvalores\tmaiores\t(o\tque\tquer\tque\tisso\n",
      "signifique)\tsignifica\t\n",
      "muito\tespalhados\n",
      ".\tpor\texemplo,\tuma\tsimples\tmedida\té\ta\n",
      "amplitude\n",
      ",\tque\té\ta\tdiferença\tentre\to\tmaior\te\to\tmenor\telemento:\n",
      "#\t“amplitude”\tjá\tpossui\tsignificado\tem\tpython,\tentão\tusaremos\tum\tnome\tdiferente\n",
      "def\tdata_range(x):\n",
      "\treturn\tmax(x)\t-\tmin(x)\n",
      "data_range(num_friends)\t\n",
      "#\t99\n",
      "a\tamplitude\té\tzero\tquando\to\t\n",
      "max\n",
      "\te\to\t\n",
      "min\n",
      "\tsão\tiguais,\to\tque\tacontece\tapenas\tse\tos\n",
      "elementos\tde\t\n",
      "x\n",
      "\tforem\ttodos\tiguais,\to\tque\tsignifica\tque\t\n",
      "os\tdados\testão\to\tmenos\n",
      "dispersos\tpossível\n",
      ".\tpor\toutro\tlado,\tse\ta\tamplitude\té\tampla,\tentão\to\t\n",
      "max\n",
      "\té\tbem\n",
      "maior\tdo\tque\to\t\n",
      "min\n",
      "\te\tos\tdados\testão\t\n",
      "mais\tespalhados\n",
      ".\n",
      "assim\tcomo\ta\tmediana,\ta\tamplitude\tnão\tdepende\tde\tfato\tde\ttodo\to\tconjunto\tde\n",
      "dados.\tum\tconjunto\tde\tdados\tcujos\tpontos\testão\ttodos\tentre\t0\tou\t100\tpossui\ta\n",
      "mesma\tamplitude\tque\tum\tcujos\tvalores\tsão\t0,\t100\te\tmuitos\t50s.\tmas\tparece\tque\n",
      "o\tprimeiro\tconjunto\tde\tdados\t“deveria”\testar\tmais\tespalhado.\n",
      "uma\tmedida\tde\tdispersão\tmais\tcomplexa\té\ta\t\n",
      "variância\n",
      ",\tcomputada\tdesta\tforma:def\tde_mean(x):\n",
      "\"\"\"desloca\tx\tao\tsubtrair\tsua\tmédia\t(então\to\tresultado\ttem\ta\tmédia\t0)\"\"\"\n",
      "x_bar\t=\tmean(x)\n",
      "return\t[x_i\t-\tx_bar\tfor\tx_i\tin\tx]\n",
      "def\tvariance(x):\n",
      "\"\"\"presume\tque\tx\ttem\tao\tmenos\tdois\telementos\"\"\"\n",
      "n\t=\tlen(x)\n",
      "deviations\t=\tde_mean(x)\n",
      "return\tsum_of_squares(deviations)\t/\t(n\t-\t1)\n",
      "variance(num_friends)\t\n",
      "#\t81.54\n",
      "parece\tque\té\tquase\to\tdesvio\tdo\tquadrado\tmédio\tda\tmédia,\texceto\tque\testamos\n",
      "dividindo\tpor\t\n",
      "n-1\n",
      "\tem\tvez\tde\t\n",
      "n\n",
      ".\tna\tverdade,\tquando\tcom\tuma\tamostra\tde\tuma\n",
      "população\tmaior,\t\n",
      "x_bar\n",
      "\té\tapenas\tuma\t\n",
      "estimativa\n",
      "\tda\tmédia\treal,\to\tque\tsignifica\tque\tna\n",
      "média\t\n",
      "(x_i\t–\tx_bar)**2\n",
      "\thá\tum\tsubestimado\tquadrado\tmédio\tda\tmédia\tde\t\n",
      "x_i\n",
      "\tda\n",
      "média,\te\té\tpor\tisso\tque\tdividimos\tpor\t\n",
      "n–1\n",
      "\tem\tvez\tde\t\n",
      "n\n",
      ".\tveja\ta\twikipédia\tem\n",
      "http://bit.ly/1l2eapi\n",
      ".\n",
      "agora,\tqualquer\tque\tseja\ta\tunidade\tna\tqual\tnossos\tdados\testão\t(por\te\n",
      "x\n",
      "emplo,\n",
      "“friends”),\ttodas\tas\tnossas\tmedidas\tde\ttendências\tcentrais\testão\tna\tmesma\n",
      "unidade.\ta\tamplitude\testará\tnaquela\tmesma\tunidade\ttambém.\ta\tvariância,\tpor\n",
      "outro\tlado,\tpossui\tunidades\tque\tsão\tos\t\n",
      "quadrados\n",
      "\tdas\tunidades\toriginais\t(por\n",
      "exemplo,\t“friends\tsquared”).\tcomo\tpode\tser\tdifícil\tentender\tisso,\tgeralmente\n",
      "olhamos\tpara\to\t\n",
      "desvio\tpadrão\n",
      ":\n",
      "def\n",
      "\tstandard_deviation(x):\n",
      "\t\n",
      "return\n",
      "\tmath.sqrt(variance(x))\n",
      "standard_deviation(num_friends)\t\n",
      "#\t9.03\n",
      "tanto\ta\tamplitude\tquanto\to\tdesvio\tpadrão\tpossuem\to\tmesmo\tproblema\tde\tvalor\n",
      "discrepante\tque\tvimos\tcom\ta\tmédia.\tusando\to\tmesmo\texemplo,\tse\tnosso\tusuário\n",
      "mais\tamigável\ttivesse\tduzentos\tamigos,\to\tdesvio\tpadrão\tseria\tde\t14,89,\tmais\tdo\n",
      "que\t60%\ta\tmais!\n",
      "e\tuma\talternativa\tmais\trobusta\tcomputa\ta\tdiferença\tentre\tos\tpercentos\t(quantos)\n",
      "75%\te\t25%\tdo\tvalor:\n",
      "def\n",
      "\tinterquartile_range(x):\n",
      "\t\n",
      "return\n",
      "\tquantile(x,\t0.75)\t-\tquantile(x,\t0.25)\n",
      "interquartile_range(num_friends)\t\n",
      "#\t6que\tnão\té\tafetado\tpor\tuma\tpequena\tquantidade\tde\tvalores\tdiscrepantes.•\n",
      "•\n",
      "correlação\n",
      "a\tvice-presidente\tde\tcrescimento\tna\tdatasciencester\ttem\tuma\tteoria\tque\ta\n",
      "quantidade\tde\ttempo\tgasto\tpelas\tpessoas\tno\tsite\té\trelacionada\tao\tnúmero\tde\n",
      "amigos\tque\telas\tpossuem\t(ela\tnão\té\tuma\tvice-presidente\tà\ttoa),\te\tela\tpediu\tpara\n",
      "você\tverificar\tisso.\n",
      "após\texaminar\tos\tregistros\tdo\ttráfego,\tvocê\tdesenvolve\tuma\tlista\t\n",
      "daily_minutes\n",
      "\tque\n",
      "mostra\tquantos\tminutos\tpor\tdia\tcada\tusuário\tpassa\tna\tdatasciencester\te\tvocê\n",
      "havia\tordenado\tessa\tlista\tpara\tque\tseus\telementos\tcorrespondessem\taos\n",
      "elementos\tda\tlista\tanterior\t\n",
      "num_\tfriends\n",
      ".\tgostaríamos\tde\tinvestigar\ta\trelação\tentre\n",
      "essas\tduas\tmétricas.\n",
      "primeiro,\tinvestigaremos\ta\t\n",
      "covariância\n",
      ",\to\tequivalente\tpareado\tda\tvariância.\n",
      "enquanto\ta\tvariância\tmede\tcomo\tuma\túnica\tvariável\tdesvia\tde\tsua\tmédia,\ta\n",
      "covariância\tmede\tcomo\tduas\tvariáveis\tvariam\tem\tconjunto\tde\tsuas\tmédias:\n",
      "def\n",
      "\tcovariance(x,\ty):\n",
      "\tn\t=\tlen(x)\n",
      "\t\n",
      "return\n",
      "\tdot(de_mean(x),\tde_mean(y))\t/\t(n\t-\t1)\n",
      "covariance(num_friends,\tdaily_minutes)\t\n",
      "#\t22.43\n",
      "lembre-se\tque\to\t\n",
      "dot\n",
      "\tresume\tos\tprodutos\tdos\tpares\tcorrespondentes\tdos\n",
      "elementos.\tquando\tos\telementos\tcorrespondentes\tde\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "\testão\tacima\tou\tabai\n",
      "x\n",
      "o\n",
      "de\tsuas\tmédias,\tum\tnúmero\tpositivo\tentra\tna\tsoma.\tquando\tum\testá\tacima\tde\n",
      "sua\tmédia\te\to\toutro\testá\tabaixo,\tum\t\n",
      "número\tnegativo\tentra\tna\tsoma.\tna\tmesma\n",
      "proporção,\tuma\tcovariância\tpositiva\t“grande”\tsignifica\tque\tx\ttende\ta\tser\tgrande\n",
      "quando\t\n",
      "y\n",
      "\té\tgrande\te\tpequeno\tquando\t\n",
      "y\n",
      "\té\tpequeno.\tuma\tcovariância\tnegativa\n",
      "“grande”\tsignifica\to\toposto\t—\tque\t\n",
      "x\n",
      "\ttende\ta\tser\tpequeno\tquando\t\n",
      "y\n",
      "\té\tgrande\te\n",
      "vice-versa.\tuma\tcovariância\tperto\tde\tzero\tsignifica\tque\ttal\trelação\tnão\texiste.\n",
      "mesmo\tassim,\tesse\tnúmero\tpode\tser\tdifícil\tde\tser\tinterpretado\tpor\tdois\tmotivos:\n",
      "suas\tunidades\tsão\to\tproduto\tdas\tunidades\tde\tentrada\t(por\texemplo,\n",
      "minutosamigo-por-dia),\to\tque\tpode\tser\tdifícil\tde\tentender.\t(o\tque\té\tum\n",
      "“minutosamigo-por-dia”?)\n",
      "se\tcada\tusuário\ttiver\tduas\tvezes\tmais\tamigos\t(mas\to\tmesmo\tnúmero\tdeminutos),\ta\tcovariância\tseria\tduas\tvezes\tmaior.\tmas,\tpor\talgum\tmotivo,\tas\n",
      "variáveis\tseriam\tapenas\tinter-relacionadas.\tvisto\tde\toutra\tmaneira,\té\n",
      "arriscado\tdizer\to\tque\tconta\tcomo\tuma\tcovariância\t“grande”.\n",
      "por\ttais\tmotivos,\té\tmais\tcomum\tconsiderar\ta\t\n",
      "correlação\n",
      ",\tque\tdivide\tos\tdesvios\n",
      "padrões\tdas\tduas\tvariáveis:\n",
      "def\tcorrelation(x,\ty):\n",
      "\tstdev_x\t=\tstandard_deviation(x)\n",
      "\tstdev_y\t=\tstandard_deviation(y)\n",
      "\tif\tstdev_x\t>\t0\tand\tstdev_y\t>\t0:\n",
      "\treturn\tcovariance(x,\ty)\t/\tstdev_x\t/\tstdev_y\n",
      "else:\n",
      "return\t0\t\t\t\t\t\n",
      "#\tse\tnão\thouver\tamplitude,\ta\tcorrelação\té\tzero\n",
      "correlation(num_friends,\tdaily_minutes)\t\n",
      "#\t0.25\n",
      "a\t\n",
      "correlation\n",
      "\tnão\tpossui\tunidade\te\tsempre\tpermanece\tentre\t–1\t(anticorrelação\n",
      "perfeita)\te\t1\t(correlação\tperfeita).\tum\tnúmero\tcomo\t0,25\trepresenta\tuma\n",
      "correlação\tpositiva\trelativamente\tfraca.\n",
      "no\tentanto,\talgo\tque\tesquecemos\tde\tfazer\tfoi\texaminar\tnossos\tdados.\tdê\tuma\n",
      "olhada\tna\t\n",
      "figura\t5-2\n",
      ".figura\t5-2.\tcorrelação\tcom\tum\tvalor\tdiscrepante\n",
      "a\tpessoa\tcom\t100\tamigos\t(que\tpassa\tapenas\tum\tminuto\tpor\tdia\tno\tsite)\té\tum\n",
      "grande\tvalor\tdiscrepante\te\ta\tcorrelação\tpode\tser\tmuito\tsensível\tpara\tvalores\n",
      "discrepantes.\to\tque\tacontece\tse\to\tignorarmos?\n",
      "outlier\t=\tnum_friends.index(100)\t\t\t\t\n",
      "#\tíndice\tdo\tvalor\tdiscrepante\n",
      "num_friends_good\t=\t[x\n",
      "\t\t\t\t\t\n",
      "for\n",
      "\ti,\tx\t\n",
      "in\n",
      "\tenumerate(num_friends)\n",
      "\t\t\t\t\t\n",
      "if\n",
      "\ti\t!=\toutlier]\n",
      "daily_minutes_good\t=\t[x\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\ti,\tx\t\n",
      "in\n",
      "\tenumerate(daily_minutes)\n",
      "\t\t\t\t\t\t\t\n",
      "if\n",
      "\ti\t!=\toutlier]\n",
      "correlation(num_friends_good,\tdaily_minutes_good)\t\n",
      "#\t0.57\n",
      "sem\to\tvalor\tdiscrepante,\thá\tuma\tcorrelação\tbem\tmais\tforte\t(\n",
      "figura\t5-3\n",
      ").figura\t5-3.\tcorrelação\tapós\ta\tremoção\tdo\tvalor\tdiscrepante\n",
      "você\taverígua\te\tdescobre\tque\to\tvalor\tdiscrepante\tera,\tna\tverdade,\tuma\tconta\n",
      "teste\n",
      "\tinterna\tque\tninguém\tse\tpreocupou\tem\tremover.\tentão\tsinta-se\tbem\tao\n",
      "excluí-la.paradoxo\tde\tsimpson\n",
      "uma\tsurpresa\tincomum\tao\tanalisar\tdados\té\to\tparadoxo\tde\tsimpson,\tem\tque\tas\n",
      "correlações\tpodem\tser\tenganosas\tquando\tas\tvariáveis\t\n",
      "de\tconfusão\n",
      "\tsão\tignoradas.\n",
      "por\texemplo,\timagine\tque\tvocê\tpossa\tidentificar\ttodos\tos\tseus\tmembros\tcomo\n",
      "cientistas\tde\tdados\tda\tcosta\tleste\te\tda\tcosta\toeste.\tvocê\tdecide\texaminar\tquais\n",
      "são\tos\tmais\tamigáveis:\n",
      "costa\n",
      "quantidade\tde\n",
      "membros\n",
      "média\tda\n",
      "quantidade\tde\n",
      "amigos\n",
      "costa\n",
      "oeste\n",
      "101\n",
      "8.2\n",
      "costa\n",
      "leste\n",
      "103\n",
      "6.5\n",
      "certamente\tparece\tque\tos\tcientistas\tde\tdados\tda\tcosta\toeste\tsão\tmais\tamigáveis\n",
      "do\tque\tos\tda\tcosta\tleste.\tseus\tcolegas\tde\ttrabalho\tinvestem\tem\ttodo\to\ttipo\tde\n",
      "teorias\tno\tmotivo\tpelo\tqual\tisso\ttalvez\taconteça:\ttalvez\tseja\to\tsol,\to\tcafé,\ta\n",
      "produção\torgânica\tou\ta\tbrisa\tdescontraída\tdo\tpacífico.\n",
      "ao\tbrincar\tcom\tos\tdados,\tvocê\tdescobre\talgo\tmuito\testranho.\tse\tvocê\tolhar\n",
      "somente\tpara\tas\tpessoas\tcom\tphds,\tos\tcientistas\tde\tdados\tda\tcosta\tleste\n",
      "possuem\tuma\tmédia\tmaior\tde\tamigos.\te,\tse\tvocê\tolhar\tpara\tas\tpessoas\tsem\n",
      "phds,\tos\tcientistas\tde\tdados\tda\tcosta\tleste\ttambém\tpossuem\tuma\tmédia\tmaior\n",
      "de\tamigos!uma\tvez\tque\tvocê\tverifica\tos\tdiplomas\tdos\tusuários,\ta\tcorrelação\tvai\tem\tdireção\n",
      "oposta!\tagrupando\tos\tdados\tcomo\tcosta\tleste/oeste\tmascarou\to\tfato\tde\tque\tos\n",
      "cientistas\tde\tdados\tda\tcosta\tleste\tse\tdistorcem\tmais\tintensamente\tcom\tos\ttipos\n",
      "de\tphds.\n",
      "tal\tfenômeno\tsurge\tno\tmundo\treal\tcom\talguma\tregularidade.\to\tponto\tchave\té\n",
      "que\ta\tcorrelação\té\tmedir\ta\trelação\tentre\tsuas\tduas\tvariáveis\t\n",
      "com\ttudo\to\tmais\n",
      "sendo\tigual\n",
      ".\tse\tas\tsuas\taulas\tde\tdados\tfossem\tatribuídas\taleatoriamente,\tcomo\tse\n",
      "fossem\tclassificadas\tcomo\tum\texperimento\tbem\tprojetado,\t“por\tmais\tque\tsejam\n",
      "iguais”\tpode\tnão\tser\tuma\tpremissa\tterrível.\tmas\tquando\thá\tum\tpadrão\tmais\n",
      "profundo\tna\tatribuição\tde\tclasse,\t“por\tmais\tque\tsejam\tiguais”\tpode\tser\tuma\n",
      "premissa\tterrível.\n",
      "o\túnico\tmodo\treal\tde\tevitar\tisso\té\t\n",
      "conhecendo\tseus\tdados\n",
      "\te\tfazendo\to\tque\tpuder\n",
      "para\tter\tcerteza\tde\tque\tverificou\tpelos\tpossíveis\tfatores\tde\tconfusão.\n",
      "evidentemente,\tnem\tsempre\té\tpossível.\tse\tvocê\tnão\ttivesse\ta\tinformação\n",
      "educacional\tdesses\t200\tcientistas\tde\tdados,\tvocê\ttalvez\tconcluísse\tque\thavia\n",
      "algo\tinerente\te\tmais\tsociável\tsobre\ta\tcosta\toeste.alguns\toutros\tpontos\tde\tatenção\tsobre\tcorrelação\n",
      "uma\tcorrelação\tde\tzero\tindica\tque\tnão\thá\tuma\trelação\tlinear\tentre\tas\tduas\n",
      "variáveis.\tporém,\tpodem\thaver\tvários\ttipos\tde\trelações.\tpor\texemplo,\tse:\n",
      "x\t=\t[-2,\t-1,\t0,\t1,\t2]\n",
      "y\t=\t[\t2,\t1,\t0,\t1,\t2]\n",
      "então\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "\tpossuem\tuma\tcorrelação\tzero.\tmas,\tcertamente,\ttêm\tuma\trelação\t—\n",
      "cada\telemento\tde\t\n",
      "y\n",
      "\té\tigual\tao\tvalor\tabsoluto\tdo\telemento\tcorrespondente\tde\t\n",
      "x\n",
      ".\to\n",
      "que\teles\tnão\ttêm\té\t\n",
      "uma\trelação\tem\tque\tsaber\tcomo\t\n",
      "x_i\n",
      "\tse\tcompara\ta\t\n",
      "mean(x)\n",
      "\tnos\n",
      "dá\tinformações\tsobre\tcomo\t\n",
      "y_i\n",
      "\tse\tcompara\ta\t\n",
      "mean(y)\n",
      ".\tesse\té\to\ttipo\tde\trelação\tque\n",
      "a\tcorrelação\tprocura.\n",
      "além\tdo\tmais,\ta\tcorrelação\tnão\tdiz\tnada\tsobre\to\ttamanho\tdas\trelações.\tas\n",
      "variáveis:\n",
      "x\t=\t[-2,\t1,\t0,\t1,\t2]\n",
      "y\t=\t[99.98,\t99.99,\t100,\t100.01,\t100.02]\n",
      "estão\tperfeitamente\tcorrelacionadas,\tmas\t(dependendo\tdo\tque\tvocê\testá\n",
      "medindo)\té\tbem\tpossível\tque\tessa\trelação\tnão\tseja\tmuito\tinteressante.correlação\te\tcausalidade\n",
      "você\tjá\tdeve\tter\tescutado\talguma\tvez\tque\t“correlação\tnão\té\tcausalidade”,\tmais\n",
      "possivelmente\tde\tuma\tpessoa\tpesquisando\tdados\tque\timpuseram\tdesafios\tàs\n",
      "partes\tda\tvisão\tde\tmundo\tque\tele\testava\trelutante\tem\tquestionar.\tapesar\tdisso,\n",
      "este\té\tum\tponto\timportante\t—\tse\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "\tpossuem\tuma\tforte\tcorrelação,\tisso\ttalvez\n",
      "signifique\tque\t\n",
      "x\n",
      "\tcausa\t\n",
      "y\n",
      ",\tque\t\n",
      "y\n",
      "\tcausa\t\n",
      "x\n",
      "\te\tque\tcada\tum\tcausa\to\toutro,\tque\talgum\n",
      "terceiro\tfator\tcausa\tambos\tou\tpode\tnão\tsignificar\tnada.\n",
      "considere\ta\trelação\tentre\t\n",
      "num_friends\n",
      "\te\t\n",
      "daily_minutes\n",
      ".\té\tpossível\tque\tter\tmais\tamigos\n",
      "faça\tcom\tque\n",
      "\tos\tusuários\tda\tdatasciencester\tpassem\tmais\ttempo\tno\tsite.\tesse\n",
      "pode\tser\to\tcaso\tse\tcada\tamigo\tpostar\tuma\tcerta\tquantidade\tde\tconteúdo\n",
      "diariamente\tpois,\tquanto\tmais\tamigos\tvocê\ttem,\tmais\ttempo\tvocê\tleva\tpara\tpôr\n",
      "em\tdia\tsuas\tatualizações.\n",
      "porém,\ttambém\té\tpossível\tque,\tquanto\tmais\ttempo\tvocê\tpasse\tdiscutindo\tnos\n",
      "fóruns\tda\tdatasciencester,\tmais\tvocê\tencontrará\te\tfará\tamizade\tcom\tpessoas\n",
      "parecidas\tcom\tvocê.\tou\tseja,\tpassar\tmais\ttempo\tno\tsite\t\n",
      "faz\tcom\tque\n",
      "\tos\tusuários\n",
      "tenham\tmais\tamigos.\n",
      "uma\tterceira\tpossibilidade\tseria\tque\tos\tusuários\tmais\tdedicados\tcom\tdata\n",
      "science\tpassassem\tmais\ttempo\tno\tsite\t(porque\teles\tacham\tmais\tinteressante)\te\n",
      "ativamente\tcolecionassem\tmais\tamigos\tdata\tscience\t(porque\teles\tnão\tquerem\tse\n",
      "associar\tcom\tmais\tninguém).\n",
      "uma\tmaneira\tde\tse\tsentir\tmais\tconfiante\tsobre\tcausalidade\té\tconduzir\n",
      "experimentos\taleatórios.\tse\tvocê\tpode\tdividir\tseus\tusuários\taleatoriamente\tem\n",
      "dois\tgrupos\tcom\tdemografia\tparecida\te\tdar\ta\tum\tdos\tgrupos\tuma\texperiência\tum\n",
      "pouco\tdiferente,\tlogo\tvocê\tverá\tque\texperiências\tdiferentes\testão\tcausando\n",
      "resultados\tdiferentes.\n",
      "por\texemplo,\tse\tvocê\tnão\tse\timportar\tde\tser\tacusado\tde\tfazer\texperimentos\tcom\n",
      "seus\tusuários\t(\n",
      "http://nyti.ms/1l2dzeg\n",
      "),\tvocê\tpode\tescolher\tum\tsubconjunto\n",
      "aleatório\tde\tusuários\te\tmostrar\ta\teles\to\tconteúdo\tde\tsomente\tuma\tparte\tdos\tseus\n",
      "amigos.\tse\tesse\tsubconjunto\tsubsequentemente\tpassar\tmenos\ttempo\tno\tsite,\tisso\n",
      "lhe\tdará\tmais\tconfiança\tde\tque\tter\tmais\tamigos\t\n",
      "faz\tpassar\n",
      "\tmais\ttempo\tno\tsite.•\n",
      "•\n",
      "—\n",
      "—\n",
      "para\tmais\tesclarecimentos\n",
      "scipy\t(\n",
      "http://bit.ly/1l2h0lj\n",
      "),\tpandas\t(\n",
      "http://pandas.pydata.org\n",
      "),\te\n",
      "statsmodels\t(\n",
      "http://bit.ly/1l2gqnc\n",
      ")\tvêm\tcom\tuma\tgrande\tvariedade\tde\n",
      "funções\testatísticas.\n",
      "estatística\té\t\n",
      "importante\n",
      ".\t(ou,\ttalvez,\testatísticas\t\n",
      "são\n",
      "\timportantes?)\tse\tvocê\n",
      "quiser\tser\tum\tbom\tcientista\tde\tdados,\tseria\tuma\tboa\tideia\tler\tum\tlivro\n",
      "didático\tde\testatística.\tmuitos\testão\tdisponíveis\tonline.\tgosto\tmuito\tdestes\n",
      "dois:\n",
      "openintro\tstatistics\t(\n",
      "http://bit.ly/1l2gkvg\n",
      ")\n",
      "openstax\tintroductory\tstatistics\t(\n",
      "http://bit.ly/1l2gjrm)capítulo\t6\n",
      "probabilidade\n",
      "as\tleis\tda\tprobabilidade,\tno\tgeral\ttão\tverdadeiras,\tno\tparticular\ttão\tenganosas\n",
      ".\n",
      "—edward\tgibbon\n",
      "é\tdifícil\tpraticar\tdata\tscience\tsem\talgum\tentendimento\tde\tprobabilidade\te\tsua\n",
      "matemática.\tigualmente\tà\tnossa\tabordagem\tsobre\testatística\tno\t\n",
      "capítulo\t5\n",
      ",\tnos\n",
      "dedicaremos\tmuito\ta\teliminar\tmuitas\tdas\ttecnicalidades.\n",
      "para\tos\tnossos\tpropósitos,\tvocê\tdeveria\tpensar\tem\tprobabilidade\tcomo\tuma\n",
      "forma\tde\tquantificar\ta\tincerteza\tassociada\tcom\t\n",
      "eventos\n",
      "\tescolhidos\ta\tpartir\tde\tum\n",
      "universo\n",
      "\tdeles.\tem\tvez\tde\testudar\ttecnicamente\tesses\tmétodos,\tpense\tem\tjogar\n",
      "um\tdado.\to\tuniverso\tconsiste\tde\ttodos\tos\tresultados\tpossíveis.\tcada\n",
      "subconjunto\tdesses\tresultados\té\tum\tevento;\tpor\texemplo,\t“o\tdado\tmostra\to\n",
      "número\tum”\tou\t“o\tdado\tmostra\tum\tnúmero\tímpar”.\n",
      "desta\tforma,\tescrevemos\tp(e)\tpara\tsignificar\t“a\tprobabilidade\tdo\tevento\te”.\n",
      "usaremos\ta\tteoria\tda\tprobabilidade\tpara\tconstruir\tmodelos.\tusaremos\ta\n",
      "probabilidade\tpara\tavaliar\tmodelos.\tusaremos\ta\tteoria\tda\tprobabilidade\tem\n",
      "todos\tos\tlugares.\n",
      "alguém\tpoderia,\tse\ttivesse\tvontade,\tir\tbem\ta\tfundo\tna\tfilosofia\tdo\tque\ta\tteoria\n",
      "da\tprobabilidade\t\n",
      "significa\n",
      ".\t(melhor\tfazer\tisso\tcom\talgumas\tcervejas.)\tnão\n",
      "faremos\tisso.dependência\te\tindependência\n",
      "a\tgrosso\tmodo,\tdizemos\tque\tdois\teventos\te\te\tf\tsão\t\n",
      "dependentes\n",
      "\tse\tsoubermos\n",
      "algo\tsobre\tse\te\tocorre\tnos\tder\tinformações\tsobre\tse\tf\tocorre\t(e\tvice-versa).\tdo\n",
      "contrário,\tsão\tindependentes.\n",
      "por\texemplo,\tse\tjogarmos\tuma\tmoeda\thonesta\tduas\tvezes,\tsabendo\tque\ta\n",
      "primeira\tjogada\té\tcoroa,\tnão\ttemos\tcomo\tsaber\tse\ta\tsegunda\tjogada\tvai\tdar\to\n",
      "mesmo\tresultado.\tesses\teventos\tsão\tindependentes.\tpor\toutro\tlado,\tse\n",
      "soubéssemos\tque\ta\tprimeira\tjogada\tfosse\tcoroa,\tcertamente\tteríamos\ta\n",
      "informação\tsobre\tse\tambas\tas\tjogadas\tseriam\tcara.\t(se\ta\tprimeira\tjogada\t\n",
      "é\n",
      "coroa,\tentão,\tdefinitivamente,\tnão\té\to\tcaso\tde\tque\tas\tduas\tjogadas\tsão\tcara.)\n",
      "esses\tdois\teventos\tsão\tdependentes.\n",
      "matematicamente,\tdizemos\tque\tos\tdois\teventos\te\te\tf\tsão\tindependentes\tse\ta\n",
      "probabilidade\tdeles\tacontecerem\té\to\tproduto\tda\tprobabilidade\tde\tque\tcada\tum\n",
      "deles\taconteça:\n",
      "p(e\n",
      ",\n",
      "f\n",
      ")\t=\n",
      "p(e)p(f)\n",
      "no\texemplo\tanterior,\ta\tprobabilidade\tda\t“primeira\tjogada\tser\tcoroa”\té\tde\t1/2,\te\ta\n",
      "probabilidade\tde\t“ambas\tserem\tcara”\té\tde\t1/4,\tmas\ta\tprobabilidade\tde\t“a\n",
      "primeira\tjogada\tser\tcoroa\te\tambas\tserem\tcara”\té\t0.1.\n",
      "2.\n",
      "probabilidade\tcondicional\n",
      "quando\tos\tdois\teventos\te\te\tf\tsão\tindependentes,\tpor\tdefinição,\ttemos:\n",
      "p(e\n",
      ",\n",
      "f\n",
      ")\t=\n",
      "p(e)p(f)\n",
      "se\tnão\tsão\tnecessariamente\tindependentes\t(e\ta\tprobabilidade\tde\tf\tnão\tfor\t0),\n",
      "logo\tdefinimos\ta\tprobabilidade\tde\te\t“condicionada\ta\tf”\tassim:\n",
      "p(e|f)\n",
      "\t=\n",
      "p(e\n",
      ",\n",
      "f\n",
      ")/(\n",
      "p(f)\n",
      "você\tdeveria\tentender\tisso\tcomo\ta\tprobabilidade\tde\te\tacontecer\tuma\tvez\tque\n",
      "sabemos\tque\tf\tacontece.\n",
      "geralmente\treescrevemos\tdesta\tforma:\n",
      "p(e\n",
      ",\n",
      "f\n",
      ")\t=\n",
      "p(e|f)p(f)\n",
      "quando\te\te\tf\tsão\tindependentes,\tvocê\tpode\tverificar\tque\tisso\tresulta\tem:\n",
      "p(e|f)\n",
      "\t=\n",
      "p(e)\n",
      "que\té\ta\tmaneira\tmatemática\tde\texplicar\tque\tsaber\tque\tf\tocorreu\tnão\tnos\tdá\n",
      "nenhuma\tinformação\tadicional\tsobre\tse\te\tocorreu.\n",
      "um\texemplo\tcomum\te\ttraiçoeiro\tenvolve\tuma\tfamília\tcom\tdois\tfilhos\n",
      "(desconhecidos).\n",
      "se\tpresumirmos\tque:\n",
      "é\tigualmente\tpossível\tque\tcada\tcriança\tseja\tmenino\tou\tmenina\n",
      "o\tgênero\tda\tsegunda\tcriança\té\tindependente\tdo\tgênero\tda\tprimeira,\tentão\n",
      "o\tevento\t\n",
      "“nenhuma\tmenina”\ttem\ta\tprobabilidade\tde\t1/4,\to\tevento\t“uma\n",
      "menina,\tum\tmenino”\ttem\ta\tprobabilidade\tde\t1/2\te\to\tevento\t“duas\n",
      "meninas”\ttem\ta\tprobabilidade\tde\t1/4.\n",
      "agora,\tpodemos\tperguntar:\tqual\ta\tprobabilidade\tde\to\tevento\t“as\tduas\tcrianças\n",
      "são\tmeninas”\t(b)\tser\tcondicionado\tpelo\tevento\t“a\tcriança\tmais\tvelha\té\tuma\n",
      "menina”\t(g)?\tusando\ta\tdefinição\tde\tprobabilidade\tcondicional:p\t(b\t|\tg)\n",
      "\t=\n",
      "p\t(b\n",
      ",\t\n",
      "g\n",
      ")\t/\n",
      "p\t(g)\n",
      "\t=\n",
      "p\t(b)\n",
      "\t/\n",
      "p\t(g)\n",
      "\t=\t1/2\n",
      "uma\tvez\tque\to\tevento\tb\te\tg\t(“ambas\tas\tcrianças\tsão\tmeninas\t\n",
      "e\n",
      "\ta\tcriança\tmais\n",
      "velha\té\tuma\tmenina”)\té\tapenas\to\tevento\tb.\t(já\tsabendo\tque\tas\tduas\tcrianças\tsão\n",
      "meninas,\té\tobrigatoriamente\tverdade\tque\ta\tcriança\tmais\tvelha\tseja\tmenina.)\n",
      "esse\tresultado\ttalvez\tcorresponda\ta\tsua\tintuição.\n",
      "também\tpoderíamos\tperguntar\tsobre\ta\tprobabilidade\tdo\tevento\t“as\tduas\n",
      "crianças\tsão\tmeninas”\tser\tcondicional\tao\tevento\t“ao\tmenos\tuma\tdas\tcrianças\té\n",
      "menina”\t(l).\tsurpreendentemente,\ta\tresposta\té\tdiferente\tde\tantes!\n",
      "anteriormente,\tos\teventos\tb\te\tl\t(“as\tduas\tcrianças\tsão\tmeninas\t\n",
      "e\n",
      "\tao\tmenos\tuma\n",
      "delas\té\tuma\tmenina”)\té\tapenas\to\tevento\tb.\tisso\tsignifica\tque\ttemos:\n",
      "p\t(b\t|\tl)\n",
      "\t=\n",
      "p\t(b\n",
      ",\t\n",
      "l\n",
      ")\t/\n",
      "p\t(l)\n",
      "\t=\t\n",
      "p\t(b)\n",
      "\t/\n",
      "p\t(l)\n",
      "\t=\t1/3\n",
      "como\tpode\tser\tesse\to\tcaso?\tbem,\tse\ttudo\tque\tvocê\tsabe\té\tque\tao\tmenos\tuma\n",
      "das\tcrianças\té\tmenina,\tentão\té\tduas\tvezes\tmais\tprovável\tque\ta\tfamília\ttenha\tum\n",
      "menino\te\tuma\tmenina\tdo\tque\tduas\tmeninas.\n",
      "podemos\tverificar\tisso\tao\t“gerar”\tvárias\tfamílias:\n",
      "def\n",
      "\t\n",
      "random_kid():\n",
      "\t\n",
      "return\n",
      "\trandom.choice([\"boy\",\t\"girl\"])\n",
      "both_girls\t=\t0\n",
      "older_girl\t=\t0\n",
      "either_girl\t=\t0\n",
      "random.seed(0)\n",
      "for\n",
      "\t_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "range(10000):\n",
      "\tyounger\t=\trandom_kid()\n",
      "\tolder\t=\trandom_kid()\n",
      "\t\n",
      "if\n",
      "\t\n",
      "older\t==\t\"girl\":\n",
      "\tolder_girl\t+=\t1\n",
      "\t\n",
      "if\n",
      "\t\n",
      "older\t==\t\"girl\"\n",
      "\t\n",
      "and\n",
      "\t\n",
      "younger\t==\t\"girl\":\n",
      "\tboth_girls\t+=\t1\n",
      "\t\n",
      "if\n",
      "\t\n",
      "older\t==\t\"girl\"\n",
      "\t\n",
      "or\n",
      "\t\n",
      "younger\t==\t\"girl\":\n",
      "\teither_girl\t+=\t1\n",
      "\t\n",
      "print\n",
      "\t\n",
      "\"p(both\t|\tolder):\",\tboth_girls\t/\tolder_girl\n",
      "\t\t\t\t\t\t\t\t\n",
      "#\t0.514\t~\t1/2\n",
      "\t\n",
      "print\n",
      "\t\n",
      "\"p(both\t|\teither):\t\",\tboth_girls\t/\teither_girl\n",
      "\t\t\t\t\t\n",
      "#\t0.342\t~\t1/3teorema\tde\tbayes\n",
      "um\tdos\tmelhores\tamigos\tdo\tcientista\tde\tdados\té\to\tteorema\tde\tbayes,\to\tqual\té\n",
      "uma\tmaneira\tde\t“reverter”\tas\tprobabilidades\tcondicionais.\tdigamos\tque\n",
      "precisamos\tsaber\ta\tprobabilidade\tde\talgum\tevento\te\tser\tcondicionado\tà\n",
      "ocorrência\tde\toutro\tevento\tf.\tmas\tapenas\ttemos\ta\tinformação\tsobre\ta\n",
      "probabilidade\tda\tocorrência\tde\tf\tsendo\tcondicionado\ta\te.\tusando\ta\tdefinição\tde\n",
      "probabilidade\tcondicional\tduas\tvezes,\tpodemos\tdizer\tque:\n",
      "p\t(e|\tf\n",
      "\t=\n",
      "p\t(e\n",
      ",\t\n",
      "f)\n",
      "/\n",
      "p\t(f)\n",
      "\t=\n",
      "p\t(f|\te)\tp\t(e)\n",
      "\t/\n",
      "p\t(f)\n",
      "o\tevento\tf\tpode\tser\tdividido\tem\tdois\teventos\tmutuamente\texclusivos\t“f\te\te”\te\n",
      "“f\te\tnão\te”.\tse\tescrevermos\te\tpara\t“não\te”\t(por\texemplo,\t“e\tnão\tacontece”),\n",
      "logo:\n",
      "então\ttemos:\n",
      "que\té\tcomo\to\tteorema\tde\tbayes\té\testabelecido.\n",
      "esse\tteorema\té\tusado\tcom\tfrequência\tpara\tdemonstrar\tporque\tos\tcientistas\tde\n",
      "dados\tsão\tmais\tespertos\tdo\tque\tmédicos.\timagine\tque\tuma\tdeterminada\tdoença\n",
      "afete\t1\ta\tcada\t10.000\tpessoas.\te\timagine\tque\thaja\tum\tteste\tpara\tessa\tdoença\tque\n",
      "mostra\to\tresultado\tcorreto\t(“doente”\tse\tvocê\ttem\ta\tdoença\te\t“não-doente”\tse\n",
      "não)\t99%\tdas\tvezes.\n",
      "o\tque\tsignifica\tum\tteste\tpositivo?\tvamos\tusar\tt\tpara\to\tevento\t“seu\tteste\té\n",
      "positivo”\te\td\tpara\to\tevento\t“você\ttem\ta\tdoença”.\to\tteorema\tde\tbayes\tdiz\tque\ta\n",
      "probabilidade\tde\tvocê\tter\ta\tdoença,\tcondicional\tao\tteste\tpositivo,\té:\n",
      "aqui\tvemos\tque\tp(t\t|\td),\ta\tprobabilidade\tde\tque\talguém\tcom\ta\tdoença\tobtenha\n",
      "um\tteste\tpositivo,\té\t0,99.\tp(d),\ta\tprobabilidade\tde\tque\tqualquer\tpessoa\ttenha\ta\n",
      "doença\té\t1/10.000\t=\t0.0001.\tp\t(t|¬d),\ta\tprobabilidade\tde\tque\talguém\tsem\ta\n",
      "doença\tobtenha\tum\tteste\tpositivo\té\t0,01.\te\tp(¬d),\ta\tprobabilidade\tde\tquequalquer\tpessoa\tnão\ttenha\ta\tdoença\té\t0,9999.\tse\tvocê\tsubstituir\tesses\tnúmeros\n",
      "no\tteorema\tde\tbayes\tvocê\tencontrará\n",
      "p\t(d)\t|\tt\n",
      "\t=\t0.98%\n",
      "ou\tseja,\tmenos\tde\t1%\tdas\tpessoas\tque\tobtém\tum\tteste\tpositivo\trealmente\n",
      "possuem\ta\tdoença.\n",
      "isso\tpresume\tque\tas\tpessoas\tfazem\to\tteste\tde\tforma\taleatória.\tse\tapenas\tas\n",
      "pessoas\tque\tpossuíssem\talguns\tsintomas\tfizessem\to\tteste,\tteríamos\tcomo\n",
      "condição\to\tevento\t“teste\tpositivo\t\n",
      "e\n",
      "\tsintomas”\te\to\tnúmero\tteria\ta\tpossibili-dade\n",
      "de\tser\tbem\tmaior.\n",
      "enquanto\tesse\té\tum\tcálculo\tsimples\tpara\tos\tcientistas\tde\tdados,\ta\tmaioria\tdos\n",
      "médicos\tchutariam\tque\tp(d|t)\tseria\tperto\tde\t2.\n",
      "uma\tforma\tmais\tintuitiva\tde\tver\tisso\té\timaginar\tuma\tpopulação\tde\tum\tmilhão\n",
      "de\tpessoas.\tvocê\tesperaria\tque\t100\tdelas\ttivessem\ta\tdoença,\te\tque\t99\tdessas\t100\n",
      "obtivessem\tum\tteste\tpositivo.\tpor\toutro\tlado,\tvocê\tesperaria\tque\t999.900\tdelas\n",
      "não\ttivessem\ta\tdoença,\te\tque\t9,999\tdelas\tobtivessem\tum\tteste\tpositivo.\to\tque\n",
      "significa\tque\tvocê\tesperaria\tque\tsomente\t99\tde\t(99\t+\t9999)\ttestes\tpositivos\n",
      "realmente\tpossuíssem\ta\tdoença.variáveis\taleatórias\n",
      "uma\t\n",
      "variável\taleatória\n",
      "\té\ta\tvariável\tcujos\tvalores\tpossíveis\tpossuem\tuma\n",
      "distribuição\tde\tprobabilidade\tassociada.\tuma\tvariável\taleatória\tbem\tsimples\té\n",
      "igual\ta\t1\tse\tum\tlançamento\tde\tmoeda\tfor\tcara\te\t0\tse\tfor\tcoroa.\tuma\tmaneira\n",
      "mais\tcomplicada\tseria\tmedir\to\tnúmero\tde\tcaras\tobservadas\tao\tlançar\ta\tmoeda\n",
      "dez\tvezes\tou\tum\tvalor\tescolhido\tde\t\n",
      "range(10),\n",
      "\tno\tqual\ttodos\tos\tnúmeros\ttêm\ta\n",
      "mesma\tprobabilidade.\n",
      "a\tdistribuição\tassociada\tdá\tas\tprobabilidades\tque\ta\tvariável\tpossui\tem\tcada\tum\n",
      "de\tseus\tvalores\tpossíveis.\ta\tvariável\tdo\tlançamento\tde\tmoeda\té\tigual\ta\t0\tcom\ta\n",
      "probabilidade\tde\t0,5\te\t1\tcom\ta\tprobabilidade\tde\t0,5.\ta\tvariável\t\n",
      "range(10)\n",
      "\ttem\tuma\n",
      "distribuição\tque\tatribui\ta\tprobabilidade\t0,1\tpara\tcada\tum\tdos\tnúmeros\tde\t0\ta\t9.\n",
      "às\tvezes\tfalaremos\tsobre\to\t\n",
      "valor\tesperado\n",
      "\tda\tvariável\taleatória,\to\tqual\té\ta\n",
      "média\tde\tseus\tvalores\tponderados\tpor\tsuas\tprobabilidades.\ta\tvariável\tde\n",
      "lançamento\tda\tmoeda\ttem\tum\tvalor\tesperado\tde\t1/2\t(=\t0\t*\t1/2\t+\t1\t*\t1/2),\te\ta\n",
      "variável\trange(10)\ttem\tum\tvalor\tesperado\tde\t4,5.\n",
      "as\tvariáveis\taleatórias\tpodem\tser\tcondicionadas\ta\teventos\tassim\tcomo\toutros\n",
      "eventos.\tvoltando\tao\texemplo\tdas\tduas\tcrianças\tda\t“probabilidade\tcondicional”\n",
      "na\tpágina\t70,\tse\tx\tfor\ta\tvariável\trandômica\trepresentando\to\tnúmero\tde\tmeninas,\n",
      "x\té\tigual\ta\t0\tcom\tprobabilidade\tde\t¼,\t1\tcom\tprobabilidade\tde\t1/2\te\t2\tcom\n",
      "probabilidade\tde\t¼.\n",
      "podemos\tdefinir\tuma\tnova\tvariável\ty\tque\tdiz\to\tnúmero\tde\tmeninas\n",
      "condicionado\ta,\tpelo\tmenos,\tuma\tdas\tcrianças\tser\tuma\tmenina.\tlogo,\ty\té\tigual\ta\n",
      "1\tcom\ta\tprobabilidade\tde\t2/3\te\t2\tcom\tprobabilidade\tde\t1/3.\ta\tvariável\tz\té\to\n",
      "número\tde\tmeninas\tque\té\tcondicionado\tao\tfilho\tmais\tvelho\tsendo\tuma\tmenina\n",
      "igual\ta\t1\tcom\tprobabilidade\tde\t1/2\te\t2\tcom\tprobabilidade\tde\t1/2.\n",
      "na\tmaioria\tdas\tvezes,\tusaremos\tas\tvariáveis\taleatórias\timplícitas\tao\tque\tfazemos\n",
      "sem\tchamar\ta\tatenção\tpara\telas.\tmas,\tse\tvocê\tolhar\tmais\tatentamente,\tvocê\tas\n",
      "verá.distribuições\tcontínuas\n",
      "um\tlançamento\tde\tmoeda\tcorresponde\ta\tuma\t\n",
      "distribuição\tdiscreta\n",
      "\t—\tuma\tque\n",
      "associa\tprobabilidade\tpositiva\tcom\tresultados\tdiscretos.\tfrequentemente,\tvamos\n",
      "querer\tmodelar\tas\tdistribuições\tpor\tmeio\tde\tum\tcontínuo\tde\tresultados.\t(para\n",
      "nossos\tpropósitos,\tesses\tresultados\tsempre\tserão\tnúmeros\treais,\tembora\tnão\tseja\n",
      "o\tcaso\tna\tvida\treal.)\tpor\texemplo,\ta\t\n",
      "distribuição\tuniforme\n",
      "\tcoloca\t\n",
      "peso\tigual\n",
      "\tem\n",
      "todos\tos\tnúmeros\tentre\t0\te\t1.\n",
      "como\texistem\tinfinitos\tnúmeros\tentre\t0\te\t1,\tisso\tsignifica\tque\to\tpeso\tque\tele\n",
      "atribui\taos\tpontos\tindividuais\tprecisa\tser\texatamente\t0.\tpor\tesse\tmotivo,\n",
      "representamos\tuma\tdistribuição\tcontínua\tcom\tuma\n",
      "\tfunção\tde\tdensidade\tde\n",
      "probabilidade\n",
      "\t(pdf,\tdo\tinglês\t\n",
      "probability\tdensity\tfunction\n",
      ")\ttal\tque\ta\n",
      "probabilidade\tde\tver\tum\tvalor\tem\tum\tdeterminado\tintervalo\té\tigual\tà\tintegral\tda\n",
      "função\tde\tdensidade\tsobre\to\tintervalo.\n",
      "se\tseu\tcálculo\tintegral\testiver\tenferrujado,\ta\tmelhor\tmaneira\tde\tentender\tisso\té\n",
      "se\ta\tdistribuição\ttem\ta\tfunção\tde\tdensidade\tf,\tlogo\ta\tprobabilidade\tde\tver\tum\n",
      "valor\tentre\t\n",
      "x\n",
      "\te\t\n",
      "x\t+\th\n",
      "\té\taproximadamente\t\n",
      "h*\tf(x)\n",
      "\tse\th\tfor\tpequeno.\n",
      "a\tfunção\tde\tdensidade\tpara\ta\tdistribuição\tuniforme\té:\n",
      "def\n",
      "\t\n",
      "uniform_pdf(x):\n",
      "\t\n",
      "return\n",
      "\t\n",
      "1\n",
      "\t\n",
      "if\n",
      "\t\n",
      "x\t>=\t0\n",
      "\t\n",
      "and\n",
      "\t\n",
      "x\t<\t1\n",
      "\t\n",
      "else\n",
      "\t\n",
      "0\n",
      "a\tprobabilidade\tde\tum\tvalor\taleatório\tseguido\tde\tdistribuição\testar\tentre\t0,2\te\n",
      "0,3\té\t1/10,\tcomo\tera\tde\tse\tesperar.\t\n",
      "random.random()\n",
      "\tde\tpython\té\tuma\tvariável\n",
      "(pseudo)\taleatória\tcom\tuma\tdensidade\tuniforme.\n",
      "estaremos\tfrequentemente\tmais\tinteressados\tna\t\n",
      "função\tde\tdistribuição\n",
      "cumulativa\n",
      "\t(cdf,\tdo\tinglês\t\n",
      "cumulative\tdistribution\tfunction\n",
      ")\tque\tfornece\ta\n",
      "probabilidade\tde\tuma\tvariável\taleatória\tser\tmenor\tou\tigual\ta\tum\tdeterminado\n",
      "valor.\tnão\té\tdifícil\tcriar\tuma\tfunção\tde\tdistribuição\tcumulativa\tpara\ta\n",
      "distribuição\tuniforme\t(\n",
      "figura\t6-1\n",
      "):\n",
      "def\n",
      "\t\n",
      "uniform_cdf(x):\n",
      "\t\n",
      "\"retorna\ta\tprobabilidade\tde\tuma\tvariável\taleatória\tuniforme\tser\t<=\tx\"\n",
      "\t\n",
      "if\n",
      "\t\n",
      "x\t<\t0:\n",
      "\t\t\t\n",
      "return\n",
      "\t\n",
      "0\n",
      "\t\t\t\t\t\n",
      "#\ta\taleatória\tuniforme\tnunca\té\tmenor\tdo\tque\t0\t\n",
      "elif\n",
      "\t\n",
      "x\t<\t1:\n",
      "\t\n",
      "return\n",
      "\t\n",
      "x\n",
      "\t\t\t\t\t\n",
      "#\tpor\texemplo\tp(x\t<=\t0.4)\t=\t0.4\n",
      "\t\n",
      "else\n",
      ":\n",
      "\t\t\t\t\t\t\n",
      "return\n",
      "\t\n",
      "1\n",
      "\t\t\t\t\t\n",
      "#\ta\taleatória\tuniforme\tsempre\té\tmenor\tdo\tque\t1\n",
      "figura\t6-1.\ta\tfunção\tde\tdistribuição\tcumulativa\tuniformea\tdistribuição\tnormal\n",
      "a\tdistribuição\tnormal\té\ta\trainha\tdas\tdistribuições.\té\tuma\tclássica\tdistribuição\tde\n",
      "curva\tem\tforma\tde\tsino\te\té\tdeterminada\tpor\tdois\tparâmetros:\tsua\tmédia\tμ\t(mi)\te\n",
      "o\tdesvio\tpadrão\tσ\t(sigma).\ta\tmédia\tindica\tonde\to\tsino\té\tcentralizado\te\to\tdesvio\n",
      "padrão\tindica\ta\tlargura\tdo\tsino.\n",
      "ela\tpossui\ta\tfunção\tde\tdistribuição:\n",
      "que\tpodemos\timplementar\tcomo:\n",
      "def\n",
      "\tnormal_pdf(x,\tmu=0,\tsigma=1):\n",
      "\tsqrt_two_pi\t=\tmath.sqrt(2\t*\tmath.pi)\n",
      "\t\n",
      "return\n",
      "\t\n",
      "(math.exp(-(x-mu)\t**\t2\t/\t2\t/\tsigma\t**\t2)\t/\t(sqrt_two_pi\t*\tsigma))\n",
      "na\t\n",
      "figura\t6-2\n",
      ",\tanalisamos\talgumas\tdessas\tfunções\tde\tdensidade\tde\n",
      "probabilidade\tpara\tver\tcomo\teles\tficam:\n",
      "xs\t=\t[x\t/\t10.0\tfor\tx\tin\trange(-50,\t50)]\n",
      "plt.plot(xs,[normal_pdf(x,sigma=1)\tfor\tx\tin\txs],'-',label='mu=0,sigma=1')\n",
      "plt.plot(xs,[normal_pdf(x,sigma=2)\tfor\tx\tin\txs],'--',label='mu=0,sigma=2')\n",
      "plt.plot(xs,[normal_pdf(x,sigma=0.5)\tfor\tx\tin\txs],':',label='mu=0,sigma=0.5')\n",
      "plt.plot(xs,[normal_pdf(x,mu=-1)\tfor\tx\tin\txs],'-.',label='mu=-1,sigma=1')\n",
      "plt.legend()\n",
      "plt.title(\"\n",
      "diversas\tfunções\tde\tdensidade\tde\tprobabilidade\tnormais\n",
      "\")\n",
      "plt.show()figura\t6-2.\tdiversas\tfunções\tde\tdensidade\tde\tprobabilidade\tnormais\n",
      "é\tchamada\tde\t\n",
      "distribuição\tnormal\tpadrão\n",
      "\tquando\tμ\t=\t0\te\tσ\t=\t1.\tse\tz\té\tuma\n",
      "variável\taleatória\tnormal\tpadrão,\tentão:\n",
      "x\n",
      "\t=\t\n",
      "σz\n",
      "\t+\t\n",
      "μ\n",
      "também\té\tnormal\tmas\tcom\ta\tmédia\tμ\te\to\tdesvio\tpadrão\tσ.\tpor\toutro\tlado,\tse\tx\té\n",
      "uma\tvariável\taleatória\tnormal\tcom\tmédia\tμ\te\tdesvio\tpadrão\tσ,\n",
      "z\n",
      "\t=\t(\n",
      "x\n",
      "\t-\t\n",
      "μ\n",
      ")/\n",
      "σ\n",
      "é\tuma\tvariável\tnormal\tpadrão.\n",
      "a\tfunção\tde\tdistribuição\tcumulativa\tpara\ta\tdistribuição\tnormal\tnão\tpode\tser\n",
      "escrita\tde\tmaneira\t“elementar”,\tmas\tpodemos\tescrever\tusando\t\n",
      "math.erf\n",
      "(\n",
      "http://en.wikipedia.org/wiki/error_function\n",
      ")\tdo\tpython:\n",
      "def\n",
      "\t\n",
      "normal_cdf(x,\tmu=0,sigma=1):\n",
      "\t\n",
      "return\n",
      "\t\n",
      "(1\t+\tmath.erf((x\t-\tmu)\t/\tmath.sqrt(2)\t/\tsigma))\t/\t2novamente,\tna\t\n",
      "figura\t6-3\n",
      ",\tvemos\talguns:\n",
      "xs\t=\t[x\t/\t10.0\tfor\tx\tin\trange(-50,\t50)]\n",
      "plt.plot(xs,[normal_cdf(x,sigma=1)\tfor\tx\tin\txs],'-',label='mu=0,sigma=1')\n",
      "plt.plot(xs,[normal_cdf(x,sigma=2)\tfor\tx\tin\txs],'--',label='mu=0,sigma=2')\n",
      "plt.plot(xs,[normal_cdf(x,sigma=0.5)\tfor\tx\tin\txs],':',label='mu=0,sigma=0.5')\n",
      "plt.plot(xs,[normal_cdf(x,mu=-1)\tfor\tx\tin\txs],'-.',label='mu=-1,sigma=1')\n",
      "plt.legend(loc=4)\t\n",
      "#\tbottom\tright\n",
      "plt.title(\"\n",
      "diversas\tfunções\tde\tdensidade\tde\tdistribuição\tcumulativa\n",
      "\")\n",
      "plt.show()\n",
      "figura\t6-3.\tdiversas\tfunções\tde\tdistribuição\tcumulativa\n",
      "algumas\tvezes\tteremos\tque\tinverter\t\n",
      "normal_cdf\n",
      "\tpara\tencontrar\to\tvalor\n",
      "correspondente\tà\tprobabilidade\tespecificada.\tnão\texiste\tuma\tforma\tsimples\tde\n",
      "computar\tesse\tinverso,\tmas\t\n",
      "normal_cdf\n",
      "\té\tcontínuo\te\tem\tcrescimento,\tportanto\n",
      "podemos\t usar\t uma\t busca\t binária\n",
      "(\n",
      "http://en.wikipedia.org/wiki/binary_search_algorithm\n",
      "):\n",
      "def\n",
      "\t\n",
      "inverse_normal_cdf(p,\tmu=0,\tsigma=1,\ttolerance=0.00001):\"\"\"encontra\to\tinverso\tmais\tpróximo\tusando\ta\tbusca\tbinária\"\"\"\n",
      "#\tse\tnão\tfor\tpadrão,\tcomputa\to\tpadrão\te\tredimensiona\n",
      "if\n",
      "\t\n",
      "mu\t!=\t0\n",
      "\t\n",
      "or\n",
      "\t\n",
      "sigma\t!=\t1:\n",
      "return\n",
      "\t\n",
      "mu\t+\tsigma\t*\tinverse_normal_cdf(p,\ttolerance=tolerance)\n",
      "low_z,\tlow_p\t=\t-10.0,\t0\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnormal_cdf(-10)\testá\t(muito\tperto\tde)\t0\n",
      "hi_z,\thi_p\t\t\t=\t\t10.0,\t1\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnormal_cdf(10)\testá\t(muito\tperto\tde)\t1\n",
      "while\n",
      "\t\n",
      "hi_z\t-\tlow_z\t>\ttolerance:\n",
      "mid_z\t=\t(low_z\t+\thi_z)\t/\t2\n",
      "\t\t\t\t\t\n",
      "#\tconsidera\to\tponto\tdo\tmeio\te\to\tvalor\tda\n",
      "mid_p\t=\tnormal_cdf(mid_z)\n",
      "\t\t\t\t\t\t\n",
      "#\tfunção\tde\tdistribuição\tcumulativa\tlá\n",
      "if\n",
      "\t\n",
      "mid_p\t<\tp:\n",
      "\t\n",
      "#\to\tponto\tdo\tmeio\tainda\testá\tbaixo,\tprocura\tacima\n",
      "\t\n",
      "low_z,\tlow_p\t=\tmid_z,\tmid_p\n",
      "elif\n",
      "\t\n",
      "mid_p\t>\tp:\n",
      "\t\n",
      "#\to\tponto\tdo\tmeio\tainda\testá\talto,\tprocura\tabaixo\n",
      "\t\n",
      "hi_z,\thi_p\t=\tmid_z,\tmid_p\n",
      "else\n",
      ":\n",
      "\t\t\n",
      "break\n",
      "return\n",
      "\t\n",
      "mid_z\n",
      "a\tfunção\tdivide\tem\tdois\tintervalos\trepetidamente\taté\tdiminuir\tpara\tum\tz\n",
      "próximo\to\tsuficiente\tda\tprobabilidade\tdesejada.o\tteorema\tdo\tlimite\tcentral\n",
      "um\tmotivo\tpara\ta\tdistribuição\tnormal\tser\ttão\tútil\té\to\t\n",
      "teorema\tdo\tlimite\tcentral\n",
      ",\n",
      "que\tdiz\tque\t(em\tessência)\tuma\tvariável\taleatória\tdefinida\tcomo\ta\tmédia\tde\tuma\n",
      "grande\tquantidade\tde\tvariáveis\taleatórias\tdistribuídas\tindependente\te\n",
      "identicamente\té\tela\tmesma\taproximadamente\tdistribuída\tnormalmente.\n",
      "em\tespecial,\tse\tx1,…,xn\tsão\tvariáveis\taleatórias\tcom\tmédia\tμ\te\tdesvio\tpadrão\tσ,\n",
      "e\tse\tn\tfor\tgrande,\tentão:\n",
      "está\taproximadamente\tdistribuída\tnormalmente\tcom\ta\tmédia\tμ\te\to\tdesvio\tpadrão\n",
      ".\tda\tmesma\tforma\t(mas\tbem\tmais\tútil),\n",
      "está\taproximadamente\tdistribuída\tnormalmente\tcom\tmédia\t0\te\tdesvio\tpadrão\t1.\n",
      "uma\tmaneira\tsimples\tde\tilustrar\tisso\té\tconsiderando\tas\tvariáveis\taleatórias\n",
      "binomiais\n",
      ",\tas\tquais\tpossuem\tdois\tparâmetros\tn\te\tp.\tuma\tvariável\taleatória\n",
      "binomial(n,p)\té\tapenas\ta\tsoma\tde\tn\tvariáveis\taleatórias\tindependentes\n",
      "bernoulli(p),\te\tcada\tuma\tdelas\té\tigual\ta\t1\tcom\tprobabilidade\tp\te\t0\tcom\n",
      "probabilidade\t1−\tp:\n",
      "def\n",
      "\t\n",
      "bernoulli_trial(p):\n",
      "\t\n",
      "return\n",
      "\t\n",
      "1\n",
      "\t\n",
      "if\n",
      "\t\n",
      "random.random()\t<\tp\n",
      "\t\n",
      "else\n",
      "\t\n",
      "0\n",
      "def\n",
      "\t\n",
      "binomial(n,\tp):\n",
      "\t\n",
      "return\n",
      "\t\n",
      "sum(bernoulli_trial(p)\n",
      "\t\n",
      "for\n",
      "\t\n",
      "_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "range(n))\n",
      "a\tmédia\tde\tuma\tvariável\tbernoulli(p)\té\tp,\te\tseu\tdesvio\tpadrão\t\n",
      "\to\n",
      "teorema\tdo\tlimite\tcentral\tdiz\tque,\tconforme\tn\taumenta,\ta\tvariável\tbinomial(n,p)\n",
      "é\taproximadamente\tuma\tvariável\taleatória\tnormal\tcom\ta\tmédia\tμ\t=\tnp\te\tdesvio\n",
      "padrão\t\n",
      "\tse\tanalisarmos\tos\tdois,\tpode-se\tver\tclaramente\ta\n",
      "semelhança:\n",
      "def\tmake_hist(p,\tn,\tnum_points):\n",
      "\t\n",
      "data\t=\t[binomial(n,\tp)\tfor\t_\tin\trange(num_points)]\t\n",
      "#\tusa\tum\tgráfico\tde\tbarras\tpara\texibir\tas\tamostrar\tbinomiais\tatuais\n",
      "\t\n",
      "histogram\t=\tcounter(data)\n",
      "\tplt.bar([x\t-\t0.4\tfor\tx\tin\thistogram.keys()],\n",
      "\t[v\t/\tnum_points\tfor\tv\tin\thistogram.values()],\n",
      "\t0.8,\n",
      "\tcolor='0.75')\n",
      "\t\n",
      "mu\t=\tp\t*\tn\n",
      "\t\n",
      "sigma\t=\tmath.sqrt(n\t*\tp\t*\t(1\t-\tp))\n",
      "\t\n",
      "#\tusa\tum\tgráfico\tde\tlinhas\tpara\texibir\tuma\taproximação\tda\tnormal\n",
      "\t\n",
      "xs\t=\trange(min(data),\tmax(data)\t+\t1)\n",
      "\tys\t=\t[normal_cdf(i\t+\t0.5,\tmu,\tsigma)\t-\tnormal_cdf(i\t-\t0.5,\tmu,\tsigma)\n",
      "for\ti\tin\txs]\n",
      "\tplt.plot(xs,ys)\n",
      "\tplt.title(\"distribuição\tbinomial\tvs.\taproximação\tnormal\"\t)\n",
      "\t\n",
      "plt.show()\n",
      "por\texemplo,\tquando\tvocê\tchama\t\n",
      "make_hist(0.75,\t100,\t10000)\n",
      ",\tvocê\tobtém\to\tgráfico\n",
      "da\t\n",
      "figura\t6-4\n",
      ".\n",
      "figura\t6-4.\ta\tsaída\tde\tmake_histo\tprincipal\tdessa\taproximação\té\tque\tse\tvocê\tquiser\tsaber\ta\tprobabilidade\tde\n",
      "(digamos)\tuma\tmoeda\thonesta\tcair\t60\tcoroas\tem\t100\tlançamentos,\tvocê\tpode\n",
      "estimar\ta\tprobabilidade\tde\tuma\tnormal(50,5)\tser\tmaior\tque\t60,\to\tque\té\tmais\n",
      "fácil\tdo\tque\tcomputar\ta\tfunção\tde\tdistribuição\tcumulativa\tbinomial(100,0.5).\n",
      "(embora\tna\tmaioria\tdas\taplicações\té\tpossível\tusar\tum\tsoftware\testatístico\tque\n",
      "computa\tquaisquer\tprobabilidades\tque\tvocê\tquiser.)•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "scipy.stats\t(\n",
      "http://bit.ly/1l2h0lj\n",
      ")\tcontém\tas\tfunções\tde\tdistribuição\n",
      "cumulativa\te\tde\tdensidade\tde\tprobabilidade\tpara\ta\tmaioria\tdas\n",
      "distribuições\tde\tprobabilidade\tpopulares.\n",
      "lembre-se\tcomo,\tno\tfinal\tdo\t\n",
      "capítulo\t5\n",
      ",\teu\tdisse\tque\tseria\tuma\tboa\tideia\n",
      "estudar\tcom\tum\tlivro\tdidático\tde\testatística?\ttambém\tseria\tuma\tboa\tideia\n",
      "estudar\tcom\tum\tlivro\tdidático\tde\tprobabilidade.\to\tmelhor\tque\teu\tconheço\n",
      "e\testá\tdisponível\tonline\té\to\t\n",
      "introduction\tto\tprobability\n",
      "(\n",
      "http://bit.ly/1l2mtyi\n",
      ")\n",
      ".capítulo\t7\n",
      "hipótese\te\tinferência\n",
      "é\tcaracterística\tde\tuma\tpessoa\trealmente\tinteligente\tser\tmovida\tpela\testatística\n",
      ".\n",
      "—george\tbernard\tshaw\n",
      "o\tque\tfaremos\tcom\ttodas\tessas\tteorias\tde\testatística\te\tprobabilidade?\ta\tparte\n",
      "ciência\n",
      "\tde\tdata\tscience\tfrequentemente\tenvolve\tformar\te\ttestar\t\n",
      "hipóteses\n",
      "\tsobre\n",
      "nossos\tdados\te\tos\tprocessos\tque\tos\tgeram.teste\testatístico\tde\thipótese\n",
      "com\tfrequência,\tcomo\tcientistas\tde\tdados,\tvamos\tquerer\ttestar\tse\tuma\n",
      "determinada\thipótese\té\tverdadeira.\tpara\tos\tnossos\tpropósitos,\tas\thipóteses\tsão\n",
      "afirmações\tcomo\t“esta\té\tuma\tmoeda\thonesta”\tou\t“os\tcientistas\tde\tdados\n",
      "preferem\tpython\ta\tr”\tou\t“seria\tmais\tprovável\tque\tas\tpessoas\tsaíssem\tda\tpágina\n",
      "sem\tler\to\tconteúdo\tse\tnós\tmostrássemos\tum\tanúncio\tpop-up\tcom\tum\tbotão\tde\n",
      "fechar\tpequeno\te\tdifícil\tde\tencontrar”\tque\tpossam\tser\ttraduzidas\tem\testatísticas\n",
      "sobre\tdados.\tsob\tdiversas\tpremissas,\ttais\testatísticas\tpodem\tser\tvistas\tcomo\n",
      "observações\tde\tvariáveis\taleatórias\ta\tpartir\tde\tdistribuições\tconhecidas,\to\tque\n",
      "permite\tque\tfaçamos\tdeclarações\tsobre\tas\tpremissas\tmais\tprováveis\tde\tserem\n",
      "corretas.\n",
      "em\tuma\tconfiguração\tclássica,\ttemos\ta\t\n",
      "hipótese\tnula\th\n",
      "0\n",
      "\tque\trepresenta\tuma\n",
      "posição\tpadrão,\te\talguma\thipótese\t\n",
      "h\n",
      "1\n",
      "\tcom\ta\tqual\tgostaríamos\tde\tcompará-la.\n",
      "usamos\ta\testatística\tpara\tdecidir\tse\trejeitamos\t\n",
      "h\n",
      "0\n",
      "\tcomo\tfalso\tou\tnão.\n",
      "provavelmente,\tfará\tmais\tsentido\tpor\tmeio\tde\tum\texemplo.exemplo:\tlançar\tuma\tmoeda\n",
      "imagine\tque\ttemos\tuma\tmoeda\te\tqueremos\ttestar\tpara\tconfirmar\tse\tela\té\n",
      "honesta.\ttemos\ta\tpremissa\tde\tque\ta\tmoeda\tpossui\ta\tprobabilidade\t\n",
      "p\n",
      "\tde\tcair\tcara,\n",
      "então\tnossa\thipótese\tnula\té\t\n",
      "que\ta\tmoeda\tseja\thonesta\t—\tou\tseja,\tque\t\n",
      "p\n",
      "\t=\t0,5.\n",
      "testaremos\tnovamente\tcontra\ta\thipótese\talternativa\t\n",
      "p\n",
      "\t≠\t0,5.\n",
      "em\tespecial,\tnosso\tteste\tenvolverá\to\tlançamento\tda\tmoeda\tem\tnúmero\t\n",
      "n\n",
      "\tde\n",
      "vezes\te\tcontando\to\tnúmero\tde\tcaras\t\n",
      "x\n",
      ".\tcada\tlançamento\tda\tmoeda\té\tuma\n",
      "tentativa\tde\tbernoulli,\to\tque\tsignifica\tque\t\n",
      "x\n",
      "\té\tuma\tvariável\taleatória\n",
      "binomial(n,\tp),\tque\t(como\tvimos\tno\t\n",
      "capítulo\t6\n",
      ")\tpodemos\taproximar\tusando\ta\n",
      "distribuição\tnormal:\n",
      "def\n",
      "\t\n",
      "normal_approximation_to_binomial(n,\tp):\n",
      "\"\"\"encontra\tmi\te\tsigma\tcorrespondendo\tao\tbinomial(n,\tp)\"\"\"\n",
      "mu\t=\tp\t*\tn\n",
      "sigma\t=\tmath.sqrt(p\t*\t(1\t-\tp)\t*\tn)\n",
      "return\n",
      "\t\n",
      "mu,\tsigma\n",
      "sempre\tque\tuma\tvariável\taleatória\tsegue\tuma\tdistribuição\tnormal,\tpodemos\tusar\n",
      "normal_\tcdf\n",
      "\tpara\tdescobrir\ta\tprobabilidade\tdos\tseus\tvalores\tresultantes\tserem\n",
      "internos\t(ou\texternos)\tem\tum\tintervalo\tespecial:\n",
      "#\to\tcdf\tnormal\té\ta\tprobabilidade\tque\ta\tvariável\testeja\tabaixo\tde\tum\tlimite\n",
      "normal_probability_below\t=\tnormal_cdf\n",
      "#\testá\tacima\tdo\tlimite\tse\tnão\testiver\tabaixo\n",
      "def\tnormal_probability_above(lo,\tmu=0,\tsigma=1):\n",
      "\treturn\t1\t-\tnormal_cdf(lo,\tmu,\tsigma)\n",
      "#\testá\tentre\tse\tfor\tmenos\tdo\tque\thi,\tmas\tnão\tmenor\tdo\tque\tlo\n",
      "def\tnormal_probability_between(lo,\thi,\tmu=0,\tsigma=1):\n",
      "\treturn\tnormal_cdf(hi,\tmu,\tsigma)\t-\tnormal_cdf(lo,\tmu,\tsigma)\n",
      "#\testá\tfora\tse\tnão\testiver\tentre\n",
      "def\tnormal_probability_outside(lo,\thi,\tmu=0,\tsigma=1):\n",
      "\treturn\t1\t-\tnormal_probability_between(lo,\thi,\tmu,\tsigma)\n",
      "também\tpodemos\tfazer\to\tcontrário\t—\tencontrar\ta\tregião\tsem\taba\tou\to\tintervalo\n",
      "(simétrico)\tem\ttorno\tda\tmédia\tque\tcontribui\tpara\to\tnível\tde\tprobabilidade.\tpor\n",
      "exemplo,\tse\tquisermos\tencontrar\tum\tintervalo\tcentrado\tna\tmédia\tcontendo\t60%de\tprobabilidade,\tentão\tencontraremos\tos\tcortes\tonde\tas\tabas\tinferiores\te\n",
      "superiores\tcontêm\t20%\tde\tprobabilidade\tcada\t(deixando\t60%):\n",
      "def\n",
      "\t\n",
      "normal_upper_bound(probability,\tmu=0,\tsigma=1):\n",
      "\t\n",
      "\"\"\"retorna\tz\tpara\tque\tp(z\t<=\tz)\t=\tprobability\"\"\"\n",
      "\t\n",
      "return\n",
      "\t\n",
      "inverse_normal_cdf(probability,\tmu,\tsigma)\n",
      "def\n",
      "\t\n",
      "normal_lower_bound(probability,\tmu=0,\tsigma=1):\n",
      "\t\n",
      "\"\"\"retorna\tz\tpara\tque\tp(z\t>=\tz)\t=\tprobability\"\"\"\n",
      "\t\n",
      "return\n",
      "\t\n",
      "inverse_normal_cdf(1\t-\tprobability,\tmu,\tsigma)\n",
      "def\n",
      "\t\n",
      "normal_two_sided_bounds(probability,\tmu=0,\tsigma=1):\n",
      "\t\n",
      "\"\"\"retorna\tos\tlimites\tsimétricos\t(sobre\ta\tmédia)\n",
      "\t\n",
      "que\tcontêm\ta\tprobabilidade\tespecífica\"\"\"\n",
      "\t\n",
      "tail_probability\t=\t(1\t-\tprobability)\t/\t2\n",
      "\t\n",
      "#\tlimite\tsuperior\tdeveria\tter\ttail_probability\tacima\n",
      "\t\n",
      "upper_bound\t=\tnormal_lower_bound(tail_probability,\tmu,\tsigma)\n",
      "\t\n",
      "#\tlimite\tinferior\tdeveria\tter\ttail_probability\tabaixo\n",
      "\t\n",
      "lower_bound\t=\tnormal_upper_bound(tail_probability,\tmu,\tsigma)\n",
      "\t\n",
      "return\n",
      "\t\n",
      "lower_bound,\tupper_bound\n",
      "em\tespecial,\tdigamos\tque\tescolhemos\tlançar\tuma\tmoeda\t\n",
      "n\n",
      "\t=\t1000\tvezes.\tse\n",
      "nossa\thipótese\tde\thonestidade\tfor\tverdadeira,\t\n",
      "x\n",
      "\tdeveria\tser\tdistribuído\n",
      "normalmente\tcom\tmédia\t500\te\tdesvio\tpadrão\tde\t15,8:\n",
      "mu_0,\tsigma_0\t=\tnormal_approximation_to_binomial(1000,\t0.5)\n",
      "precisamos\ttomar\tuma\tdecisão\tsobre\t\n",
      "significância\n",
      "\t—\tde\tquanto\té\ta\tvontade\tque\n",
      "temos\tde\tfazer\tum\t\n",
      "erro\ttipo\t1\n",
      "\t(“falso\tpositivo”),\tem\tque\trejeitamos\t\n",
      "h\n",
      "0\n",
      "\tmesmo\tse\n",
      "for\tverdadeiro.\tpor\tmotivos\tperdidos\tpelas\tmemórias\tda\thistória,\tessa\tvontade\té\n",
      "configurada\tpara\t5%\tou\t1%,\tgeralmente.\tvamos\tescolher\t5%.\n",
      "considere\to\tteste\tque\trejeita\t\n",
      "h\n",
      "0\n",
      "\tse\tx\tcair\tfora\tdos\tlimites\tdados\tpor:\n",
      "normal_two_sided_bounds(0.95,\tmu_0,\tsigma_0)\t\t\t\t\n",
      "#\t(469,\t531)\n",
      "presumindo\tque\t\n",
      "p\n",
      "\tseja\tigual\ta\t0,5\t(por\texemplo,\t\n",
      "h\n",
      "0\n",
      "\té\tverdadeiro),\thá\tapenas\t5%\n",
      "de\tchance\tde\tobservarmos\tque\tum\t\n",
      "x\n",
      "\tpermanece\tfora\tdesse\tintervalo,\tpois\té\n",
      "exatamente\ta\tsignificância\tque\tqueríamos.\tde\toutra\tforma,\tse\t\n",
      "h\n",
      "0\n",
      "\tfor\tverdadeiro,\n",
      "esse\tteste\tapresentará\to\tresultado\tcorreto\taproximadamente\tem\t19\tde\t20\tvezes.\n",
      "também\testamos\tinteressados\tno\t\n",
      "poder\n",
      "\tde\tum\tteste,\tque\té\ta\tprobabilidade\tde\n",
      "não\tcometer\tum\t\n",
      "erro\ttipo\t2\n",
      ",\tno\tqual\tfalhamos\tem\trejeitar\t\n",
      "h\n",
      "0\n",
      "\tmesmo\tele\tsendofalso.\ta\tfim\tde\tmedir\tesse\tprocedimento,\ttemos\tque\tespecificar\to\tque\t\n",
      "realmente\n",
      "significa\t\n",
      "h\n",
      "0\n",
      "\tser\tfalso.\t(sabendo\tao\tmenos\tque\tp\t\n",
      "não\n",
      "\té\t0,5\tnão\tlhe\tdá\tuma\n",
      "informação\tsignificativa\tsobre\ta\tdistribuição\tde\t\n",
      "x\n",
      ".)\tem\tespecial,\tverificaremos\to\n",
      "que\tacontece\tse\t\n",
      "p\n",
      "\trealmente\tfor\t0,55,\ta\tfim\tde\tque\ta\tmoeda\testeja\tlevemente\n",
      "inclinada\ta\tser\tcara.\n",
      "nesse\tcaso,\tpodemos\tcalcular\to\tpoder\tdo\tteste\tcom:\n",
      "#\t95%\tdos\tlimites\tbaseados\tna\tpremissa\tp\té\t0,5\n",
      "lo,\thi\t=\tnormal_two_sided_bounds(0.95,\tmu_0,\tsigma_0)\n",
      "#\tmi\te\tsigma\treais\tbaseados\tem\tp\t=\t0,55\n",
      "mu_1,\tsigma_1\t=\tnormal_approximation_to_binomial(1000,\t0.55)\n",
      "#\tum\terro\ttipo\t2\tsignifica\tque\tfalhamos\tao\trejeitar\ta\thipótese\tnula\n",
      "#\tque\tacontecerá\tquando\tx\tainda\testiver\tem\tnosso\tintervalo\toriginal\n",
      "type_2_probability\t=\tnormal_probability_between(lo,\thi,\tmu_1,\tsigma_1)\n",
      "power\t=\t1\t-\ttype_2_probability\t\t\t\t\n",
      "#\t0.887\n",
      "agora,\timagine\tque\ta\tnossa\thipótese\tnula\tfosse\tque\ta\tmoeda\tnão\tseria\tinclinada\n",
      "a\tcara,\tou\tque\t\n",
      "p\n",
      "\t≤\t0,5.\tnesse\tcaso,\tqueríamos\tum\t\n",
      "teste\tunilateral\n",
      "\tque\trejeitasse\ta\n",
      "hipótese\tnula\tquando\t\n",
      "x\n",
      "\tfosse\tmuito\tmaior\tque\t50\tmas\tnão\tquando\t\n",
      "x\n",
      "\tfosse\n",
      "menor.\tportanto,\tum\tteste\tde\tsignificância\t\n",
      "de\t5%\tenvolveria\tusar\n",
      "normal_probability_below\n",
      "\tpara\tencontrar\to\tcorte\tabaixo\tdos\t95%\tem\tque\ta\n",
      "probabilidade\tficaria:\n",
      "hi\t=\tnormal_upper_bound(0.95,\tmu_0,\tsigma_0)\n",
      "#\té\t526\t(<\t531,\tjá\tque\tprecisamos\tde\tmais\tprobabilidade\tna\taba\tsuperior)\n",
      "type_2_probability\t=\tnormal_probability_below(hi,\tmu_1,\tsigma_1)\n",
      "power\t=\t1\t-\ttype_2_probability\t\t\t\t\n",
      "#\t0.936\n",
      "esse\tteste\té\tmais\tpoderoso,\tvisto\tque\tele\tnão\tmais\trejeita\t\n",
      "h\n",
      "0\n",
      "\tquando\t\n",
      "x\n",
      "\testá\n",
      "abaixo\tde\t469\t(improvável\tde\tacontecer\tse\t\n",
      "h\n",
      "1\n",
      "\tfor\tverdadeiro)\te,\tao\tinvés,\trejeita\n",
      "h\n",
      "0\n",
      "\tquando\t\n",
      "x\n",
      "\testá\tentre\t526\te\t531\t(provável\tde\tacontecer\tse\t\n",
      "h\n",
      "1\n",
      "\tfor\tverdadeiro).p\n",
      "\t\n",
      "-values\n",
      "uma\toutra\tmaneira\tde\tpensar\tsobre\to\tteste\tanterior\tenvolve\t\n",
      "p-values\n",
      ".\tem\tvez\tde\n",
      "escolher\tlimites\tcom\tbase\tem\talguma\tprobabilidade\tde\tcorte,\tnós\tcomputamos\ta\n",
      "probabilidade\t—\tpresumindo\tque\t\n",
      "h\n",
      "0\n",
      "\tseja\tverdadeiro\t—\tque\tpodemos\tver\tum\n",
      "valor\tao\tmenos\ttão\textremo\tquanto\tao\tque\trealmente\tobservamos.\n",
      "para\to\tnosso\tteste\tbilateral\tpara\ta\tmoeda\thonesta,\tcomputamos:\n",
      "def\n",
      "\t\n",
      "two_sided_p_value(x,\tmu=0,\tsigma=1):\n",
      "\t\n",
      "if\n",
      "\t\n",
      "x\t>=\tmu:\n",
      "\t\n",
      "#\tse\tx\tfor\tmaior\tdo\tque\ta\tmédia,\ta\tcoroa\tserá\to\tque\tfor\tmaior\tdo\tque\tx\n",
      "\t\n",
      "return\n",
      "\t\n",
      "2\t*\tnormal_probability_above(x,\tmu,\tsigma)\n",
      "\t\n",
      "else\n",
      ":\n",
      "\t\n",
      "#\tse\tx\tfor\tmenor\tdo\tque\ta\tmédia,\ta\tcoroa\tserá\to\tque\tfor\tmenor\tdo\tque\tx\n",
      "\t\n",
      "return\n",
      "\t\n",
      "2\t*\tnormal_probability_below(x,\tmu,\tsigma)\n",
      "se\tvíssemos\t530\tcaras,\tcomputaríamos:\n",
      "two_sided_p_value(529.5,\tmu_0,\tsigma_0)\t\t\t\t\n",
      "#\t0.062\n",
      "por\tque\tusamos\t529,5\tem\tvez\tde\t530?\tisso\té\to\tque\tchamamos\tde\t\n",
      "correção\tde\n",
      "continuidade\t(\n",
      "http://en.wikipedia.org/wiki/continuity_correction\n",
      ")\n",
      ".\treflete\to\n",
      "fato\tde\tque\t\n",
      "normal_probability_between(529.5,\t530.5,\tmu_0,\tsigma_0)\n",
      "\té\ta\n",
      "melhor\testimativa\tda\tprobabilidade\tde\tver\t530\tcaras\tdo\tque\n",
      "normal_probability_between(530,\t531,\tmu_0,\tsigma_0)\n",
      "\tseria.\n",
      "desta\tforma,\t\n",
      "normal_probability_above(529.5,\tmu_0,\tsigma_0)\n",
      "\té\ta\tmelhor\n",
      "estimativa\tda\tprobabilidade\tde\tver\tao\tmenos\t530\tcaras.\tvocê\tdeve\tter\tnotado\n",
      "que\ttambém\tusamos\tisso\tno\tcódigo\tproduzido\tna\t\n",
      "figura\t6-4\n",
      ".\n",
      "uma\tforma\tde\tse\tconvencer\tda\trelevância\tdessa\testimativa\té\tpor\tmeio\tde\tuma\n",
      "simulação:\n",
      "extreme_value_count\t=\t0\n",
      "for\t_\tin\trange(100000):\n",
      "\tnum_heads\t=\tsum(1\tif\trandom.random()\t<\t0.5\telse\t0\t\t\t\t\t#\tcontagem\tdo\t#\tde\tcaras\n",
      "\t\t\t\t\tfor\t_\tin\trange(1000))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#\tem\t1000\tlançamentos\n",
      "\tif\tnum_heads\t>=\t530\tor\tnum_heads\t<=\t470:\t\t\t\t\t\t\t\t\t\t\t\t\t\t#\te\tcontagem\tda\tfrequência\n",
      "\textreme_value_count\t+=\t1\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#\tque\t#\té\t'extrema'\n",
      "print\textreme_value_count\t/\t100000\t#\t0.062\n",
      "desde\tque\t\n",
      "p\n",
      "-value\tseja\tmaior\tdo\tque\ta\tsignificância\tde\t5%,\tnão\trejeitamos\tahipótese\tnula.\tse\tvíssemos\t532\tcaras,\to\t\n",
      "p\n",
      "-value\tseria:\n",
      "two_sided_p_value(531.5,\tmu_0,\tsigma_0)\n",
      "\t\t\t\t\t\t\n",
      "#\t0.0463\n",
      "que\té\tmenor\tdo\tque\ta\tsignificância\tde\t5%,\tlogo,\trejeitaríamos\ta\thipótese\tnula.\té\n",
      "exatamente\to\tmesmo\tteste\tde\tantes.\té\tapenas\tuma\tforma\tdiferente\tde\tabordar\ta\n",
      "estatística.\n",
      "da\tmesma\tmaneira,\tteríamos:\n",
      "upper_p_value\t=\tnormal_probability_above\n",
      "lower_p_value\t=\tnormal_probability_below\n",
      "se\tnós\tvíssemos\t525\tcaras\tpara\to\tteste\tunilateral,\tcomputaríamos:\n",
      "upper_p_value(524.5,\tmu_0,\tsigma_0)\n",
      "\t\n",
      "#\t0.061\n",
      "mostrando\tque\tnão\trejeitaríamos\ta\thipótese\tnula.\tse\tnós\tvíssemos\t527\tcaras,\ta\n",
      "computação\tseria:\n",
      "upper_p_value(526.5,\tmu_0,\tsigma_0)\n",
      "\t\n",
      "#\t0.047\n",
      "e\tnós\trejeitaríamos\ta\thipótese\tnula.\n",
      "certifique-se\tde\tque\tseu\tdado\testá\tdistribuído\tnormalmente\tantes\tde\tusar\n",
      "normal_probability_above\n",
      "\tpara\tcomputar\t\n",
      "p\n",
      "-values.\tas\tmemórias\truins\tde\tdata\n",
      "science\testão\trepletas\tde\texemplos\tde\tpessoas\topinando\tque\ta\tchance\tde\talgum\n",
      "evento\tobservado\tocorrer\taleatoriamente\té\tuma\tem\tum\tmilhão,\tquando\to\tque\n",
      "eles\trealmente\tquerem\tdizer\té\t“a\tchance,\tpresumindo\tque\to\tdado\tseja\n",
      "distribuído\tnormalmente”\te\té\tbem\tinútil\tse\to\tdado\tnão\to\tfor.\n",
      "existem\tdiversos\ttestes\testatísticos\tpara\ta\tnormalidade,\tno\tentanto,\taté\tmesmo\ta\n",
      "elaboração\tde\tgráfico\tdos\tdados\té\tuma\tboa\tideia.intervalos\tde\tconfiança\n",
      "temos\ttestado\thipóteses\tsobre\to\tvalor\tda\tprobabilidade\t\n",
      "p\n",
      ",\tdo\tresultado\tcara\tque\n",
      "é\tum\t\n",
      "parâmetro\n",
      "\tda\tdesconhecida\tdistribuição\t“cara”.\tquando\to\tcaso\té\tesse,\tuma\n",
      "terceira\tabordagem\té\tconstruir\tum\t\n",
      "intervalo\tde\tconfiança\n",
      "\tem\ttorno\tdo\tvalor\n",
      "observado\tdo\tparâmetro.\n",
      "por\texemplo,\tpodemos\testimar\ta\tprobabilidade\tde\tuma\tmoeda\tviciada\tao\n",
      "analisar\to\tvalor\tmédio\tdas\tvariáveis\tbernoulli\tcorrespondentes\ta\tcada\n",
      "lançamento\t—\t1\tse\tcara,\t0\tse\tcoroa.\tse\tnós\tobservarmos\t525\tcaras\tde\t1000\n",
      "lançamentos,\tlogo\testimamos\t\n",
      "p\n",
      "\tem\t0,525.\n",
      "quão\t\n",
      "confiantes\n",
      "\tpodemos\tser\tnessa\testimativa?\tbem,\tse\tsoubéssemos\to\tvalor\n",
      "exato\tde\t\n",
      "p\n",
      ",\to\tteorema\tde\tlimite\tcentral\t(lembre-se\tde\t“o\tteorema\tdo\tlimite\n",
      "central”\tna\tpágina\t78)\tnos\tdiz\tque\ta\tmédia\tdaquelas\tvariáveis\tbernoulli\n",
      "deveriam\tser\tquase\tnormais,\tcom\ta\tmédia\t\n",
      "p\n",
      "\te\tdesvio\tpadrão:\n",
      "math.sqrt(p\t*\t(1\t-\tp)\t/\t1000)\n",
      "aqui\tnão\tconhecemos\t\n",
      "p\n",
      ",\tportanto\tusamos\tnossa\testimativa:\n",
      "p_hat\t=\t525\t/\t1000\n",
      "mu\t=\tp_hat\n",
      "sigma\t=\tmath.sqrt(p_hat\t*\t(1\t-\tp_hat)\t/\t1000)\t\t\t\n",
      "#\t0.0158\n",
      "isso\tnão\té\tinteiramente\tcomprovado,\tmas\tas\tpessoas\tparecem\tfazê-lo\tde\n",
      "qualquer\tforma.\tao\tusar\ta\taproximação\tnormal,\tconcluímos\tque\tsomos\t“95%\n",
      "confiantes”\tde\tque\tparâmetro\tseguinte\tcontém\to\tverdadeiro\tparâmetro\t\n",
      "p\n",
      ":\n",
      "normal_two_sided_bounds(0.95,\tmu,\tsigma)\n",
      "\t\t\t\t\t\t\t\n",
      "#\t[0.4940,\t0.5560]\n",
      "essa\tdeclaração\té\tsobre\to\t\n",
      "intervalo\n",
      "\te\tnão\tsobre\t\n",
      "p\n",
      ".\tvocê\tdeveria\tentender\tcomo\n",
      "uma\tpremissa\tse\tfosse\trepetir\to\texperimento\tmuitas\tvezes,\t95%\tdas\tvezes\to\n",
      "parâmetro\t“verdadeiro”\t(que\té\to\tmesmo\ttodas\tas\tvezes)\tficaria\tdentro\tdo\n",
      "intervalo\tde\tconfiança\tobservada\t(que\tpode\tser\tdiferente\ta\tcada\tvez).\n",
      "em\tespecial\tnão\tconcluímos\tque\ta\tmoeda\tseja\tviciada,\tjá\tque\t0,5\tcai\tdentro\tde\n",
      "nosso\tintervalo\tde\tconfiança.\n",
      "se,\tem\tvez\tdisso,\ttivéssemos\tvisto\t540\tcaras,\tteríamos:\n",
      "p_hat\t=\t540\t/\t1000mu\t=\tp_hat\n",
      "sigma\t=\tmath.sqrt(p_hat\t*\t(1\t-\tp_hat)\t/\t1000)\t\n",
      "#\t0.0158\n",
      "normal_two_sided_bounds(0.95,\tmu,\tsigma)\n",
      "\t\n",
      "#\t[0.5091,\t0.5709]\n",
      "aqui,\ta\t“moeda\thonesta”\tnão\tfica\tno\tintervalo\tde\tconfiança.\t(a\thipótese\tda\n",
      "“moeda\thonesta”\tnão\tpassaria\tno\tteste\tesperado\t95%\tdas\tvezes\tse\tfosse\n",
      "verdade.)p-hacking\n",
      "um\tprocedimento\tque\trejeita\ta\thipótese\tnula\terroneamente\tsomente\t5%\tdas\n",
      "vezes\tvai\t—\tpor\tdefinição\t—\trejeitar\terroneamente\t5%\tdas\tvezes\ta\thipótese\n",
      "nula:\n",
      "def\n",
      "\t\n",
      "run_experiment():\n",
      "\"\"\"lança\tuma\tmoeda\t1000\tvezes,\ttrue\t=\tcara,\tfalse\t=\tcoroa\"\"\"\n",
      "return\n",
      "\t\n",
      "[random.random()\t<\t0.5\n",
      "\t\n",
      "for\n",
      "\t\n",
      "_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "range(1000)]\n",
      "def\n",
      "\t\n",
      "reject_fairness(experiment):\n",
      "\"\"\"usando\t5%\tdos\tníveis\tde\tsignificância\"\"\"\n",
      "num_heads\t=\tlen([flip\n",
      "\t\n",
      "for\n",
      "\t\n",
      "flip\n",
      "\t\n",
      "in\n",
      "\t\n",
      "experiment\n",
      "\t\n",
      "if\n",
      "\t\n",
      "flip])\n",
      "return\n",
      "\t\n",
      "num_heads\t<\t469\n",
      "\t\n",
      "or\n",
      "\t\n",
      "num_heads\t>\t531\n",
      "random.seed(0)\n",
      "experiments\t=\t[run_experiment()\t\n",
      "for\n",
      "\t\n",
      "_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "range(1000)]\n",
      "num_rejections\t=\tlen([experiment\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\t\n",
      "experiment\n",
      "\t\n",
      "in\n",
      "\t\n",
      "experiments\n",
      "\t\t\t\t\t\t\t\n",
      "if\n",
      "\t\n",
      "reject_fairness(experiment)])\n",
      "print\n",
      "\t\n",
      "num_rejections\n",
      "\t\t\t\n",
      "#\t46\n",
      "o\tque\tisso\tquer\tdizer\té\tque\tvocê\testá\ttentando\tencontrar\tresultados\n",
      "“significativos”\te\tgeralmente\tvocê\tconsegue.\tteste\thipóteses\tsuficientes\tcontra\to\n",
      "seu\tconjunto\tde\tdados\te\tum\tdeles,\tcertamente,\tparecerá\tsignificante.\tremova\tos\n",
      "valores\tdiscrepantes\tcertos,\te\tserá\tprovável\tconseguir\tseu\t\n",
      "p\n",
      "-value\tabaixo\tde\n",
      "0,05.\t(fizemos\talgo\tvagamente\tparecido\tem\t“correlação”\tna\tpágina\t62;\n",
      "percebeu?)\n",
      "isto\té,\tpor\treter,\tchamado\tp-hacking\t(\n",
      "http://bit.ly/1l2qtcr\n",
      "),\te\té,\tde\tcerta\tforma,\n",
      "uma\tconsequência\tda\t“inferência\ta\tpartir\tda\testrutura\tdos\t\n",
      "p\n",
      "-values”.\tum\tartigo\n",
      "ótimo\tcriticando\tessa\tabordagem\té\t“the\tearth\tis\tround”\t(\n",
      "http://bit.ly/1l2qj4a\n",
      ").\n",
      "se\tvocê\tquer\tpraticar\tuma\tboa\t\n",
      "ciência\n",
      ",\tvocê\tdeveria\tdeterminar\tsuas\thipóteses\n",
      "antes\tde\tverificar\tos\tdados,\tdeveria\tlimpar\tseus\tdados\tsem\tpensar\tnas\thipóteses,\n",
      "e\tdeveria\tter\tem\tmente\tque\t\n",
      "p\n",
      "-values\tnão\tsão\tsubstitutos\tpara\to\tsenso\tcomum.\n",
      "(uma\tabordagem\talternativa\tseria\t“inferência\tbayesiana”\tna\tpágina\t88.)exemplo:\texecutando\tum\tteste\ta/b\n",
      "uma\tde\tnossas\tresponsabilidades\tiniciais\tna\tdatasciencester\té\ttestar\ta\n",
      "otimização,\tum\teufemismo\tpara\ttentar\tfazer\tcom\tque\tas\tpessoas\tcliquem\tnos\n",
      "anúncios.\tum\tde\tseus\tanunciantes\tdesenvolveu\tuma\tbebida\tenergética\tvoltada\n",
      "para\tos\tcientistas\tde\tdados,\te\to\tvice-presidente\tde\tpublicidade\tquer\ta\tsua\tajuda\n",
      "para\tescolher\tentre\ta\tpropaganda\ta\t(“bom\tsabor!”)\tou\tpropaganda\tb\t(“menos\n",
      "polarização!”).\n",
      "por\tser\tum\t\n",
      "cientista\n",
      ",\tvocê\tdecide\texecutar\tum\t\n",
      "experimento\n",
      "\tmostrando\taos\n",
      "visitantes\tdo\tsite\tuma\tdas\tduas\tpropagandas\te\tregistrando\tquantas\tpessoas\n",
      "clicam\tem\tcada\tum.\n",
      "se\t990\tde\t1000\tvisualizadores\tdo\tanúncio\ta\tclicam\tna\tpropaganda\tenquanto\tque\n",
      "10\tde\t1000\tvisualizadores\tdo\tb\tclicam,\tvocê\tpode\tficar\tconfiante\tde\tque\ta\té\n",
      "melhor\tdo\tque\tb.\tmas\te\tse\tas\tdiferenças\tnão\tsão\ttão\tgraves?\taqui\té\tonde\tvocê\n",
      "usaria\tinferência\testatística.\n",
      "digamos\tque\tpessoas\t\n",
      "n\n",
      "a\n",
      "\tvejam\to\tanúncio\ta,\te\tque\t\n",
      "n\n",
      "a\n",
      "\tcliquem\tnele.\tpodemos\n",
      "pensar\tem\tcada\tvisualização\tdo\tanúncio\tcomo\tuma\ttentativa\tde\tbernoulli\tem\n",
      "que\t\n",
      "p\n",
      "a\n",
      "\té\ta\tprobabilidade\tde\talguém\tclicar\tno\tanúncio\ta.\tentão\t(se\t\n",
      "n\n",
      "a\n",
      "\tfor\n",
      "grande,\te\té\taqui)\tsabemos\tque\t\n",
      "n\n",
      "a\n",
      "/n\n",
      "a\n",
      "\té\taproximadamente\tuma\tvariável\taleatória\n",
      "com\tmédia\t\n",
      "p\n",
      "a\n",
      "\te\tdesvio\tpadrão\tde\t\n",
      "igualmente,\t\n",
      "n\n",
      "b\n",
      "/n\n",
      "b\n",
      "\té\taproximadamente\tuma\tvariável\taleatória\tcom\tmédia\t\n",
      "p\n",
      "b\n",
      "\te\n",
      "desvio\tpadrão\tde\t\n",
      "def\n",
      "\t\n",
      "estimated_parameters(n,\tn):\n",
      "\tp\t=\tn\t/\tn\n",
      "\t\n",
      "sigma\t=\tmath.sqrt(p\t*\t(1\t-\tp)\t/\tn)\n",
      "\t\n",
      "return\n",
      "\t\n",
      "p,\tsigma\n",
      "se\tpresumirmos\tque\tas\tduas\tnormais\tsão\tindependentes\t(parece\trazoável,\tjá\tque\n",
      "a\ttentativa\tde\tbernoulli\tdeveria\tser),\tentão\tsuas\tdiferenças\ttambém\tdeveriam\tser\n",
      "normais\tcom\ta\tmédia\t\n",
      "p\n",
      "b\n",
      "\t–\t\n",
      "p\n",
      "a\n",
      "\te\to\tdesvio\tpadrão\t\n",
      "é\tquase\tuma\ttrapaça.\ta\tmatemática\tsó\tfunciona\texatamente\tdesse\tjeito\tse\tvocêconhece\n",
      "\tos\tdesvios\tpadrões.\taqui,\testamos\testimando-os\ta\tpartir\tdos\tdados,\to\n",
      "que\tsignifica\tque\trealmente\tdeveríamos\tusar\ta\tdistribuição\t\n",
      "t\n",
      ".\tmas\tpara\n",
      "conjuntos\tde\tdados\tsuficientemente\tgrandes\tnão\tfaz\ttanta\tdiferença.\n",
      "isso\tsignifica\tque\tpodemos\ttestar\ta\t\n",
      "hipótese\tnula\n",
      "\tque\t\n",
      "p\n",
      "a\n",
      "\te\t\n",
      "p\n",
      "b\n",
      "\tsão\ta\tmesma\t(ou\n",
      "seja,\tque\t\n",
      "p\n",
      "b\n",
      "\t–\t\n",
      "p\n",
      "a\n",
      "\té\tzero)\tusando\ta\testatística:\n",
      "def\n",
      "\t\n",
      "a_b_test_statistic(n_a,\tn_a,\tn_b,\tn_b):\n",
      "\tp_a,\tsigma_a\t=\testimated_parameters(n_a,\tn_a)\n",
      "\tp_b,\tsigma_b\t=\testimated_parameters(n_b,\tn_b)\n",
      "\t\n",
      "return\n",
      "\t\n",
      "(p_b\t-\tp_a)\t/\tmath.sqrt(sigma_a\t**\t2\t+\tsigma_b\t**\t2)\n",
      "que\tdeveria\tser\tuma\tnormal\tpadrão.\n",
      "por\texemplo,\tse\t“bom\tsabor”\trecebe\t200\tcliques\tde\t1000\tvisualizações\te\t“menos\n",
      "polarização”\trecebe\t180\tcliques\tde\t1000\tvisualizações,\ta\testatística\té\testa:\n",
      "z\t=\ta_b_test_statistic(1000,\t200,\t1000,\t180)\n",
      "\t\t\t\t\t\t\n",
      "#\t-1.14\n",
      "a\tprobabilidade\tde\tver\ttal\tdiferença\tse\ta\tmédia\tfosse\trealmente\tigual\tseria:\n",
      "two_sided_p_value(z)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t0.254\n",
      "que\té\tgrande\to\tsuficiente\te\tvocê\tnão\tconsegue\tsaber\tse\ttal\tdiferença\texiste.\tpor\n",
      "outro\tlado,\tse\t“menos\tpolarização”\trecebesse\tsomente\t150\tcliques,\tteríamos:\n",
      "z\t=\ta_b_test_statistic(1000,\t200,\t1000,\t150)\n",
      "\t\t\t\t\t\n",
      "#\t-2.94\n",
      "two_sided_p_value(z)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\t0.003\n",
      "que\tsignifica\tque\thá\tsomente\ta\tprobabilidade\tde\t0,0003\tque\tvocê\tveria\ttal\n",
      "diferença\tse\tas\tpropagandas\tfossem\tigualmente\teficazes.inferência\tbayesiana\n",
      "os\tprocedimentos\tque\tvimos\tse\tdedicaram\ta\tfazer\tas\tdeclarações\tde\n",
      "probabilidade\tsobre\tnossos\t\n",
      "testes\n",
      ":\t“há\tapenas\tuma\tchance\tde\t3%\tde\tvocê\tter\n",
      "observado\ttal\testatística\textrema\tse\tnossa\thipótese\tnula\tfosse\tverdadeira”.\n",
      "uma\tabordagem\talternativa\tpara\ta\tinferência\tenvolve\ttratar\tos\tparâmetros\n",
      "desconhecidos\tcomo\tvariáveis\taleatórias.\to\tanalista\t(ou\tseja,\tvocê)\tcomeça\tcom\n",
      "uma\t\n",
      "distribuição\tanterior\n",
      "\t(\n",
      "a\tpriori\n",
      ")\tpara\tos\tparâmetros\te\tusa\tos\tdados\n",
      "observados\te\to\tteorema\tde\tbayes\tpara\treceber\tuma\tatualização\tda\t\n",
      "distribuição\n",
      "posterior\n",
      "\t(\n",
      "a\tposteriori\n",
      ")\tpara\tos\tparâmetros.\tem\tvez\tde\tjulgar\ta\tprobabilidade\n",
      "sobre\tos\ttestes,\tjulgue\ta\tprobabilidade\tsobre\tos\tpróprios\tparâmetros.\n",
      "por\texemplo,\tquando\to\tparâmetro\tdesconhecido\té\tuma\tprobabilidade\t(como\tno\n",
      "nosso\texemplo\tde\tlançamento\tde\tmoeda),\tfrequentemente\tusamos\tuma\tanterior\ta\n",
      "partir\tda\t\n",
      "distribuição\tbeta\n",
      ",\tcolocando\ttodas\tas\tprobabilidades\tentre\t0\te\t1:\n",
      "def\tb(alpha,\tbeta):\n",
      "\t\n",
      "\"\"\"uma\tconstante\tnormalizada\tpara\tque\ta\tprobabilidade\ttotal\tseja\t1\"\"\"\n",
      "\t\n",
      "return\tmath.gamma(alpha)\t*\tmath.gamma(beta)\t/\tmath.gamma(alpha\t+\tbeta)\n",
      "\t\n",
      "def\tbeta_pdf(x,\talpha,\tbeta):\n",
      "\tif\tx\t<\t0\tor\tx\t>\t1:\t\t\t\t\t\t\t\t\t\n",
      "#\tsem\tpeso\tfora\tde\t[0,\t1]\n",
      "\t\n",
      "return\t0\n",
      "\treturn\tx\t**\t(alpha\t-\t1)\t*\t(1\t-\tx)\t**\t(beta\t-\t1)\t/\tb(alpha,\tbeta)\n",
      "em\tgeral,\tessa\tdistribuição\tcentraliza\tseu\tpeso\tem:\n",
      "alpha\t/\t(alpha\t+\tbeta)\n",
      "e\tquanto\tmaiores\tos\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "\tsão,\tmais\t“estreita”\té\ta\tdistribuição.\n",
      "por\texemplo,\tse\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "\tforem\t1,\té\tapenas\ta\tdistribuição\tuniforme\t(centrada\n",
      "em\t0,5,\tmuito\tdispersa).\tse\t\n",
      "alpha\n",
      "\tfor\tmuito\tmaior\tdo\tque\t\n",
      "beta\n",
      ",\ta\tmaioria\tdo\tpeso\n",
      "fica\tperto\tde\t1.\te,\tse\t\n",
      "alpha\n",
      "\tfor\tmuito\tmenor\tdo\tque\t\n",
      "beta\n",
      ",\ta\tmaioria\tdo\tpeso\tfica\n",
      "perto\tde\t0.\ta\t\n",
      "figura\t7-1\n",
      "\tmostra\tvárias\tdistribuições\tbetas\tdiferentes.\n",
      "então,\tdigamos\tque\tpresumimos\tuma\tdistribuição\tanterior\tem\t\n",
      "p\n",
      ".\ttalvez\tnão\n",
      "queremos\ttomar\tuma\tposição\tse\ta\tmoeda\tfor\thonesta\te\tnós\tescolhermos\t\n",
      "alpha\n",
      "\te\n",
      "beta\n",
      "\tpara\tambas\tserem1.\tou,\ttalvez,\ttenhamos\tuma\tforte\tcerteza\tde\tque\tdará\tcara\t55%\tdas\tvezes,\te\n",
      "escolhemos\t\n",
      "alpha\n",
      "\tigual\ta\t55,\t\n",
      "beta\n",
      "\tigual\ta\t45.\n",
      "lançamos\tnossa\tmoeda\tmuitas\tvezes\te\tvemos\t\n",
      "h\n",
      "\tpara\t\n",
      "heads\n",
      "\t(cara)\te\t\n",
      "t\n",
      "\tpara\t\n",
      "tails\n",
      "(coroa).\to\tteorema\tde\tbayes\t(e\tum\tpouco\tde\tmatemática\tque\té\tmuito\tentediante\n",
      "para\teu\ttocar\tnesse\tassunto)\tnos\tdiz\tque\ta\tdistribuição\tposterior\tpara\t\n",
      "p\n",
      "\té\n",
      "novamente\tuma\tdistribuição\tbeta\tmas\tcom\tparâmetros\t\n",
      "alpha\t+\th\n",
      "\te\t\n",
      "beta\t+\tt\n",
      ".\n",
      "não\té\tcoincidência\tque\ta\tdistribuição\tposterior\tseja\tnovamente\tuma\tdistribuição\n",
      "beta.\to\tnúmero\tde\tcaras\té\tfornecido\tpela\tdistribuição\tbinomial,\te\ta\tbeta\té\n",
      "conjugada\tanterior\t(\n",
      "http://www.johndcook.com/blog/conjugate_\n",
      "prior_diagram\n",
      "/)\n",
      "\tdela.\tisso\tsignifica\tque\ta\tqualquer\tmomento\tque\tvocê\tatualizar\n",
      "uma\tbeta\tanterior\tusando\tobservações\ta\tpartir\tdo\tcorrespondente\tbinomial,\n",
      "você\treceberá\tuma\tbeta\tposterior.\n",
      "figura\t7-1.\texemplos\tde\tdistribuições\tbeta\n",
      "digamos\tque\tvocê\tlance\ta\tmoeda\t10\tvezes\tmas\tsó\tveja\t3\tcaras.se\tvocê\ttivesse\tcomeçado\tcom\tuma\tdistribuição\tanterior\tuniforme\t(de\tcerta\n",
      "forma\tse\trecusando\ta\ttomar\tuma\tposição\tsobre\ta\thonestidade\tda\tmoeda),\tsua\n",
      "distribuição\tposterior\tseria\tuma\tbeta(4,\t8),\tcentrada\tpróximo\tde\t0,33.\tjá\tque\n",
      "você\tconsiderou\ttodas\tas\tprobabilidades\tigualmente\tpossíveis,\tseu\tmelhor\n",
      "palpite\té\talgo\tbem\tperto\tda\tprobabilidade\tobservada.\n",
      "se\tvocê\ttivesse\tcomeçado\tcom\tum\tbeta(20,\t20)\t(acreditando\tque\ta\tmoeda\tera\n",
      "mais\tou\tmenos\thonesta),\tsua\tdistribuição\tposterior\tseria\tum\tbeta(23,\t27)\n",
      "centrada\tpróximo\tde\t0,46,\tindicando\tuma\tsegurança\tque\ttalvez\ta\tmoeda\tseja\n",
      "levemente\tinclinada\tpara\tcoroa.\n",
      "e\tse\tvocê\tcomeçasse\tcom\tum\tbeta(30,\t10)\t(acreditando\tque\ta\tmoeda\testava\n",
      "inclinada\ta\tlançar\tcara\tem\t75%),\tsua\tdistribuição\tposterior\tseria\tde\tum\tbeta(33,\n",
      "17),\tcentrado\tpróximo\tde\t0,66.\tnesse\tcaso,\tvocê\tainda\tacreditaria\tna\tinclinação\n",
      "para\tcara,\tmas\tmenos\tdo\tque\tacreditaria\tno\tinício.\tessas\ttrês\tdistribuições\n",
      "posteriores\tdiferentes\testão\texibidas\tna\t\n",
      "figura\t7-2\n",
      ".\n",
      "figura\t7-2.\tposteriores\tsurgindo\tde\tanteriores\tdiferentesse\tvocê\tlançasse\tuma\tmoeda\tmais\te\tmais\tvezes,\ta\tanterior\tteria\tmenos\n",
      "importância\taté\teventualmente\tter\t(quase)\ta\tmesma\tdistribuição\tposterior,\tsem\n",
      "importar\tem\tqual\tanterior\tvocê\tcomeçou.\n",
      "por\texemplo,\tnão\timporta\ta\tinclinação\tque\tvocê\tpensou\tque\ta\tmoeda\ttinha,\tseria\n",
      "difícil\tacreditar\tnisso\tdepois\tde\tver\t1000\tcaras\tde\t2000\tlançamentos\t(a\tmenos\n",
      "que\tvocê\tseja\tum\tlunático\tque\tescolhe\tuma\tanterior\ttipo\tbeta(1000000,1)).\n",
      "o\tinteressante\té\tque\tisso\tpermite\tque\tfaçamos\tdeclarações\tde\tprobabilidade\n",
      "sobre\thipóteses:\t“baseado\tna\tanterior\te\tnos\tdados\tobservados,\thá\tapenas\t5%\tde\n",
      "probabilidade\tque\tas\tcaras\tda\tmoeda\testejam\tentre\t49%\te\t51%”.\n",
      "filosoficamente,\té\tmuito\tdiferente\tde\tuma\tdeclaração\tcomo\t“se\ta\tmoeda\tfosse\n",
      "honesta,\tesperaríamos\tobservar\tdados\ttão\textremos\tsomente\t5%\tdas\tvezes”.\n",
      "o\tuso\tda\tinferência\tbayesiana\tpara\ttestar\thipóteses\té\tconsiderado\tum\tpouco\n",
      "controverso\t—\tem\tparte\tporque\tsua\tmatemática\tpode\tse\ttornar\tcomplicada\te,\tem\n",
      "parte,\tpor\tcausa\tda\tnatureza\tsubjetiva\tde\tse\tescolher\tuma\tanterior.\tnão\tusaremos\n",
      "isso\tem\tmais\tnenhum\tlugar\tdeste\tlivro,\tmas\té\tbom\tsaber\tsobre\tisso.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "quase\tnem\ttocamos\tna\tsuperfície\tdo\tque\tvocê\tdeveria\tsaber\tsobre\n",
      "inferência\testatística.\tos\tlivros\trecomendados\tno\tfinal\tdo\tcapítulo\t5\n",
      "entram\tem\tmuito\tmais\tdetalhes.\n",
      "a\tcoursera\toferece\to\tcurso\tanálise\tde\tdados\te\tinferência\testatística\t(em\n",
      "inglês)\tque\taborda\tmuitos\tdesses\ttópicos.capítulo\t8\n",
      "gradiente\tdescendente\n",
      "aqueles\tque\tse\tgabam\tde\tseus\tdescendentes,\tcontam\tvantagem\tdo\tque\tdevem\taos\toutros\n",
      ".\n",
      "—seneca\n",
      "frequentemente,\tao\tpraticar\tdata\tscience,\ttentamos\tencontrar\to\tmelhor\tmodelo\n",
      "para\tuma\tdeterminada\tsituação.\te,\tgeralmente,\ta\t“melhor”\tsignificará\talgo\tcomo\n",
      "“minimiza\to\terro\tdo\tmodelo”\tou\t“maximiza\ta\tprobabilidade\tdo\tdado”.\tem\n",
      "outras\tpalavras,\trepresenta\ta\tsolução\tpara\talgum\ttipo\tde\tproblema\tde\totimização.\n",
      "isso\tsignifica\tque\tprecisaremos\tresolver\tuma\tquantidade\tde\tproblemas\tde\n",
      "otimização.\te,\tem\tespecial,\tprecisaremos\tresolvê-los\tdo\tzero.\tnossa\tabordagem\n",
      "será\tuma\ttécnica\tchamada\t\n",
      "gradiente\tdescendente\n",
      ",\tque\tse\tdispõe\tmuito\tbem\tpara\n",
      "um\ttratamento\tdo\tzero.\tvocê\ttalvez\tnão\tache\tmuito\tanimador,\tmas\tela\tnos\n",
      "permitirá\tfazer\tcoisas\tempolgantes\tno\tdecorrer\tdo\tlivro,\tportanto,\ttenha\n",
      "paciência.a\tideia\tpor\ttrás\tdo\tgradiente\tdescendente\n",
      "suponha\tque\ttenhamos\ta\tfunção\t\n",
      "f\n",
      "\tque\ttem\tcomo\tentrada\tum\tvetor\tde\tnúmeros\n",
      "reais\te\texibe,\tcomo\tsaída,\tum\túnico\tnúmero\treal.\ttal\tfunção\tsimples\té:\n",
      "def\n",
      "\t\n",
      "sum_of_squares(v):\n",
      "\"\"\"computa\ta\tsoma\tdos\telementos\tao\tquadrado\tem\tv\"\"\"\n",
      "return\n",
      "\t\n",
      "sum(v_i\t**\t2\n",
      "\t\n",
      "for\n",
      "\t\n",
      "v_i\n",
      "\t\n",
      "in\n",
      "\t\n",
      "v)\n",
      "com\tfrequência,\tprecisaremos\tmaximizar\t(ou\tminimizar)\ttais\tfunções.\tou\tseja,\n",
      "precisamos\tencontrar\ta\tentrada\tv\tque\tproduz\to\tmaior\t(ou\tmenor)\tvalor\tpossível.\n",
      "para\tfunções\tcomo\ta\tnossa,\to\t\n",
      "gradiente\n",
      "\t(se\tvocê\tse\tlembra\tdos\tseus\testudos\tde\n",
      "cálculo,\tele\té\to\tvetor\tdas\tderivadas\tparciais)\tmostra\ta\tdireção\tda\tentrada\tem\tque\n",
      "a\tfunção\tcresce\tmais\trapidamente.\t(se\tvocê\tnão\tse\tlembra\tdos\tseus\testudos\tde\n",
      "cálculo,\tacredite\tem\tmim\tou\tprocure\tna\tinternet.)\n",
      "igualmente,\tuma\tabordagem\tpara\tmaximizar\tuma\tfunção\té\tpegar\tum\tponto\tde\n",
      "início\taleatório,\tcomputar\to\tgradiente,\tandar\tum\tpequeno\tpasso\tna\tdireção\tdo\n",
      "gradiente\t(por\texemplo,\ta\tdireção\tque\tfaz\tcom\tque\ta\tfunção\tcresça\tmais),\te\n",
      "repetir\tcom\to\tnovo\tponto\tde\tinício.\tda\tmesma\tforma,\tvocê\tpode\ttentar\n",
      "minimizar\tuma\tfunção\tao\tandar\tpoucos\tpassos\tna\tdireção\t\n",
      "oposta\n",
      ",\tcomo\tmostra\ta\n",
      "figura\t8-1\n",
      ".figura\t8-1.\tencontrando\tuma\tmínima\tusando\tum\tgradiente\tdescendente\n",
      "se\tuma\tfunção\tpossui\tuma\tmínima\tglobal\túnica,\té\tprovável\tque\tesse\n",
      "procedimento\ta\tencontre.\tse\tuma\tfunção\tpossui\tmínimas\tmúltiplas\t(locais),\tesse\n",
      "procedimento\ttalvez\t“encontre”\ta\terrada\te,\tnesse\tcaso,\tvocê\ttalvez\ttenha\tque\n",
      "retomar\to\tprocedimento\ta\tpartir\tde\tvários\tpontos\tde\tinício.\tse\tuma\tfunção\tnão\n",
      "possui\tmínima,\tentão\té\tpossível\tque\to\tprocedimento\tdure\tpara\tsempre.estimando\to\tgradiente\n",
      "se\t\n",
      "f\n",
      "\té\tuma\tfunção\tde\tuma\tvariável,\tsua\tderivada\tem\tum\tponto\t\n",
      "x\n",
      "\tindica\tcomo\t\n",
      "f(x)\n",
      "muda\tquando\tfazemos\tuma\tmudança\tbem\tpequena\tem\t\n",
      "x\n",
      ".\té\tdefinida\tcomo\to\n",
      "limite\tde\tquocientes\tdiferenciais:\n",
      "def\n",
      "\t\n",
      "difference_quotient(f,\tx,\th):\n",
      "return\n",
      "\t\n",
      "(f(x\t+\th)\t-\tf(x))\t/\th\n",
      "conforme\t\n",
      "h\n",
      "\tse\taproxima\tde\tzero.\n",
      "(muitos\talunos\tde\tcálculo\tem\tpotencial\tforam\tatrapalhados\tpela\tdefinição\n",
      "matemática\tde\tlimite.\taqui\tvamos\ttrapacear\te\tsimplesmente\tdizer\tque\tela\n",
      "significa\to\tque\tvocê\tacha\tque\tsignifica.)\n",
      "figura\t8-2.\taproximando\tuma\tderivada\tcom\tum\tquociente\tdiferenciala\tderivada\té\ta\tinclinação\tda\tlinha\ttangente\tem\t\n",
      "(x,\tf(x))\n",
      ",\tenquanto\to\tquociente\n",
      "diferencial\té\ta\tinclinação\tda\tlinha-não-tão-tangente\tque\tpassa\tpor\t\n",
      "(x+h,\tf(x+h))\n",
      ".\n",
      "conforme\t\n",
      "h\n",
      "\tvai\tficando\tmenor,\ta\tlinha-não-tão-tangente\tchega\tcada\tvez\tmais\n",
      "perto\tda\tlinha\ttangente\t(\n",
      "figura\t8-2\n",
      ").\n",
      "para\tmuitas\tfunções\té\tfácil\tcalcular\tas\tderivadas\tcom\texatidão.\tpor\texemplo,\ta\n",
      "função\t\n",
      "square\n",
      ":\n",
      "def\n",
      "\t\n",
      "square(x):\n",
      "return\n",
      "\t\n",
      "x\t*\tx\n",
      "tem\ta\tderivada:\n",
      "def\n",
      "\t\n",
      "derivative(x):\n",
      "return\n",
      "\t\n",
      "2\t*\tx\n",
      "que\tvocê\tpode\tverificar\t—\tse\tvocê\testiver\tcom\tvontade\t—\tao\texplicitamente\n",
      "computar\to\tquociente\tdiferencial\te\ttomando\to\tlimite.\n",
      "e\tse\tvocê\tnão\tpudesse\t(ou\tnão\tquisesse)\tencontrar\to\tgradiente?\tembora\tnão\n",
      "possamos\tter\tlimites\tcom\tpython,\tpodemos\testimar\tderivadas\tao\tavaliar\to\n",
      "quociente\tdiferencial\tpor\tum\tpequeno\te.\ta\t\n",
      "figura\t8-3\n",
      "\tmostra\tos\tresultados\tpara\n",
      "tal\testimativa:\n",
      "derivative_estimate\t=\tpartial(difference_quotient,\tsquare,\th=0.00001)\n",
      "#\tplaneja\tmostrar\tque\tsão\tbasicamente\to\tmesmo\n",
      "import\tmatplotlib.pyplot\tas\tplt\n",
      "x\t=\trange(-10,10)\n",
      "plt.title(\"actual\tderivatives\tvs.\testimates\")\n",
      "plt.plot(x,\tmap(derivative,\tx),\t'rx',\tlabel='actual')\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tvermelho\tx\n",
      "plt.plot(x,\tmap(derivative_estimate,\tx),\t'b+',\tlabel='estimate')\t\n",
      "#\tazul\t+\n",
      "plt.legend(loc=9)\n",
      "plt.show()figura\t8-3.\ta\tbondade\tda\taproximação\tdo\tquociente\tdiferencial\n",
      "quando\t\n",
      "f\n",
      "\té\tuma\tfunção\tde\tmuitas\tvariáveis,\tpossui\tmúltiplas\t\n",
      "derivadas\tparciais\n",
      ",\n",
      "cada\tuma\tindicando\tcomo\t\n",
      "f\n",
      "\tmuda\tquando\tfazemos\tpequenas\tmudanças\tem\n",
      "apenas\tuma\tdas\tvariáveis\tde\tentrada.\n",
      "calculamos\tsua\tderivada\tparcial\t\n",
      "i-\n",
      "ésimo\tao\ttratá-la\tcomo\tuma\tfunção\tde\tapenas\n",
      "a\t\n",
      "i\n",
      "-ésima\tvariável,\tcontendo\tas\toutras\tvariáveis\tfixas:\n",
      "def\tpartial_difference_quotient(f,\tv,\ti,\th):\n",
      "\"\"\"computa\to\ti-ésimo\tquociente\tdiferencial\tparcial\tde\tf\tem\tv\"\"\"\n",
      "w\t=\t[v_j\t+\t(h\tif\tj\t==\ti\telse\t0)\t\n",
      "#\tadiciona\th\tao\telemento\ti-ésimo\tde\tv\n",
      "\t\tfor\tj,\tv_j\tin\tenumerate(v)]\n",
      "\t\n",
      "return\t(f(w)\t-\tf(v))\t/\th\n",
      "depois\tdo\tque\tpodemos\testimar\to\tgradiente\tdo\tmesmo\tjeito:\n",
      "def\n",
      "\t\n",
      "estimate_gradient(f,\tv,\th=0.00001):\n",
      "return\n",
      "\t\n",
      "[partial_difference_quotient(f,\tv,\ti,\th)\n",
      "\t\n",
      "for\n",
      "\t\n",
      "i,\t_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "enumerate(v)]a\tmaior\tdesvantagem\tda\tabordagem\t“estimar\tusando\tos\tquocientes\n",
      "diferenciais”\té\tsair\tcaro\tem\ttermos\tde\tcomputação.\tse\t\n",
      "v\n",
      "\ttem\to\ttamanho\t\n",
      "n\n",
      ",\n",
      "estimate_gradient\n",
      "\ttem\tque\tavaliar\t\n",
      "f\n",
      "\tem\t\n",
      "2n\n",
      "\tentradas\tdiferentes.\tse\tvocê\testá\n",
      "estimando\tgradientes\tum\tapós\to\toutro,\testá\tfazendo\tmuito\tmais\ttrabalho\textra.usando\to\tgradiente\n",
      "é\tfácil\tver\tque\ta\tfunção\t\n",
      "sum_of_squares\n",
      "\ttem\tseu\tmínimo\tvalor\tquando\tsua\tentrada\tv\n",
      "é\tum\tvetor\tde\tzeros.\tmas\timagine\tque\tnão\tsabíamos\tdisso.\tusaremos\tos\n",
      "gradientes\tpara\tencontrar\to\tmínimo\tentre\ttodos\tos\tvetores\ttridimensionais.\n",
      "pegaremos\tum\tponto\tinicial\taleatório\te\tandaremos\tpequenos\tpassos\tna\tdireção\n",
      "oposta\tdo\tgradiente,\taté\tchegarmos\tem\tum\tponto\tem\tque\to\tgradiente\tseja\tmuito\n",
      "pequeno:\n",
      "def\n",
      "\t\n",
      "step(v,\tdirection,\tstep_size):\n",
      "\"\"\"move\tstep_size\tna\tdireção\ta\tpartir\tde\tv\"\"\"\n",
      "return\n",
      "\t\n",
      "[v_i\t+\tstep_size\t*\tdirection_i\n",
      "\t\t\n",
      "for\n",
      "\t\n",
      "v_i,\tdirection_i\n",
      "\t\n",
      "in\n",
      "\t\n",
      "zip(v,\tdirection)]\n",
      "def\n",
      "\t\n",
      "sum_of_squares_gradient(v):\n",
      "return\n",
      "\t\n",
      "[2\t*\tv_i\n",
      "\t\n",
      "for\n",
      "\t\n",
      "v_i\n",
      "\t\n",
      "in\n",
      "\t\n",
      "v]\n",
      "#\tescolhe\tum\tponto\tinicial\taleatório\n",
      "v\t=\t[random.randint(-10,10)\n",
      "\t\n",
      "for\n",
      "\t\n",
      "i\n",
      "\t\n",
      "in\n",
      "\t\n",
      "range(3)]\n",
      "tolerance\t=\t0.0000001\n",
      "while\n",
      "\t\n",
      "true:\n",
      "gradient\t=\tsum_of_squares_gradient(v)\t\t\n",
      "#\tcomputa\to\tgradiente\tem\tv\n",
      "next_v\t=\tstep(v,\tgradient,\t-0.01)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "#\tpega\tum\tpasso\tgradiente\tnegativo\n",
      "if\n",
      "\t\n",
      "distance(next_v,\tv)\t<\ttolerance:\n",
      "\t\t\t\t\t\t\t\n",
      "#\tpara\tse\testivermos\tconvergindo\n",
      "\t\t\n",
      "break\n",
      "v\t=\tnext_v\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcontinua\tse\tnão\testivermos\n",
      "se\tvocê\tcodificar\tisso,\tsaberá\tque\tele\tsempre\ttermina\tcom\tum\t\n",
      "v\n",
      "\tmuito\tpróximo\ta\n",
      "[0,0,0]\n",
      ".\tquanto\tmenor\tfor\ta\t\n",
      "tolerance\n",
      ",\tmais\tpróximo\tele\tserá.•\n",
      "•\n",
      "•\n",
      "escolhendo\to\ttamanho\tdo\tpróximo\tpasso\n",
      "embora\ta\tlógica\tde\tse\tmover\tem\tdireção\tao\tgradiente\testeja\tclara,\ta\tdistância\n",
      "não\testá.\tde\tfato,\tescolher\to\ttamanho\tdo\tpróximo\tpasso\té\tmais\tuma\tarte\tdo\tque\n",
      "uma\tciência.\tas\topções\tmais\tpopulares\tsão:\n",
      "usar\tum\tpasso\tde\ttamanho\tfixo\n",
      "diminuir\tgradualmente\to\ttamanho\tdo\tpasso\ta\tcada\tvez\n",
      "a\tcada\tpasso,\tescolher\to\ttamanho\tdo\tpasso\tque\tminimize\to\tvalor\tda\n",
      "função\tobjetiva\n",
      "a\túltima\topção\tparece\tperfeita\tmas\té,\tna\tprática,\tuma\tcomputação\tcustosa.\n",
      "podemos\taproximá-la\tao\ttentar\tuma\tvariedade\tde\ttamanhos\tde\tpassos\te\tescolher\n",
      "um\tque\tresulte\tno\tmenor\tvalor\tda\tfunção\tobjetiva:\n",
      "step_sizes\t=\t[100,\t10,\t1,\t0.1,\t0.01,\t0.001,\t0.0001,\t0.00001]\n",
      "é\tpossível\tque\tdeterminados\ttamanhos\tde\tpassos\tresultarão\tem\tentradas\n",
      "inválidas\tpara\tnossa\tfunção.\tentão,\tvocê\tprecisará\tcriar\tuma\tfunção\t“aplicação\n",
      "segura”\tque\tretorna\tinfinito\t(que\tnunca\tdeveria\tser\to\tmínimo\tde\tnada)\tpara\n",
      "entradas\tinválidas:\n",
      "def\n",
      "\t\n",
      "safe(f):\n",
      "\"\"\"retorna\tuma\tnova\tfunção\tque\té\tigual\ta\tf\n",
      ",\n",
      "exceto\tque\tele\texibe\tinfinito\tcomo\tsaída\ttoda\tvez\tque\tf\tproduz\tum\terro\"\"\"\n",
      "def\n",
      "\t\n",
      "safe_f(*args,\t**kwargs):\n",
      "\t\n",
      "try\n",
      ":\n",
      "\t\t\n",
      "return\n",
      "\t\n",
      "f(*args,\t**kwargs)\n",
      "\t\n",
      "except\n",
      ":\n",
      "\t\n",
      "return\n",
      "\t\n",
      "float('inf')\n",
      "\t\t\t\t\t\t\n",
      "#\tisso\tsignifica\t“infinito”\tem\tpython\n",
      "return\n",
      "\t\n",
      "safe_fjuntando\ttudo\n",
      "no\tgeral,\ttemos\talguma\t\n",
      "target_fn\n",
      "\tque\tqueremos\tminimizar,\te\ttambém\ttemos\to\tseu\n",
      "gradient_fn\n",
      ".\tpor\texemplo,\t\n",
      "target_fn\n",
      "\tpoderia\trepresentar\terros\tem\tum\tmodelo\tcomo\n",
      "uma\tfunção\tdos\tseus\tparâmetros,\te\ttalvez\tqueiramos\tencontrar\tos\tparâmetros\n",
      "que\tproduzem\tos\tmenores\terros\tpossíveis.\n",
      "além\tdo\tmais,\tdigamos\tque\tescolhemos\t(de\talguma\tforma)\tum\tvalor\tinicial\tpara\n",
      "os\tparâmetros\t\n",
      "theta_0\n",
      ".\tlogo,\tpodemos\timplementar\to\tgradiente\tdescendente\n",
      "como:\n",
      "def\n",
      "\t\n",
      "minimize_batch(target_fn,\tgradient_fn,\ttheta_0,\ttolerance=0.000001):\n",
      "\"\"\"usa\to\tgradiente\tdescendente\tpara\tencontrar\ttheta\tque\tminimize\ta\tfunção\talvo\"\"\"\n",
      "\t\n",
      "step_sizes\t=\t[100,\t10,\t1,\t0.1,\t0.01,\t0.001,\t0.0001,\t0.00001]\n",
      "\t\n",
      "theta\t=\ttheta_0\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tajusta\ttheta\tpara\to\tvalor\tinicial\n",
      "target_fn\t=\tsafe(target_fn)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "#\tversão\tsegura\tde\ttarget_fn\n",
      "value\t=\ttarget_fn(theta)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tvalor\tque\testamos\tminimizando\n",
      "\t\n",
      "while\n",
      "\t\n",
      "true:\n",
      "\tgradient\t=\tgradient_fn(theta)\n",
      "\tnext_thetas\t=\t[step(theta,\tgradient,\t-step_size)\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\t\n",
      "step_size\n",
      "\t\n",
      "in\n",
      "\t\n",
      "step_sizes]\n",
      "\t\t\t\t\t\t\t\n",
      "#\tescolhe\taquele\tque\tminimiza\ta\tfunção\tde\terro\n",
      "\t\t\t\t\t\t\t\n",
      "next_theta\t=\tmin(next_thetas,\tkey=target_fn)\n",
      "\t\t\t\t\t\t\t\n",
      "next_value\t=\ttarget_fn(next_theta)\n",
      "\t\t\t\t\t\t\t\n",
      "#\tpara\tse\testivermos\t“convergindo”\n",
      "\t\t\t\t\t\t\t\n",
      "if\n",
      "\t\n",
      "abs(value\t-\tnext_value)\t<\ttolerance:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "return\n",
      "\t\n",
      "theta\n",
      "\t\t\t\t\t\t\t\n",
      "else\n",
      ":\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "theta,\tvalue\t=\tnext_theta,\tnext_value\n",
      "chamamos\tde\t\n",
      "minimize_batch\n",
      "\tporque,\tpara\tcada\tpasso\tdo\tgradiente,\tele\tconsidera\to\n",
      "conjunto\tinteiro\tde\tdados\t(devido\tao\t\n",
      "target_fn\n",
      "\tretornar\to\terro\tno\tconjunto\tde\tdados\n",
      "inteiro).\tna\tpróxima\tseção,\tveremos\tuma\tabordagem\talternativa\tque\tconsidera\n",
      "apenas\tum\tponto\tde\tcada\tvez.\n",
      "às\tvezes\tvamos\tquerer\t\n",
      "maximizar\n",
      "\tuma\tfunção\te\tpodemos\tfazê-la\tao\tminimizar\n",
      "seu\tnegativo\t(que\tpossui\tum\tgradiente\tnegativo\tcorrespondente):\n",
      "def\n",
      "\t\n",
      "negate(f):\n",
      "\"\"\"retorna\tuma\tfunção\tque,\tpara\tqualquer\tentrada,\tx\tretorna\t-f(x)\"\"\"\n",
      "return\n",
      "\t\n",
      "lambda\n",
      "\t\n",
      "*args,\t**kwargs:\t-f(*args,\t**kwargs)def\n",
      "\t\n",
      "negate_all(f):\n",
      "\"\"\"o\tmesmo\tquando\tf\tretorna\tuma\tlista\tde\tnúmeros\"\"\"\n",
      "return\n",
      "\t\n",
      "lambda\n",
      "\t\n",
      "*args,\t**kwargs:\t[-y\n",
      "\t\n",
      "for\n",
      "\t\n",
      "y\n",
      "\t\n",
      "in\n",
      "\t\n",
      "f(*args,\t**kwargs)]\n",
      "def\n",
      "\t\n",
      "maximize_batch(target_fn,\tgradient_fn,\ttheta_0,\ttolerance=0.000001):\n",
      "return\n",
      "\t\n",
      "minimize_batch(negate(target_fn),\n",
      "negate_all(gradient_fn),\n",
      "theta_0,\n",
      "tolerance)gradiente\tdescendente\testocástico\n",
      "conforme\tmencionamos\tanteriormente,\tusaremos\tcom\tfrequência\to\tgradiente\n",
      "descendente\tpara\tescolher\tos\tparâmetros\tde\tum\tmodelo\tde\tmodo\tque\tminimize\n",
      "alguma\tnoção\tde\terro.\tao\tusar\to\tgrupo\tde\tabordagens\tanteriores,\tcada\tpasso\n",
      "gradiente\trequer\tque\tnós\tfaçamos\tuma\tprevisão\te\tcomputemos\to\tgradiente\tpara\n",
      "o\tconjunto\tde\tdados\tinteiro,\tfazendo\tcom\tque\tcada\tpasso\tleve\tmais\ttempo.\n",
      "normalmente,\tessas\tfunções\tde\terro\tsão\t\n",
      "aditivas\n",
      ",\to\tque\tsignifica\tque\to\terro\n",
      "previsto\tno\tconjunto\tde\tdados\tinteiro\té\tsimplesmente\ta\tsoma\tdos\terros\tpreditivos\n",
      "para\tcada\tponto.\n",
      "quando\to\tcaso\té\tesse,\tpodemos\taplicar\tuma\ttécnica\tchamada\t\n",
      "gradiente\n",
      "descendente\testocástico\n",
      ",\tque\tcomputa\to\tgradiente\t(e\tanda\tum\tpasso)\tapenas\tum\n",
      "ponto\tde\tcada\tvez.\tele\tcircula\tsobre\tnossos\tdados\trepetidamente\taté\talcançar\tum\n",
      "ponto\tde\tparada.\n",
      "durante\tcada\tciclo,\tvamos\tquerer\titerar\tsobre\tnossos\tdados\tem\tordem\taleatória:\n",
      "def\n",
      "\t\n",
      "in_random_order(data):\n",
      "\"\"\"gerador\tretorna\tos\telementos\tdo\tdado\tem\tordem\taleatória\"\"\"\n",
      "indexes\t=\t[i\n",
      "\t\n",
      "for\n",
      "\t\n",
      "i,\t_\n",
      "\t\n",
      "in\n",
      "\t\n",
      "enumerate(data)]\n",
      "#\tcria\tuma\tlista\tde\tíndices\n",
      "random.shuffle(indexes)\n",
      "\t\t\t\t\n",
      "#\tos\tembaralha\n",
      "for\n",
      "\t\n",
      "i\n",
      "\t\n",
      "in\n",
      "\t\n",
      "indexes:\n",
      "\t\t\t\t\t\t\t\t\n",
      "#\tretorna\tos\tdados\tnaquela\tordem\n",
      "yield\n",
      "\t\n",
      "data[i]\n",
      "andaremos\tum\tpasso\tgradiente\tpara\tcada\tponto\tde\tdados.\tesse\tmétodo\tdeixa\ta\n",
      "possibilidade\tde\tcircularmos\tpróximos\ta\tum\tmínimo\tpara\tsempre,\tentão\tquando\n",
      "pararmos\tde\tobter\tmelhorias,\tdiminuiremos\to\ttamanho\tdo\tpasso\te,\n",
      "eventualmente,\tpararemos:\n",
      "def\tminimize_stochastic(target_fn,\tgradient_fn,\tx,\ty,\ttheta_0,\talpha_0=0.01):\n",
      "data\t=\tzip(x,\ty)\n",
      "theta\t=\ttheta_0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpalpite\tinicial\n",
      "alpha\t=\talpha_0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttamanho\tdo\tpasso\tinicial\n",
      "min_theta,\tmin_value\t=\tnone,\tfloat(\"inf\")\t\t\n",
      "#\to\tmínimo\taté\tagora\n",
      "iterations_with_no_improvement\t=\t0\n",
      "#\tse\tformos\taté\t100\titerações\tsem\tmelhorias,\tparamos\n",
      "while\titerations_with_no_improvement\t<\t100:\n",
      "value\t=\tsum(\ttarget_fn(x_i,\ty_i,\ttheta)\tfor\tx_i,\ty_i\tin\tdata\t)\n",
      "if\tvalue\t<\tmin_value:#\tse\tachou\tum\tnovo\tmínimo,\tlembre-se\n",
      "#\te\tvolte\tpara\to\ttamanho\tdo\tpasso\toriginal\n",
      "min_theta,\tmin_value\t=\ttheta,\tvalue\n",
      "iterations_with_no_improvement\t=\t0\n",
      "alpha\t=\talpha_0\n",
      "else:\n",
      "#\tdo\tcontrário,\tnão\testamos\tmelhorando,\tportanto\ttente\n",
      "#\tdiminuir\to\ttamanho\tdo\tpasso\n",
      "iterations_with_no_improvement\t+=\t1\n",
      "alpha\t*=\t0.9\n",
      "#\te\tande\tum\tpasso\tgradiente\tpara\ttodos\tos\tpontos\tde\tdados\n",
      "for\tx_i,\ty_i\tin\tin_random_order(data):\n",
      "gradient_i\t=\tgradient_fn(x_i,\ty_i,\ttheta)\n",
      "theta\t=\tvector_subtract(theta,\tscalar_multiply(alpha,\tgradient_i))\n",
      "return\tmin_theta\n",
      "a\tversão\testocástica\tserá\ttipicamente\tmais\trápida\tdo\tque\ta\tversão\tbatch.\n",
      "naturalmente,\tvamos\tquerer\tuma\tversão\tque\tmaximize\tda\tmesma\tforma:\n",
      "def\n",
      "\t\n",
      "maximize_stochastic(target_fn,\tgradient_fn,\tx,\ty,\ttheta_0,\talpha_0=0.01):\n",
      "return\n",
      "\t\n",
      "minimize_stochastic(negate(target_fn),\n",
      "\t\t\t\tnegate_all(gradient_fn),\n",
      "\t\t\t\tx,\ty,\ttheta_0,\talpha_0)•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "continue\tlendo!\tusaremos\tgradiente\tdescendente\tpara\tresolver\tproblemas\n",
      "pelo\trestante\tdo\tlivro.\n",
      "neste\tponto,\tvocê\tjá\testá\tcansado\tde\tme\tver\trecomendar\ta\tleitura\tde\tlivros\n",
      "didáticos.\tse\tservir\tde\tconsolo,\t\n",
      "active\tcalculus\t(\n",
      "http://gvsu.edu/s/xr\n",
      "/)\n",
      "parece\tmais\tlegal\tdo\tque\tos\tlivros\tdidáticos\tde\tcálculo\tcom\tque\teu\n",
      "aprendi.\n",
      "scikit-learn\tpossui\tum\tmódulo\tde\tgradiente\tdescendente\testocástico\n",
      "(\n",
      "http://scikit-learn.org/stable/modules/sgd.html\n",
      ").\tnão\té\ttão\tgeral\tquanto\to\n",
      "nosso\tem\talguns\tpontos\te\tmais\tgeral\tem\toutros.\tapesar\tde\tque,\tna\tmaioria\n",
      "das\tsituações\tdo\tmundo\treal,\tvocê\tusará\tbibliotecas\tnas\tquais\ta\totimização\n",
      "já\testará\tpronta,\tentão\tvocê\tnão\tterá\tque\tse\tpreocupar\tcom\telas\t(exato\n",
      "quando\tnão\tfuncionar\tcorretamente,\to\tque,\tum\tdia,\tinevitavelmente,\n",
      "acontecerá).capítulo\t9\n",
      "obtendo\tdados\n",
      "para\tescrevê-lo,\tlevou\ttrês\tmeses;\tpara\tconcebê-lo,\ttrês\tminutos;\tpara\tcoletar\tos\tdados\tnele,\ttoda\ta\tminha\n",
      "vida\n",
      ".\n",
      "—f.\tscott\tfitzgerald\n",
      "para\tse\ttornar\tum\tcientista\tde\tdados,\tvocê\tprecisa\tde\tdados.\tna\tverdade,\tcomo\n",
      "um\tcientista\tde\tdados,\tvocê\tpassará\tuma\tembaraçosa\tgrande\tfração\tdo\tseu\ttempo\n",
      "adquirindo,\tlimpando\te\ttransformando\tdados.\tem\tuma\temergência,\tvocê\tsempre\n",
      "pode\tinserir\tos\tdados\tvocê\tmesmo\t(ou,\tse\tvocê\ttiver\tminions,\tfaça\tos\tfazê-lo)\n",
      "mas,\tgeralmente,\tnão\té\tum\tbom\tuso\tdo\tseu\ttempo.\tneste\tcapítulo,\n",
      "consideraremos\tmaneiras\tdiferentes\tde\tobter\tdados\tpara\tpython\te\tnos\tformatos\n",
      "adequados.stdin\te\tstdout\n",
      "se\tvocê\texecutar\tseus\tscripts\tde\tpython\tna\tlinha\tde\tcomando,\tvocê\tpode\n",
      "canalizar\n",
      "\t(\n",
      "pipe\n",
      ")\tos\tdados\tpor\tmeio\tdeles\tusando\t\n",
      "sys.stdin\n",
      "\te\t\n",
      "sys.stdout\n",
      ".\tpor\texemplo,\n",
      "este\té\tum\tscript\tque\tlê\tlinhas\tde\ttexto\te\tdevolve\tas\tque\tcombinarem\tcom\tuma\n",
      "expressão\tregular:\n",
      "#\tegrep.py\n",
      "import\tsys,\tre\n",
      "#\tsys.argv\té\ta\tlista\tdos\targumentos\tda\tlinha\tde\tcomandos\n",
      "#\tsys.argv\t[0]\té\to\tnome\tdo\tprograma\tem\tsi\n",
      "#\tsys.argv\t[1]\tserá\to\tregex\tespecificado\tna\tlinha\tde\tcomandos\n",
      "regex\t=\tsys.argv[1]\n",
      "#\tpara\tcada\tlinha\tpassada\tpelo\tscript\n",
      "for\n",
      "\tline\t\n",
      "in\n",
      "\tsys.stdin:\n",
      "#\tse\tcombinar\tcom\to\tregex,\tescreva-o\tpara\to\tstdout\n",
      "if\n",
      "\tre.search(regex,\tline):\n",
      "sys.stdout.write(line)\n",
      "e\teste\té\tum\tque\tconta\tas\tlinhas\trecebidas\te\texibe\ta\tcontagem:\n",
      "#\tline_count.py\n",
      "import\tsys\n",
      "count\t=\t0\n",
      "for\n",
      "\tline\t\n",
      "in\n",
      "\tsys.stdin:\n",
      "count\t+=\t1\n",
      "#\tprint\tvai\tpara\tsys.stdout\n",
      "print\n",
      "\tcount\n",
      "você\tpoderia\tusá-los\tpara\tcontar\tquantas\tlinhas\tde\tum\tarquivo\tcontêm\tnúmeros.\n",
      "no\twindows,\tvocê\tusaria:\n",
      "type\tsomefile.txt\t|\tpython\tegrep.py\t\"[0-9]\"\t|\tpython\tline_count.py\n",
      "enquanto\tque\tno\tsistema\tunix:\n",
      "cat\tsomefile.txt\t|\tpython\tegrep.py\t\"[0-9]\"\t|\tpython\tline_count.py\n",
      "este\té\to\tcaractere\tpipe\t|,\tque\tsignifica\t“use\ta\tsaída\tdo\tcomando\tda\tesquerda\n",
      "como\ta\tentrada\tdo\tcomando\tda\tdireita”.\tvocê\tpode\tconstruir\tencadeamentos\n",
      "(\n",
      "pipelines\n",
      ")\telaborados\tde\tprocessamento\tde\tdados\tdessa\tforma.se\tvocê\testá\tusando\to\twindows,\tpode\tdeixar\ta\tparte\tpython\tfora\tdeste\tcomando:\n",
      "type\tsomefile.txt\t|\tegrep.py\t\"[0-9]\"\t|\tline_count.py\n",
      "se\tvocê\testá\tno\tsistema\tunix,\ttal\tcomando\ttalvez\trequeira\tum\tpouco\tmais\tde\ttrabalho\n",
      "para\tser\tfeito\t(\n",
      "http://bit.ly/1l2wgb7\n",
      ").\n",
      "igualmente,\teste\tscript\tconta\tas\tpalavras\tem\tsua\tentrada\te\texibe\tas\tmais\tcomuns:\n",
      "#\tmost_common_words.py\n",
      "import\tsys\n",
      "from\tcollections\timport\tcounter\n",
      "#\tpassa\to\tnúmero\tde\tpalavras\tcomo\tprimeiro\targumento\n",
      "try:\n",
      "num_words\t=\tint(sys.argv[1])\n",
      "except:\n",
      "print\t\"usage:\tmost_common_words.py\tnum_words\"\n",
      "sys.exit(1)\t\t\t\t\t\t\t\t\t\n",
      "#\tcódigo\tde\tsaída\tnão-zero\tindica\terro\n",
      "counter\t=\tcounter(word.lower()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpalavras\tem\tminúsculas\n",
      "for\tline\tin\tsys.stdin\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\n",
      "for\tword\tin\tline.strip().split()\t\t\n",
      "#\tse\tseparam\tpor\tespaços\n",
      "if\tword)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpula\tas\t'palavras'\tvazias\n",
      "for\tword,\tcount\tin\tcounter.most_common(num_words):\n",
      "sys.stdout.write(str(count))\n",
      "sys.stdout.write(\"\\t\")\n",
      "sys.stdout.write(word)\n",
      "sys.stdout.write(\"\n",
      "\\n\n",
      "\")\n",
      "depois\tdisso,\tvocê\tpoderia\tfazer\talgo\tcomo:\n",
      "c:\\datascience>type\tthe_bible.txt\t|\tpython\tmost_common_words.py\t10\n",
      "64193\t\t\tthe\n",
      "51380\t\t\tand\n",
      "34753\t\t\tof\n",
      "13643\t\t\tto\n",
      "12799\t\t\tthat\n",
      "12560\t\t\tin\n",
      "10263\t\t\the\n",
      "9840\t\t\t\tshall\n",
      "8987\t\t\t\tunto\n",
      "8836\t\t\t\t\n",
      "for\n",
      "se\tvocê\tfor\tum\tprogramador\tfamiliarizado\tcom\tunix,\tprovavelmente\tvocê\testá\n",
      "familiarizado\tcom\tuma\tgrande\tvariedade\tde\tferramentas\tde\tlinhas\tde\tcomando\t(por\n",
      "exemplo,\t\n",
      "egrep\n",
      ")\tque\tsão\tconstruídos\tdentro\tdo\tseu\tsistema\toperacional\te\n",
      "provavelmente\tvocês\tas\tprefere\tdo\tque\tconstruir\ta\tsua\tprópria\tdo\tzero.\tainda\tassim,é\tbom\tsaber\tque\tvocê\tpode\tse\tprecisar.lendo\tarquivos\n",
      "você\ttambém\tpode\tler\ta\tpartir\tde\te\tescrever\tnos\tarquivos\tdiretamente\tno\tseu\n",
      "código.\tpython\tfacilita\to\ttrabalho\tcom\tarquivos.\n",
      "o\tbásico\tde\tarquivos\ttexto\n",
      "o\tprimeiro\tpasso\tpara\ttrabalhar\tcom\tarquivos\tde\ttexto\té\tobter\tum\t\n",
      "objeto\tde\n",
      "arquivo\n",
      "\tusando\t\n",
      "open\n",
      ":\n",
      "#\t'r'\tsignifica\tsomente\tleitura\n",
      "file_for_reading\t=\topen('reading_file.txt',\t'r')\n",
      "#\t'w'\té\tescrever\t-\t-\tdestruirá\to\tarquivo\tse\tele\tjá\texistir!\n",
      "file_for_writing\t=\topen('writing_file.txt',\t'w')\n",
      "#\t'a'\té\tanexar\t-\t-\tpara\tadicionar\tao\tfinal\tdo\tarquivo\n",
      "file_for_appending\t=\topen('appending_file.txt',\t'a')\n",
      "#\tnão\tse\tesqueça\tde\tfechar\tos\tarquivos\tao\tterminar\n",
      "file_for_writing.close()\n",
      "como\té\tmuito\tfácil\tesquecer\tde\tfechar\tos\tarquivos,\tvocê\tdeveria\tsempre\tusá-los\n",
      "em\tum\tbloco\t\n",
      "with\n",
      ",\tpois\tno\ttérmino\tde\tcada\tum\teles\tserão\tfechados\n",
      "automaticamente:\n",
      "with\n",
      "\topen(filename,'r')\t\n",
      "as\n",
      "\tf:\n",
      "data\t=\tfunction_that_gets_data_from(f)\n",
      "#\tneste\tponto\tf\tjá\tfoi\tfechado,\tnão\ttente\tusá-lo\n",
      "process(data)\n",
      "se\tvocê\tprecisar\tler\tum\tarquivo\tde\ttexto\tinteiro,\tvocê\tpode\tapenas\titerar\tsobre\tas\n",
      "linhas\tdo\tarquivo\tusando\t\n",
      "for\n",
      ":\n",
      "starts_with_hash\t=\t0\n",
      "with\n",
      "\topen('input.txt','r')\t\n",
      "as\n",
      "\tf:\n",
      "for\n",
      "\tline\t\n",
      "in\n",
      "\tfile:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tobserve\tcada\tlinha\tdo\tarquivo\n",
      "if\n",
      "\tre.match(\"^#\",line):\t\t\t\t\t\t\t\t\t\n",
      "#\tuse\tum\tregex\tpara\tver\tse\tcomeça\tcom\t'#'\n",
      "starts_with_hash\t+=\t1\t\t\n",
      "#\tse\tcomeçar,\tadicione\t1\tà\tcontagem\n",
      "toda\tlinha\tque\tvocê\tobtém\tdesse\tmodo\ttermina\tem\tum\tcaractere\tde\tnova\tlinha\n",
      "(\n",
      "newline\n",
      "),\tlogo,\tvocê\tvai\tquerer\t\n",
      "strip()\n",
      "\tremovê-lo\tfrequentemente\tantes\tde\tfazerqualquer\tcoisa.\n",
      "por\texemplo,\timagine\tque\tvocê\ttenha\tum\tarquivo\tcheio\tde\tendereços\tde\te-mail,\n",
      "um\tpor\tlinha\te\tque\tvocê\tprecisa\tgerar\tum\thistograma\tde\tdomínios.\tas\tregras\n",
      "para\textrair\tos\tdomínios\tcorretamente\tsão\tsutis\t(por\texemplo,\ta\tlista\tpública\tde\n",
      "sufixo\tem\t\n",
      "https://publicsuffix.org\n",
      "),\tuma\tboa\tprimeira\taproximação\té\tpegar\tas\n",
      "partes\tdos\tendereços\tde\te-mails\tque\tvêm\tdepois\tdo\t\n",
      "@\n",
      ".\t(o\tque\tnos\tdá\tuma\n",
      "relação\terrada\tpara\tendereços\tde\te-mail\tcomo\t\n",
      "joel@mail.datasciencester.com\n",
      ".)\n",
      "def\n",
      "\tget_domain(email_address):\n",
      "\"\"\"separa\tno\t'@'\te\tretorna\tna\túltima\tparte\"\"\"\n",
      "return\n",
      "\temail_address.lower().split(\"@\")[-1]\n",
      "with\n",
      "\topen('email_addresses.txt',\t'r')\t\n",
      "as\n",
      "\tf:\n",
      "domain_counts\t=\tcounter(get_domain(line.strip())\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tline\t\n",
      "in\n",
      "\tf\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "if\n",
      "\t\"@\"\t\n",
      "in\n",
      "\tline)\n",
      "arquivos\tdelimitados\n",
      "o\tendereço\tde\te-mail\thipotético\tque\tacabamos\tde\tprocessar\ttem\tum\tendereço\n",
      "por\tlinha.\tcom\tmais\tfrequência,\tvocê\ttrabalhará\tcom\tarquivos\tcom\tmuitos\tdados\n",
      "em\tcada\tlinha.\ttais\tarquivos\tsão\t\n",
      "separados\tpor\tvírgula\n",
      "\t(\n",
      "comma-separated\n",
      ")\tou\n",
      "por\ttabulação\n",
      "\t(\n",
      "tab-separated\n",
      ").\tcada\tlinha\tpossui\tdiversos\tcampos,\tcom\tuma\n",
      "vírgula\t(ou\tuma\ttabulação)\tindicando\tonde\tum\tcampo\ttermina\te\to\toutro\tcomeça.\n",
      "começa\ta\tficar\tcomplicado\tquando\tvocê\ttem\tcampos\tcom\tvírgulas,\ttabulações\te\n",
      "newlines\tneles\t(inevitavelmente\tvocê\tterá).\tpor\tesse\tmotivo,\té\tquase\tsempre\tum\n",
      "erro\ttentar\tanalisar\tsozinho.\tem\tvez\tdisso,\tvocê\tdeveria\tusar\to\tmodulo\t\n",
      "csv\n",
      "\tdo\n",
      "python\t(ou\tas\tbibliotecas\t\n",
      "pandas\n",
      ").\tpor\trazões\ttécnicas\t—\tfique\tà\tvontade\tpara\n",
      "culpar\ta\tmicrosoft\t—\tvocê\tdeve\tsempre\ttrabalhar\tcom\tarquivos\t\n",
      "csv\n",
      "\tno\t\n",
      "modo\n",
      "binário\n",
      "\tincluindo\tum\t\n",
      "b\n",
      "\tdepois\tde\t\n",
      "r\n",
      "\tou\t\n",
      "w\n",
      "\t(veja\tstack\toverflow\tem\n",
      "http://bit.ly/1l2y7wl\n",
      ").\n",
      "se\tseu\tarquivo\tnão\tpossuir\tcabeçalho\t(o\tque\tsignifica\tque\tvocê\tquer\tque\tcada\n",
      "linha\tseja\tcomo\tuma\t\n",
      "list\n",
      "\tque\tdeposita\tem\tvocê\to\tfardo\tde\tsaber\to\tconteúdo\tde\n",
      "cada\tcoluna),\tvocê\tpode\tusar\t\n",
      "csv.reader\n",
      "\tpara\titerar\tsobre\tas\tlinhas,\tcada\tqual\tserá\n",
      "uma\tlista\tapropriadamente\tseparada.\n",
      "por\texemplo,\tse\ttivéssemos\tum\tarquivo\tdelimitado\tpor\ttabulação\tde\tpreços\tdeações:\n",
      "6/20/2014\t\t\taapl\t\t\t\t\t\t90.91\n",
      "6/20/2014\t\t\tmsft\t\t\t\t\t\t41.68\n",
      "6/20/2014\t\t\tfb\t\t\t64.5\n",
      "6/19/2014\t\t\taapl\t\t\t\t\t\t91.86\n",
      "6/19/2014\t\t\tmsft\t\t\t\t\t\t41.51\n",
      "6/19/2014\t\t\tfb\t\t\t64.34\n",
      "poderíamos\tprocessá-los\tcom:\n",
      "import\tcsv\n",
      "with\n",
      "\topen('tab_delimited_stock_prices.txt',\t'rb')\t\n",
      "as\n",
      "\tf:\n",
      "reader\t=\tcsv.reader(f,\tdelimiter='\n",
      "\\t\n",
      "')\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\treader:\n",
      "date\t=\trow[0]\n",
      "symbol\t=\trow[1]\n",
      "closing_price\t=\tfloat(row[2])\n",
      "process(date,\tsymbol,\tclosing_price)\n",
      "se\tseu\tarquivo\tpossui\tcabeçalhos:\n",
      "date:symbol:closing_price\n",
      "6/20/2014:aapl:90.91\n",
      "6/20/2014:msft:41.68\n",
      "6/20/2014:fb:64.5\n",
      "você\tpode\tpular\ta\tlinha\t(com\tuma\tchamada\tinicial\tpara\t\n",
      "reader.next()\n",
      ")\tou\tobter\tcada\n",
      "linha\tcomo\tum\t\n",
      "dict\n",
      "\t(com\tos\tcabeçalhos\tcomo\tchaves)\tusando\t\n",
      "csv.dictreader\n",
      ":\n",
      "with\n",
      "\topen('colon_delimited_stock_prices.txt',\t'rb')\t\n",
      "as\n",
      "\tf:\n",
      "reader\t=\tcsv.dictreader(f,\tdelimiter=':')\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\treader:\n",
      "date\t=\trow[\"date\"]\n",
      "symbol\t=\trow[\"symbol\"]\n",
      "closing_price\t=\tfloat(row[\"closing_price\"])\n",
      "process(date,\tsymbol,\tclosing_price)\n",
      "mesmo\tse\tseu\tarquivo\tnão\ttiver\tcabeçalhos\tvocê\tainda\tpode\tusar\t\n",
      "dictreader\n",
      "\tao\n",
      "passar\ta\tchave\ta\teles\tcomo\to\tparâmetro\t\n",
      "fieldnames\n",
      ".\n",
      "da\tmesma\tforma,\tvocê\tpode\ttranscrever\tos\tdados\tdelimitados\tusando\t\n",
      "csv.writer\n",
      ":\n",
      "today_prices\t=\t{\t'aapl'\t:\t90.91,\t'msft'\t:\t41.68,\t'fb'\t:\t64.5\t}\n",
      "with\n",
      "\topen('comma_delimited_stock_prices.txt','wb')\t\n",
      "as\n",
      "\tf:\n",
      "writer\t=\tcsv.writer(f,\tdelimiter=',')\n",
      "for\n",
      "\tstock,\tprice\t\n",
      "in\n",
      "\ttoday_prices.items():\n",
      "writer.writerow([stock,\tprice])csv.writer\n",
      "\tfará\ta\tcoisa\tcerta\tse\tseus\tcampos\tpossuírem\tvírgulas.\tseu\tescritor\tfeito\tà\n",
      "mão\tprovavelmente\tnão.\tpor\texemplo,\tse\tvocê\ttentar:\n",
      "results\t=\t[[\"test1\",\t\"success\",\t\"monday\"],\n",
      "\t\t\t\t[\"test2\",\t\"success,\tkind\tof\",\t\"tuesday\"],\n",
      "\t\t\t\t[\"test3\",\t\"failure,\tkind\tof\",\t\"wednesday\"],\n",
      "\t\t\t\t[\"test4\",\t\"failure,\tutter\",\t\"thursday\"]]\n",
      "#\tnão\tfaça\tisso!\n",
      "with\n",
      "\topen('bad_csv.txt',\t'wb')\t\n",
      "as\n",
      "\tf:\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tresults:\n",
      "f.write(\",\".join(map(str,\trow)))\t\t\t\n",
      "#\ttalvez\ttenha\tmuitas\tvírgulas\tnele!\n",
      "f.write(\"\n",
      "\\n\n",
      "\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ta\tlinha\tpode\tter\tnewlines\ttambém!\n",
      "você\tacabará\tcom\tum\tarquivo\t\n",
      "csv\n",
      "\tque\tse\tparece\tcom:\n",
      "test1,success,monday\n",
      "test2,success,\tkind\tof,tuesday\n",
      "test3,failure,\tkind\tof,wednesday\n",
      "test4,failure,\tutter,thursday\n",
      "e\tninguém\tmais\tconseguirá\tentender.extraindo\tdados\tda\tinternet\n",
      "outra\tmaneira\tde\tse\tobter\tdados\té\textraindo-os\tdas\twebpages.\tpesquisar\tpáginas\n",
      "da\tweb\té\tmuito\tfácil;\textrair\tinformações\testruturadas\te\tsignificativas\tnão\té\ttão\n",
      "fácil.\n",
      "html\te\tsua\tsubsequente\tpesquisa\n",
      "as\tpáginas\tna\tinternet\tsão\tescritas\tem\thtml,\tna\tqual\to\ttexto\t(idealmente)\té\n",
      "marcado\tem\telementos\te\tatributos:\n",
      "<html>\n",
      "\t\t\n",
      "<head>\n",
      "\t\t\t\t\n",
      "<title>\n",
      "a\tweb\tpage\n",
      "</title>\n",
      "\t\t\n",
      "</head>\n",
      "\t\t\n",
      "<body>\n",
      "\t\t\t\t\n",
      "<p\n",
      "\tid=\"author\"\n",
      ">\n",
      "joel\tgrus\n",
      "</p>\n",
      "\t\t\t\t\n",
      "<p\n",
      "\tid=\"subject\"\n",
      ">\n",
      "data\tscience\n",
      "</p>\n",
      "\t\t\n",
      "</body>\n",
      "</html>\n",
      "em\tum\tmundo\tperfeito,\tem\tque\ttodas\tas\tpáginas\tda\tinternet\tsão\tmarcadas\n",
      "semanticamente\ta\tnosso\tfavor,\tseríamos\tcapazes\tde\textrair\tdados\tusando\tregras\n",
      "como\t“encontre\to\telemento\t\n",
      "<p>\n",
      "\tcujo\t\n",
      "id\n",
      "\té\t\n",
      "subject\n",
      "\te\tretorne\to\ttexto\tque\tele\tcontém”.\n",
      "no\tmundo\treal,\thtml\tnão\té\tmuito\tbem\tformulado,\tmuito\tmenos\tcomentado.\n",
      "isso\tsignifica\tque\tprecisaremos\tde\tajuda\tpara\tentender\ttudo\tisso.\n",
      "para\textrair\tdados\tdo\thtml,\tusaremos\ta\tbiblioteca\tbeautifulsoup\n",
      "(\n",
      "http://www.crummy.com/software/beautifulsoup\n",
      "/\n",
      "),\tpois\tela\tconstrói\tuma\tárvore\n",
      "a\tpartir\tde\tvários\telementos\tde\tuma\tpágina\te\tfornece\tuma\tsimples\tinterface\tpara\n",
      "acessá-los.\tenquanto\teu\tescrevo\teste\tlivro,\ta\tversão\tmais\trecente\té\n",
      "beautifulsoup\t4.3.2\t(pip\tinstall\tbeautifulsoup4),\tque\té\ta\tque\t\n",
      "usaremos.\ttambém\n",
      "usaremos\tas\tbibliotecas\tde\tpedidos\t(\n",
      "pip\tinstall\trequests\n",
      "),\tque\té\tuma\tmaneira\tmais\n",
      "simpática\tde\tfazer\tpedidos\t(\n",
      "http://docs.python-requests.org/en/latest\n",
      "/\n",
      ")\tao\thttp\n",
      "do\tque\tpara\tqualquer\tcoisa\tconstruída\tdentro\tde\tpython.\n",
      "o\tinterpretador\thtml\tembutido\tem\tpython\tnão\té\ttão\tflexível,\to\tque\tsignifica\n",
      "que\tnem\tsempre\tele\tse\tdá\tbem\tcom\to\thtml\tque\tnão\tpossui\tboa\tformação.\tpor\n",
      "esse\tmotivo,\tusaremos\tum\tinterpretador\tdiferente,\tque\tprecisamos\tinstalar:pip\tinstall\thtml5lib\n",
      "para\tusar\to\tbeautiful\tsoup,\tteremos\tque\tpassar\tum\tpouco\tde\thtml\tpara\ta\n",
      "função\t\n",
      "beautifulsoup()\n",
      ".\tem\tnossos\texemplos,\teste\tserá\to\tresultado\tde\tuma\tchamada\n",
      "para\t\n",
      "requests.get\n",
      ":\n",
      "from\tbs4\timport\n",
      "\tbeautifulsoup\n",
      "import\trequests\n",
      "html\t=\trequests.get(\"http://www.example.com\").text\n",
      "soup\t=\tbeautifulsoup(html,\t'html5lib')\n",
      "depois\tdisso,\tiremos\tlonge\tusando\tpoucos\tmétodos\tsimples.\n",
      "trabalharemos,\tna\tmaior\tparte,\tcom\tobjetos\t\n",
      "tag\n",
      "\tque\tcorrespondem\tàs\tmarcações\n",
      "(\n",
      "tags\n",
      ")\trepresentando\ta\testrutura\tde\tuma\tpágina\thtml.\n",
      "por\texemplo,\tpara\tencontrar\ta\tprimeira\tmarcação\t\n",
      "<p>\n",
      "\tvocê\tpode\tusar:\n",
      "first_paragraph\t=\tsoup.find('p')\t\t\t\t\t\t\t\t\t\n",
      "#\tou\tsomente\tsoup.p\n",
      "você\tpode\tobter\to\tconteúdo\tdo\ttexto\tde\tuma\t\n",
      "tag\n",
      "\tusando\ta\tpropriedade\t\n",
      "text\n",
      ":\n",
      "first_paragraph_text\t=\tsoup.p.text\n",
      "first_paragraph_words\t=\tsoup.p.text.split()\n",
      "e\tvocê\tpode\textrair\tos\tatributos\tde\tuma\tmarcação\ttratando-a\tcomo\tum\t\n",
      "dict\n",
      ":\n",
      "first_paragraph_id\t=\tsoup.p['id']\t\t\t\t\t\t\t\n",
      "#\tsurge\tkeyerror\tse\tnão\ttiver\t'id'\n",
      "first_paragraph_id2\t=\tsoup.p.get('id')\t\t\n",
      "#\tretorna\tnone\tse\tnão\ttiver\t'id'\n",
      "você\tpode\tobter\tmúltiplas\tmarcações\tao\tmesmo\ttempo:\n",
      "all_paragraphs\t=\tsoup.find_all('p')\t\t\t\t\t\t\t\t\t\n",
      "#\tou\tapenas\tsoup('p')\n",
      "paragraphs_with_ids\t=\t[p\t\n",
      "for\n",
      "\tp\t\n",
      "in\n",
      "\tsoup('p')\t\n",
      "if\n",
      "\tp.get('id')]\n",
      "frequentemente,\tvocê\tencontrará\tmarcações\tcom\tuma\t\n",
      "class\n",
      "\tespecífica:\n",
      "important_paragraphs\t=\tsoup('p',\t{'class'\t:\t'important'})\n",
      "important_paragraphs2\t=\tsoup('p',\t'important')\n",
      "important_paragraphs3\t=\t[p\t\n",
      "for\n",
      "\tp\t\n",
      "in\n",
      "\tsoup('p')\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "if\n",
      "\t'important'\t\n",
      "in\n",
      "\tp.get('class',\t[])]\n",
      "você\tpode\tcombiná-los\tpara\timplementar\tuma\tlógica\tmais\telaborada.\tpor\n",
      "exemplo,\tse\tvocê\tquiser\tencontrar\ttodo\telemento\t\n",
      "<span>\n",
      "\tque\testá\tcontido\tdentro\n",
      "de\tum\telemento\t\n",
      "<div>\n",
      ",\tvocê\tpoderia\tfazer\tassim:\n",
      "#\tatenção,\tvai\tretornar\to\tmesmo\tspan\tmúltiplas\tvezes\n",
      "#\tse\tele\tficar\tdentro\tde\tmúltiplos\tdivs\n",
      "#\tseja\tmais\tesperto\tse\tesse\tfor\to\tcasospans_inside_divs\t=\t[span\n",
      "for\n",
      "\tdiv\t\n",
      "in\n",
      "\tsoup('div')\t\t\t\t\t\t\n",
      "#\tpara\tcada\t<div>\tna\tpágina\n",
      "for\n",
      "\tspan\t\n",
      "in\n",
      "\tdiv('span')]\t\t\t\t\n",
      "#\tencontra\tcada\t<span>\tdentro\n",
      "esse\tpunhado\tde\trecursos\tpermitirá\tque\tfaçamos\tbastante\tcoisa.\tse\tvocê\tprecisar\n",
      "fazer\tcoisas\tmais\tcomplicadas\t(ou\tse\té\tcurioso),\tverifique\ta\tdocumentação.\n",
      "naturalmente,\tqualquer\tdado\tque\tseja\timportante\tpode\tnão\tser\tclassificado\tcomo\n",
      "class=\"important\"\n",
      ".\tvocê\tterá\tque\tinspecionar\tcom\tcuidado\ta\tfonte\tdo\thtml,\n",
      "raciocinar\tcom\tsua\tlógica\tseletiva,\te\tse\tpreocupar\tcom\tcasos\textremos\tpara\tse\n",
      "certificar\tque\tseu\tdado\testá\tcorreto.\tveremos\tum\texemplo.\n",
      "exemplo:\tlivros\to’reilly\tsobre\tdados\n",
      "um\tinvestidor\tem\tpotencial\tpara\ta\tdatasciencester\tacha\tque\tdados\tsão\tapenas\n",
      "uma\tmoda\tpassageira.\tpara\tprovar\tque\tele\testá\terrado,\tvocê\tdecide\texaminar\n",
      "quantos\tlivros\tsobre\tdados\ta\to'reilly\tpublicou\tao\tlongo\tdos\tanos.\tdepois\tde\n",
      "fuçar\tpelo\tsite,\tvocê\tencontra\tmuitas\tpáginas\tde\tlivros\tsobre\tdados\t(e\tvídeos)\te\n",
      "30\titens\texploráveis\tem\tuma\tpágina\tde\tdiretórios\tcom\turls\tcomo\testa:\n",
      "http://shop.oreilly.com/category/browse-subjects/data.do?\n",
      "sortby=publicationdate&page=1\n",
      "a\tmenos\tque\tvocê\tseja\tum\tidiota\t(e\ta\tmenos\tque\tvocê\tqueira\tque\tseu\textrator\n",
      "seja\tbanido),\tsempre\tque\tvocê\tquiser\textrair\tdados\tde\tum\twebsite,\tvocê\tdeve\n",
      "verificar\tprimeiro\tse\tele\tpossui\talgum\ttipo\tde\tpolítica\tde\tacesso.\tolhando\tem:\n",
      "http://oreilly.com/terms/\n",
      "não\tparece\thaver\tnada\tproibindo\tesse\tprojeto.\ta\tfim\tde\tsermos\tbons\tcidadãos,\n",
      "também\tdevemos\tprocurar\tpelo\tarquivo\t\n",
      "robots.txt\n",
      "\tque\tdizem\taos\t\n",
      "webcrawlers\n",
      "(programas\tque\tcoletam\tdados\tda\tinternet)\tcomo\tse\tcomportar.\tas\tpartes\n",
      "importantes\tem\t\n",
      "http://shop.oreilly.com/robots.txt\n",
      "\tsão:\n",
      "crawl-delay:\t30\n",
      "request-rate:\t1/30\n",
      "a\tprimeira\tlinha\tnos\tdiz\tque\tdevemos\tesperar\t30\tsegundos\tentre\tum\tpedido\te\n",
      "outro;\ta\tsegunda,\tque\tdevemos\tpedir\tuma\tpágina\ta\tcada\t30\tsegundos.\tentão,\n",
      "basicamente,\telas\tsão\tduas\tformas\tdiferentes\tde\tdizer\ta\tmesma\tcoisa.\t(existem\n",
      "outras\tlinhas\tque\tindicam\tdiretórios\tpara\tnão\tserem\textraídos,\tmas\telas\tnão\n",
      "incluem\tnossa\turl,\tportanto\testamos\tbem.)há\tsempre\ta\tpossibilidade\tque\ta\to'reilly\tvá\tremodelar\tseu\tsite\te\tquebrar\ttoda\ta\n",
      "lógica\tdesta\tseção.\tfarei\to\tque\teu\tpuder\tpara\tprevenir\tisso,\tclaro,\tmas\teu\tnão\tpossuo\n",
      "muita\tinfluência\tsobre\teles.\tembora,\tse\tcada\tum\tde\tvocês\tpudesse\tconvencer\tcada\n",
      "um\tque\tvocês\tconhecem\ta\tcomprar\tum\texemplar\tdeste\tlivro…\n",
      "para\tdescobrir\tcomo\textrair\tos\tdados,\tvamos\tbaixar\tuma\tdaquelas\tpáginas\te\n",
      "jogá-las\tno\tbeautiful\tsoup:\n",
      "#\tvocê\tnão\tprecisa\tdividir\ta\turl\tdesta\tforma\ta\tmenos\tque\tela\tprecise\tcaber\tem\tum\tlivro\n",
      "url\t=\t\"http://shop.oreilly.com/category/browse-subjects/\"\t+\t\\\n",
      "\t\t\t\t\"data.do?sortby=publicationdate&page=1\"\n",
      "soup\t=\tbeautifulsoup(requests.get(url).text,\t'html5lib')\n",
      "se\tvocê\tvir\ta\tfonte\tda\tpágina\t(no\tseu\tnavegador,\tclique\tcom\to\tbotão\tdireito\te\n",
      "selecione\t(“exibir\tcódigo-fonte”\tou\t“exibir\tcódigo-fonte\tda\tpágina”\tou\tqualquer\n",
      "outra\topção\tque\tse\tpareça\tcom\tisso),\tvocê\tverá\tque\tcada\tlivro\t(ou\tvídeo)\tparece\n",
      "estar\tcontido\tunicamente\tem\tum\telemento\t\n",
      "<td>\n",
      "\tda\tcélula\tda\ttabela\tcuja\t\n",
      "class\n",
      "\té\n",
      "thumbtext\n",
      ".\testa\té\t(em\tversão\tresumida)\to\thtml\trelevante\tpara\tum\tlivro:\n",
      "<td\n",
      "\tclass=\"thumbtext\"\n",
      ">\n",
      "\t\t\n",
      "<div\n",
      "\tclass=\"thumbcontainer\"\n",
      ">\n",
      "\t\n",
      "<div\n",
      "\tclass=\"thumbdiv\"\n",
      ">\n",
      "\t\t\t\n",
      "<a\n",
      "\thref=\"/product/9781118903407.do\"\n",
      ">\n",
      "\t\t\t\t\t\n",
      "<img\n",
      "\tsrc=\"...\"\n",
      "/>\n",
      "\t\t\t\n",
      "</a>\n",
      "\t\n",
      "</div>\n",
      "\t\t\n",
      "</div>\n",
      "<div\n",
      "\tclass=\"widthchange\"\n",
      ">\n",
      "\t\t\n",
      "<div\n",
      "\tclass=\"thumbheader\"\n",
      ">\n",
      "\t\t\n",
      "<a\n",
      "\thref=\"/product/9781118903407.do\"\n",
      ">\n",
      "getting\ta\tbig\tdata\tjob\tfor\tdummies\n",
      "</a>\n",
      "\t\t\n",
      "</div>\n",
      "\t\n",
      "<div\n",
      "\tclass=\"authorname\"\n",
      ">\n",
      "by\tjason\twilliamson\n",
      "</div>\n",
      "\t\n",
      "<span\n",
      "\tclass=\"directorydate\"\n",
      ">\n",
      "\tdecember\t2014\t\n",
      "</span>\n",
      "\t\n",
      "<div\n",
      "\tstyle=\"clear:both;\"\n",
      ">\n",
      "\t\n",
      "<div\n",
      "\tid=\"146350\"\n",
      ">\n",
      "\t\t\t\n",
      "<span\n",
      "\tclass=\"pricelabel\"\n",
      ">\n",
      "\t\t\t\tebook:\n",
      "\t\t\t\t\n",
      "<span\n",
      "\tclass=\"price\"\n",
      ">\t\n",
      "$29.99\n",
      "</span>\n",
      "\t\t\t\n",
      "</span>\n",
      "\t\t\t\n",
      "</div>\n",
      "\t\t\n",
      "</div>\n",
      "\t\n",
      "</div>\n",
      "</td>\n",
      "um\tbom\tprimeiro\tpasso\té\tencontrar\ttodos\tos\telementos\tde\tmarcação\t\n",
      "td\n",
      "\t\n",
      "thumbtext\n",
      ":tds\t=\tsoup('td',\t'thumbtext')\n",
      "print\n",
      "\tlen(tds)\n",
      "#\t30\n",
      "gostaríamos\tde\tfiltrar\tos\tvídeos.\t(esse\taspirante\ta\tinvestidor\tsó\tse\timpressiona\n",
      "com\tlivros.)\tse\tinspecionarmos\to\thtml\tum\tpouco\tmais\talém,\tvemos\tque\tcada\n",
      "td\n",
      "\tcontém\tum\tou\tmais\telementos\t\n",
      "span\n",
      "\tcuja\t\n",
      "class\n",
      "\té\t\n",
      "pricelabel\n",
      ",\te\tcujo\ttexto\tse\tparece\n",
      "com\t\n",
      "ebook:\n",
      "\tou\t\n",
      "video:\n",
      "\tou\t\n",
      "print:\n",
      ".\tparece\tque\tos\tvídeos\tcontêm\tapenas\tum\t\n",
      "pricelabel\n",
      ",\n",
      "cujo\ttexto\tcomeça\tcom\t\n",
      "video\n",
      "\t(após\tremover\tos\tespaços\timportantes).\tdesse\n",
      "modo,\tpodemos\ttestar\tpara\tvídeos\tcom:\n",
      "def\n",
      "\tis_video(td):\n",
      "\"\"\"é\tum\tvídeo\tse\ttiver\texatamente\tum\tpricelabel,\te\tse\n",
      "o\ttexto\tcorrido\tdentro\tdo\tpricelabel\tcomeçar\tcom\t'video\"\"\"\n",
      "pricelabels\t=\ttd('span',\t'pricelabel')\n",
      "return\n",
      "\t(len(pricelabels)\t==\t1\t\n",
      "and\n",
      "pricelabels[0].text.strip().startswith(\"video\"))\n",
      "print\n",
      "\tlen([td\t\n",
      "for\n",
      "\ttd\t\n",
      "in\n",
      "\ttds\t\n",
      "if\tnot\n",
      "\tis_video(td)])\n",
      "#\t21\tpara\tmim,\ttalvez\tseja\tdiferente\tpara\tvocê\n",
      "agora\testamos\tprontos\tpara\tcomeçar\ta\tpuxar\tos\tdados\tpara\tfora\tdos\telementos\n",
      "td\n",
      ".\tparece\tque\to\ttítulo\tdo\tlivro\té\to\ttexto\tdentro\tda\tmarcação\t\n",
      "<a>\n",
      "\tdentro\tde\t\n",
      "<div\n",
      "class=\"thumbheader\">\n",
      ":\n",
      "title\t=\ttd.find(\"div\",\t\"thumbheader\").a.text\n",
      "os\tautores\testão\tno\ttexto\tde\t\n",
      "authorname\t<div>\n",
      ".\teles\tsão\tintroduzidos\tpor\tum\t\n",
      "by\n",
      "\t(do\n",
      "qual\tqueremos\tnos\tlivrar)\te\tseparados\tpor\tvírgulas\t(que\tqueremos\tseparar,\n",
      "depois\tteremos\tque\tnos\tlivrar\tdos\tespaços):\n",
      "author_name\t=\ttd.find('div',\t'authorname').text\n",
      "authors\t=\t[x.strip()\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\tre.sub(\"^by\t\",\t\"\",\tauthor_name).split(\",\")]\n",
      "o\tisbn\tparece\testar\tcontido\tno\tlink\tque\testá\tem\t\n",
      "thumbheader\t<div>\n",
      ":\n",
      "isbn_link\t=\ttd.find(\"div\",\t\"thumbheader\").a.get(\"href\")\n",
      "#\tre.match\tcaptura\ta\tparte\tdo\tregex\tem\tparênteses\n",
      "isbn\t=\tre.match(\"/product/(.*)\\.do\",\tisbn_link).group(1)\n",
      "e\ta\tdata\té\tsó\to\tconteúdo\tde\t\n",
      "<span\tclass=\"directorydate\">\n",
      ":\n",
      "date\t=\ttd.find(\"span\",\t\"directorydate\").text.strip()\n",
      "vamos\tcolocar\ttudo\tjunto\tem\tuma\tfunção:def\n",
      "\tbook_info(td):\n",
      "\"\"\"dado\tuma\tmarcação\tbeautifulsoup\t<td>\trepresentando\tum\tlivro\n",
      ",\n",
      "extrai\tos\tdetalhes\tdo\tlivro\te\tretorna\tum\tdict\"\"\"\n",
      "title\t=\ttd.find(\"div\",\t\"thumbheader\").a.text\n",
      "by_author\t=\ttd.find('div',\t'authorname').text\n",
      "authors\t=\t[x.strip()\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\tre.sub(\"^by\t\",\t\"\",\tby_author).split(\",\")]\n",
      "isbn_link\t=\ttd.find(\"div\",\t\"thumbheader\").a.get(\"href\")\n",
      "isbn\t=\tre.match(\"/product/(.*)\\.do\",\tisbn_link).groups()[0]\n",
      "date\t=\ttd.find(\"span\",\t\"directorydate\").text.strip()\n",
      "return\n",
      "\t{\n",
      "\"title\"\t:\ttitle,\n",
      "\"authors\"\t:\tauthors,\n",
      "\"isbn\"\t:\tisbn,\n",
      "\"date\"\t:\tdate\n",
      "}\n",
      "agora\testamos\tprontos\tpara\textrair:\n",
      "from\tbs4\timport\n",
      "\tbeautifulsoup\n",
      "import\trequests\n",
      "from\ttime\timport\n",
      "\tsleep\n",
      "base_url\t=\t\"http://shop.oreilly.com/category/browse-subjects/\"\t+\t\\\n",
      "\t\t\t\t\"data.do?sortby=publicationdate&page=\"\n",
      "books\t=\t[]\n",
      "num_pages\t=\t31\t\t\t\n",
      "#\tna\tépoca\tda\tescrita\tdeste\tlivro,\tprovavelmente\tmais\tagora\n",
      "for\n",
      "\tpage_num\t\n",
      "in\n",
      "\trange(1,\tnum_pages\t+\t1):\n",
      "print\n",
      "\t\"souping\tpage\",\tpage_num,\t\",\",\tlen(books),\t\"\tfound\tso\tfar\"\n",
      "url\t=\tbase_url\t+\tstr(page_num)\n",
      "soup\t=\tbeautifulsoup(requests.get(url).text,\t'html5lib')\n",
      "for\n",
      "\ttd\t\n",
      "in\n",
      "\tsoup('td',\t'thumbtext'):\n",
      "if\tnot\n",
      "\tis_video(td):\n",
      "\t\t\tbooks.append(book_info(td))\n",
      "#\tagora\tseja\tum\tbom\tcidadão\te\trespeite\tos\trobots.txt!\n",
      "sleep(30)\n",
      "extrair\tdados\tde\thtml\tdesta\tforma\té\tmais\tuma\tarte\tdo\tque\tuma\tciência\tdos\tdados.\n",
      "existem\toutras\tincontáveis\tlógicas\tencontre-os-livros\te\tencontre-o-título\tque\tteriam\n",
      "funcionado\tbem\ttambém.\n",
      "agora\tque\tcoletamos\tos\tdados,\tpodemos\ttraçar\to\tnúmero\tde\tlivros\tpublicados\ta\n",
      "cada\tano\t(\n",
      "figura\t9-1\n",
      "):\n",
      "def\tget_year(book):\"\"\"book[\"date\"]\tse\tparece\tcom\t'november\t2014'\tentão\tprecisamos\n",
      "dividir\tno\tespaço\te\tentão\tpegar\to\tsegundo\tpedaço\"\"\"\n",
      "return\tint(book[\"date\"].split()[1])\n",
      "#\t2014\té\to\túltimo\tano\tcompleto\tde\tdados\t(quando\teu\tfiz\tisso)\n",
      "year_counts\t=\tcounter(get_year(book)\tfor\tbook\tin\tbooks\n",
      "\t\t\t\t\t\tif\tget_year(book)\t<=\t2014)\n",
      "import\tmatplotlib.pyplot\tas\tplt\n",
      "years\t=\tsorted(year_counts)\n",
      "book_counts\t=\t[year_counts[year]\tfor\tyear\tin\tyears]\n",
      "plt.plot(years,\tbook_counts)\n",
      "plt.ylabel(\"#\tde\tlivros\tde\tdados\")\n",
      "plt.title(\"a\tárea\tde\tdados\té\tgrande!\")\n",
      "plt.show()\n",
      "figura\t9-1.\tnúmero\tde\tlivros\tde\tdados\tpor\tano\n",
      "infelizmente,\to\taspirante\ta\tinvestidor\tolha\tpara\to\tgráfico\te\tdecide\tque\t2013\tfoi\ta\n",
      "“taxa\tmáxima\tde\tdados”.usando\tapis\n",
      "muitos\twebsites\te\tserviços\tweb\tfornecem\tinterfaces\tde\tprogramação\tde\n",
      "aplicativos\t(apis),\tpermitindo\tque\tvocê\tsolicite\tos\tdados\tem\tformato\n",
      "estruturado.\tisso\tpoupa\to\ttrabalho\tde\tter\tque\textraí-los!\n",
      "json\t(e\txml)\n",
      "como\to\thttp\té\tum\tprotocolo\tpara\ta\ttransferência\tde\t\n",
      "texto\n",
      ",\tos\tdados\tque\tvocê\n",
      "solicita\tpor\tmeio\tde\tuma\tapi\tda\tweb\tdeve\tser\t\n",
      "serializada\n",
      "\tem\tformato\tde\tstring.\n",
      "geralmente,\tessa\tserialização\tusa\to\tjavascript\tobject\tnotation\t(json).\tos\n",
      "objetos\tjavascript\tse\tparecem\tbastante\tcom\tos\t\n",
      "dict\n",
      "s\tdo\tpython,\to\tque\tfacilita\ta\n",
      "interpretação\tde\tsuas\tstrings:\n",
      "{\t\"title\"\t:\t\"data\tscience\tbook\",\n",
      "\t\t\t\"author\"\t:\t\"joel\tgrus\",\n",
      "\t\t\t\"publicationyear\"\t:\t2014,\n",
      "\t\t\t\"topics\"\t:\t[\t\"data\",\t\"science\",\t\"data\tscience\"]\t}\n",
      "podemos\tanalisar\tjson\tusando\to\tmódulo\t\n",
      "json\n",
      "\tdo\tpython.\tem\tespecial,\tusaremos\n",
      "a\tfunção\t\n",
      "load\n",
      "s,\tque\tdesserializa\tuma\tstring\trepresentando\tum\tobjeto\tjson\tem\tum\n",
      "objeto\tpython:\n",
      "import\tjson\n",
      "serialized\t=\t\"\"\"{\t\"title\"\t:\t\"data\tscience\tbook\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\"author\"\t:\t\"joel\tgrus\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\"publicationyear\"\t:\t2014,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\"topics\"\t:\t[\t\"data\",\t\"science\",\t\"data\tscience\"]\t}\"\"\"\n",
      "#\tanalisa\to\tjson\tpara\tcriar\tum\tdict\tdo\tpython\n",
      "deserialized\t=\tjson.loads(serialized)\n",
      "if\n",
      "\t\"data\tscience\"\t\n",
      "in\n",
      "\tdeserialized[\"topics\"]:\n",
      "print\n",
      "\tdeserialized\n",
      "às\tvezes,\tum\tprovedor\tapi\tte\todeia\te\tfornece\tapenas\trespostas\tem\txml:\n",
      "<book>\n",
      "\t\t\t\n",
      "<title>\n",
      "data\tscience\tbook\n",
      "</title>\n",
      "<author>\n",
      "joel\tgrus\n",
      "</author>\n",
      "<publicationyear>\n",
      "2014\n",
      "</publicationyear>\n",
      "<topics>\n",
      "\t\t\t\n",
      "<topic>\n",
      "data\n",
      "</topic>\n",
      "\t\t\t\n",
      "<topic>\n",
      "science\n",
      "</topic>\t\t\t\n",
      "<topic>\n",
      "data\tscience\n",
      "</topic>\n",
      "</topics>\n",
      "</book>\n",
      "você\tpode\tusar\t\n",
      "beautifulsoup\n",
      "\tpara\tobter\tos\tdados\tdo\txml\tda\tmesma\tforma\tcomo\n",
      "usamos\tpara\tobter\tdo\thtml;\tverifique\ta\tsua\tdocumentação\tpara\tdetalhes.\n",
      "usando\tuma\tapi\tnão\tautenticada\n",
      "a\tmaioria\tdas\tapis\tde\thoje\tem\tdia\trequer\tque\tvocê\tprimeiro\tas\tautentique\ta\tfim\n",
      "de\tpoder\tusá-las.\tenquanto\tnão\tnos\tresignamos\ta\tessa\tpolítica,\tela\tcria\tmuitos\n",
      "padrões\textras\tque\tdistorcem\ta\tnossa\texposição.\tassim,\tdaremos\tuma\tprimeira\n",
      "olhada\tna\tapi\tdo\tgithub\t(\n",
      "http://developer.github.com/v3\n",
      "/\n",
      "),\tcom\ta\tqual\tvocê\n",
      "pode\tpraticar\tcoisas\tsimples\tnão-autenticadas:\n",
      "import\trequests\n",
      ",\t\n",
      "json\n",
      "endpoint\t=\t\"https://api.github.com/users/joelgrus/repos\"\n",
      "repos\t=\tjson.loads(requests.get(endpoint).text)\n",
      "nesse\tmomento,\t\n",
      "repos\n",
      "\té\tuma\t\n",
      "list\n",
      "\tde\t\n",
      "dict\n",
      "s\tdo\tpython,\tcada\tuma\trepresentando\tum\n",
      "repositório\tpúblico\tna\tminha\tconta\tgithub.\t(sinta-se\tà\tvontade\tpara\tsubstituir\n",
      "seu\tnome\tde\tusuário\te\tpegar\tseu\trepositório\tde\tdados\tgithub.\tvocê\tpossui\tum\n",
      "conta\tgithub,\tcerto?)\n",
      "podemos\tusar\tisso\tpara\tdescobrir\tem\tquais\tmeses\te\tdias\tda\tsemana\ttenho\tmais\n",
      "tendências\tpara\tcriar\tum\trepositório.\to\túnico\tproblema\té\tque\tas\tdatas\tna\n",
      "resposta\tsão\tstrings\t(unicode):\n",
      "u'created_at':\tu'2013-07-05t02:02:28z'\n",
      "o\tpython\tnão\tvem\tcom\tum\tbom\tanalisador\tde\tdatas,\tentão\tteremos\tque\tinstalar\n",
      "um:\n",
      "pip\tinstall\tpython-dateutil\n",
      "do\tqual\tvocê\tprovavelmente\tsó\tprecisará\tda\tfunção\t\n",
      "dateutil.parser.parse\n",
      ":\n",
      "from\tdateutil.parser\timport\n",
      "\tparse\n",
      "dates\t=\t[parse(repo[\"created_at\"])\t\n",
      "for\n",
      "\trepo\t\n",
      "in\n",
      "\trepos]\n",
      "month_counts\t=\tcounter(date.month\t\n",
      "for\n",
      "\tdate\t\n",
      "in\n",
      "\tdates)\n",
      "weekday_counts\t=\tcounter(date.weekday()\t\n",
      "for\n",
      "\tdate\t\n",
      "in\n",
      "\tdates)\n",
      "da\tmesma\tforma,\tvocê\tpode\tobter\tas\tlinguagens\tdos\tmeus\tcinco\túltimos\n",
      "repositórios:last_5_repositories\t=\tsorted(repos,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tkey=\n",
      "lambda\n",
      "\tr:\tr[\"created_at\"],\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\treverse=true)[:5]\n",
      "last_5_languages\t=\t[repo[\"language\"]\n",
      "\t\t\t\t\n",
      "for\n",
      "\trepo\t\n",
      "in\n",
      "\tlast_5_repositories]\n",
      "basicamente,\tnão\ttrabalharemos\tcom\tapis\tnesse\tnível\tbaixo\tde\t“faça\tos\tpedidos\n",
      "e\tanalise\tas\trespostas\tvocê\tmesmo”.\tum\tdos\tbenefícios\tde\tse\tusar\tpython\té\tque\n",
      "alguém\tjá\tconstruiu\tuma\tbiblioteca\tpara\tquase\tqualquer\tapi\tque\tvocê\testeja\n",
      "interessado\tem\tacessar.\tquando\telas\tsão\tbem-feitas,\telas\tpodem\tte\tpoupar\tde\n",
      "muitos\tproblemas\tao\ttentar\tentender\tos\tdetalhes\tmais\tcabeludos\tdo\tacesso\tapi.\n",
      "(quando\telas\tnão\tsão\tbem-feitas,\tou\tquando\tsão\tbaseadas\tem\tversões\textintas\n",
      "das\tapis\tcorrespondentes,\telas\tpodem\tdar\tenormes\tdores\tde\tcabeça.)\n",
      "apesar\tdisso,\tvocê\ttalvez\ttenha\tque\timplantar\tseu\tpróprio\tacesso\tà\tbiblioteca\n",
      "api\t(ou,\tmais\tprovável,\tdepurar\tporque\ta\tde\talguém\tnão\testá\tfuncionando),\n",
      "portanto,\té\tbom\tsaber\tde\talguns\tdetalhes.\n",
      "encontrando\tapis\n",
      "se\tvocê\tprecisa\tde\tdados\tde\tum\tsite\tespecífico,\tprocure\tpor\tdesenvolvedores\tou\n",
      "a\tseção\tde\tapi\tdo\tsite\tpara\tdetalhes,\te\ttente\tprocurar\tna\tweb\tpor\t“python__api”\n",
      "para\tencontrar\tuma\tbiblioteca.\texiste\tuma\tapi\trotten\ttomatoes\tpara\tpython.\n",
      "existem\tmúltiplas\tcamadas\t(wrappers)\tpara\ta\tapi\tklout,\tpara\ta\tapi\tyelp,\tpara\ta\n",
      "api\timdb,\te\tassim\tpor\tdiante.\n",
      "se\tvocê\testá\tprocurando\tpor\tlistas\tde\tapis\tque\ttenham\tas\tcamadas\tpython,\tdois\n",
      "diretórios\testão\tem\tpython\tapi\t(\n",
      "http://www.pythonapi.com\n",
      ")\te\tpython\tfor\n",
      "beginners\t(\n",
      "http://bit.ly/1l35vor\n",
      ").\n",
      "se\tvocê\tquer\tum\tdiretório\tde\tapis\tweb\tmais\tabrangente\t(sem\tnecessariamente\n",
      "as\tcamadas\tpython),\tum\tbom\trecurso\té\to\tprogrammable\tweb\n",
      "(\n",
      "http://www.programmableweb.com\n",
      "),\to\tqual\tpossui\tum\tenorme\tdiretório\tde\tapis\n",
      "categorizados.\n",
      "e\tse\tdepois\tde\ttudo\tisso\tvocê\tnão\tencontrar\to\tque\tprecisa,\thá\tsempre\ta\topção\tde\n",
      "extração,\to\túltimo\trefúgio\tde\tum\tcientista\tde\tdados.1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "5.\n",
      "6.\n",
      "7.\n",
      "8.\n",
      "exemplo:\tusando\tas\tapis\tdo\ttwitter\n",
      "o\ttwitter\té\tum\tfonte\tfantástica\tde\tdados\tcom\to\tqual\ttrabalhar.\tvocê\tpode\tusá-lo\n",
      "para\tver\tas\tnotícias\tem\ttempo\treal.\tvocê\tpode\tusá-lo\tpara\tmedir\tas\treações\taos\n",
      "eventos\tatuais.\tvocê\tpode\tusá-lo\tpara\tencontrar\tlinks\trelacionados\ta\ttópicos\n",
      "específicos.\tvocê\tpode\tusá-lo\tpara\tpraticamente\ttudo\tque\tvocê\tpossa\timaginar,\n",
      "contanto\tque\tvocê\tconsiga\tacesso\taos\tseus\tdados.\te\tvocê\tpode\tter\tesse\tacesso\n",
      "por\tmeio\tdas\tapis.\n",
      "para\tinteragir\tcom\tas\tapis\tdo\ttwitter,\tusaremos\ta\tbiblioteca\ttwython\tem\n",
      "https://github.com/ryanmcgrath/twython\n",
      ",\t(\n",
      "pip\tinstall\ttwython\n",
      ").\texistem\talgumas\n",
      "bibliotecas\tpython\tpara\to\ttwitter\tpor\taí,\tmas\tfoi\tcom\tessa\tque\teu\tobtive\tmais\n",
      "sucesso.\tsinta-se\tencorajado\ta\texplorar\tas\toutras\ttambém!\n",
      "obtendo\tcredenciais\n",
      "para\tusar\tas\tapis\tdo\ttwitter,\tvocê\tdeve\tter\talgumas\tcredenciais\t(logo,\tvocê\n",
      "precisa\tde\tuma\tconta\tno\ttwitter,\te\tdeveria\tter\tde\tqualquer\tforma\tpara\tfazer\tparte\n",
      "da\tviva\te\tamigável\tcomunidade\t\n",
      "#datascience\n",
      "\tno\ttwitter).\tcomo\ttodas\tas\tinstruções\n",
      "que\tse\trelacionam\tcom\tos\twebsites\tque\teu\tnão\tcontrolo,\ttalvez\tisto\tse\ttorne\n",
      "obsoleto\tem\talgum\tmomento,\tmas\tespero\tque\tfuncione\tpor\tum\ttempo.\t(apesar\n",
      "de\teles\tjá\tterem\tmudado\tpelo\tmenos\tuma\tvez\tenquanto\teu\testava\tescrevendo\n",
      "este\tlivro,\tentão\tboa\tsorte!)\n",
      "vá\tpara\t\n",
      "https://apps.twitter.com\n",
      "/\n",
      ".\n",
      "se\tvocê\tnão\testiver\tlogado,\tclique\tem\tentrar\te\tinsira\tseu\tnome\tde\tusuário\te\n",
      "senha\tdo\ttwitter.\n",
      "clique\tem\tcriar\tum\tnovo\taplicativo.\n",
      "dê\ta\tele\tum\tnome\t(como\t“data\tscience”)\te\tuma\tdescrição,\te\tcoloque\n",
      "qualquer\turl\tcomo\twebsite\t(não\timporta\tqual).\tdeixe\ta\turl\tde\tretorno\n",
      "em\tbranco.\n",
      "concorde\tcom\tos\ttermos\tde\tserviço\te\tclique\tem\tcriar.\n",
      "anote\ta\tchave\te\to\tsegredo\tdo\tconsumidor.\n",
      "clique\tem\t“criar\tmeu\ttoken\tde\tacesso”.\n",
      "anote\to\ttoken\tde\tacesso\te\to\tde\tsegredo\t(talvez\tvocê\ttenha\tque\tatualizar\tapágina).\n",
      "a\tchave\te\to\tsegredo\tdo\tconsumidor\tdizem\tao\ttwitter\tqual\taplicação\testá\n",
      "acessando\tsuas\tapis,\tenquanto\tque\to\ttoken\tde\tacesso\te\to\ttoken\tde\tacesso\tdo\n",
      "segredo\tdizem\tao\ttwitter\t\n",
      "quem\n",
      "\testá\tacessando\tsuas\tapis.\tse\tvocê\tjá\tusou\tsua\n",
      "conta\tdo\ttwitter\tpara\tentrar\tem\toutro\tsite,\t\n",
      "a\tpágina\t“clique\tpara\tautorizar”\n",
      "estava\tgerando\tum\ttoken\tde\tacesso\tpara\taquele\tsite\tusar\ta\tfim\tde\tconvencer\to\n",
      "twitter\tque\tfoi\tvocê\t(ou,\tao\tmenos,\tagindo\tcomo\tse\tfosse\tvocê).\tcomo\tnão\n",
      "precisamos\tda\tfuncionalidade\t“deixar\tqualquer\tum\tentrar”,\tpodemos\tsobreviver\n",
      "com\to\ttoken\tde\tacesso\te\to\ttoken\tde\tacesso\tdo\tsegredo\tgerados.\n",
      "a\tchave/segredo\tdo\tconsumidor\te\ta\tchave/segredo\tdo\ttoken\tde\tacesso\tdevem\n",
      "ser\ttratadas\tcomo\t\n",
      "senhas\n",
      ".\tvocê\tnão\tdeve\tcompartilhá-las,\tpublicá-las\tem\tseu\n",
      "livro\tou\tacessá-las\tno\trepositório\tpúblico\tgithub.\tuma\tsolução\tsimples\té\n",
      "armazená-las\tem\tum\tarquivo\t\n",
      "credentials.json\n",
      "\tque\tnão\té\tacessado\te\tusar\tseu\n",
      "código\t\n",
      "json.loads\n",
      "\tpara\trecuperá-la.\n",
      "usando\ttwython\n",
      "primeiro\t observaremos\t o\t search\t api\n",
      "(\n",
      "https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "),\to\tqual\trequer\tapenas\ta\n",
      "chave\te\to\tsegredo\tdo\tconsumidor\te\tnão\to\ttoken\tde\tacesso\tou\tsegredo:\n",
      "from\ttwython\timport\n",
      "\ttwython\n",
      "twitter\t=\ttwython(consumer_key,\tconsumer_secret)\n",
      "#\tsearch\tfor\ttweets\tcontaining\tthe\tphrase\t\"data\tscience\"\n",
      "for\n",
      "\tstatus\t\n",
      "in\n",
      "\ttwitter.search(q='\"data\tscience\"')[\"statuses\"]:\n",
      "user\t=\tstatus[\"user\"][\"screen_name\"].encode('utf-8')\n",
      "text\t=\tstatus[\"text\"].encode('utf-8')\n",
      "print\n",
      "\tuser,\t\":\",\ttext\n",
      "print\n",
      "o\t\n",
      ".encode(\"utf-8\")\n",
      "\té\tnecessário\tpara\tlidar\tcom\to\tfato\tde\tque\tos\ttweets\tgeralmente\n",
      "contêm\tcaracteres\tunicode\tcom\tos\tquais\t\n",
      "print\n",
      "\tnão\tpode\tlidar.\t(se\tvocê\tdeixar\tde\n",
      "lado,\tvocê\tdeve\treceber\tum\t\n",
      "unicodeencodeerror\n",
      ".)\n",
      "é\tquase\tcerto\tque\tem\talgum\tmomento\tde\tsua\tcarreira\tde\tdata\tscience\tvocê\tvai\tse\n",
      "deparar\tcom\tsérios\tproblemas\tunicode\te,\tem\talgum\tmomento,\tvocê\tprecisará\tse\n",
      "referir\tà\tdocumentação\tpython\t(\n",
      "http://bit.ly/1ycodjw\n",
      ")\tou\trelutantemente\tcomeçar\ta\n",
      "usar\tpython\t3,\to\tqual\tlida\tmuito\tmelhor\tcom\ttexto\tunicode.\n",
      "se\tvocê\texecutar\tisso,\tvocê\tdeverá\treceber\ttweets\tcomo:haithemnyc:\tdata\tscientists\twith\tthe\ttechnical\tsavvy\t&\tanalytical\tchops\tto\n",
      "derive\tmeaning\tfrom\tbig\tdata\tare\tin\tdemand.\thttp://t.co/hsf9q0dshp\n",
      "rpubsrecent:\tdata\tscience\thttp://t.co/6hchuz2phm\n",
      "spleonard1:\tusing\t#dplyr\tin\t#r\tto\twork\tthrough\ta\tprocrastinated\tassignment\tfor\n",
      "@rdpeng\tin\t@coursera\tdata\tscience\tspecialization.\tso\teasy\tand\tawesome.\n",
      "isso\tnão\té\tmuito\tinteressante,\tprincipalmente\tporque\to\tsearch\tapi\tdo\ttwitter\n",
      "apenas\tmostra\ta\tparte\tdos\tresultados\tque\tele\tquer.\tquando\tvocê\testá\tpraticando\n",
      "data\tscience,\tvocê\tvai\tquerer\tcada\tvez\tmais\ttweets.\té\taí\tque\to\tstreaming\tapi\n",
      "(\n",
      "http://bit.ly/1ycoegg\n",
      ")\té\tútil.\tele\tpermite\tque\tvocê\tse\tconecte\tà\t(uma\tamostra\n",
      "de)\tavalanche\ttwitter.\tpara\tusá-lo,\tvocê\tprecisará\tse\tidentificar\tusando\tseus\n",
      "tokens\tde\tacesso.\n",
      "a\tfim\tde\tacessar\to\tstreaming\tapi\tcom\ttwython,\tprecisamos\tdefinir\tuma\tclasse\n",
      "que\therde\t\n",
      "twythonstreamer\n",
      "\te\tque\tanule\to\tmétodo\t\n",
      "on_success\n",
      "\t(e\tpossivelmente\tseu\n",
      "método\t\n",
      "on_error\n",
      "):\n",
      "from\ttwython\timport\ttwythonstreamer\n",
      "#\tanexar\tdados\tà\tvariável\tglobal\té\tbem\tpobre\n",
      "#\tmas\tsimplifica\to\texemplo\n",
      "tweets\t=\t[]\n",
      "class\tmystreamer(twythonstreamer):\n",
      "\"\"\"nossa\tprópria\tsubclasse\tde\ttwythonstreamer\tque\tespecifica\n",
      "como\tinteragir\tcom\to\tstream\"\"\"\n",
      "def\ton_success(self,\tdata):\n",
      "\"\"\"o\tque\tfazemos\tquando\to\ttwitter\tnos\tenvia\tdados?\n",
      "aqui\tos\tdados\tserão\tum\tdict\tde\tpython\trepresentando\tum\ttweet\"\"\"\n",
      "#\tquer\tcoletar\tapenas\ttweets\tda\tlíngua\tinglesa\n",
      "if\tdata['lang']\t==\t'en':\n",
      "\t\t\ttweets.append(data)\n",
      "\t\t\tprint\t\"received\ttweet\t#\",\tlen(tweets)\n",
      "#\tpara\tquando\tcoleta\to\tsuficiente\n",
      "if\tlen(tweets)\t>=\t1000:\n",
      "\t\t\tself.disconnect()\n",
      "def\ton_error(self,\tstatus_code,\tdata):\n",
      "print\tstatus_code,\tdata\n",
      "self.disconnect()\n",
      "mystreamer\tvai\tse\tconectar\to\tstream\tdo\ttwitter\te\tesperar\tque\to\ttwitter\to\n",
      "abasteça\tde\tdados.\ttoda\tvez\tque\tele\treceber\tdados\t(aqui,\tum\ttweet\té\n",
      "representado\tpor\tum\tobjeto\tde\tpython),\tele\tpassa\tpara\to\tmétodo\t\n",
      "on_success\n",
      ",\tque\toanexa\tà\tnossa\tlista\tde\t\n",
      "tweets\n",
      "\tse\tsua\tlíngua\tfor\tinglesa,\te\tentão\tdesconecta\to\n",
      "streamer\tapós\tter\tcoletado\t1000\ttweets.\n",
      "tudo\to\tque\tresta\tpara\tinicializá-lo\te\tfazê-lo\tfuncionar:\n",
      "stream\t=\tmystreamer(consumer_key,\tconsumer_secret,\n",
      "\t\t\t\taccess_token,\taccess_token_secret)\n",
      "#\tcomeça\ta\tconsumir\tstatus\tpúblicos\tque\tcontenham\ta\tpalavra-chave\t'data'\n",
      "stream.statuses.filter(track='data')\n",
      "#\tse\tquiséssemos\tcomeçar\ta\tconsumir\tuma\tamostra\tde\t*all*\tstatus\tpúblicos\n",
      "#\tstream.statuses.sample()\n",
      "ele\texecutará\taté\tcoletar\t1000\ttweets\t(ou\taté\tencontrar\tum\terro)\te\tirá\tparar\te\té\n",
      "nesse\tmomento\tque\tvocê\tpode\tcomeçar\ta\tinicializar\ttais\ttweets.\tpor\texemplo,\n",
      "você\tpoderia\tencontrar\tas\thashtags\tmais\tfamosas\tcom:\n",
      "top_hashtags\t=\tcounter(hashtag['text'].lower()\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\ttweet\t\n",
      "in\n",
      "\ttweets\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\thashtag\t\n",
      "in\n",
      "\ttweet[\"entities\"][\"hashtags\"])\n",
      "print\n",
      "\ttop_hashtags.most_common(5)\n",
      "cada\ttweet\tcontém\tmuitos\tdados.\tvocê\tpode\tpassear\tou\tmergulhar\tfundo\tna\n",
      "documentação\tapi\tdo\ttwitter\t(\n",
      "https://dev.twitter.com/overview/api/tweets\n",
      ").\n",
      "em\tum\tprojeto\tque\tnão\tseja\tde\tbrincadeira,\tvocê\tnão\tgostaria\tde\tdepender\tde\tuma\n",
      "list\n",
      "\tin-memory\tpara\tarmazenar\tseus\ttweets.\tem\tvez\tdisso,\tvocê\tos\tsalvaria\tem\tum\n",
      "arquivo\tou\tbanco\tde\tdados,\tpara\tque\tvocê\tpossa\ttê-los\tpermanentemente.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "pandas\t(\n",
      "http://pandas.pydata.org\n",
      "/\n",
      ")\té\ta\tbiblioteca\tprimária\tcom\ta\tqual\tos\n",
      "tipos\tde\tdata\tscience\tusam\tpara\ttrabalhar\t(e,\tem\tespecial,\timportar)\tdados.\n",
      "scrapy\t(\n",
      "http://scrapy.org\n",
      "/\n",
      ")\té\tuma\tbiblioteca\tcheia\tde\trecursos\tpara\n",
      "construir\textratores\tda\tweb\tmais\tcomplicados,\tque\tfazem\tcoisas\tcomo\n",
      "seguir\tlinks\tdesconhecidos.capítulo\t10\n",
      "trabalhando\tcom\tdados\n",
      "os\tespecialistas,\tmuitas\tvezes,\tpossuem\tmais\tdados\tdo\tque\tjuízo\n",
      ".\n",
      "—colin\tpowell\n",
      "trabalhar\tcom\tdados\té\tuma\tarte\te\tuma\tciência.\ttemos\tdiscutido\tmais\tsobre\ta\n",
      "parte\tcientífica,\tmas\tneste\tcapítulo\tconsideraremos\tum\tpouco\tde\tarte.explorando\tseus\tdados\n",
      "após\tidentificar\tas\tquestões\tque\tvocê\ttem\ttentado\tresponder\te\tter\tposto\tas\tmãos\n",
      "em\talguns\tdados,\tvocê\tpode\tficar\ttentado\ta\tir\tmais\tfundo,\tcomeçar\ta\tconstruir\n",
      "modelos\te\tobter\trespostas.\tmas\tvocê\tdeveria\tresistir\ta\tesse\timpulso.\tseu\n",
      "primeiro\tpasso\tdeveria\tser\t\n",
      "explorar\n",
      "\tseus\tdados.\n",
      "explorando\tdados\tunidimensionais\n",
      "o\tcaso\tmais\tsimples\té\tquando\tvocê\ttem\tum\tconjunto\tde\tdados\tunidimensional,\n",
      "apenas\tuma\tcoleção\tde\tnúmeros.\tpor\texemplo,\teles\tpoderiam\tser\ta\tmedia\tdiária\n",
      "de\tminutos\tque\tcada\tusuário\tpassa\tno\tseu\tsite,\to\tnúmero\tde\tvezes\tque\tcada\n",
      "coleção\tde\tvídeos\ttutoriais\tde\tdata\tscience\tfoi\tvista\tou\to\tnúmero\tde\tpáginas\tde\n",
      "cada\tlivro\tde\tdata\tscience\tna\tsua\tbiblioteca.\n",
      "um\tprimeiro\tpasso\tinevitável\té\tcomputar\talgumas\testatísticas\tsumárias.\tvocê\n",
      "gostaria\tde\tsaber\tquantos\tpontos\tde\tdados\tvocê\ttem,\to\tmenor,\to\tmaior,\ta\tmédia\te\n",
      "o\tdesvio\tpadrão.\n",
      "mas\tnem\tisso\ttudo\tfornece,\tnecessariamente,\tum\tbom\tentendimento.\tum\n",
      "próximo\tpasso\tadequado\té\tcriar\tum\thistograma\tpara\tagrupar\tseus\tdados\tem\n",
      "agrupamentos\t(\n",
      "buckets\n",
      ")\tdiscretos\te\tcontar\tquantos\tpontos\tvão\tpara\tcada\tum:\n",
      "def\tbucketize(point,\tbucket_size):\n",
      "\"\"\"reduza\to\tponto\tpara\to\tpróximo\tmúltiplo\tmais\tbaixo\tde\tbucket_size\"\"\"\n",
      "return\tbucket_size\t*\tmath.floor(point\t/\tbucket_size)\n",
      "def\tmake_histogram(points,\tbucket_size):\n",
      "\"\"\"agrupa\tos\tpontos\te\tconta\tquantos\tem\tcada\tbucket\"\"\"\n",
      "return\tcounter(bucketize(point,\tbucket_size)\tfor\tpoint\tin\tpoints)\n",
      "def\tplot_histogram(points,\tbucket_size,\ttitle=\"\"):\n",
      "histogram\t=\tmake_histogram(points,\tbucket_size)\n",
      "plt.bar(histogram.keys(),\thistogram.values(),\twidth=bucket_size)\n",
      "plt.title(title)\n",
      "plt.show()\n",
      "por\texemplo,\tconsidere\tos\tseguintes\tconjuntos\tde\tdados:\n",
      "random.seed(0)\n",
      "#\tuniforme\tentre\t–100\te\t100\n",
      "uniform\t=\t[200\t*\trandom.random()\t-\t100\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(10000)]#\tdistribuição\tnormal\tcom\tmédia\t0,\tdesvio\tpadrão\t57\n",
      "normal\t=\t[57\t*\tinverse_normal_cdf(random.random())\n",
      "\t\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(10000)]\n",
      "ambos\tpossuem\tmédias\tpróximas\ta\t0\te\tdesvios\tpadrões\tpróximos\ta\t58.\tno\n",
      "entanto,\tpossuem\tdistribuições\tbem\tdiferentes.\ta\t\n",
      "figura\t10-1\n",
      "\tmostra\ta\n",
      "distribuição\tde\t\n",
      "uniform\n",
      ":\n",
      "plot_histogram(uniform,\t10,\t\"histograma\tde\tuniform\")\n",
      "já\ta\t\n",
      "figura\t10-2\n",
      "\tmostra\ta\tdistribuição\tde\t\n",
      "normal\n",
      ":\n",
      "plot_histogram(normal,\t10,\t\"histograma\tnormal\")\n",
      "nesse\tcaso,\tas\tduas\tdistribuições\tpossuem\t\n",
      "max\n",
      "\te\t\n",
      "min\n",
      "\tmuito\tdiferentes,\tmas\n",
      "mesmo\tsabendo\tisso\tnão\tseria\tsuficiente\tpara\tentender\t\n",
      "como\n",
      "\telas\tdiferem.\n",
      "figura\t10-1.\thistograma\tde\tuniformduas\tdimensões\n",
      "agora\timagine\tque\tvocê\ttenha\tum\tconjunto\tde\tdados\tcom\tduas\tdimensões.\n",
      "talvez,\talém\tde\tminutos\tdiários,\tvocê\ttambém\ttenha\tanos\tde\texperiência\tem\n",
      "data\tscience.\tcertamente,\tvocê\tgostaria\tde\tentender\tcada\tdimensão\n",
      "individualmente.\tmas\tvocê\ttambém\tdeve\tquerer\tdispersar\tos\tdados.\n",
      "por\texemplo,\tconsidere\toutro\tconjunto\tde\tdados\tfalso:\n",
      "def\n",
      "\trandom_normal():\n",
      "\"\"\"retorna\tum\tdesenho\taleatório\tde\tuma\tdistribuição\tnormal\tpadrão\"\"\"\n",
      "return\n",
      "\tinverse_normal_cdf(random.random())\n",
      "xs\t=\t[random_normal()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(1000)]\n",
      "ys1\t=\t[\tx\t+\trandom_normal()\t/\t2\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\txs]\n",
      "ys2\t=\t[-x\t+\trandom_normal()\t/\t2\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\txs]\n",
      "se\tvocê\tfosse\texecutar\tplot_histogram\tem\tys1\te\tys2,\tvocê\tteria\tgráficos\tmuito\n",
      "parecidos\t(aliás,\tambos\tsão\tdistribuídos\tnormalmente\tcom\ta\tmesma\tmédia\te\n",
      "desvio\tpadrão).\n",
      "figura\t10-2.\thistograma\tde\tnormal\n",
      "mas\tcada\tum\tteria\tdistribuições\tconjuntas\tdiferentes\tcom\txs,\tcomo\tmostra\ta\n",
      "figura\t10-3\n",
      ":\n",
      "plt.scatter(xs,\tys1,\tmarker='.',\tcolor='black',\tlabel='ys1')\n",
      "plt.scatter(xs,\tys2,\tmarker='.',\tcolor='gray',\tlabel='ys2')\n",
      "plt.xlabel('xs')\n",
      "plt.ylabel('ys')\n",
      "plt.legend(loc=9)\n",
      "plt.title(\"distribuições\tconjuntas\tmuito\tdiferentes\")\n",
      "plt.show()\n",
      "figura\t10-3.\tdispersão\tde\tdois\tys\tdiferentes\n",
      "essa\tdiferença\ttambém\tseria\taparente\tse\tvocê\tobservasse\tas\tcorrelações:\n",
      "print\n",
      "\tcorrelation(xs,\tys1)\t\t\t\t\t\t\n",
      "#\t\t0.9\n",
      "print\n",
      "\tcorrelation(xs,\tys2)\t\t\t\t\t\t\n",
      "#\t-0.9muitas\tdimensões\n",
      "com\tmuitas\tdimensões,\tvocê\tgostaria\tde\tsaber\tcomo\ttodas\tas\tdimensões\tse\n",
      "relacionam\tumas\tcom\tas\toutras.\tuma\tabordagem\tsimples\té\tobservar\ta\t\n",
      "matriz\n",
      "correlacional\n",
      "\t(\n",
      "correlation\tmatrix\n",
      "),\tna\tqual\ta\tentrada\tna\tlinha\t\n",
      "i\n",
      "\te\tna\tcoluna\t\n",
      "j\n",
      "\té\ta\n",
      "correlação\tentre\tas\tdimensões\ti-ésima\te\tj-ésima\tdos\tdados:\n",
      "def\tcorrelation_matrix(data):\n",
      "\"\"\"retorna\to\tnum_columns\tx\tnum_columns\tmatrix\tcuja\tentrada\t(i,\tj)-ésima\n",
      "é\ta\tcorrelação\tentre\tas\tcolunas\tde\tdados\ti\te\tj\"\"\"\n",
      "_,\tnum_columns\t=\tshape(data)\n",
      "def\tmatrix_entry(i,\tj):\n",
      "return\tcorrelation(get_column(data,\ti),\tget_column(data,\tj))\n",
      "return\tmake_matrix(num_columns,\tnum_columns,\tmatrix_entry)\n",
      "uma\tabordagem\tmais\tvisual\t(se\tvocê\tnão\ttiver\tmuitas\tdimensões)\té\tfazer\tuma\n",
      "matriz\tde\tgráfico\tde\tdispersão\n",
      "\t(\n",
      "scatterplot\tmatrix\n",
      "\t—\t\n",
      "figura\t10-4\n",
      ")\tmostrando\n",
      "todos\tos\tpareamentos\tdos\tgráficos\tde\tdispersão.\tpara\tfazer\tisso,\tusaremos\n",
      "plt.subplots()\n",
      ",\tque\tpermite\tque\tcriemos\tuma\tsubparcela\tdo\tnosso\tgráfico.\tnós\n",
      "fornecemos\to\tnúmero\tde\tlinhas\te\tcolunas,\te\tele\tretorna\tum\tobjeto\t\n",
      "figure\n",
      "\t(que\tnão\n",
      "usaremos)\te\tum\tarray\tbidimensional\tde\tobjetos\t\n",
      "axes\n",
      "\t(cada\tqual\tcom\tseu\tgráfico):\n",
      "import\tmatplotlib.pyplot\tas\tplt\n",
      "_,\tnum_columns\t=\tshape(data)\n",
      "fig,\tax\t=\tplt.subplots(num_columns,\tnum_columns)\n",
      "for\ti\tin\trange(num_columns):\n",
      "for\tj\tin\trange(num_columns):\n",
      "#\tdispersa\ta\tcolumn_j\tno\teixo\tx\tversus\tcolumn_i\tno\teixo\ty\n",
      "if\ti\t!=\tj:\tax[i][j].scatter(get_column(data,\tj),\tget_column(data,\ti))\n",
      "#\ta\tmenos\tque\ti\t==j,\tem\tcujo\tcaso\tmostra\to\tnome\tda\tsérie\n",
      "else:\tax[i][j].annotate(\"série\"\t+\tstr(i),\t(0.5,\t0.5),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\txycoords='axes\tfraction',\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tha=\"center\",\tva=\"center\")\n",
      "#\tentão\tesconde\tas\tetiquetas\tdos\teixos\texceto\n",
      "#\tos\tgráficos\tinferiores\te\tda\tesquerda\n",
      "if\ti\t<\tnum_columns\t-\t1:\tax[i][j].xaxis.set_visible(false)\n",
      "if\tj\t>\t0:\tax[i][j].yaxis.set_visible(false)\n",
      "#\tconserta\tas\tetiquetas\tinferiores\tà\tdireita\te\tsuperiores\tà\tesquerda\tdos\teixos\n",
      ",\n",
      "#\tque\testá\terrado\tpois\tseus\tgráficos\tsomente\tpossuem\ttextos\n",
      "ax[-1][-1].set_xlim(ax[0][-1].get_xlim())ax[0][0].set_ylim(ax[0][1].get_ylim())\n",
      "plt.show()\n",
      "figura\t10-4.\tmatriz\tde\tgráfico\tde\tdispersão\n",
      "ao\tobservar\tos\tgráficos\tde\tdispersão,\tvocê\tpode\tver\tque\ta\tsérie\t1\té\tmuito\n",
      "negativamente\tcorrelacionada\tcom\ta\tsérie\t0,\ta\tsérie\t2\té\tpositivamente\n",
      "correlacionada\tcom\ta\tsérie\t1\te\ta\tsérie\t3\tsomente\taceita\tos\tvalores\t0\te\t6,\tcom\t0\n",
      "correspondendo\taos\tvalores\tmenores\tda\tsérie\t2\te\t6\tcorrespondendo\taos\tmaiores.\n",
      "essa\té\tuma\tmaneira\trápida\tde\tter\tuma\tideia\tde\tcomo\tas\tsuas\tvariáveis\tsão\n",
      "correlacionadas\t(a\tmenos\tque\tvocê\tpasse\thoras\tajustando\t\n",
      "matplotlib\n",
      "\tpara\texibir\tas\n",
      "coisas\texatamente\tdo\tjeito\tque\tvocê\tquer\te,\tnesse\tcaso,\tnão\té\tmuito\trápido).limpando\te\ttransformando\n",
      "os\tdados\tdo\tmundo\treal\tsão\t\n",
      "sujos\n",
      ".\tmuitas\tvezes,\tvocê\tterá\tque\ttrabalhar\tneles\n",
      "antes\tde\tusá-los.\tvimos\talguns\texemplos\tdisso\tno\t\n",
      "capítulo\t9\n",
      ".\ttemos\tque\n",
      "converter\tstrings\tpara\t\n",
      "float\n",
      "s\tou\t\n",
      "int\n",
      "s\tantes\tde\tusá-las.\tanteriormente,\tfizemos\tisso\n",
      "um\tpouco\tantes\tde\tusarmos\tos\tdados:\n",
      "closing_price\t=\tfloat(row[2])\n",
      "mas\té\tmenos\tpropício\tao\terro\tfazer\ta\tanálise\tno\tfluxo\tde\tentrada,\to\tque\tpodemos\n",
      "fazer\tao\tcriar\tuma\tfunção\tque\tenvolva\t\n",
      "csv.reader\n",
      ".\tforneceremos\tuma\tlista\tde\n",
      "interpretadores\ta\tele,\tcada\tum\tespecificando\tcomo\tanalisar\tuma\tdas\tcolunas.\n",
      "usaremos\t\n",
      "none\n",
      "\tpara\trepresentar\t“não\tfaça\tnada\tcom\testa\tcoluna”:\n",
      "def\n",
      "\tparse_row(input_row,\tparsers):\n",
      "\"\"\"dada\tuma\tlista\tde\tinterpretadores\t(alguns\tpodem\tser\tnone)\n",
      "aplique\to\tapropriado\ta\tcada\telemento\tde\tinput_row\"\"\"\n",
      "return\n",
      "\t[parser(value)\t\n",
      "if\n",
      "\tparser\t\n",
      "is\tnot\n",
      "\tnone\t\n",
      "else\n",
      "\tvalue\n",
      "for\n",
      "\tvalue,\tparser\t\n",
      "in\n",
      "\tzip(input_row,\tparsers)]\n",
      "def\n",
      "\tparse_rows_with(reader,\tparsers):\n",
      "\"\"\"envolve\tum\treader\tpara\taplicar\tos\tinterpretadores\tem\n",
      "cada\tuma\tde\tsuas\tlinhas\"\"\"\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\treader:\n",
      "yield\n",
      "\tparse_row(row,\tparsers)\n",
      "e\tse\ttiver\talgum\tdado\truim?\tum\tvalor\t“float”\tque\tnão\trepresente\tum\tnúmero?\n",
      "preferiríamos\treceber\tum\t\n",
      "none\n",
      "\tdo\tque\ttravar\tnosso\tprograma.\tpodemos\tfazer\tisso\n",
      "com\tuma\tfunção\tauxiliadora:\n",
      "def\n",
      "\ttry_or_none(f):\n",
      "\"\"\"envolve\tf\tpara\tretornar\tnone\tse\tf\tlevantar\tuma\texceção\n",
      "presume\tque\tf\tleve\tapenas\tuma\tentrada\"\"\"\n",
      "def\n",
      "\tf_or_none(x):\n",
      "try\n",
      ":\t\n",
      "return\n",
      "\tf(x)\n",
      "except\n",
      ":\t\n",
      "return\n",
      "\tnone\n",
      "return\n",
      "\tf_or_none\n",
      "depois\tdisso\tpodemos\treescrever\t\n",
      "parse_row\n",
      "\tpara\tusá-lo:\n",
      "def\n",
      "\tparse_row(input_row,\tparsers):\n",
      "return\n",
      "\t[try_or_none(parser)(value)\t\n",
      "if\n",
      "\tparser\t\n",
      "is\tnot\n",
      "\tnone\t\n",
      "else\n",
      "\tvalue\t\t\t\n",
      "for\n",
      "\tvalue,\tparser\t\n",
      "in\n",
      "\tzip(input_row,\tparsers)]\n",
      "por\texemplo,\tse\ttivermos\tos\tpreços\tdas\tações\tseparados\tpor\tvírgulas\tcom\tdados\n",
      "ruins:\n",
      "6/20/2014,aapl,90.91\n",
      "6/20/2014,msft,41.68\n",
      "6/20/3014,fb,64.5\n",
      "6/19/2014,aapl,91.86\n",
      "6/19/2014,msft,n/a\n",
      "6/19/2014,fb,64.34\n",
      "podemos\tler\te\tanalisar\tem\tum\túnico\tpasso\tagora:\n",
      "import\tdateutil.parser\n",
      "data\t=\t[]\n",
      "with\n",
      "\topen(\"comma_delimited_stock_prices.csv\",\t\"rb\")\t\n",
      "as\n",
      "\tf:\n",
      "reader\t=\tcsv.reader(f)\n",
      "for\n",
      "\tline\t\n",
      "in\n",
      "\tparse_rows_with(reader,\t[dateutil.parser.parse,\tnone,\tfloat]):\n",
      "data.append(line)\n",
      "depois\tdisso\tsomente\tprecisamos\tchecar\tpor\tlinhas\t\n",
      "none\n",
      ":\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata:\n",
      "if\n",
      "\tany(x\t\n",
      "is\n",
      "\tnone\t\n",
      "for\n",
      "\tx\t\n",
      "in\n",
      "\trow):\n",
      "print\n",
      "\trow\n",
      "e\tdecidir\to\tque\tqueremos\tfazer\tcom\teles.\t(de\tmodo\tgeral,\tas\ttrês\topções\tsão\n",
      "jogá-los\tfora,\tvoltar\tpara\ta\tfonte\te\ttentar\tconsertar\to\tdado\truim/faltoso,\tou\tnão\n",
      "fazer\tnada\te\tcruzar\tos\tdedos.)\n",
      "poderíamos\tcriar\tauxiliadores\tsemelhantes\tpara\t\n",
      "csv.dictreader\n",
      ".\tnesse\tcaso,\tvocê\n",
      "apenas\tteria\tque\tfornecer\tum\t\n",
      "dict\n",
      "\tde\tanalisadores\tpor\tmeio\tde\tum\tnome\tde\n",
      "campo.\tpor\texemplo:\n",
      "def\n",
      "\ttry_parse_field(field_name,\tvalue,\tparser_dict):\n",
      "\"\"\"tenta\tanalisar\to\tvalor\tusando\ta\tfunção\tadequada\ta\tpartir\tde\tparser_dict\"\"\"\n",
      "parser\t=\tparser_dict.get(field_name)\t\n",
      "#\tnone\tse\tnão\ttiver\ttal\tentrada\n",
      "if\n",
      "\tparser\t\n",
      "is\tnot\n",
      "\tnone:\n",
      "return\n",
      "\ttry_or_none(parser)(value)\n",
      "else\n",
      ":\n",
      "return\n",
      "\tvalue\n",
      "def\n",
      "\tparse_dict(input_dict,\tparser_dict):\n",
      "return\n",
      "\t{\tfield_name\t:\ttry_parse_field(field_name,\tvalue,\tparser_dict)\n",
      "\t\t\t\t\t\n",
      "for\n",
      "\tfield_name,\tvalue\t\n",
      "in\n",
      "\tinput_dict.iteritems()\t}\n",
      "uma\tpróxima\tetapa\tseria\tchecar\tpor\tvalores\tdiscrepantes,\tusando\ttécnicas\tdo“explorando\tseus\tdados”\tna\tpágina\t121\tou\tpor\tinvestigação\tad\thoc.\tpor\n",
      "exemplo,\tvocê\treparou\tque\tuma\tdas\tdatas\tno\tarquivo\tdas\tações\ttinha\to\tano\n",
      "3014?\tisso\tnão\tgerará\tnenhum\terro\t(possivelmente),\tmas\té\tclaramente\terrado,\te\n",
      "você\tterá\tresultados\truins\tse\tvocê\tnão\tconsertá-lo.\tos\tdados\tdo\tmundo\treal\ttêm\n",
      "pontos\tdecimais\tfaltosos,\tzeros\textras,\terros\ttipográficos\te\toutros\tproblemas\n",
      "incontáveis\te\té\to\tseu\ttrabalho\tcapturá-los.\ttalvez\tnão\tseja\tseu\ttrabalho\toficial,\n",
      "mas\tquem\tmais\tvai\tfazer?1.\n",
      "2.\n",
      "3.\n",
      "1.\n",
      "2.\n",
      "manipulando\tdados\n",
      "uma\tdas\thabilidades\tmais\timportantes\tde\tum\tcientista\tde\tdados\té\t\n",
      "manipular\n",
      "dados\n",
      ".\té\tmais\tuma\tvisão\tgeral\tdo\tque\tuma\ttécnica\tespecífica,\tportanto\n",
      "trabalharemos\tcom\tum\tgrupo\tde\texemplos\tpara\tmostrar\tum\tpouco.\n",
      "imagine\tque\testamos\ttrabalhando\tcom\t\n",
      "dict\n",
      "s\tdos\tpreços\tdas\tações\tque\tse\tparecem\n",
      "com:\n",
      "data\t=\t[\n",
      "{'closing_price':\t102.06,\n",
      "\t'date':\tdatetime.datetime(2014,\t8,\t29,\t0,\t0),\n",
      "\t'symbol':\t'aapl'},\n",
      "#\n",
      "\t...\n",
      "]\n",
      "conceitualmente,\tpensaremos\tneles\tcomo\tlinhas\t(como\tem\tuma\tplanilha).\n",
      "vamos\tcomeçar\tperguntando\tsobre\tesses\tdados.\tpelo\tcaminho,\tperceberemos\n",
      "padrões\tno\tque\testamos\tfazendo\te\tabstrairemos\talgumas\tferramentas\tpara\n",
      "facilitar\ta\tmanipulação.\n",
      "por\texemplo,\tsuponha\tque\tqueremos\tsaber\to\tpreço\tmais\talto\tpara\ta\taapl.\n",
      "vamos\tseparar\tem\tetapas\tconcretas:\n",
      "restringir\tem\tlinhas\taapl.\n",
      "pegar\to\t\n",
      "closing_price\n",
      "\tde\tcada\tlinha.\n",
      "levar\to\t\n",
      "max\n",
      "\tde\ttais\tpreços.\n",
      "podemos\tfazer\tos\ttrês\tde\tuma\tsó\tvez\tusando\tuma\tcompreensão\tde\tlista:\n",
      "max_aapl_price\t=\tmax(row[\"closing_price\"]\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata\n",
      "\t\t\t\t\t\t\n",
      "if\n",
      "\trow[\"symbol\"]\t==\t\"aapl\")\n",
      "com\tmais\tfrequência,\ttalvez\tqueiramos\tsaber\to\tpreço\tmais\talto\tpara\tcada\tação\n",
      "em\tnosso\tconjunto\tde\tdados.\tuma\tmaneira\tde\tfazer\té:\n",
      "agrupar\ttodas\tas\tlinhas\tcom\to\tmesmo\t\n",
      "symbol\n",
      "\t(símbolo).\n",
      "dentro\tde\tcada\tgrupo,\tfazer\to\tmesmo\tde\tantes:\n",
      "#\tagrupa\tas\tlinhas\tpor\tsímboloby_symbol\t=\tdefaultdict(list)\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata:\n",
      "by_symbol[row[\"symbol\"]].append(row)\n",
      "#\tusa\ta\tcompreensão\tdo\tdict\tpara\tencontrar\to\tmax\tpara\tcada\tsímbolo\n",
      "max_price_by_symbol\t=\t{\tsymbol\t:\tmax(row[\"closing_price\"]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tgrouped_rows)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tsymbol,\tgrouped_rows\t\n",
      "in\n",
      "\tby_symbol.iteritems()\t}\n",
      "já\texistem\talguns\tpadrões\taqui.\tnos\tdois\texemplos,\ttivemos\tque\tpuxar\to\tvalor\n",
      "closing_\tprice\n",
      "\tpara\tfora\tde\tcada\t\n",
      "dict\n",
      ".\tentão\tvamos\tcriar\tuma\tfunção\tpara\trecolher\tum\n",
      "campo\tde\tum\t\n",
      "dict\n",
      ",\te\toutra\tfunção\tpara\tarrancar\tesse\tmesmo\tcampo\tde\tuma\n",
      "coleção\tde\t\n",
      "dict\n",
      "s:\n",
      "def\n",
      "\tpicker(field_name):\n",
      "\"\"\"retorna\tuma\tfunção\tque\trecolhe\tum\tcampo\tde\tum\tdict\"\"\"\n",
      "return\tlambda\n",
      "\trow:\trow[field_name]\n",
      "def\n",
      "\tpluck(field_name,\trows):\n",
      "\"\"\"transforma\tuma\tlista\tde\tdicts\tem\tuma\tlista\tde\tvalores\tfield_name\"\"\"\n",
      "return\n",
      "\tmap(picker(field_name),\trows)\n",
      "também\tpodemos\tcriar\tuma\tfunção\tpara\tagrupar\tas\tlinhas\tpelo\tresultado\tde\tuma\n",
      "função\t\n",
      "grouper\n",
      "\te\taplicar,\tpor\topção,\tum\ttipo\tde\t\n",
      "value_transform\n",
      "\tem\tcada\tgrupo:\n",
      "def\n",
      "\tgroup_by(grouper,\trows,\tvalue_transform=none):\n",
      "#\ta\tchave\té\ta\tsaída\tde\tgrouper,\to\tvalor\té\tuma\tlista\tde\tlinhas\n",
      "grouped\t=\tdefaultdict(list)\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\trows:\n",
      "grouped[grouper(row)].append(row)\n",
      "if\n",
      "\tvalue_transform\t\n",
      "is\n",
      "\tnone:\n",
      "return\n",
      "\tgrouped\n",
      "else\n",
      ":\n",
      "return\n",
      "\t{\tkey\t:\tvalue_transform(rows)\n",
      "for\n",
      "\tkey,\trows\t\n",
      "in\n",
      "\tgrouped.iteritems()\t}\n",
      "isso\tpermite\tque\tnós\treescrevamos\tos\texemplos\tanteriores\tde\tforma\tsimples.\tpor\n",
      "exemplo:\n",
      "max_price_by_symbol\t=\tgroup_by(picker(\"symbol\"),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "lambda\n",
      "\trows:\tmax(pluck(\"closing_price\",\trows)))\n",
      "agora\tpodemos\tcomeçar\ta\tperguntar\tassuntos\tmais\tcomplicados,\tcomo\tquais\tsão\n",
      "as\tmaiores\te\tmenores\tmudanças\tde\tporcentagem\tao\tdia\tem\tnosso\tconjunto\tde\n",
      "dados.\ta\tmudança\tna\tporcentagem\té\t\n",
      "price_today\t/\tprice_yesterday\t–\t1\n",
      ",\tlogo\tprecisamos1.\n",
      "2.\n",
      "3.\n",
      "de\talguma\tforma\tde\tassociar\to\tpreço\tde\thoje\tcom\to\tde\tontem.\tum\tmétodo\n",
      "possível\té\tagrupar\tos\tpreços\tpor\tsímbolo\te,\tentão,\tdentro\tde\tcada\tgrupo:\n",
      "ordenar\tos\tpreços\tpor\tdata.\n",
      "usar\t\n",
      "zip\n",
      "\tpara\tter\tpares\t(anteriores,\tatuais).\n",
      "transformar\tos\tpares\tem\tlinhas\tnovas\tde\t“mudança\tde\tpercentual”.\n",
      "começaremos\tescrevendo\tuma\tfunção\tque\tfaça\to\ttrabalho\tdentro\tde\tcada\tgrupo:\n",
      "def\n",
      "\tpercent_price_change(yesterday,\ttoday):\n",
      "return\n",
      "\ttoday[\"closing_price\"]\t/\tyesterday[\"closing_price\"]\t-\t1\n",
      "def\n",
      "\tday_over_day_changes(grouped_rows):\n",
      "#\torganiza\tas\tlinhas\tpor\tdata\n",
      "ordered\t=\tsorted(grouped_rows,\tkey=picker(\"date\"))\n",
      "#\tcompacta\tcom\tuma\tcompensação\tpara\tter\tpares\tde\tdias\tconsecutivos\n",
      "return\n",
      "\t[{\t\"symbol\"\t:\ttoday[\"symbol\"],\n",
      "\t\t\t\t\"date\"\t:\ttoday[\"date\"],\n",
      "\t\t\t\t\"change\"\t:\tpercent_price_change(yesterday,\ttoday)\t}\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tyesterday,\ttoday\t\n",
      "in\n",
      "\tzip(ordered,\tordered[1:])]\n",
      "então\tpodemos\tusá-lo\tcomo\to\t\n",
      "value_transform\n",
      "\tem\tum\t\n",
      "group_by\n",
      ":\n",
      "#\ta\tchave\té\tsymbol,\to\tvalor\té\tuma\tchange\tde\tdicts\n",
      "changes_by_symbol\t=\tgroup_by(picker(\"symbol\"),\tdata,\tday_over_day_changes)\n",
      "#\tcoleta\ttodas\tas\tchanges\tde\tdicts\tpara\tuma\tlista\tgrande\n",
      "all_changes\t=\t[change\n",
      "\t\t\t\t\t\t\tfor\tchanges\tin\tchanges_by_symbol.values()\n",
      "\t\t\t\t\t\t\tfor\tchange\tin\tchanges]\n",
      "nesse\tponto,\tfica\tfácil\tde\tencontrar\to\tmaior\te\to\tmenor:\n",
      "max(all_changes,\tkey=picker(\"change\"))\n",
      "#\t{'change':\t0.3283582089552237\n",
      ",\n",
      "#\t'date':\tdatetime.datetime(1997,\t8,\t6,\t0,\t0)\n",
      ",\n",
      "#\t'symbol':\t'aapl'}\n",
      "#\tsee,\te.g.\thttp://news.cnet.com/2100-1001-202143.html\n",
      "min(all_changes,\tkey=picker(\"change\"))\n",
      "#\t{'change':\t-0.5193370165745856\n",
      ",\n",
      "#\t'date':\tdatetime.datetime(2000,\t9,\t29,\t0,\t0)\n",
      ",\n",
      "#\t'symbol':\t'aapl'}\n",
      "#\tveja\tpor\texemplo\thttp://money.cnn.com/2000/09/29/markets/techwrap/\n",
      "podemos\tusar\tagora\to\tconjunto\tde\tdados\tnovo\t\n",
      "all_changes\n",
      "\tpara\tencontrar\tqual\tmês\n",
      "é\to\tmelhor\tpara\tinvestir\tem\tações\ttecnológicas.\tprimeiro,\tagrupamos\tas\n",
      "mudanças\tpor\tmês;\tentão\tcomputamos\ta\tmudança\tgeral\tdentro\tde\tcada\tgrupo.mais\tuma\tvez,\tescrevemos\tum\t\n",
      "value_transform\n",
      "\tadequado\te\tusamos\t\n",
      "group_by\n",
      ":\n",
      "#\tpara\tcombinar\tas\tmudanças\tpercentuais,\tadicionamos\t1\ta\tcada\tum,\tos\tmultiplicamos\n",
      "#\te\tsubtraímos\t1\tpor\texemplo,\tse\tcombinarmos\t+10%\te\t–20%,\ta\tmudança\tgeral\té\n",
      "#\t\t\t(1\t+\t10%)\t*\t(1\t-\t20%)\t-\t1\t=\t1.1\t*\t.8\t-\t1\t=\t-12%\n",
      "def\tcombine_pct_changes(pct_change1,\tpct_change2):\n",
      "return\t(1\t+\tpct_change1)\t*\t(1\t+\tpct_change2)\t-\t1\n",
      "def\toverall_change(changes):\n",
      "return\treduce(combine_pct_changes,\tpluck(\"change\",\tchanges))\n",
      "overall_change_by_month\t=\tgroup_by(lambda\trow:\trow['date'].month,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tall_changes,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\toverall_change)\n",
      "faremos\tesses\ttipos\tde\tmanipulações\tno\tdecorrer\tdo\tlivro,\tgeralmente\tsem\n",
      "chamar\tmuita\tatenção\tdireta\tpara\telas.redimensionando\n",
      "muitas\ttécnicas\tsão\tsensíveis\tà\tescala\tdos\tseus\tdados.\tpor\texemplo,\timagine\tum\n",
      "conjunto\tde\tdados\tque\tconsiste\tde\taltura\te\tpesos\tde\tcentenas\tde\tcientistas\tde\n",
      "dados\te\tque\tvocê\testá\ttentando\tidentificar\to\t\n",
      "agrupamento\n",
      "\t(\n",
      "cluster\n",
      ")\tdos\ttamanhos\n",
      "dos\tcorpos.\n",
      "intuitivamente,\tgostaríamos\tque\tos\tagrupamentos\trepresentassem\tpontos\n",
      "próximos\tuns\taos\toutros,\to\tque\tsignifica\tque\tprecisamos\tde\talguma\tnoção\tde\n",
      "distância\tentre\teles.\tnós\tjá\ttemos\ta\tfunção\t\n",
      "distance\n",
      "\t(distância)\teuclideana,\n",
      "portanto\tuma\tabordagem\tnatural\tseria\ttratar\tos\tpares\t(altura,\tpeso)\tcomo\tpontos\n",
      "em\tum\tespaço\tbidimensional.\tobserve\tas\tpessoas\tna\tlista\tda\t\n",
      "tabela\t10-1\n",
      ".\n",
      "tabela\t10-1.\talturas\te\tpesos\n",
      "se\tmedirmos\ta\taltura\tem\tpolegadas,\to\tvizinho\tmais\tpróximo\tde\tb\té\ta:\n",
      "a_to_b\t=\tdistance([63,\t150],\t[67,\t160])\t\t\t\t\t\t\n",
      "#\t10.77\n",
      "a_to_c\t=\tdistance([63,\t150],\t[70,\t171])\t\t\t\t\t\t\n",
      "#\t22.14\n",
      "b_to_c\t=\tdistance([67,\t160],\t[70,\t171])\t\t\t\t\t\t\n",
      "#\t11.40\n",
      "porém,\tse\tmedirmos\tem\tcentímetros,\to\tvizinho\tmais\tpróximo\tde\tb\té\tc:\n",
      "a_to_b\t=\tdistance([160,\t150],\t[170.2,\t160])\t\t\t\t\t\n",
      "#\t14.28\n",
      "a_to_c\t=\tdistance([160,\t150],\t[177.8,\t171])\t\t\t\t\t\n",
      "#\t27.53\n",
      "b_to_c\t=\tdistance([170.2,\t160],\t[177.8,\t171])\t\t\t\n",
      "#\t13.37\n",
      "é\tuma\tproblemática\tevidente\tse\ta\tmudança\tdas\tunidades\tmudam\tos\tresultados\n",
      "dessa\tforma.\tpor\tesse\tmotivo,\tquando\tas\tdimensões\tnão\tsão\tcomparáveis\tumas\n",
      "com\tas\toutras,\tàs\tvezes\t\n",
      "redimensionamos\n",
      "\tnossos\tdados\ta\tfim\tde\tque\tcada\n",
      "dimensão\ttenha\tmédia\t0\te\tdesvio\tpadrão\t1.\tisso\tnos\tlivra\tdas\tunidades,\n",
      "convertendo\tcada\tdimensão\tpara\t“desvios\tpadrões\ta\tpartir\tda\tmédia”.\n",
      "a\tpartir\tdessa\texplicação,\tprecisaremos\tcomputar\ta\t\n",
      "mean\n",
      "\te\to\t\n",
      "standard_deviation\n",
      "\tpara\n",
      "cada\tcoluna:def\n",
      "\tscale(data_matrix):\n",
      "\"\"\"retorna\ta\tmédia\te\tos\tdesvios\tpadrões\tde\tcada\tcoluna\"\"\"\n",
      "num_rows,\tnum_cols\t=\tshape(data_matrix)\n",
      "means\t=\t[mean(get_column(data_matrix,j))\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tj\t\n",
      "in\n",
      "\trange(num_cols)]\n",
      "stdevs\t=\t[standard_deviation(get_column(data_matrix,j))\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tj\t\n",
      "in\n",
      "\trange(num_cols)]\n",
      "return\n",
      "\tmeans,\tstdevs\n",
      "e\tentão\tos\tusa\tpara\tcriar\tuma\tnova\tmatriz\tde\tdados:\n",
      "def\trescale(data_matrix):\n",
      "\"\"\"redimensiona\tos\tdados\tde\tentrada\tpara\tque\tcada\tcoluna\n",
      "tenha\tmédia\t0\te\tdesvio\tpadrão\t1\n",
      "deixa\tintactas\tcolunas\tsem\tdesvio\"\"\"\n",
      "means,\tstdevs\t=\tscale(data_matrix)\n",
      "def\trescaled(i,\tj):\n",
      "if\tstdevs[j]\t>\t0:\n",
      "\t\t\treturn\t(data_matrix[i][j]\t-\tmeans[j])\t/\tstdevs[j]\n",
      "else:\n",
      "\t\t\treturn\tdata_matrix[i][j]\n",
      "num_rows,\tnum_cols\t=\tshape(data_matrix)\n",
      "return\tmake_matrix(num_rows,\tnum_cols,\trescaled)\n",
      "como\tsempre,\tvocê\tprecisa\tutilizar\tde\tseu\tbom\tsenso.\tse\tvocê\tfosse\tpegar\tum\n",
      "conjunto\tde\tdados\tenorme\tde\talturas\te\tpesos\te\tfiltrá-los\tsomente\tpara\tas\tpessoas\n",
      "que\tpossuíssem\tentre\t69,5\te\t70,5\tpolegadas,\tseria\tbem\tprovável\t(dependendo\tda\n",
      "questão\tque\tvocê\testeja\ttentando\tresponder)\tque\ta\tvariação\tpermanecesse\tapenas\n",
      "como\tum\truído\te\tvocê\tpoderia\tnão\tquerer\tcolocar\ttal\tdesvio\tpadrão\tem\tuma\n",
      "relação\tde\tigualdade\tcom\tos\tdesvios\tdas\toutras\tdimensões.redução\tda\tdimensionalidade\n",
      "às\tvezes,\tas\tdimensões\t“reais”\t(ou\túteis)\tdos\tdados\tpodem\tnão\tcorresponder\tàs\n",
      "dimensões\tque\ttemos.\tpor\texemplo,\tobserve\to\tconjunto\tde\tdados\tna\t\n",
      "figura\t10-5\n",
      ".\n",
      "figura\t10-5.\tdados\tcom\tos\teixos\t“errados”\n",
      "a\tmaioria\tdas\tvariações\tnos\tdados\tparecem\tser\tde\tuma\túnica\tdimensão\tque\tnão\n",
      "corresponde\tao\teixo\tx\tnem\tao\teixo\ty.\n",
      "quando\tesse\té\to\tcaso,\tpodemos\tusar\tuma\ttécnica\tchamada\tde\t\n",
      "análise\tde\n",
      "componentes\tprincipais\n",
      "\tpara\textrair\tuma\tou\tmais\tdimensões\tque\tcapturem\ta\n",
      "maior\tvariação\tdos\tdados\tpossível.\n",
      "na\tprática,\tvocê\tnão\tusaria\tessa\ttécnica\tem\tum\tconjunto\tde\tdados\tcom\to\tdimensional\n",
      "tão\tbaixo.\ta\tredução\tde\tdimensionalidade\té\tmais\tútil\tquando\tseu\tconjunto\tde\tdados\n",
      "possui\tum\tgrande\tnúmero\tde\tdimensões\te\tvocê\tquer\tencontrar\tuma\tsubparcela\tque\n",
      "captura\ta\tmaior\tparte\tda\tvariação.\tinfelizmente,\tesse\tcaso\té\tdifícil\tde\tser\tilustrado\temlivro\tcom\tformato\tbidimensional.\n",
      "na\tprimeira\tetapa,\tprecisaremos\ttransformar\tos\tdados\tpara\tque\tcada\tdimensão\n",
      "tenha\tmédia\tzero:\n",
      "def\n",
      "\tde_mean_matrix(a):\n",
      "\"\"\"retorna\to\tresultado\tde\tsubtrair\tde\tcada\tvalor\tem\ta\to\tvalor\n",
      "da\tmédia\tda\tsua\tcoluna.\ta\tmatriz\tresultante\ttem\tmédia\t0\tem\tcada\tcoluna\"\"\"\n",
      "nr,\tnc\t=\tshape(a)\n",
      "column_means,\t_\t=\tscale(a)\n",
      "return\n",
      "\tmake_matrix(nr,\tnc,\t\n",
      "lambda\n",
      "\ti,\tj:\ta[i][j]\t-\tcolumn_means[j])\n",
      "(se\tnão\tfizermos\tisso,\té\tpossível\tque\tnossas\ttécnicas\tidentificarão\ta\tmédia\tem\tsi\n",
      "em\tvez\tde\tidentificar\ta\tvariação\tnos\tdados.)\n",
      "a\t\n",
      "figura\t10-6\n",
      "\tmostra\tos\texemplos\tde\tdados\tapós\to\tdesconto\tda\tmédia.\n",
      "figura\t10-6.\tdados\tapós\to\tdesconto\tda\tmédia\n",
      "agora,\tdada\tuma\tmatriz\tdescontada\tde\tmédia\t\n",
      "x\n",
      ",\tpodemos\tperguntar:\tqual\té\tadireção\tque\tcaptura\ta\tmaior\tvariação\tnos\tdados?\n",
      "especificamente,\tdada\tuma\tdireção\t\n",
      "d\n",
      "\t(um\tvetor\tde\tmagnitude\t1),\tcada\tlinha\t\n",
      "x\n",
      "\tna\n",
      "matriz\tse\testende\t\n",
      "dot(x,\td)\n",
      "\tna\tdireção\tde\t\n",
      "d\n",
      ".\tcada\tvetor\tnão-zero\t\n",
      "w\n",
      "\tdetermina\tuma\n",
      "direção\tse\tos\tredimensionarmos\tpara\tter\tmagnitude\t1:\n",
      "def\n",
      "\tdirection(w):\n",
      "mag\t=\tmagnitude(w)\n",
      "return\n",
      "\t[w_i\t/\tmag\t\n",
      "for\n",
      "\tw_i\t\n",
      "in\n",
      "\tw]\n",
      "portanto,\tdado\tum\tvetor\tnão-zero\t\n",
      "w\n",
      ",\tpodemos\tcomputar\ta\tvariância\tdo\tnosso\n",
      "conjunto\tde\tdados\tna\tdireção\tdeterminada\tpor\t\n",
      "w\n",
      ":\n",
      "def\tdirectional_variance_i(x_i,\tw):\n",
      "\"\"\"a\tvariância\tna\tlinha\tx_i\tna\tdireção\tdeterminada\tpor\tw\"\"\"\n",
      "return\tdot(x_i,\tdirection(w))\t**\t2\n",
      "def\tdirectional_variance(x,\tw):\n",
      "\"\"\"a\tvariância\tdos\tdados\tna\tdireção\tdeterminada\tpor\tw\"\"\"\n",
      "return\tsum(directional_variance_i(x_i,\tw)\n",
      "\t\t\t\t\t\t\t\t\tfor\tx_i\tin\tx)\n",
      "gostaríamos\tde\tencontrar\ta\tdireção\tque\tmaximiza\tessa\tvariância.\tpodemos\tfazer\n",
      "isso\tusando\to\tgradiente\tdescente,\tassim\tque\ttivermos\ta\tfunção\tgradiente:\n",
      "def\n",
      "\tdirectional_variance_gradient_i(x_i,\tw):\n",
      "\"\"\"a\tcontribuição\tda\tlinha\tx_1\tpara\to\tgradiente\tda\n",
      "variância\tda\tdireção\tw\"\"\"\n",
      "projection_length\t=\tdot(x_i,\tdirection(w))\n",
      "return\n",
      "\t[2\t*\tprojection_length\t*\tx_ij\t\n",
      "for\n",
      "\tx_ij\t\n",
      "in\n",
      "\tx_i]\n",
      "def\n",
      "\tdirectional_variance_gradient(x,\tw):\n",
      "return\n",
      "\tvector_sum(directional_variance_gradient_i(x_i,w)\n",
      "\t\t\t\t\t\n",
      "for\n",
      "\tx_i\t\n",
      "in\n",
      "\tx)\n",
      "o\tcomponente\tprincipal\té\tsomente\ta\tdireção\tque\tmaximiza\ta\tfunção\n",
      "directional_variance\n",
      ":\n",
      "def\n",
      "\tfirst_principal_component(x):\n",
      "guess\t=\t[1\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\tx[0]]\n",
      "unscaled_maximizer\t=\tmaximize_batch(\n",
      "partial(directional_variance,\tx),\t\t\t\t\t\t\t\t\t\t\n",
      "#\tagora\té\tuma\tfunção\tde\tw\n",
      "partial(directional_variance_gradient,\tx),\t\n",
      "#\tagora\té\tuma\tfunção\tde\tw\n",
      "guess)\n",
      "return\n",
      "\tdirection(unscaled_maximizer)\n",
      "ou,\tse\tvocê\tpreferir\to\tgradiente\tdescendente\testocástico:\n",
      "#\taqui\tnão\thá\t“y”,\tentão\tpassamos\tum\tvetor\tde\tnones#\te\tfunções\tque\tignoram\taquela\tentrada\n",
      "def\tfirst_principal_component_sgd(x):\n",
      "guess\t=\t[1\tfor\t_\tin\tx[0]]\n",
      "unscaled_maximizer\t=\tmaximize_stochastic(\n",
      "lambda\tx,\t_,\tw:\tdirectional_variance_i(x,\tw),\n",
      "lambda\tx,\t_,\tw:\tdirectional_variance_gradient_i(x,\tw),\n",
      "x,\n",
      "[none\tfor\t_\tin\tx],\t\n",
      "#\to\t\"y\"\tfalso\n",
      "guess)\n",
      "return\tdirection(unscaled_maximizer)\n",
      "no\tconjunto\tde\tdados\tdescontado\tda\tmédia,\tisso\tretorna\ta\tdireção\t\n",
      "[0.924,\t0.383]\n",
      ",\n",
      "que\tparece\tpara\tcapturar\to\teixo\tprimário\tao\tlongo\tdo\tqual\ta\tvariação\tdos\tdados\n",
      "(\n",
      "figura\t10-7\n",
      ").\n",
      "figura\t10-7.\to\tprimeiro\tcomponente\tprincipal\n",
      "uma\tvez\tque\tachamos\ta\tdireção,\tque\té\to\tprincipal\tcomponente,\tpodemos\n",
      "projetar\tnossos\tdados\tpara\tencontrar\tos\tvalores\tdaquele\tcomponente:\n",
      "def\tproject(v,\tw):\"\"\"retorna\ta\tprojeção\tde\tv\tna\tdireção\tw\"\"\"\n",
      "projection_length\t=\tdot(v,\tw)\n",
      "return\tscalar_multiply(projection_length,\tw)\n",
      "se\tquisermos\tencontrar\tcomponentes\tmais\tdistantes,\tprimeiro\ttemos\tque\n",
      "remover\tas\tprojeções\ta\tpartir\tdos\tdados:\n",
      "def\n",
      "\tremove_projection_from_vector(v,\tw):\n",
      "\"\"\"projeta\tv\tem\tw\te\tsubtrai\to\tresultado\tde\tv\"\"\"\n",
      "return\n",
      "\tvector_subtract(v,\tproject(v,\tw))\n",
      "def\n",
      "\tremove_projection(x,\tw):\n",
      "\"\"\"para\tcada\tlinha\tde\tx\n",
      "projeta\ta\tlinha\tem\tw,\te\tsubtrai\to\tresultado\tda\tlinha\"\"\"\n",
      "return\n",
      "\t[remove_projection_from_vector(x_i,\tw)\t\n",
      "for\n",
      "\tx_i\t\n",
      "in\n",
      "\tx]\n",
      "como\tesse\texemplo\tde\tconjunto\tde\tdados\té\tbidimensional,\tapós\tremovermos\to\n",
      "primeiro\tcomponente,\to\tque\tsobra\tserá\tefetivamente\tunidimensional\t(\n",
      "figura\t10-\n",
      "8\n",
      ").\n",
      "figura\t10-8.\tdados\tapós\ta\tremoção\tda\tprimeira\tcomponente\tprincipalnesse\tponto,\tpodemos\tencontrar\to\tpróximo\tcomponente\tprincipal\tao\trepetir\to\n",
      "processo\tsobre\to\tresultado\t\n",
      "remove_projection\n",
      "\t(\n",
      "figura\t10-9\n",
      ").\n",
      "em\tum\tconjunto\tde\tdados\tde\tdimensão\tmais\talta,\tpodemos\tencontrar\ttantos\n",
      "componentes\tquanto\tquisermos:\n",
      "def\n",
      "\tprincipal_component_analysis(x,\tnum_components):\n",
      "components\t=\t[]\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(num_components):\n",
      "component\t=\tfirst_principal_component(x)\n",
      "components.append(component)\n",
      "x\t=\tremove_projection(x,\tcomponent)\n",
      "return\n",
      "\tcomponents\n",
      "podemos\tentão\t\n",
      "transformar\n",
      "\tnossos\tdados\tno\tespaço\tde\tdimensão\tmais\tbaixa\n",
      "coberto\tpelos\tcomponentes:\n",
      "def\n",
      "\ttransform_vector(v,\tcomponents):\n",
      "return\n",
      "\t[dot(v,\tw)\t\n",
      "for\n",
      "\tw\t\n",
      "in\n",
      "\tcomponents]\n",
      "def\n",
      "\ttransform(x,\tcomponents):\n",
      "return\n",
      "\t[transform_vector(x_i,\tcomponents)\t\n",
      "for\n",
      "\tx_i\t\n",
      "in\n",
      "\tx]\n",
      "essa\ttécnica\té\tvaliosa\tpor\tdois\tmotivos.\tprimeiro,\tela\tpode\tnos\tajudar\ta\tlimpar\n",
      "nossos\tdados\tao\teliminar\tdimensões\tque\tsão\tmero\truído\te\tconsolidar\tdimensões\n",
      "que\tsão\taltamente\tcorrelacionadas.figura\t10-9.\tos\tprimeiros\tdois\tcomponentes\tprincipais\n",
      "segundo,\tapós\textrair\tuma\trepresentação\tde\tdimensão\tmais\tbaixa\tdos\tnossos\n",
      "dados,\tpodemos\tusar\tuma\tvariedade\tde\ttécnicas\tque\tnão\tfuncionam\tbem\tem\n",
      "dados\tde\talta\tdimensão.\tveremos\talguns\texemplos\tde\ttais\ttécnicas\tno\tdecorrer\n",
      "do\tlivro.\n",
      "ao\tmesmo\ttempo,\tenquanto\tpode\tajudar\ta\tconstruir\tmodelos\tmelhores,\ttambém\n",
      "pode\ttorná-los\tmais\tdifíceis\tde\tserem\tinterpretados.\té\tfácil\tentender\tconclusões\n",
      "como\t“cada\tano\textra\tde\texperiência\tadiciona\tuma\tmédia\tde\t$10k\tno\tsalário”.\té\n",
      "mais\tdifícil\tde\tentender\tque\t“cada\taumento\tde\t0,1\tno\tterceiro\tcomponente\n",
      "principal\tadiciona\tuma\tmédia\tde\t$10k\tno\tsalário”.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "como\tmencionamos\tno\tfinal\tdo\t\n",
      "capítulo\t9\n",
      ",\t\n",
      "pandas\n",
      "(\n",
      "http://pandas.pydata.org\n",
      "/)\n",
      "\tprovavelmente\té\ta\tferramenta\tprimária\tde\n",
      "python\tpara\tlimpar,\ttransformar,\tmanipular\te\ttrabalhar\tcom\tdados.\ttodos\n",
      "os\texemplos\tque\tfizemos\tà\tmão\tneste\t\n",
      "capítulo\tpoderiam\tter\tsido\tfeitos\n",
      "com\tmais\tsimplicidade\tusando\t\n",
      "pandas\n",
      ".\t\n",
      "python\tfor\tdata\tanalysis\n",
      "(o’reilly)\té\ta\tmelhor\tmaneira\tde\taprender\t\n",
      "pandas\n",
      ".\n",
      "scikit-learn\tpossui\tuma\tgrande\tvariedade\tde\tfunções\tde\tdecomposição\tde\n",
      "matriz\t(\n",
      "http://bit.ly/1ycoljd\n",
      "),\tincluindo\tanálise\tde\tcomponente\tprincipal\n",
      "(principal\tcomponent\tanalyses\t–\tpca).capítulo\t11\n",
      "aprendizado\tde\tmáquina\n",
      "estou\tsempre\tdisposto\ta\taprender\tapesar\tde\tnem\tsempre\tgostar\tde\tser\tensinado\n",
      ".\n",
      "—winston\tchurchill\n",
      "muitas\tpessoas\timaginam\tque\tdata\tscience\té,\tem\tmaior\tparte,\taprendizado\tde\n",
      "máquina\te\tque\tos\tcientistas\tde\tdados\tconstroem,\tpraticam\te\tajustam\tmodelos\tde\n",
      "aprendizado\tde\tmáquina\to\tdia\tinteiro.\te,\tnovamente,\tmuitas\tdesas\tpessoas\tnão\n",
      "sabem\to\tque\t\n",
      "é\n",
      "\taprendizado\tde\tmáquina.\tna\tverdade,\tdata\tscience\té\tmais\n",
      "transformar\tproblemas\tempresariais\tem\tproblemas\tde\tdados\te\tcoletar,\tentender,\n",
      "limpar\te\tformatar\tos\tdados,\tapós\to\tque\taprendizado\tde\tmáquina\té\tpraticamente\n",
      "uma\tconsideração\tsubsequente.\tmesmo\tassim,\té\tuma\treferência\tinteressante\te\n",
      "essencial\tque\tvocê\tdeve\tsaber\ta\tfim\tde\tpraticar\tdata\tscience.modelagem\n",
      "antes\tde\tpodemos\tfalar\tsobre\to\taprendizado\tde\tmáquina,\tprecisamos\tfalar\tsobre\n",
      "modelos\n",
      ".\n",
      "o\tque\té\tum\tmodelo?\té\tsimplesmente\ta\tespecificação\tde\tuma\trelação\tmatemática\n",
      "(ou\tprobabilística)\texistente\tentre\tvariáveis\tdiferentes.\n",
      "por\texemplo,\tse\tvocê\testá\ttentado\ta\tlevantar\tdinheiro\tpara\to\tseu\tsite\tde\trede\n",
      "social,\ttalvez\tvocê\tprecise\tde\tum\t\n",
      "modelo\tde\tnegócios\n",
      "\t(possivelmente\tem\tuma\n",
      "planilha)\tque\treceba\tentradas\tcomo\t“número\tde\tusuários”,\t“rendimento\tde\n",
      "propaganda\tpor\tusuário”\te\t“número\tde\tfuncionários”\te\texiba\tcomo\tsaída\tseu\n",
      "lucro\tanual\tpelos\tpróximos\tanos.\tum\tlivro\tde\treceitas\timplica\tum\tmodelo\tque\n",
      "relaciona\tentradas\tcomo\t“número\tde\tcomensais”\te\t“apetite”\tpara\tas\tquantidades\n",
      "dos\tingredientes\tnecessários.\te,\tse\tvocê\tjá\tassistiu\tpôquer\tna\ttelevisão,\tvocê\n",
      "sabe\tque\teles\testimam\ta\t“probabilidade\tde\tganhar”\tde\tcada\tjogador\tem\ttempo\n",
      "real\tbaseado\tem\tum\tmodelo\tque\tleva\tem\tconsideração\tas\tcartas\tque\tforam\n",
      "reveladas\taté\tentão\te\ta\tdistribuição\tde\tcartas\tno\tbaralho.\n",
      "o\tmodelo\tde\tnegócios\té,\tprovavelmente,\tbaseado\tem\trelações\tsimples\tde\n",
      "matemática:\tlucro\té\to\trendimento\tmenos\tas\tdespesas,\to\trendimento\té\tsoma\tdas\n",
      "unidades\tvendidas\tvezes\to\tpreço\tmédio\te\tassim\tpor\tdiante.\to\tmodelo\tdo\tlivro\tde\n",
      "receitas\té\tbaseado\tem\ttentativas\te\terros\t—\talguém\t\n",
      "foi\tna\tcozinha\te\n",
      "experimentou\tcombinações\tdiferentes\tde\tingredientes\taté\tencontrar\tuma\tque\n",
      "gostasse.\to\tmodelo\tdo\tpôquer\té\tbaseado\tna\tteoria\tda\tprobabilidade,\tas\tregras\tdo\n",
      "pôquer\te\talgumas\tpremissas\trazoavelmente\tinócuos\tsobre\to\tprocesso\taleatório\n",
      "pelo\tqual\tas\tcartas\tsão\tdistribuídas.•\n",
      "•\n",
      "•\n",
      "•\n",
      "o\tque\té\taprendizado\tde\tmáquina?\n",
      "todo\tmundo\tpossui\tsua\tprópria\tdefinição,\tmas\tusaremos\t\n",
      "aprendizado\tde\n",
      "máquina\n",
      "\tpara\tnos\treferir\tà\tcriação\te\tao\tuso\tde\tmodelos\tque\tsão\taprendidos\t\n",
      "a\n",
      "partir\tdos\tdados\n",
      ".\tem\toutros\tcontextos\tisso\tpode\tser\tchamado\tde\t\n",
      "modelo\n",
      "preditivo\n",
      "\tou\t\n",
      "mineração\tde\tdados\n",
      ",\tmas\tvamos\tmanter\to\taprendizado\tde\tmáquina.\n",
      "normalmente,\tnosso\tobjetivo\tserá\tusar\tos\tdados\texistentes\tpara\tdesenvolver\n",
      "modelos\tque\tpossamos\tusar\tpara\t\n",
      "prever\n",
      "\tpossíveis\tsaídas\tpara\tos\tdados\tnovos,\n",
      "como:\n",
      "prever\tse\tuma\tmensagem\tde\te-mail\té\tspam\tou\tnão\n",
      "prever\tse\tuma\ttransação\tdo\tcartão\tde\tcrédito\té\tfraudulenta\n",
      "prever\tqual\ta\tprobabilidade\tde\tum\tcomprador\tclicar\tem\tuma\tpropaganda\n",
      "prever\tqual\ttime\tde\tfutebol\tganhará\to\tsuper\tbowl\n",
      "consideraremos\tos\tmodelos\t\n",
      "supervisionados\n",
      "\t(nos\tquais\texiste\tum\tconjunto\tde\n",
      "dados\tetiquetados\tcom\ta\tresposta\tcorreta\tpara\taprendizagem)\te\tmodelos\t\n",
      "sem\n",
      "supervisão\n",
      "\t(nos\tquais\tnão\texistem\ttais\tetiquetas).\texistem\tvários\toutros\ttipos\n",
      "como\t\n",
      "semisupervisionados\n",
      "\t(nos\tquais\tapenas\talguns\tdados\tsão\tetiquetados)\te\n",
      "online\n",
      "\t(nos\tquais\to\tmodelo\tprecisa\tter\tum\tajuste\tcontínuo\tem\tface\tda\tchegada\tde\n",
      "novos\tdados),\tmas\tnão\tserão\tabordados\tneste\tlivro.\n",
      "agora,\taté\tmesmo\tna\tsituação\tmais\tsimples\texiste\tum\tuniverso\tinteiro\tde\n",
      "modelos\tque\tpodem\tdescrever\ta\trelação\tna\tqual\testamos\tinteressados.\tna\n",
      "maioria\tdos\tcasos,\tnós\tmesmos\tescolheremos\tuma\tfamília\t\n",
      "parametrizada\n",
      "\tde\n",
      "modelos\te\tentão\tusaremos\tos\tdados\tpara\taprender\tparâmetros\tque\tsão,\tde\tcerta\n",
      "forma,\tótimos.\n",
      "por\texemplo,\tpodemos\tpresumir\tque\ta\taltura\tde\tuma\tpessoa\té\t(mais\tou\tmenos)\n",
      "uma\tfunção\tlinear\tdo\tseu\tpeso\te\tentão\tusar\tos\tdados\tpara\tdescobrir\tqual\tfunção\n",
      "linear\té\tessa.\tou,\tpodemos\tpresumir\tque\tuma\tárvore\tde\tdecisão\té\tuma\tboa\n",
      "maneira\tde\tidentificar\tquais\tdoenças\tnossos\tpacientes\tpossuem\te\tentão\tusar\tos\n",
      "dados\tpara\tdescobrir\ta\tótima\tárvore\tde\tdecisão.\tpelo\trestante\tdo\tlivro\n",
      "investigaremos\tfamílias\tdiferentes\tde\tmodelos\tque\tpodemos\taprender.\n",
      "mas\tantes\tdisso,\tprecisamos\tentender\tmelhor\tos\tfundamentos\tdo\taprendizado\tdemáquina.\tpelo\tresto\tdo\tcapítulo,\tdiscutiremos\talguns\tconceitos\tbásicos\tantes\tde\n",
      "chegarmos\tnos\tmodelos\tpropriamente\tditos.sobreajuste\te\tsub-ajuste\n",
      "um\tperigo\tcomum\tem\taprendizado\tde\tmáquina\té\to\t\n",
      "sobreajuste\n",
      "\t—\tproduzir\tum\n",
      "modelo\tde\tbom\tdesempenho\tcom\tos\tdados\tque\tvocê\ttreina,\tmas\tque\tnão\tlide\n",
      "muito\tbem\tcom\tnovos\tdados.\n",
      "isso\tpode\timplicar\to\t\n",
      "aprender\n",
      "\tcom\tbase\tno\truído\tdos\tdados.\tou,\tpode\timplicar\n",
      "em\taprender\ta\tidentificar\tentradas\tespecíficas\tem\tvez\tde\tqualquer\tfator\tque\n",
      "sejam\tde\tfato\tpreditivos\tda\tsaída\tdesejada.\n",
      "o\toutro\tlado\té\to\t\n",
      "sub-ajuste\n",
      ",\tproduzindo\tum\tmodelo\tque\tnão\tdesempenha\tbem\n",
      "nem\tcom\tos\tdados\tusados\tno\ttreino,\tapesar\tde\tque,\tquando\tacontece\tisso,\tvocê\n",
      "decide\tque\tseu\tmodelo\tnão\té\tbom\to\tsuficiente\te\tcontinua\ta\tprocurar\tpor\n",
      "melhores.\n",
      "figura\t11-1.\tsobreajuste\te\tsub-ajustena\t\n",
      "figura\t11-1\n",
      ",\tencaixei\ttrês\tpolinômios\tem\tuma\tamostra\tde\tdados.\t(não\tse\n",
      "preocupe\tem\tcomo,\tchegaremos\tlá\tnos\tcapítulos\tposteriores.)\n",
      "a\tlinha\thorizontal\tmostra\to\tmelhor\tgrau\tadequado\tpolinomial\t0\t(isto\té,\n",
      "constante).\tele\t\n",
      "sub-ajusta\n",
      "\to\tdado\tem\ttreinamento\tintensamente.\to\tmelhor\tajuste\n",
      "por\tum\tpolinômio\tdo\t9º\tgrau\t(isto\té,\tparâmetro\t10)\tpassa\tpor\ttodos\tos\tpontos\tde\n",
      "dados\tem\ttreinamento,\tmas\t\n",
      "sobreajusta\n",
      "\tgravemente\t—\tse\tfossemos\tadquirir\tum\n",
      "pouco\tmais\tde\tpontos\tde\tdados,\tprovavelmente\tsairiam\tbem\terrados.\te\ta\tlinha\n",
      "de\t1º\tgrau\ttem\tum\tbom\tequilíbrio\t—\té\tbem\tpróximo\ta\tcada\tponto,\te\t(se\tesses\n",
      "dados\tsão\trepresentativos)\ta\tlinha\testará\tpróxima\tdos\tnovos\tpontos\tde\tdados\n",
      "também.\n",
      "evidentemente,\tos\tmodelos\tque\tsão\tmuito\tcomplexos\ttendem\tao\tsobreajuste\te\n",
      "não\tlidam\tbem\tcom\tdados\talém\tdaqueles\tcom\tos\tquais\tforam\ttreinados.\tentão,\n",
      "como\ttemos\tcerteza\tque\tnossos\tmodelos\tnão\tsão\tmuito\tcomplexos?\to\tmétodo\n",
      "mais\tfundamental\tenvolve\to\tuso\tde\tdados\tdiferentes\tpara\ttreinar\te\ttestar\to\n",
      "modelo.\n",
      "a\tmaneira\tmais\tfácil\tde\tfazer\tisso\té\tdividir\tseu\tconjunto\tde\tdados,\ta\tfim\tde\tque,\n",
      "por\texemplo,\tdois\tterços\tdele\tsejam\tusados\tpara\ttreinar\to\tmodelo\te\tdepois\tmedir\n",
      "o\tdesempenho\tdo\tmodelo\tcom\ta\tparte\trestante:\n",
      "def\n",
      "\tsplit_data(data,\tprob):\n",
      "\"\"\"divide\tos\tdados\tem\tfrações\t[prob,\t1\t–\tprob]\"\"\"\n",
      "results\t=\t[],\t[]\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata:\n",
      "results[0\t\n",
      "if\n",
      "\trandom.random()\t<\tprob\t\n",
      "else\n",
      "\t1].append(row)\n",
      "return\n",
      "\tresults\n",
      "com\tfrequência,\tteremos\tuma\tmatriz\t\n",
      "x\n",
      "\tde\tvariáveis\tde\tentrada\te\tum\tvetor\t\n",
      "y\n",
      "\tde\n",
      "variáveis\tde\tsaída.\tnesse\tcaso,\tprecisamos\tnos\tcertificar\tde\tcolocar\tos\tvalores\n",
      "correspondentes\ttanto\tnos\tdados\tem\ttreinamento\tcomo\tnos\tdados\tde\tteste:\n",
      "def\ttrain_test_split(x,\ty,\ttest_pct):\n",
      "data\t=\tzip(x,\ty)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpar\tde\tvalores\tcorrespondentes\n",
      "train,\ttest\t=\tsplit_data(data,\t1\t-\ttest_pct)\t\t\n",
      "#\tdivide\to\tconjunto\tde\tpares\tde\tdados\n",
      "x_train,\ty_train\t=\tzip(*train)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttruque\tmágico\tde\tun-zip\t(descompactação)\n",
      "x_test,\ty_test\t=\tzip(*test)\n",
      "return\tx_train,\tx_test,\ty_train,\ty_test\n",
      "a\tfim\tde\tfazer\talgo\tcomo:\n",
      "model\t=\tsomekindofmodel()x_train,\tx_test,\ty_train,\ty_test\t=\ttrain_test_split(xs,\tys,\t0.33)\n",
      "model.train(x_train,\ty_train)\n",
      "performance\t=\tmodel.test(x_test,\ty_test)\n",
      "se\to\tmodelo\tfoi\tsobreajustado\tpara\tos\tdados\tem\ttreinamento,\tentão\tele\tdeve\n",
      "desempenhar\tmal\tsobre\tos\tdados\tde\tteste\t(completamente\tseparados).\tde\toutra\n",
      "maneira,\tse\tele\tdesempenha\tbem\tsobre\tos\tdados\tde\tteste,\tentão\tvocê\tpode\tficar\n",
      "mais\tconfiante\tque\tele\testá\t\n",
      "ajustado\n",
      "\tem\tvez\tde\t\n",
      "sobreajustado\n",
      ".\n",
      "porém,\texistem\tduas\tformas\tde\tdar\ttudo\terrado.\n",
      "a\tprimeira\té\tse\texistirem\tpadrões\tcomuns\taos\tdados\tde\tteste\te\tde\ttreinamento\n",
      "que\tnão\tseriam\tgeneralizados\tem\tum\tconjunto\tmaior\tde\tdados.\n",
      "por\texemplo,\timagine\tque\tseu\tconjunto\tde\tdados\tconsiste\tda\tatividade\tdo\n",
      "usuário,\tuma\tlinha\tpor\tusuário\tpor\tsemana.\tem\ttal\tcaso,\ta\tmaioria\tdos\tusuários\n",
      "aparecerá\tem\tambos\tos\tdados\tde\tteste\te\tde\ttreinamento\te\talguns\tmodelos\ttalvez\n",
      "aprendessem\ta\t\n",
      "identificar\n",
      "\tos\tusuários\tem\tvez\tde\tdescobrir\trelações\tenvolvendo\n",
      "atributos\n",
      ".\tnão\té\tde\tgrande\tpreocupação,\tapesar\tde\tter\tacontecido\tcomigo\tuma\n",
      "vez.\n",
      "um\tproblema\tmaior\té\tse\tvocê\tusar\ta\tdivisão\tde\ttestes/treinamento\tnão\tapenas\n",
      "para\tavaliar\tum\tmodelo\tmas,\ttambém,\tpara\t\n",
      "escolher\n",
      "\tentre\tos\tvários\tmodelos.\n",
      "nesse\tcaso,\tembora\tcada\tmodelo\tindividual\tpossa\tnão\tser\tsobreajustado,\to\n",
      "“escolha\tum\tmodelo\tque\tdesempenhe\tmelhor\tnos\tdados\tde\tteste”\té\tum\tquase\n",
      "treinamento\tque\tfaz\tcom\tque\to\tconjunto\tde\ttestes\tfuncione\tcomo\tum\tsegundo\n",
      "conjunto\tde\ttreinamento.\t(é\tclaro\tque\to\tmodelo\tque\ttiver\tmelhor\tdesempenho\tno\n",
      "teste\tterá\tum\tmelhor\tdesempenho\tno\tconjunto\tde\tteste.)\n",
      "em\tuma\tsituação\tcomo\tessa,\tvocê\tdeveria\tdividir\tos\tdados\tem\ttrês\tpartes:\tum\n",
      "conjunto\tde\t\n",
      "treinamento\n",
      "\tpara\tconstruir\tmodelos,\tum\tconjunto\tde\t\n",
      "validação\n",
      "\tpara\n",
      "escolher\tentre\tos\tmodelos\ttreinados\te\tum\tconjunto\tde\t\n",
      "teste\n",
      "\tpara\tavaliar\to\tmodelo\n",
      "final.•\n",
      "•\n",
      "•\n",
      "•\n",
      "precisão\n",
      "quando\tnão\testou\tpraticando\tdata\tscience,\teu\tme\taventuro\tna\tmedicina.\te,\tno\n",
      "meu\ttempo\tlivre,\teu\tinventei\tum\tteste\tsimples,\tnão-invasivo\tque\tpode\tser\tfeito\n",
      "com\tum\trecém-nascido\tque\tprediz\t—\tcom\tuma\tprecisão\tmaior\tque\t98%\t—\tse\to\n",
      "recém-nascido\tdesenvolverá\tleucemia.\tmeu\tadvogado\tme\tconvenceu\tde\tque\to\n",
      "teste\tnão\té\tpatenteável,\tportanto\tcompartilharei\tcom\tvocê\tos\tdetalhes\taqui:\n",
      "prever\ta\tleucemia\tse\te\tsomente\tse\to\tnome\tdo\tbebê\tfor\tluke\t(que\tse\tparece\tum\n",
      "pouco\tcom\to\tsom\tde\t\n",
      "leukemia\n",
      ",\tleucemia\tem\tinglês).\n",
      "como\tveremos\ta\tseguir,\tesse\tteste\tpossui\tmesmo\tmais\tde\t98%\tde\tprecisão.\n",
      "apesar\tdisso,\té\tum\tteste\tincrivelmente\testúpido\te\tuma\tboa\tilustração\tdo\tmotivo\n",
      "pelo\tqual\tnós\tnão\tusamos\t“precisão”\tpara\tmedir\ta\teficiência\tde\tum\tmodelo.\n",
      "imagine\tconstruir\tum\tmodelo\tpara\tfazer\tuma\tavaliação\t\n",
      "binária\n",
      ".\tesse\te-mail\té\n",
      "spam?\tdeveríamos\tcontratar\teste\tcandidato?\teste\tviajante\té\tum\tterrorista\tem\n",
      "segredo?\n",
      "dado\tum\tconjunto\tde\tdados\tetiquetados\te\tum\tmodelo\tpreditivo,\tcada\tponto\tde\n",
      "dados\tse\testabelece\tem\tquatro\tcategorias:\n",
      "positivo\tverdadeiro:\t“esta\tmensagem\té\tspam\te\tprevimos\tspam\n",
      "corretamente.”\n",
      "positivo\tfalso\t(erro\ttipo\t1):\t“esta\tmensagem\tnão\té\tspam,\tmas\tprevimos\n",
      "que\tera.”\n",
      "negativo\tfalso\t(erro\ttipo\t2):\t“esta\tmensagem\té\tspam,\tmas\tprevimos\tque\n",
      "não\tera.”\n",
      "negativo\tverdadeiro:\t“esta\tmensagem\tnão\té\tspam\te\tprevimos\tque\tnão\n",
      "era.”\n",
      "representamos\tessa\tcontagem\tem\tuma\t\n",
      "matriz\tde\tconfusão\n",
      ":\n",
      "\t\n",
      "spam\n",
      "não\té\tspam\n",
      "premissa\n",
      "“spam”\n",
      "positivo\n",
      "verdadeiro\n",
      "positivo\tfalsopremissa\n",
      "“não\té\n",
      "spam”\n",
      "negativo\n",
      "falso\n",
      "negativo\n",
      "verdadeiro\n",
      "vamos\tver\tcomo\tmeu\tteste\tde\tleucemia\tse\tencaixa\tnessa\testrutura.\tpor\tagora,\n",
      "aproximadamente\t5\tbebês\tde\t1000\tse\tchamam\tluke\t(\n",
      "http://bit.ly/1cchaqt\n",
      ").\ta\n",
      "incidência\tde\tsempre\tda\tleucemia\té\tde\taproximadamente\t1,4%,\tou\t14\tde\tcada\n",
      "1000\tpessoas\t(\n",
      "http://1.usa.gov/1ycorjo\n",
      ").\n",
      "se\tacreditarmos\tque\tesses\tdois\tfatores\tsão\tindependentes\te\taplicar\tmeu\tteste\n",
      "“luke\tpara\tleucemia”\tem\tum\tmilhão\tde\tpessoas,\tesperaríamos\tver\tuma\tmatriz\n",
      "de\tconfusão\tcom\testa:\n",
      "podemos\tusar\tisso\tentão\tpara\tcomputar\tdiversas\testatísticas\tsobre\to\tdesempenho\n",
      "do\tmodelo.\tpor\texemplo,\ta\t\n",
      "acurácia\n",
      "\té\tdefinida\tcomo\ta\tfração\tde\tpremissas\n",
      "corretas:\n",
      "def\n",
      "\taccuracy(tp,\tfp,\tfn,\ttn):\n",
      "correct\t=\ttp\t+\ttn\n",
      "total\t=\ttp\t+\tfp\t+\tfn\t+\ttn\n",
      "return\n",
      "\tcorrect\t/\ttotal\n",
      "print\n",
      "\taccuracy(70,\t4930,\t13930,\t981070)\t\t\t\t\t\t\n",
      "#\t0.98114\n",
      "parece\tum\tnúmero\tbem\tinteressante.\tmas,\tevidentemente,\tnão\té\tum\tbom\tteste,\to\n",
      "que\tsignifica\tque\tnão\tdeveríamos\tcolocar\tmuita\tcrença\tna\tacurácia\tbruta.\n",
      "é\tcomum\tconsiderar\ta\tcombinação\tde\t\n",
      "precisão\te\tsensibilidade\n",
      ".\texatidão\n",
      "significa\to\tquão\tprecisas\tnossas\tprevisões\t\n",
      "positivas\n",
      "\teram:\n",
      "def\n",
      "\tprecision(tp,\tfp,\tfn,\ttn):\n",
      "return\n",
      "\ttp\t/\t(tp\t+\tfp)\n",
      "print\n",
      "\tprecision(70,\t4930,\t13930,\t981070)\t\t\t\t\t\t\n",
      "#\t0.014\n",
      "a\tsensibilidade\tmede\tqual\tfração\tdos\tpositivos\tnossos\tmodelos\tidentificam:\n",
      "def\n",
      "\trecall(tp,\tfp,\tfn,\ttn):\n",
      "return\n",
      "\ttp\t/\t(tp\t+\tfn)print\n",
      "\trecall(70,\t4930,\t13930,\t981070)\t\t\t\t\t\t\n",
      "#\t0.005\n",
      "ambos\tsão\tnúmeros\tterríveis,\trefletindo\tum\tmodelo\tterrível.\n",
      "às\tvezes,\tprecisão\te\tsensibilidade\tsão\tcombinados\tao\t\n",
      "f1\tscore\n",
      ",\tdefinido\tassim:\n",
      "def\n",
      "\tf1_score(tp,\tfp,\tfn,\ttn):\n",
      "p\t=\tprecision(tp,\tfp,\tfn,\ttn)\n",
      "r\t=\trecall(tp,\tfp,\tfn,\ttn)\n",
      "return\n",
      "\t2\t*\tp\t*\tr\t/\t(p\t+\tr)\n",
      "essa\té\ta\t\n",
      "média\tharmônica\t(\n",
      "http://en.wikipedia.org/wiki/harmonic_mean\n",
      ")\n",
      "\tda\n",
      "acurácia\te\tsensibilidade\te\tse\tacha\tnecessariamente\tencontrada\tentre\telas.\n",
      "geralmente,\ta\tescolha\tde\tum\tmodelo\timplica\tem\tum\tcompromisso\tentre\n",
      "acurácia\te\tsensibilidade.\tum\tmodelo\tque\tprevê\t“sim”\tquando\tse\testá\tum\tpouco\n",
      "confiante\tprovavelmente\tterá\t\n",
      "uma\tsensibilidade\talta\tmas\tuma\tacurácia\tbaixa;\tum\n",
      "modelo\tque\tprevê\t“sim”\tsomente\tquando\testá\textremamente\tconfiante\n",
      "provavelmente\tterá\tuma\tsensibilidade\tbaixa\te\tuma\tacurácia\talta.\n",
      "como\talternativa,\tvocê\tpode\tpensar\tnisso\tcomo\tuma\ttroca\tentre\tpositivos\te\n",
      "negativos\tfalsos.\tdizer\t“sim”\tcom\tmuita\tfrequência\ttrará\tmuitos\tpositivos\tfalsos;\n",
      "dizer\t“não”\tcom\tmuita\tfrequência\ttrará\tmuitos\tnegativos\tfalsos.\n",
      "imagine\tque\texistiram\tdez\tfatores\tde\trisco\tpara\ta\tleucemia\te\tque,\tquanto\tmais\n",
      "você\tos\ttenha,\tmais\tvocê\testará\tpropenso\ta\tdesenvolver\tleucemia.\tnesse\tcaso,\n",
      "você\tpode\timaginar\tuma\tcontinuidade\tde\ttestes:\t“prever\tleucemia\tse\thouver\tao\n",
      "menos\tum\tfator\tde\trisco”,\t“prever\tleucemia\tse\thouver\tao\tmenos\tdois\tfatores\tde\n",
      "risco”\te\tassim\tpor\tdiante.\tconforme\to\tlimite\taumenta,\tvocê\taumenta\ta\texatidão\n",
      "do\tteste\t(desde\tque\tas\tpessoas\tcom\tmais\tfatores\tde\trisco\tsejam\tmais\tpropensas\ta\n",
      "desenvolver\ta\tdoença)\te\tdiminui\ta\tconfirmação\tdo\tteste\t(uma\tvez\tque\tcada\tvez\n",
      "menos\tpacientes\tda\tdoença\tchegarão\tao\tlimite).\tem\tcasos\tcomo\tesse,\tescolher\to\n",
      "limite\tcerto\té\tuma\tquestão\tde\tencontrar\to\tcompromisso\tcerto.compromisso\tentre\tpolarização\te\tvariância\n",
      "outra\tmaneira\tde\tpensar\tsobre\to\tproblema\tde\tsobreajuste\té\tum\tcompromisso\n",
      "entre\tpolarização\te\tvariância.\n",
      "ambas\tsão\tmedidas\tdo\tque\taconteceria\tse\tvocê\tfosse\ttreinar\tseu\tmodelo\n",
      "novamente\tmuitas\tvezes\tem\tdiferentes\tconjuntos\tde\tdados\tde\ttreinamento\t(da\n",
      "mesma\tpopulação).\n",
      "por\texemplo,\to\tmodelo\tpolinomial\tde\tgrau\t0\tem\t“sobreajustando\te\tsub-\n",
      "ajustando”\tna\tpágina\t142\tcometerá\tmuitos\terros\tpara\tqualquer\tconjunto\tde\n",
      "dados\tem\ttreinamento\t(tirados\tda\tmesma\tpopulação),\to\tque\tsignifica\tque\tele\n",
      "possui\tuma\tpolarização\talta.\tporém,\tquaisquer\tdois\tconjuntos\tde\ttreinamento\n",
      "escolhidos\taleatoriamente\tdeveriam\tfornecer\tmodelos\tsimilares\t(uma\tvez\tque\n",
      "quaisquer\tdois\tconjuntos\tde\ttreinamento\tescolhidos\taleatoriamente\tdeveriam\tter\n",
      "valores\tmédios\tbem\tsimilares).\tentão\tdizemos\tque\tele\tpossui\tuma\tbaixa\n",
      "variância\n",
      ".\tpolarização\talta\te\tvariância\tbaixa\tgeralmente\tpertencem\tao\tsub-\n",
      "ajuste.\n",
      "por\toutro\tlado,\to\tmodelo\tpolinomial\tde\tgrau\t9\tse\tencaixa\tno\tconjunto\tde\n",
      "treinamento\tcom\tperfeição.\tpossui\tpolarização\tbaixa,\tmas\tvariância\tmuito\talta\n",
      "(quaisquer\tdois\tconjuntos\tem\ttreinamento\tdariam\torigem\ta\tmodelos\tbem\n",
      "diferentes).\teles\tcorrespondem\tao\tsobreajuste.\n",
      "pensar\tsobre\tproblemas\tde\tmodelos\tdessa\tforma\tpode\tajudar\ta\tdescobrir\to\tque\n",
      "fazer\tquando\tseu\tmodelo\tnão\tfunciona\tmuito\tbem.\n",
      "se\to\tseu\tmodelo\tpossui\ta\tpolarização\talta\t(o\tque\tsignifica\tque\tele\tnão\tpossui\tum\n",
      "bom\tdesempenho\tno\tseu\tconjunto\tem\ttreinamento),\talgo\tmais\ta\ttentar\té\n",
      "adicionar\tmais\tcaracterísticas.\tir\tdo\tmodelo\tpolinomial\tde\tgrau\t0\tem\n",
      "“sobreajustando\te\tsub-ajustando”\tna\tpágina\t142\tpara\to\tmodelo\tpolinomial\tde\n",
      "grau\t1\tfoi\tuma\tgrande\tmelhoria.\n",
      "se\to\tseu\tmodelo\ttem\tvariância\talta,\tentão\tvocê\tpode\tde\tmodo\tsimilar\t\n",
      "remover\n",
      "características.\tmas\toutra\tsolução\tseria\tobter\tmais\tdados\t(se\tpuder).figura\t11-2.\treduzindo\ta\tvariância\tcom\tmais\tdados\n",
      "na\t\n",
      "figura\t11-2\n",
      ",\tajustamos\tum\tpolinômio\tde\tgrau\t9\tpara\tdiferentes\tamostras.\to\n",
      "modelo\tajustado\tcom\tbase\tnos\t10\tpontos\tde\tdados\testá\tem\ttodo\tlugar,\tcomo\n",
      "vimos\tanteriormente\tse\ttreinássemos\tcom\t100\tpontos\tde\tdados,\thaveria\tmuito\n",
      "menos\tsobreajuste.\te\to\tmodelo\ttreinado\ta\tpartir\tdos\t1000\tpontos\tde\tdados\té\n",
      "muito\tparecido\tcom\to\tmodelo\tde\tgrau\t1.\n",
      "mantendo\tuma\tconstante\tna\tcomplexidade\tdo\tmodelo,\tquanto\tmais\tdados\thá,\n",
      "mais\tdifícil\té\tpara\tsobreajustar.\n",
      "por\toutro\tlado,\tmais\tdados\tnão\tajuda\tcom\ta\tpolarização.\tse\tseu\tmodelo\tnão\tusa\n",
      "recursos\tsuficientes\tpara\tcapturar\tregularidades\tnos\tdados,\tcolocar\tmais\tdados\n",
      "não\tajudará.•\n",
      "•\n",
      "•\n",
      "recursos\textração\te\tseleção\tde\tcaracterística\n",
      "como\tmencionamos,\tquando\tos\tseus\tdados\tnão\ttiverem\tcaracterísticas\n",
      "suficientes,\té\tpossível\tque\tseu\tmodelo\tsub-ajuste.\te\tquando\tseus\tdados\tpossuem\n",
      "muitas\tcaracterísticas,\tfica\tfácil\tde\tsobreajustar.\tmas\to\tque\tsão\tcaracterísticas\te\n",
      "de\tonde\telas\tvêm?\n",
      "características\n",
      "\tsão\tquaisquer\tentradas\tque\tfornecemos\tao\tnosso\tmodelo.\n",
      "no\tcaso\tmais\tsimples,\tas\tcaracterísticas\tsão\tfornecidas\tapenas\ta\tvocê.\tse\tvocê\n",
      "quiser\tprever\to\tsalário\tde\talguém\tbaseado\tem\tseus\tanos\tde\texperiência,\tentão\n",
      "anos\tde\texperiência\té\ta\túnica\tcaracterística\tque\tvocê\tpossui.\n",
      "(apesar\tde\tque,\tcomo\tvimos\tem\t“sobreajuste\te\tsub-ajuste”\tna\tpágina\t142,\tvocê\n",
      "também\tpode\tconsiderar\tadicionar\tanos\tcomo\texperiência\tao\tquadrado,\tao\tcubo,\n",
      "e\tassim\tpor\tdiante\tse\tisso\tajudar\ta\tconstruir\tum\tmodelo\tmelhor.)\n",
      "as\tcoisas\tficam\tmais\tinteressantes\tconforme\tseus\tdados\tficam\tmais\n",
      "complicados.\timagine\ttentar\tconstruir\tum\tfiltro\tde\tspam\tpara\tprever\tse\tum\te-\n",
      "mail\té\tlixo\tou\tnão.\ta\tmaioria\tdos\tmodelos\tnão\tsaberá\to\tque\tfazer\tcom\to\te-mail\n",
      "em\tsi,\tcru,\tque\té\tapenas\tuma\tcoleção\tde\ttexto.\tvocê\tterá\tque\textrair\tas\n",
      "características.\tpor\texemplo:\n",
      "esse\te-mail\tcontém\ta\tpalavra\t“viagra”?\n",
      "quantas\tvezes\ta\tletra\td\taparece?\n",
      "qual\tera\to\tdomínio\tdo\tremetente?\n",
      "a\tprimeira\té\tsomente\tsim\tou\tnão,\to\tque\tremete\ta\t1\tou\t0.\ta\tsegunda\té\tum\n",
      "número\te\ta\tterceira\té\tuma\tescolha\tde\tum\tleque\tde\topções.\n",
      "quase\tsempre,\textrairemos\tcaracterísticas\tdos\tnossos\tdados\tque\tcairão\tem\tuma\n",
      "dessas\ttrês\tcategorias.\talém\tdo\tmais,\to\ttipo\tde\tcaracterísticas\tque\ttemos\n",
      "restringe\to\ttipo\tde\tmodelos\tque\tpodemos\tusar.\n",
      "o\tclassificador\tnaive\tbayes\tque\tconstruiremos\tno\t\n",
      "capítulo\t13\n",
      "\té\tdestinado\tàs\n",
      "características\tsim-ou-não,\tcomo\to\tprimeiro\tna\tlista\tanterior.\n",
      "modelos\tde\tregressão,\tcomo\testudaremos\tnos\t\n",
      "capítulos\t14\n",
      "\te\t\n",
      "16\n",
      ",\trequeremcaracterísticas\tnuméricas\t(incluindo\tvariáveis\tpostiças\t(dummy)\tde\t0s\te\t1s).\n",
      "e\tas\tárvores\tde\tdecisão,\tas\tquais\tveremos\tno\t\n",
      "capítulo\t17\n",
      ",\tpodem\tlidar\tcom\n",
      "dados\tnuméricos\tou\tcategóricos.\n",
      "apesar\tde\ttentarmos\tcriar\tcaracterísticas\tno\texemplo\tdo\tfiltro\tde\tspam,\talgumas\n",
      "vezes\ttentaremos\tremovê-las.\n",
      "por\texemplo,\tsuas\tentradas\tpodem\tser\tvetores\tde\tvárias\tcentenas\tde\tnúmeros.\n",
      "dependendo\tda\tsituação,\ttalvez\tseja\tapropriado\tdiminuir\tpara\tapenas\tas\n",
      "dimensões\timportantes\t(como\tem\t“redução\tda\tdimensionalidade”\tna\tpágina\n",
      "134)\te\tusar\tsomente\tum\tnúmero\tpequeno\tde\tcaracterísticas.\tou\ttalvez\tseria\n",
      "apropriado\tusar\tuma\ttécnica\t(como\tregularização\tem\t“regularização”\tna\tpágina\n",
      "186)\tque\tpenaliza\tos\tmodelos\tquanto\tmais\tcaracterísticas\teles\tusam.\n",
      "como\tescolhemos\tessas\tcaracterísticas?\taqui\té\tonde\tuma\tcombinação\tde\n",
      "experiência\n",
      "\te\t\n",
      "domínio\tde\tentendimento\n",
      "\tentra\tem\tjogo.\tse\tvocê\trecebe\tmuitos\te-\n",
      "mails,\tlogo\té\tpossível\tque\tvocê\ttenha\tpercebido\ta\tpresença\tde\tcertas\tpalavras\n",
      "como\tum\tindicador\tde\tspam.\ttambém\t\n",
      "pode\tter\tpercebido\tque\to\tnúmero\tde\td\n",
      "pode\tnão\tser\tum\tindicador\tde\tspam.\tmas,\tno\tgeral,\tvocê\tterá\tque\ttentar\tmétodos\n",
      "diferentes,\to\tque\tfaz\tparte\tda\tdiversão.•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "continue\tlendo!\tos\tpróximos\tcapítulos\tsão\tsobre\tfamílias\tdiferentes\tde\n",
      "modelos\tde\taprendizado\tde\tmáquina.\n",
      "o\tcurso\tmachine\tlearning\tda\tcoursera\té\to\tmooc\t(do\tinglês\t\n",
      "massive\n",
      "open\tonline\tcourse\n",
      ")\toriginal\te\té\tum\tbom\tlugar\tpara\tum\tentendimento\n",
      "mais\tprofundo\tsobre\taprendizado\tde\tmáquina.\to\tmooc\tmachine\n",
      "learning\tda\tcaltech\ttambém\té\tbom.\n",
      "the\t\n",
      "elements\tof\tstatistical\tlearning\n",
      "\té\tum\tlivro\tdidático\tcanônico\tque\n",
      "pode\tser\tbaixado\tgratuitamente\t(\n",
      "http://stanford.io/1ycoxbo\n",
      ").\tmas\testeja\n",
      "avisado:\ttem\t\n",
      "muita\n",
      "\tmatemática.capítulo\t12\n",
      "k–vizinhos\tmais\tpróximos\n",
      "se\tvocê\tquiser\tperturbar\tseus\tvizinhos,\tdiga\ta\tverdade\tsobre\teles\n",
      ".\n",
      "—pietro\taretino\n",
      "imagine\tque\tvocê\testá\ttentando\tprever\tcomo\teu\tvou\tvotar\tnas\tpróximas\teleições\n",
      "presidenciais.\tse\tvocê\tnão\tsabe\tmais\tnada\tsobre\tmim\t(e\tse\tvocê\ttiver\tos\tdados),\n",
      "uma\tabordagem\tlógica\té\tconsiderar\tcomo\tmeus\t\n",
      "vizinhos\n",
      "\testão\tplanejando\tvotar.\n",
      "como\teu\tmoro\tno\tcentro\tde\tseattle,\tmeus\tvizinhos\testão\tplanejando\tvotar\tno\n",
      "candidato\tdemocrata,\to\tque\tsugere\tque\to\t“candidato\tdemocrata”\té\tum\tbom\n",
      "palpite\tpra\tmim\ttambém.\n",
      "agora,\timagine\tque\tvocê\tsaiba\tmais\tsobre\tmim\tdo\tque\tsomente\tonde\teu\tmoro\n",
      "—\ttalvez\tvocê\tsaiba\tminha\tidade,\tmeus\trendimentos,\tquantos\tfilhos\teu\ttenho,\te\n",
      "assim\tpor\tdiante.\tconsiderando\tque\to\tmeu\tcomportamento\té\tinfluenciado\t(ou\n",
      "caracterizado)\tpor\ttais\tcoisas\tao\tmáximo,\tconsiderar\tapenas\tmeus\tvizinhos\tque\n",
      "estão\tpróximos\tde\tmim\tem\ttodas\tessas\tdimensões\tparece\tser\tuma\tclassificação\n",
      "melhor\tdo\tque\tconsiderar\ttodos\tos\tmeus\tvizinhos.\tessa\té\ta\tideia\tpor\ttrás\tda\n",
      "classificação\tdos\tvizinhos\tmais\tpróximos\n",
      ".•\n",
      "•\n",
      "o\tmodelo\n",
      "os\tvizinhos\tmais\tpróximos\té\tum\tdos\tmodelos\tpreditivos\tmais\tsimples\tque\n",
      "existe.\tele\tnão\tpossui\tpremissas\tmatemáticas\te\tnão\trequer\tnenhum\ttipo\tde\n",
      "maquinário\tpesado.\tele\tapenas\trequer:\n",
      "uma\tnoção\tde\tdistância\n",
      "uma\tpremissa\tde\tque\tpontos\tque\testão\tperto\tum\tdo\toutro\tsão\tsimilares\n",
      "a\tmaioria\tdas\ttécnicas\tque\tveremos\tneste\tlivro\tconsideram\to\tconjunto\tde\tdados\n",
      "como\tum\ttodo\ta\tfim\tde\taprender\tpadrões\tnos\tdados.\tos\tvizinhos\tmais\tpróximos,\n",
      "por\toutro\tlado,\trejeitam\tmuitas\tinformações\tconscientemente,\tuma\tvez\tque\ta\n",
      "previsão\tpara\tcada\tponto\tnovo\tdepende\tsomente\tde\talguns\tpontos\tmais\n",
      "próximos.\n",
      "mais\tainda,\tos\tvizinhos\tmais\tpróximos\tprovavelmente\tnão\tvão\tlhe\tajudar\ta\n",
      "entender\tos\tfatores\tdeterminantes\tde\tquaisquer\tfenômenos\tos\tquais\tvocê\testeja\n",
      "considerando.\tprever\tos\tmeus\tvotos\tbaseados\tnos\tvotos\tdos\tmeus\tvizinhos\tnão\n",
      "lhe\tdiz\tmuito\tsobre\to\tque\tme\tfaz\tvotar\tdo\tmeu\tjeito,\tenquanto\tque\talgum\tmodelo\n",
      "alternativo\tque\tprevê\tmeu\tvoto\tbaseado\t(digamos)\tno\tmeu\tsalário\te\tno\tmeu\n",
      "estado\tcivil\ttalvez\tpossa\tdizer.\n",
      "em\tuma\tsituação\tgeral,\ttemos\talguns\tpontos\tde\tdados\te\tum\tconjunto\tde\trótulos\n",
      "correspondentes.\tos\trótulos\tpodem\tser\t\n",
      "true\n",
      "\te\t\n",
      "false\n",
      ",\tindicando\tse\tcada\tentrada\n",
      "satisfaz\talgumas\tcondições\tcomo\t“é\tspam?”\tou\t“é\tvenenoso?”\tou\t“seria\n",
      "prazeroso\tassistir?”\tou\teles\tpoderiam\tser\tcategorias,\tcomo\tclassificações\n",
      "indicativas\tde\tfilmes\t(l,\t10,\t12,\t14,\t16,\t18).\tou\teles\tpoderiam\tser\tnomes\tdos\n",
      "candidatos\tà\tpresidência.\tou\teles\tpoderiam\tser\tlinguagens\tde\tprogramação\n",
      "preferidas.\n",
      "no\tnosso\tcaso,\tos\tpontos\tde\tdados\tserão\tvetores,\to\tque\tsignifica\tque\tpodemos\n",
      "usar\ta\tfunção\t\n",
      "distance\n",
      "\tdo\t\n",
      "capítulo\t4\n",
      ".\n",
      "digamos\tque\tescolhemos\tum\tnúmero\t\n",
      "k\n",
      "\tcomo\t3\tou\t5.\tentão,\tquando\tqueremos\n",
      "classificar\talguns\tnovos\tpontos\tde\tdados,\tencontramos\tos\tpontos\trotulados\t\n",
      "k\n",
      "mais\tpróximos\te\tos\tdeixamos\tvotar\tna\tnova\tsaída.•\n",
      "•\n",
      "•\n",
      "para\tfazer\tisso,\tprecisaremos\tde\tuma\tfunção\tque\tconte\tos\tvotos.\tuma\n",
      "possibilidade\té:\n",
      "def\n",
      "\traw_majority_vote(labels):\n",
      "votes\t=\tcounter(labels)\n",
      "winner,\t_\t=\tvotes.most_common(1)[0]\n",
      "return\n",
      "\twinner\n",
      "mas\tisso\tnão\tfaz\tnada\tde\tinteligente\tcom\tas\trelações.\tpor\texemplo,\timagine\tque\n",
      "estamos\tclassificando\tos\tfilmes\te\tos\tcinco\tfilmes\tmais\tpróximos\tsão\n",
      "classificados\tem\tl,\tl,\t10,\t10,\t12.\tl\te\t10\ttêm\tdois\tvotos.\tnesse\tcaso,\ttemos\n",
      "várias\topções:\n",
      "escolher\tum\tdos\tvencedores\taleatoriamente.\n",
      "ponderar\tos\tvotos\tà\tdistância\te\tescolher\to\tvencedor\tmais\tvotado.\n",
      "reduzir\t\n",
      "k\n",
      "\taté\tencontrarmos\tum\tvencedor\túnico.\n",
      "implementaremos\to\tterceiro:\n",
      "def\n",
      "\tmajority_vote(labels):\n",
      "\"\"\"presume\tque\tas\tetiquetas\tsão\tordenadas\tdo\tmais\tpróximo\tpara\to\tmais\tdistante\"\"\"\n",
      "vote_counts\t=\tcounter(labels)\n",
      "winner,\twinner_count\t=\tvote_counts.most_common(1)[0]\n",
      "num_winners\t=\tlen([count\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tcount\t\n",
      "in\n",
      "\tvote_counts.values()\n",
      "\t\t\t\t\t\t\n",
      "if\n",
      "\tcount\t==\twinner_count])\n",
      "if\n",
      "\tnum_winners\t==\t1:\n",
      "return\n",
      "\twinner\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tvencedor\túnico,\tentão\to\tdevolve\n",
      "else\n",
      ":\n",
      "return\n",
      "\tmajority_vote(labels[:-1])\t\n",
      "#\ttenta\tnovamente\tsem\to\tmais\tdistante\n",
      "é\tcerteza\tque\tesse\tmétodo\tfuncionará\tem\talgum\tmomento,\tjá\tque\tna\tpior\tdas\n",
      "hipóteses\treduziríamos\tpara\tsomente\tum\trótulo\te,\tnesse\tcaso,\tele\tvence.\n",
      "com\tessa\tfunção\té\tfácil\tcriar\tum\tclassificador:\n",
      "def\tknn_classify(k,\tlabeled_points,\tnew_point):\n",
      "\"\"\"cada\tponto\trotulado\tdeveria\tser\tum\tpar\t(point,\tlabel)\"\"\"\n",
      "#\torganiza\tos\tpontos\trotulados\tdo\tmais\tpróximo\tpara\to\tmais\tdistante\n",
      "by_distance\t=\tsorted(labeled_points,\n",
      "\t\t\t\t\t\t\tkey=lambda\t(point,\t_):\tdistance(point,\tnew_point))\n",
      "#\tencontra\tos\trótulos\tpara\tos\tk\tmais\tpróximos\n",
      "k_nearest_labels\t=\t[label\tfor\t_,\tlabel\tin\tby_distance[:k]]#\te\tos\tdeixa\tvotar\n",
      "return\tmajority_vote(k_nearest_labels)\n",
      "vamos\tver\tcomo\tisso\tfunciona.exemplo:\tlinguagens\tfavoritas\n",
      "o\tresultado\tda\tprimeira\tpesquisa\tde\tusuários\tda\tdatasciencester\testá\tde\tvolta,\te\n",
      "descobrimos\tas\tlinguagens\tde\tprogramação\tpreferidas\tdos\tnossos\tusuários\tem\n",
      "algumas\tcidades\tgrandes:\n",
      "#\tcada\tentrada\té\t([longitude,\tlatitude],\tfavorite_language)\n",
      "cities\t=\t[([-122.3,\t47.53],\t\"python\"),\t\t\n",
      "#\tseattle\n",
      "\t\t\t([\t-96.85,\t32.85],\t\"java\"),\t\t\t\n",
      "#\taustin\n",
      "\t\t\t([\t-89.33,\t43.13],\t\"r\"),\t\t\t\t\t\t\n",
      "#\tmadison\n",
      "\t\t\t\n",
      "#\t…\te\tassim\tpor\tdiante\n",
      "]\n",
      "o\tvice-presidente\tdo\tenvolvimento\tcomunitário\tquer\tsaber\tse\tpodemos\tusar\tesses\tresultados\tpara\n",
      "prever\ta\tlinguagem\tde\tprogramação\tpreferida\tpara\tlugares\tque\tnão\tfizeram\tparte\tda\tpesquisa.\n",
      "como\tsempre,\tum\tprimeiro\tbom\tpasso\té\tdemarcar\tos\tdados\t(\n",
      "figura\t12-1\n",
      "):\n",
      "#\ta\tchave\té\ta\tlinguagem,\to\tvalor\té\to\tpar\t(longitudes,\tlatitudes)\n",
      "plots\t=\t{\t\"java\"\t:\t([],\t[]),\t\"python\"\t:\t([],\t[]),\t\"r\"\t:\t([],\t[])\t}\n",
      "#\tqueremos\tque\tcada\tlinguagem\ttenha\tmarcador\te\tcor\tdiferentes\n",
      "markers\t=\t{\t\"java\"\t:\t\"o\",\t\"python\"\t:\t\"s\",\t\"r\"\t:\t\"^\"\t}\n",
      "colors\t=\t{\t\"java\"\t:\t\"r\",\t\"python\"\t:\t\"b\",\t\"r\"\t:\t\"g\"\t}\n",
      "for\t(longitude,\tlatitude),\tlanguage\tin\tcities:\n",
      "\t\tplots[language][0].append(longitude)\n",
      "\t\tplots[language][1].append(latitude)\n",
      "#\tcria\tuma\tsérie\tde\tdispersão\tpara\tcada\tlinguagem\n",
      "for\tlanguage,\t(x,\ty)\tin\tplots.iteritems():\n",
      "\t\tplt.scatter(x,\ty,\tcolor=colors[language],\tmarker=markers[language],\n",
      "\t\t\t\t\t\t\t\t\tlabel=language,\tzorder=10)\n",
      "plot_state_borders(plt)\t\t\t\t\t\t\n",
      "#\tfinge\tque\ttemos\tuma\tfunção\tque\tfaça\tisso\n",
      "plt.legend(loc=0)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tdeixa\tmatplotlib\tescolher\to\tlocal\n",
      "plt.axis([-130,-60,20,55])\t\t\n",
      "#\tajusta\tos\teixos\n",
      "plt.title(\"linguagens\tde\tprogramação\tpreferidas\")\n",
      "plt.show()1.\n",
      "2.\n",
      "3.\n",
      "figura\t12-1.\tlinguagens\tde\tprogramação\tpreferidas\n",
      "você\tdeve\tter\tnotado\ta\tchamada\tpara\t\n",
      "plot_state_borders()\n",
      ",\tuma\tfunção\tque\tainda\tnão\n",
      "definimos.\thá\tuma\timplementação\tna\tpágina\tdo\tlivro\tno\tgithub\n",
      "(\n",
      "http://bit.ly/1ycp2m8\n",
      "),\te\té\tum\tbom\texercício\tpara\ttentar\tfazer\tsozinho:\n",
      "procure\tna\tinternet\tpor\talgo\tcomo\t\n",
      "fronteiras\tdos\testados\n",
      "latitude\tlongitude\n",
      ".\n",
      "converta\tquaisquer\tdados\tque\tvocê\tencontrar\tem\tuma\tlista\tde\n",
      "segmentos\t[(long1,\tlat1),\t(long2,\tlat2)].\n",
      "use\t\n",
      "plt.plot()\n",
      "\tpara\tdesenhar\tos\tsegmentos.\n",
      "já\tque\tos\tlugares\tmais\tperto\ttendem\ta\tgostar\tda\tmesma\tlinguagem,\tos\t\n",
      "k-\n",
      "vizinhos\n",
      "mais\tpróximos\tparecem\tser\tuma\tboa\tescolha\tpara\tum\tmodelo\tpreditivo.\n",
      "para\tcomeçar,\tvamos\tver\to\tque\tacontece\tse\ttentarmos\tprever\ta\tlinguagem\n",
      "preferida\tde\tcada\tcidade\tusando\tseus\tvizinhos\tem\tvez\tda\tprópria\tcidade:#\ttenta\tvários\tvalores\tdiferentes\tpara\tk\n",
      "for\n",
      "\tk\t\n",
      "in\n",
      "\t[1,\t3,\t5,\t7]:\n",
      "num_correct\t=\t0\n",
      "for\n",
      "\tcity\t\n",
      "in\n",
      "\tcities:\n",
      "location,\tactual_language\t=\tcity\n",
      "other_cities\t=\t[other_city\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tother_city\t\n",
      "in\n",
      "\tcities\n",
      "\t\t\t\t\t\t\t\t\n",
      "if\n",
      "\tother_city\t!=\tcity]\n",
      "predicted_language\t=\tknn_classify(k,\tother_cities,\tlocation)\n",
      "if\n",
      "\tpredicted_language\t==\tactual_language:\n",
      "\t\t\tnum_correct\t+=\t1\n",
      "print\n",
      "\tk,\t\"neighbor[s]:\",\tnum_correct,\t\"correct\tout\tof\",\tlen(cities)\n",
      "parece\tque\ttrês\tvizinhos\tmais\tpróximos\tdesempenham\tmelhor,\tmostrando\to\n",
      "resultado\tcorreto\tem\t59%\tdas\tvezes:\n",
      "1\t\tvizinho[s]:\t\t40\tcertos\t\tde\t\t75\n",
      "3\t\tvizinho[s]:\t\t44\tcertos\t\tde\t\t75\n",
      "5\t\tvizinho[s]:\t\t41\tcertos\t\tde\t\t75\n",
      "7\t\tvizinho[s]:\t\t35\tcertos\t\tde\t\t75\n",
      "agora\tpodemos\tver\tquais\tregiões\tseriam\tclassificadas\tpara\tquais\tlinguagens\n",
      "dentro\tdo\tesquema\tdos\tvizinhos\tmais\tpróximos.\tpodemos\tfazer\tisso\tao\n",
      "classificar\tuma\trede\tinteira\tcheia\tde\tpontos,\te\tentão\tdemarcá-las\tcomo\tfizemos\n",
      "com\tas\tcidades:\n",
      "plots\t=\t{\t\"java\"\t:\t([],\t[]),\t\"python\"\t:\t([],\t[]),\t\"r\"\t:\t([],\t[])\t}\n",
      "k\t=\t1\t\n",
      "#\tor\t3,\tor\t5,\tor\n",
      "\t...\n",
      "for\n",
      "\tlongitude\t\n",
      "in\n",
      "\trange(-130,\t-60):\n",
      "for\n",
      "\tlatitude\t\n",
      "in\n",
      "\trange(20,\t55):\n",
      "predicted_language\t=\tknn_classify(k,\tcities,\t[longitude,\tlatitude])\n",
      "plots[predicted_language][0].append(longitude)\n",
      "plots[predicted_language][1].append(latitude)\n",
      "por\texemplo,\ta\t\n",
      "figura\t12-2\n",
      "\tmostra\to\tque\tacontece\tquando\tolhamos\tapenas\to\n",
      "vizinho\tmais\tpróximo\t(\n",
      "k\n",
      "\t=\t1).\n",
      "vemos\tmuitas\tmudanças\tabruptas\tde\tuma\tlinguagem\tpara\toutra\tcom\tlimites\tbem\n",
      "acentuados.\tconforme\taumentamos\to\tnúmero\tde\tvizinhos\tpara\ttrês,\tvemos\n",
      "regiões\tmais\tflexíveis\tpara\tcada\tlinguagem\t(\n",
      "figura\t12-3\n",
      ").\n",
      "e\tconforme\taumentamos\tos\tvizinhos\tpara\tcinco,\tos\tlimites\tficam\tcada\tvez\tmaisacentuados\t(\n",
      "figura\t12-4\n",
      ").\n",
      "aqui,\tnossas\tdimensões\tsão\tbastante\tcomparáveis,\tmas\tse\telas\tnão\tfossem\tvocê\n",
      "talvez\tquisesse\tredimensionar\tos\tdados\tcomo\tfizemos\tem\t“redimensionando”\n",
      "na\tpágina\t132.\n",
      "figura\t12-2.\tlinguagens\tde\tprogramação\t1-vizinho\tmais\tpróximoa\tmaldição\tda\tdimensionalidade\n",
      "os\t\n",
      "k-\n",
      "vizinhos\tmais\tpróximos\tentram\tem\tperigo\tem\tdimensões\tmais\taltas\tgraças\n",
      "à\t“maldição\tda\tdimensionalidade”,\tque\tse\tresume\tao\tfato\tde\tque\tespaços\tde\talta\n",
      "dimensão\tsão\t\n",
      "vastos\n",
      ".\tos\tpontos\tem\tespaços\tde\talta\tdimensão\ttendem\ta\tnão\tser\n",
      "próximos\tuns\tdos\toutros.\tuma\tmaneira\tde\tobservar\tisso\té\tgerar\tpares\tde\tpontos\n",
      "aleatórios\tna\t“unidade\tcubo”\td-dimensional\tem\tuma\tvariedade\tde\tdimensões\te\n",
      "calcular\ta\tdistância\tentre\teles.\n",
      "figura\t12-3.\tlinguagens\tde\tprogramação\t3-vizinhos\tmais\tpróximos\n",
      "gerar\tpontos\taleatórios\tdeve\tser\tautomático\tagora:\n",
      "def\n",
      "\trandom_point(dim):\n",
      "\t\t\t\t\n",
      "return\n",
      "\t[random.random()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(dim)]assim\tcomo\té\tescrever\tuma\tfunção\tque\tgera\tas\tdistâncias:\n",
      "def\n",
      "\trandom_distances(dim,\tnum_pairs):\n",
      "\t\t\t\t\n",
      "return\n",
      "\t[distance(random_point(dim),\trandom_point(dim))\n",
      "\t\t\t\t\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(num_pairs)]\n",
      "figura\t12-4.\tlinguagens\tde\tprogramação\t5-vizinhos\tmais\tpróximos\n",
      "para\tcada\tdimensão\tde\t1\taté\t100,\tcomputaremos\t10.000\tdistâncias\te\tas\tusaremos\n",
      "para\tcomputar\ta\tdistância\tmédia\tentre\tos\tpontos\te\ta\tdistância\tmínima\tentre\tos\n",
      "pontos\tde\tcada\tdimensão\t(\n",
      "figura\t12-5\n",
      "):\n",
      "dimensions\t=\trange(1,\t101)\n",
      "avg_distances\t=\t[]\n",
      "min_distances\t=\t[]\n",
      "random.seed(0)\n",
      "for\n",
      "\tdim\t\n",
      "in\n",
      "\tdimensions:\n",
      "distances\t=\trandom_distances(dim,\t10000)\t\t\n",
      "#\t10.000\tpares\taleatórios\n",
      "avg_distances.append(mean(distances))\t\t\t\t\t\n",
      "#\trastreia\ta\tmédia\n",
      "min_distances.append(min(distances))\t\t\t\t\t\t\n",
      "#\trastreia\to\tmínimofigura\t12-5.\ta\tmaldição\tda\tdimensionalidade\n",
      "conforme\to\tnúmero\tde\tdimensões\taumenta,\ta\tdistância\tmédia\tentre\tos\tpontos\n",
      "também\taumenta.\tmas\to\tque\té\tmais\tproblemático\té\ta\trelação\tentre\ta\tdistância\n",
      "mais\tpróxima\te\ta\tdistância\tmédia\t(\n",
      "figura\t12-6\n",
      "):\n",
      "min_avg_ratio\t=\t[min_dist\t/\tavg_dist\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tmin_dist,\tavg_dist\t\n",
      "in\n",
      "\tzip(min_distances,\tavg_distances)]figura\t12-6.\ta\tmaldição\tda\tdimensionalidade\tnovamente\n",
      "em\tconjuntos\tde\tdados\tde\tbaixa\tdimensão,\tos\tpontos\tmais\tpróximos\ttendem\ta\n",
      "ser\tmais\tpróximos\tdo\tque\ta\tmédia.\tmas\tos\tdois\tpontos\testão\tpróximos\tsomente\n",
      "se\teles\testiverem\tpróximos\tem\ttodas\tas\tdimensões\te\tcada\tdimensão\textra\t—\n",
      "mesmo\tse\tsomente\tum\truído\t—\té\toutra\toportunidade\tpara\tcada\tponto\tser\tmais\n",
      "distante\tdos\toutros.\tquando\thá\tmuitas\tdimensões,\té\tprovável\tque\tos\tpontos\tmais\n",
      "próximos\tnão\tsejam\ttão\tpróximos\tquanto\ta\tmédia,\to\tque\tsignifica\tque\tdois\n",
      "pontos\testarem\tpróximos\tnão\tsignifica\tmuita\tcoisa\t(a\tmenos\tque\thaja\tbastante\n",
      "estrutura\tem\tseus\tdados\tque\tfaça\tcom\tque\teles\tse\tcomportem\tcomo\tse\n",
      "estivessem\tem\tuma\tdimensão\tmuito\tmais\tbaixa).\n",
      "uma\tforma\tdiferente\tde\tpensar\tsobre\to\tproblema\tenvolve\ta\tdispersão\tde\tespaços\n",
      "de\talta\tdimensão.\n",
      "se\tvocê\tescolher\t50\tnúmeros\taleatórios\tentre\t0\te\t1,\té\tprovável\tque\tvocê\ttenha\n",
      "uma\tboa\tparte\tdo\tintervalo\tunitário\t(\n",
      "figura\t12-7\n",
      ").figura\t12-7.\tcinquenta\tpontos\taleatórios\tem\tuma\tdimensão\n",
      "se\tvocê\tescolher\t50\tpontos\taleatórios\tno\tquadrado\tunitário,\tvocê\tterá\tmenos\n",
      "cobertura\t(\n",
      "figura\t12-8\n",
      ").figura\t12-8.\tcinquenta\tpontos\taleatórios\tem\tduas\tdimensões\n",
      "e\tem\ttrês\tdimensões\tmenos\tainda\t(\n",
      "figura\t12-9\n",
      ").\n",
      "matplotlib\n",
      "\tnão\tpermite\tgráficos\tde\tquatro\tdimensões\tmuito\tbem,\tportanto\teste\té\to\n",
      "máximo\tque\tiremos,\tmas\tvocê\tjá\tpode\tver\tque\testão\tcomeçando\ta\tter\tgrandes\n",
      "espaços\tvazios\tsem\tpontos\tperto\tdeles.\tem\tmais\tdimensões\t—\ta\tmenos\tque\tvocê\n",
      "tenha\tmuito\tmais\tdados\t—\tesses\tespaços\tgrandes\te\tvazios\trepresentam\tregiões\n",
      "distantes\tde\ttodos\tos\tpontos\tque\tvocê\tquer\tusar\tnas\tsuas\tprevisões.\n",
      "então,\tse\tvocê\testiver\ttentando\tusar\tos\tvizinhos\tmais\tpróximos\tem\tuma\n",
      "dimensão\tmais\talta,\té\tprovavelmente\tuma\tboa\tideia\tfazer\tuma\tredução\tde\n",
      "dimensionalidade\tprimeiro.figura\t12-9.\tcinquenta\tpontos\taleatórios\tem\ttrês\tdimensõespara\tmais\tesclarecimentos\n",
      "scikit-learn\tpossui\tmuitos\tmodelos\tde\tvizinhos\tmais\tpróximos\n",
      "(\n",
      "http://bit.ly/1ycp5rj\n",
      ").capítulo\t13\n",
      "naive\tbayes\n",
      "“\n",
      "eu\tprefiro\to\terro\tdo\tentusiasmo\tà\tindiferença\tdo\tbom\tsenso.”\n",
      "—anatole\tfrance\n",
      "uma\trede\tsocial\tnão\té\ttão\tboa\tse\tas\tpessoas\tnão\tconseguem\tse\tconectar.\n",
      "portanto,\ta\tdatasciencester\tpossui\tum\tatributo\tpopular\tque\tpermite\tque\n",
      "membros\tenviem\tmensagens\tuns\taos\toutros.\te\tenquanto\ta\tmaioria\tdos\tmembros\n",
      "são\tcidadãos\tresponsáveis\tque\tsomente\tenviam\tmensagens\tde\t“como\tvocê\n",
      "está?”,\talguns\tsão\tcanalhas\te\tenviam\tmensagens\tde\tspam\tsobre\tesquemas\tpara\n",
      "ficarem\tricos,\tmedicamentos\tsem\treceita\te\tprogramas\tde\tcredenciamento\tde\tdata\n",
      "science.\tseus\tusuários\tcomeçaram\ta\treclamar\te\ta\tvice-presidente\tde\tmensagem\n",
      "pediu\tque\tvocê\tusasse\tdata\tscience\tpara\tdescobrir\tcomo\tfiltrar\tessas\tmensagens\n",
      "de\tspam.um\tfiltro\tde\tspam\tmuito\testúpido\n",
      "imagine\tum\t“universo”\tque\tconsiste\tem\treceber\tuma\tmensagem\tescolhida\tao\n",
      "acaso\tentre\ttodas\tas\tpossíveis.\tdeixe\t\n",
      "s\n",
      "\tser\to\tevento\t“a\tmensagem\té\tspam”\te\t\n",
      "v\n",
      "ser\to\tevento\t“a\tmensagem\tcontém\ta\tpalavra\t\n",
      "viagra\n",
      "”.\tlogo,\to\tteorema\tde\tbayes\n",
      "nos\tdiz\tque\ta\tprobabilidade\tde\ta\tmensagem\tser\tspam\tdepende\tde\tconter\ta\n",
      "palavra\t\n",
      "viagra\n",
      ":\n",
      "o\tnumerador\té\ta\tprobabilidade\tde\ta\tmensagem\tser\tspam\t\n",
      "e\n",
      "\tconter\t\n",
      "viagra\n",
      ",\n",
      "enquanto\to\tdenominador\té\tapenas\ta\tprobabilidade\tde\ta\tmensagem\tconter\t\n",
      "viagra\n",
      ".\n",
      "logo,\tvocê\tpode\tpensar\tnesse\tcálculo\tcomo\tuma\tsimples\trepresentação\tda\n",
      "proporção\tde\tmensagens\t\n",
      "viagra\n",
      "\tque\tsão\tspam.\n",
      "se\tnós\ttemos\tuma\tgrande\tcoleção\tde\tmensagens\tque\tsabemos\tque\tsão\tspam,\te\n",
      "uma\tgrande\tcoleção\tque\tnão\té\tspam,\tnós\tpodemos\tfacilmente\tcalcular\t\n",
      "p(v\n",
      "|\n",
      "s)\n",
      "\te\n",
      "p(v\n",
      "|\n",
      "\t¬s)\n",
      ".\tse\tpresu-mirmos\t\n",
      "que\tqualquer\tmensagem\té\tigualmente\tprovável\tde\n",
      "ser\tspam\tou\tnão-spam\t(assim\t\n",
      "p(s)\n",
      "\t=\t\n",
      "p(¬s)\n",
      "\t=0.5),\tentão:\n",
      "por\texemplo,\tse\t50%\tdas\tmensagens\tspam\tpossuem\ta\tpalavra\t\n",
      "viagra\n",
      ",\tmas\n",
      "apenas\t1%\tdas\tmensagens\tnão-spam\tpossuem,\tentão\ta\tprobabilidade\tde\tque\n",
      "qualquer\te-mail\tque\tcontenha\t\n",
      "viagra\n",
      "\tseja\tspam\té:\n",
      "0.5/(0.5\t+\t0.01)\t=\t98%um\tfiltro\tde\tspam\tmais\tsofisticado\n",
      "agora\timagine\tque\ttemos\tum\tvocabulário\tde\tmuitas\tpalavras\t\n",
      "w\n",
      "1\n",
      ",\t…,\t\n",
      "w\n",
      "n\n",
      ".\tpara\n",
      "chegar\tneste\treino\tda\tteoria\tda\tprobabilidade,\tescreveremos\t\n",
      "x\n",
      "i\n",
      "\tpara\to\tevento\n",
      "“uma\tmensagem\tcontém\ta\tpalavra\t\n",
      "w\n",
      "1\n",
      "”.\timagine\ttambém\tque\t(por\tmeio\tde\tum\n",
      "processo\tnão-especificado-nesse-ponto)\tencontramos\tum\tp(x\n",
      "i\n",
      "|s)\tcomo\n",
      "estimativa\tpara\ta\tprobabilidade\tde\ta\tmensagem\tde\tspam\tconter\ta\tpalavra\t\n",
      "i\n",
      "-\n",
      "ésimo,\te\tcomo\testimativa\tparecida\tp(x\n",
      "i\n",
      "|¬s)\tpara\ta\tprobabilidade\tde\tuma\n",
      "mensagem\tnão-spam\tconter\ta\tpalavra\t\n",
      "i\n",
      "-ésimo.\n",
      "a\tchave\tpara\tnaive\tbayes\té\tfazer\ta\t(grande)\tsuposição\tde\tque\tas\tpresenças\t(ou\n",
      "ausências)\tde\tcada\tpalavra\tsão\tindependentes\tumas\tdas\toutras,\tcondição\tpara\n",
      "uma\tmensagem\tser\tspam\tou\tnão.\tintuitivamente,\tessa\tsuposição\tsignifica\tque\n",
      "saber\tse\tuma\tcerta\tmensagem\tde\tspam\tcontém\ta\tpalavra\t“viagra”\tou\tnão,\tnão\n",
      "lhe\tdá\tnenhuma\tinformação\tsobre\ta\tmesma\tmensagem\tconter\tou\tnão\tpalavra\n",
      "“rolex”.\tem\ttermos\tmatemáticos,\tisso\tsignifica\tque:\n",
      "essa\té\tuma\thipótese\textrema.\t(há\tum\tmotivo\tpara\tconter\t“naive”\t(inocente)\tno\n",
      "nome\tda\ttécnica.)\timagine\tque\ttodo\to\tnosso\tvocabulário\tconsista\t\n",
      "apenas\n",
      "\tdas\n",
      "palavras\t“viagra”\te\t“rolex”,\te\tque\tmetade\tde\ttodas\tas\tmensagens\tde\tspam\tsejam\n",
      "“viagra\tbarato”\te\tque\ta\toutra\tmetade\tseja\t“rolex\tautêntico”.\tnesse\tcaso,\ta\n",
      "estimativa\tnaive\tbayes\tde\tque\tuma\tmensagem\tde\tspam\tcontenha\tambos,\n",
      "“viagra”\te\t“rolex”\té:\n",
      "uma\tvez\tque\tafastamos\ta\tteoria\tde\tque\t“viagra”\te\t“rolex”\tnunca\tacontecem\n",
      "juntos.\tapesar\tda\tirrealidade\tdessa\tsuposição,\ttal\tmodelo\tgeralmente\té\tbem-\n",
      "sucedido\te\té\tusado\tem\tfiltros\tde\tspam\treais.\n",
      "o\tmesmo\tteorema\tde\tbayes\tusado\tpara\tnosso\tfiltro\tde\tspam\t“apenas_viagra”\n",
      "nos\tdiz\tque\tpodemos\tcalcular\ta\tprobabilidade\tde\tuma\tmensagem\tser\tspam\n",
      "usando\ta\tequação:\n",
      "a\tsuposição\tnaive\tbayes\tpermite\tque\tcomputemos\tcada\tuma\tdas\tprobabilidades\n",
      "à\tdireita\tsimplesmente\tmultiplicando\tjunto\tas\testimativas\tde\tprobabilidade\n",
      "individual\tpara\tcada\tpalavra\tdo\tvocabulário.\n",
      "na\tprática,\tvocê\tgeralmente\tquer\tevitar\ta\tmultiplicação\tde\tmuitas\tprobabilidades\n",
      "ao\tmesmo\ttempo,\tpara\tevitar\tum\tproblema\tchamado\t\n",
      "underflow\n",
      ",\tno\tqual\n",
      "computadores\tnão\tlidam\tbem\tcom\tnúmeros\tde\tpontos\tflutuantes\tmuito\tpróximos\n",
      "a\tzero.\trelembrando\tda\tálgebra\tem\tque\tlog(\n",
      "ab\n",
      ")\t=\tlog\t\n",
      "a\n",
      "\t+\tlog\t\n",
      "b\n",
      "\te\tque\texp\t(log\t\n",
      "x\n",
      ")\n",
      "=\t\n",
      "x\n",
      ",\tnós\tgeralmente\tcomputamos\t\n",
      "p\n",
      "1\n",
      "\t*…*\t\n",
      "p\n",
      "n\n",
      "\tcomo\to\tequivalente\t(mas\tmais\n",
      "amigável\tao\tponto\tflutuante):\n",
      "o\túnico\tdesafio\trestante\tvem\tcom\tas\testimativas\tpara\t\n",
      "p\n",
      "(x\n",
      "i\n",
      "|\n",
      "s\n",
      ")\te\t\n",
      "p\n",
      "(x\n",
      "i\n",
      "|\n",
      "¬s\n",
      "),\tas\n",
      "probabilidades\tde\tuma\tmensagem\tde\tspam\t(ou\tnão-spam)\tconter\ta\tpalavra\t\n",
      "w\n",
      "i\n",
      ".\tse\n",
      "temos\tum\tnúmero\tjusto\tde\tmensagens\trotuladas\tcomo\tspam\tou\tnão,\ta\tprimeira\n",
      "tentativa\tóbvia\té\tcalcular\tp(x\n",
      "i\n",
      "|s)\tsimplesmente\tcomo\tuma\tfração\tde\tmensagens\n",
      "spam\tcontendo\ta\tpalavra\t\n",
      "w\n",
      "i\n",
      ".\n",
      "no\tentanto,\tisso\tcausa\tum\tgrande\tproblema.\timagine\tque\tem\tnosso\tvocabulário\n",
      "de\ttreinamento\ta\tpalavra\t“dado”\tocorra\tapenas\tem\tmensagens\tnão-spam.\tentão\n",
      "nós\tcalcularíamos\tp(“dado”|\n",
      "s\n",
      ")=0.\to\tresultado\té\tque\tnosso\tclassificador\tnaive\n",
      "bayes\tsempre\tatribuiria\ta\tprobabilidade\tde\tspam\t0\ta\t\n",
      "qualquer\n",
      "\tmensagem\n",
      "contendo\ta\tpalavra\t“dado”,\tmesmo\tuma\tmensagem\tcomo\t“dado\tem\tviagra\n",
      "barato\te\trelógios\trolex\tautênticos”.\tpara\tevitar\tesse\tproblema,\tnós\tusaríamos\n",
      "algum\ttipo\tde\tsuavizador.\n",
      "particularmente,\tescolheríamos\tuma\t\n",
      "pseudocount—k—\n",
      "e\tcalcularíamos\ta\n",
      "probabilidade\tde\tver\ta\tpalavra\t\n",
      "i\n",
      "-ésimo\tem\tum\tspam\tcomo:\n",
      "p(x\n",
      "i\n",
      "|s)\t=\t(\n",
      "k\n",
      "\t+\tnúmero\tde\tspams\tcontendo\t\n",
      "w\n",
      "i\n",
      ")\t/\t(\n",
      "2k\n",
      "\t+\tnúmero\tde\tspams)\n",
      "igualmente\tpara\t\n",
      "p\n",
      "(x\n",
      "i\n",
      "|\n",
      "¬s\n",
      ").\tisso\té,\tquando\tcomputamos\tas\tprobabilidades\tde\n",
      "spam\tpara\ta\tpalavra\t\n",
      "i\n",
      "-ésimo,\tnós\tpresumimos\tque\ttambém\tvimos\tspams\n",
      "adicionais\t\n",
      "k\n",
      "\tcontendo\ta\tpalavra\te\t\n",
      "k\n",
      "\tspams\tadicionais\tnão\tcontendo.\n",
      "por\texemplo,\tse\t“dado”\tocorre\tem\t0/98\tdocumentos\tspam\te\tse\t\n",
      "k\n",
      "\té\t1,\tnós\n",
      "calculamos\tp(“dado”|\n",
      "s\n",
      ")\tcomo\t1/100\t=\t0,001,\to\tque\tpermite\tque\tnossoclassificador\tatribua\talguma\tprobabilidade\tspam\tdiferente\tde\tzero\tpara\n",
      "mensagens\tque\tcontenham\ta\tpalavra\t“dado”.implementação\n",
      "agora\ttemos\ttodos\tos\tpedaços\tdos\tquais\tprecisamos\tpara\to\tnosso\tclassificador.\n",
      "primeiro,\tvamos\tcriar\tuma\tfunção\tsimples\tpara\tquebrar\t(ou\t\n",
      "tokenize\n",
      ")\tmensagens\n",
      "em\tpalavras\tdistintas.\tprimeiro\tconverteremos\tcada\tmensagem\tpara\tcaixa\tbaixa;\n",
      "use\t\n",
      "re.findall()\n",
      "\tpara\textrair\t“palavras”\tconsistentes\tde\tletras,\tnúmeros\te\tapóstrofo;\te\n",
      "finalmente,\tuse\t\n",
      "set()\n",
      "\tpara\tpegar\tapenas\tpalavras\tdistintas:\n",
      "def\ttokenize(message):\n",
      "message\t=\tmessage.lower()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tconverte\tpara\tminúsculas\n",
      "all_words\t=\tre.findall(\"[a-z0-9']+\",\tmessage)\t\t\t\n",
      "#\textrai\tas\tpalavras\n",
      "return\tset(all_words)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tremove\tduplicadas\n",
      "nossa\tsegunda\tfunção\tcontará\tas\tpalavras\tem\tum\tconjunto\tde\tmensagens\n",
      "rotuladas\tpara\ttreino.\tserá\tretornado\tum\tdicionário\tno\tqual\tas\tchaves\tsão\n",
      "palavras,\te\tcujos\tvalores\tsão\tlistas\tde\tdois\telementos\t\n",
      "[spam_count,\tnon_spam_count]\n",
      ",\n",
      "correspondentes\ta\tquantidade\tde\tvezes\tque\tvimos\taquela\tpalavra\tem\tambas\n",
      "mensagens,\tspam\te\tnão-spam:\n",
      "def\n",
      "\tcount_words(training_set):\n",
      "\"\"\"o\tconjunto\tem\ttreinamento\tconsiste\tde\tpares\t(message,\tis_spam)\"\"\"\n",
      "counts\t=\tdefaultdict(\n",
      "lambda\n",
      ":\t[0,\t0])\n",
      "for\n",
      "\tmessage,\tis_spam\t\n",
      "in\n",
      "\ttraining_set:\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\ttokenize(message):\n",
      "\t\t\t\t\t\tcounts[word][0\t\n",
      "if\n",
      "\tis_spam\t\n",
      "else\n",
      "\t1]\t+=\t1\n",
      "return\n",
      "\tcounts\n",
      "nosso\tpróximo\tpasso\té\ttransformar\ttais\tcontas\tem\tprobabilidades\testimadas\n",
      "usando\to\tsuavizador\tdescrito\tanteriormente.\tnossa\tfunção\tretornará\tuma\tlista\tde\n",
      "triplas\tcontendo\tcada\tpalavra,\ta\tprobabilidade\tde\tver\ttal\tpalavra\tem\tuma\n",
      "mensagem\tde\tspam\te\ta\tprobabilidade\tde\tvê-la\tem\tuma\tnão-spam:\n",
      "def\n",
      "\tword_probabilities(counts,\ttotal_spams,\ttotal_non_spams,\tk=0.5):\n",
      "\"\"\"transforma\to\tword_counts\tem\tuma\tlista\tde\ttriplas\n",
      "w,\tp(w\t|\tspam)\te\tp(w\t|\t~spam)\"\"\"\n",
      "return\n",
      "\t[(w,\n",
      "\t\t\t(spam\t+\tk)\t/\t(total_spams\t+\t2\t*\tk),\n",
      "\t\t\t(non_spam\t+\tk)\t/\t(total_non_spams\t+\t2\t*\tk))\n",
      "\t\t\t\n",
      "for\n",
      "\tw,\t(spam,\tnon_spam)\t\n",
      "in\n",
      "\tcounts.iteritems()]\n",
      "a\túltima\tparte\té\tusar\tessas\tprobabilidades\tde\tpalavras\t(e\tnossas\thipóteses\tnaive\n",
      "bayes)\tpara\tatribuir\tprobabilidades\ta\tmensagens:def\n",
      "\tspam_probability(word_probs,\tmessage):\n",
      "message_words\t=\ttokenize(message)\n",
      "log_prob_if_spam\t=\tlog_prob_if_not_spam\t=\t0.0\n",
      "\t\n",
      "#\titera\tcada\tpalavra\tem\tnosso\tvocabulário\n",
      "for\n",
      "\tword,\tprob_if_spam,\tprob_if_not_spam\t\n",
      "in\n",
      "\tword_probs:\n",
      "#\tse\t“word”\taparecer\tna\tmensagem\n",
      ",\n",
      "#\tadicione\ta\tprobabilidade\tlog\tde\tvê-la\n",
      "if\n",
      "\tword\t\n",
      "in\n",
      "\tmessage_words:\n",
      "\t\t\t\t\t\tlog_prob_if_spam\t+=\tmath.log(prob_if_spam)\n",
      "\t\t\t\t\t\tlog_prob_if_not_spam\t+=\tmath.log(prob_if_not_spam)\n",
      "#\tse\t“word”\tnão\taparecer\tna\tmensagem\n",
      "#\tadicione\ta\tprobabilidade\tlog\tde\tnão\tvê-la\n",
      "#\tque\té\tlog(1\t–\tprobabilidade\tde\tvê-la)\n",
      "else\n",
      ":\n",
      "\t\t\t\t\t\tlog_prob_if_spam\t+=\tmath.log(1.0\t-\tprob_if_spam)\n",
      "\t\t\t\t\t\tlog_prob_if_not_spam\t+=\tmath.log(1.0\t-\tprob_if_not_spam)\n",
      "prob_if_spam\t=\tmath.exp(log_prob_if_spam)\n",
      "prob_if_not_spam\t=\tmath.exp(log_prob_if_not_spam)\n",
      "return\n",
      "\tprob_if_spam\t/\t(prob_if_spam\t+\tprob_if_not_spam)\n",
      "podemos\tcolocar\ttudo\tisso\tjunto\tno\tnosso\tclassificador\tnaive\tbayes:\n",
      "class\tnaivebayesclassifier\n",
      ":\n",
      "def\n",
      "\t__init__(self,\tk=0.5):\n",
      "self.k\t=\tk\n",
      "self.word_probs\t=\t[]\n",
      "def\n",
      "\ttrain(self,\ttraining_set):\n",
      "#\tconta\tmensagens\tspam\te\tnão-spam\n",
      "num_spams\t=\tlen([is_spam\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tmessage,\tis_spam\t\n",
      "in\n",
      "\ttraining_set\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "if\n",
      "\tis_spam])\n",
      "num_non_spams\t=\tlen(training_set)\t-\tnum_spams\n",
      "#\troda\tdados\tde\ttreinamento\tpela\tnossa\t“pipeline”\n",
      "word_counts\t=\tcount_words(training_set)\n",
      "self.word_probs\t=\tword_probabilities(word_counts,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnum_spams,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnum_non_spams,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.k)\n",
      "def\n",
      "\tclassify(self,\tmessage):\n",
      "\t\t\t\n",
      "return\n",
      "\tspam_probability(self.word_probs,\tmessage)testando\tnosso\tmodelo\n",
      "um\tbom\t(e\tde\tcerta\tforma\tvelho)\tconjunto\tde\tdados\té\to\tspamassassin\tpublic\n",
      "corpus\t(\n",
      "https://spamassassin.apache.org/publiccorpus\n",
      "/\n",
      ").\tnós\tveremos\tos\n",
      "arquivos\tprefixados\tcom\t\n",
      "20021010\n",
      ".\t(no\twindows,\tvocê\tprecisará\tde\tum\n",
      "programa\tcomo\t7-zip\t(\n",
      "http://www.7-zip.org\n",
      "/\n",
      ")\tpara\tdescompactar\te\textrair\tos\n",
      "arquivos.)\n",
      "após\textrair\tos\tdados\t(para,\tdigamos,\t\n",
      "c:\\spam\n",
      "),\tvocê\tdeve\tter\ttrês\tpastas:\t\n",
      "spam,\n",
      "easy_ham\n",
      "\te\t\n",
      "hard_ham\n",
      ".\tcada\tpasta\tcontém\tmuitos\te-mails,\tcada\tqual\tcontido\tem\n",
      "um\túnico\tarquivo.\tpara\tmanter\ttudo\t\n",
      "bem\tsimples\n",
      ",\tolharemos\tapenas\to\tassunto\tde\n",
      "cada\te-mail.\n",
      "como\tidentificamos\ta\tlinha\tde\tassunto?\tolhando\tpelos\tarquivos,\ttodos\tparecem\n",
      "começar\tcom\t“subject:”.\tlogo,\tprocuraremos\tpor\tisto:\n",
      "import\tglob,\tre\n",
      "#\tmodifique\tcom\to\tcaminho\tno\tqual\tvocê\tcolocou\tos\tarquivos\n",
      "path\t=\tr\"c:\\spam\\*\\*\"\n",
      "data\t=\t[]\n",
      "#\tglob.glob\tretorna\ttodo\tnome\tde\tarquivo\tque\tcombine\tcom\to\tcaminho\tdeterminado\n",
      "for\tfn\tin\tglob.glob(path):\n",
      "is_spam\t=\t\"ham\"\tnot\tin\tfn\n",
      "with\topen(fn,'r')\tas\tfile:\n",
      "for\tline\tin\tfile:\n",
      "if\tline.startswith(\"subject:\"):\n",
      "\t\t\t\n",
      "#\tremove\to\tprimeiro\t“subject:”\te\tmantém\to\tque\tsobrou\n",
      "\t\t\tsubject\t=\tre.sub(r\"^subject:\t\",\t\"\",\tline).strip()\n",
      "\t\t\tdata.append((subject,\tis_spam))\n",
      "agora\tpodemos\tdividir\tos\tdados\tem\tdados\tde\ttreinamentos\te\tdados\tde\tteste\te,\n",
      "então,\testaremos\tprontos\tpara\tconstruir\tum\tclassificador:\n",
      "random.seed(0)\t\n",
      "#\tsó\tpara\tque\treceba\ta\tmesma\tresposta\tque\teu\n",
      "train_data,\ttest_data\t=\tsplit_data(data,\t0.75)\n",
      "classifier\t=\tnaivebayesclassifier()\n",
      "classifier.train(train_data)\n",
      "e\tagora\tpodemos\tverificar\tcomo\to\tnosso\tmodelo\tfaz:\n",
      "#\ttriplas\t(subject,\tis_spam\treal,\tprobabilidade\tde\tspam\tprevisto)classified\t=\t[(subject,\tis_spam,\tclassifier.classify(subject))\n",
      "\t\t\t\t\t\tfor\tsubject,\tis_spam\tin\ttest_data]\n",
      "#\tpresuma\tque\tspam_probability\t>\t0.5\tcorresponde\tà\tprevisão\tde\tspam\n",
      "#\te\tconta\tas\tcombinações\tde\t(is_spam\treal,\tis_spam\tprevisto)\n",
      "counts\t=\tcounter((is_spam,\tspam_probability\t>\t0.5)\n",
      "for\t_,\tis_spam,\tspam_probability\tin\tclassified)\n",
      "isso\tdá\t101\tpositivos\tverdadeiros\t(spam\tclassificado\tcomo\t“spam”),\t33\tpositivos\n",
      "falsos\t(ham\tclassificados\tcomo\t“spam”),\t704\tnegativos\tverdadeiros\t(ham\n",
      "classificados\tcomo\t“ham”)\te\t38\tnegativos\tfalsos\t(spam\tclassificados\tcomo\n",
      "“ham”).\tisso\tsignifica\tque\tnossa\tacurácia\té\t101\t/\t(101\t+\t33)\t=\t75%,\te\tnossa\n",
      "sensibilidade\té\t101\t/\t(101\t+\t38)\t=\t73%,\tque\tnão\tsão\tnúmeros\truins\tpara\tum\n",
      "modelo\ttão\tsimples.\n",
      "também\té\tinteressante\tolhar\tpara\tos\tmais\tmal\tclassificados:\n",
      "#\tordena\tspam_probability\tdo\tmenor\tpara\to\tmaior\n",
      "classified.sort(key=\n",
      "lambda\n",
      "\trow:\trow[2])\n",
      "#\tas\tmaiores\tprobabilidades\tde\tspam\tprevistos\tentre\tos\tnão-spams\n",
      "spammiest_hams\t=\tfilter(\n",
      "lambda\n",
      "\trow:\t\n",
      "not\n",
      "\trow[1],\tclassified)[-5:]\n",
      "#\tas\tmenores\tprobabilidades\tde\tspam\tprevistos\tentre\tos\tspams\n",
      "hammiest_spams\t=\tfilter(\n",
      "lambda\n",
      "\trow:\trow[1],\tclassified)[:5]\n",
      "as\tduas\thams\tcom\tmais\tjeito\tde\tspam\tpossuem\tas\tpalavras\t“precisa”\t(77\tvezes\n",
      "mais\tprovável\tde\taparecer\tem\tspam),\t“seguro”\t(30\tvezes\tmais\tprovável\tde\n",
      "aparecer\tem\tspam)\te\t“importante”\t(10\tvezes\tmais\tprovável\tde\taparecer\tem\n",
      "spam).\n",
      "o\tspam\tcom\tmais\tjeito\tde\tham\té\tmuito\tcurto\t(“re:\tgarotas”)\tpara\tjulgarmos\te\to\n",
      "segundo\té\tuma\tsolicitação\tde\tcartão\tde\tcrédito\tem\tque\ta\tmaioria\tdas\tpalavras\n",
      "não\testava\tno\tconjunto\tde\ttreinamento.\n",
      "podemos\tver\tas\tpalavras\tque\tpossuem\tmais\tjeito\tde\tspam:\n",
      "def\n",
      "\tp_spam_given_word(word_prob):\n",
      "\"\"\"usa\to\tteorema\tde\tbayes\tpara\tcomputar\tp(spam\t|\tmessage\tcontains\tword)\"\"\"\n",
      "\t\n",
      "#\tword_prob\té\tuma\tdas\ttriplas\tproduzidas\tpor\tword_probabilities\n",
      "word,\tprob_if_spam,\tprob_if_not_spam\t=\tword_prob\n",
      "return\n",
      "\tprob_if_spam\t/\t(prob_if_spam\t+\tprob_if_not_spam)\n",
      "words\t=\tsorted(classifier.word_probs,\tkey=p_spam_given_word)\n",
      "spammiest_words\t=\twords[-5:]\n",
      "hammiest_words\t=\twords[:5]•\n",
      "•\n",
      "•\n",
      "•\n",
      "as\tpalavras\t“money”,\t“systemworks”,\t“rates”,\t“sale”\te\t“year”\tsão\tas\tque\n",
      "possuem\tmais\tspams,\ttodas\tparecem\trelacionadas\ta\ttentar\tfazer\tas\tpessoas\n",
      "comprarem\tcoisas.\te\tas\tpalavras\t“spambayes”,\t“users”,\t“razor”,\t“zzzzteana”\te\n",
      "“sadev”\tsão\tdo\ttipo\tham,\tem\tque\ta\tmaioria\tparece\trelacionada\tcom\tprevenção\tde\n",
      "spam,\tpor\tmais\testranho\tque\tseja.\n",
      "como\tpoderíamos\tobter\tuma\tperformance\tmelhor?\tuma\tmaneira\tóbvia\tseria\n",
      "pegar\tmais\tdados\tpara\ttreinar.\texistem\tvárias\tmaneiras\tde\tmelhorar\to\tmodelo.\n",
      "estas\tsão\talgumas\tpossibilidades\tque\tvocê\tpode\ttentar:\n",
      "olhe\to\tconteúdo\tda\tmensagem,\tnão\tolhe\tsomente\ta\tlinha\tdo\tassunto.\tvocê\n",
      "deve\tser\tcauteloso\tao\tver\tos\ttítulos\tdas\tmensagens.\n",
      "nosso\tclassificador\tleva\tem\tconsideração\tcada\tpalavra\tque\taparece\tno\n",
      "conjunto\tde\ttreinamento,\taté\tmesmo\tas\tpalavras\tque\tsó\taparecem\tuma\tvez.\n",
      "modifique\to\tclassificador\tpara\taceitar\tum\tlimite\topcional\t\n",
      "min_count\n",
      "\te\tignore\n",
      "os\tsímbolos\tque\tnão\taparecem\ttantas\tvezes.\n",
      "o\t\n",
      "tokenizer\n",
      "\tnão\ttem\tpercepção\tde\tpalavras\tsimilares\t(por\texemplo,\n",
      "“cheap”\te\t“cheapest”).\tmodifique\to\tclassificador\tpara\tter\tuma\tfunção\n",
      "stemmer\n",
      "\tque\tconverte\tpalavras\tpara\tas\t\n",
      "classes\tequivalentes\n",
      "\tde\tpalavras.\tpor\n",
      "exemplo,\tuma\tfunção\tstemmer\tsimples\tpode\tser:\n",
      "\t\t\t\t\t\t\t\t\n",
      "def\n",
      "\tdrop_final_s(word):\n",
      "\t\t\t\t\t\t\t\t\n",
      "return\n",
      "\tre.sub(\"s$\",\t\"\",\tword)\n",
      "criar\tuma\tboa\tfunção\tstemmer\té\tdifícil.\tas\tpessoas\tgeralmente\tusam\ta\n",
      "porter\tstemmer\t(\n",
      "http://tartarus.org/martin/porterstemmer\n",
      "/\n",
      ").\n",
      "mesmo\tque\ttodas\tas\tnossas\tcaracterísticas\tsejam\t“mensagens\tcontendo\ta\n",
      "palavra\t\n",
      "w\n",
      "i´\n",
      "”,\tnão\thá\tmotivo\tpara\ttal.\tem\tnossa\timplementação,\tnós\n",
      "pudemos\tacrescentar\tcaracterísticas\textras\tcomo\t“mensagem\tcontendo\tum\n",
      "número”\tcriando\ttokens\tfictícios\tcomo\t\n",
      "contains:number\n",
      "\te\tmodificando\to\n",
      "tokenizer\n",
      "\tpara\temiti-los\tquando\tnecessário.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "os\tartigos\tde\tpaul\tgraham,\t“a\tplan\tfor\tspam”\t(\n",
      "http://bit.ly/1ycpcma\n",
      ")\te\n",
      "“better\tbayesian\tfiltering”\t(\n",
      "http://bit.ly/1ycpbiy\n",
      ")\t(são\tinteressantes\te)\tdão\n",
      "uma\tmaior\tcompreensão\tsobre\ta\tconstrução\tde\tfiltros\tde\tspam.\n",
      "scikit-learn\n",
      "\t(\n",
      "http://bit.ly/1ycp9ar\n",
      ")\tcontém\tum\tmodelo\t\n",
      "bernoullinb\n",
      "\tque\n",
      "implementa\to\tmesmo\talgoritmo\tnaive\tbayes\tque\timplementamos\taqui,\n",
      "bem\tcomo\toutras\tvariações\tdo\tmodelo.capítulo\t14\n",
      "regressão\tlinear\tsimples\n",
      "a\tarte,\tcomo\ta\tmoralidade,\tconsiste\tem\testabelecer\tum\tlimite\tem\talgum\tlugar\n",
      ".\n",
      "—\n",
      "g.k.\tcherterton\n",
      "no\t\n",
      "capítulo\t5\n",
      ",\tnós\tusamos\ta\tfunção\t\n",
      "correlation\n",
      "\tpara\tmedir\ta\tforça\tdo\n",
      "relacionamento\tlinear\tentre\tduas\tvariáveis.\tpara\ta\tmaioria\tdas\taplicações,\tsaber\n",
      "que\ttal\trelacionamento\tlinear\texiste\tnão\té\to\tbastante.\tnós\tqueremos\tconseguir\n",
      "entender\ta\tnatureza\tdo\trelacionamento.\té\taí\tque\tusamos\tregressão\tlinear\n",
      "simples.o\tmodelo\n",
      "lembre-se\tde\tque\tnós\testávamos\tinvestigando\to\trelacionamento\tentre\to\tnúmero\n",
      "de\tamigos\tde\tum\tusuário\tda\tdatasciencester\te\to\ttempo\tque\tele\tpassa\tno\tsite\tpor\n",
      "dia.\tvamos\tsupor\tque\tvocê\tse\tconvenceu\tde\tque\tter\tmais\tamigos\t\n",
      "faz\n",
      "\tas\tpessoas\n",
      "passarem\tmais\ttempo\tno\tsite,\tmas\tnão\tdas\texplicações\talternativas\tque\n",
      "discutimos.\n",
      "a\tvice-presidente\tde\trelacionamentos\t(\n",
      "engagement\n",
      ")\tpede\tpara\tvocê\tconstruir\n",
      "um\tmodelo\tdescrevendo\tessa\trelação.\tjá\tque\tvocê\tencontrou\tum\trelacionamento\n",
      "linear\tforte,\tum\tbom\tlugar\tpara\tcomeçar\té\to\tmodelo\tlinear.\n",
      "em\tparticular,\tvocê\tcria\tuma\thipótese\tde\tque\thá\tconstantes\tα\t(alfa)\te\tβ\t(beta)\ttais\n",
      "que:\n",
      "em\tque\t\n",
      "y\n",
      "i\n",
      "\té\to\tnúmero\tde\tminutos\tque\to\tusuário\t\n",
      "i\n",
      "\tpassa\tno\tsite\tdiariamente,\t\n",
      "x\n",
      "i\n",
      "\té\to\n",
      "número\tde\tamigos\tque\to\tusuário\t\n",
      "i\n",
      "\tpossui\te\tε\n",
      "i\n",
      "\té\tum\ttermo\tde\terro\t(esperamos\tque\n",
      "pequeno)\trepresentando\to\tfato\tde\texistirem\toutros\tfatores\tnão\tcontabilizados\n",
      "para\tesse\tsimples\tmodelo.\n",
      "supondo\tque\tdeterminamos\ttais\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      ",\tpodemos\tfazer\tprevisões\n",
      "simplesmente\tcom:\n",
      "def\n",
      "\tpredict(alpha,\tbeta,\tx_i):\n",
      "return\n",
      "\tbeta\t*\tx_i\t+\talpha\n",
      "como\tescolhemos\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "?\tbom,\tqualquer\tescolha\tde\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "\tnos\tdá\tuma\n",
      "saída\tprevista\tpara\tcada\tentrada\t\n",
      "x_i\n",
      ".\tcomo\tsabemos\ta\tverdadeira\tsaída\t\n",
      "y_i\n",
      ",\n",
      "podemos\tcomputar\to\terro\tpara\tcada\tpar:\n",
      "def\terror(alpha,\tbeta,\tx_i,\ty_i):\n",
      "\"\"\"erro\tde\tprever\tbeta\t*\tx_i\t+\talpha\n",
      "quando\to\tvalor\treal\té\ty_i\"\"\"\n",
      "return\ty_i\t-\tpredict(alpha,\tbeta,\tx_i)\n",
      "o\tque\trealmente\tgostaríamos\tde\tsaber\té\to\terro\ttotal\tsobre\ttodo\to\tconjunto\tde\n",
      "dados.\tmas\tnão\tqueremos\tapenas\tadicionar\terros\t—\tse\ta\tprevisão\tpara\t\n",
      "x_1\n",
      "\tfor\n",
      "alta\tdemais\te\ta\tprevisão\tpara\t\n",
      "x_2\n",
      "\tfor\tbaixa\tdemais,\tos\terros\tpodem\tapenas\tseranulados.\n",
      "então,\tem\tvez\tdisso,\tnós\tadicionamos\tos\terros\tao\t\n",
      "quadrado\n",
      ":\n",
      "\t\n",
      "def\n",
      "\tsum_of_squared_errors(alpha,\tbeta,\tx,\ty):\n",
      "\t\n",
      "return\n",
      "\tsum(error(alpha,\tbeta,\tx_i,\ty_i)\t**\t2\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tx_i,\ty_i\t\n",
      "in\n",
      "\tzip(x,\ty))\n",
      "a\t\n",
      "solução\tmínima\tdos\tquadrados\n",
      "\té\tescolher\to\t\n",
      "alpha\n",
      "\te\to\t\n",
      "beta\n",
      "\tque\ttornarão\ta\tsoma\n",
      "sum_of_\tsquared_errors\n",
      "\ta\tmenor\tpossível.\n",
      "usando\tcálculo\t(ou\ta\ttediosa\tálgebra),\ta\tminimização\tde\terro\talpha\te\tbeta\té\tdada\n",
      "por:\n",
      "def\n",
      "\tleast_squares_fit(x,\ty):\n",
      "\"\"\"dados\tos\tvalores\tem\ttreinamento\tpara\tx\te\ty\n",
      ",\n",
      "encontra\tos\tvalores\tmínimos\tdos\tquadrados\tde\talfa\te\tbeta\"\"\"\n",
      "beta\t=\tcorrelation(x,\ty)\t*\tstandard_deviation(y)\t/\tstandard_deviation(x)\n",
      "alpha\t=\tmean(y)\t-\tbeta\t*\tmean(x)\n",
      "return\n",
      "\talpha,\tbeta\n",
      "sem\tpercorrer\ta\tmatemática\texata,\tvamos\tpensar\tno\tporquê\tessa\tpode\tser\tuma\n",
      "solução\trazoável.\ta\tescolha\tde\t\n",
      "alpha\n",
      "\tsimplesmente\tdiz\tque\tquando\tvemos\ta\n",
      "média\tda\tvariável\tindependente\t\n",
      "x\n",
      ",\tfazemos\tuma\tprevisão\tda\tmédia\tda\tvariável\n",
      "dependente\t\n",
      "y\n",
      ".\n",
      "a\tescolha\tde\tbeta\tsignifica\tque,\tquando\to\tvalor\tde\tentrada\taumenta\tpor\t\n",
      "standard_\n",
      "deviation(x)\n",
      ",\ta\tprevisão\taumenta\tpor\t\n",
      "correlation(x,\ty)\t*\tstandard_deviation(y)\n",
      ".\tquando\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "são\tperfeitamente\tcorrelacionados,\tum\taumento\tde\t\n",
      "um\tdesvio\tpadrão\n",
      "\tem\t\n",
      "x\n",
      "resulta\tem\tuma\tdivergência\tde\tum\tpadrão\tde\t\n",
      "y\n",
      "\tna\tprevisão.\tquando\teles\tsão\n",
      "perfeitamente\tnão\tcorrelacionados,\to\taumento\tem\t\n",
      "x\n",
      "\tresulta\tem\tuma\t\n",
      "diminuição\n",
      "da\tprevisão.\te\tquando\ta\tcorrelação\té\tzero,\t\n",
      "beta\n",
      "\té\tzero,\to\tque\tsignifica\tque\n",
      "mudanças\tem\t\n",
      "x\n",
      "\tnão\tafetarão\ta\tprevisão.\n",
      "é\tfácil\taplicar\tisso\taos\tdados\tdos\tvalores\tdiscrepantes\tdo\t\n",
      "capítulo\t5\n",
      ":\n",
      "alpha,\tbeta\t=\tleast_squares_fit(num_friends_good,\tdaily_minutes_good)\n",
      "isso\tdá\tvalores\tde\talfa\t=\t22,95\te\tbeta\t=\t0,903.\tportanto,\tnosso\tmodelo\tdiz\tque\n",
      "esperamos\tque\tum\tusuário\tcom\t\n",
      "n\n",
      "\tamigos\tpasse\t\n",
      "22,95\t+\tn\t*\t0,903\n",
      "\tminutos\tno\tsite\tpor\n",
      "dia.\tou\tseja,\tnós\tprevimos\tque\tum\tusuário\tsem\tamigos\tna\tdatasciencester\tainda\n",
      "assim\tpassaria\tcerca\tde\t23\tminutos\tno\tsite\tpor\tdia.\te,\tpara\tcada\tamigo\tadicional,nós\tesperamos\tque\to\tusuário\tgaste\tquase\tum\tminuto\ta\tmais\tno\tsite\tpor\tdia.\n",
      "na\t\n",
      "figura\t14-1\n",
      ",\tnós\tassinalamos\ta\tlinha\tde\tprevisão\tpara\tentender\tcomo\tesse\n",
      "modelo\té\tadequado\taos\tdados\tobservados.\n",
      "figura\t14-1.\tnosso\tmodelo\tlinear\tsimples\n",
      "claro,\tnós\tprecisamos\tde\tuma\tforma\tmelhor\tde\tdescobrir\tquão\tbem\n",
      "conseguimos\tajustar\tos\tdados\tem\tvez\tde\tolhar\tpara\to\tgráfico.\tuma\tmedida\n",
      "comum\té\to\t\n",
      "coeficiente\tde\tdeterminação\n",
      "\t(ou\t\n",
      "r²\n",
      ")\tque\tmede\ta\tfração\tda\tvariação\n",
      "total\tna\tvariável\tdependente\tque\té\tcapturada\tpelo\tmodelo:\n",
      "def\ttotal_sum_of_squares(y):\n",
      "\"\"\"a\tsoma\ttotal\tdos\tquadrados\tdas\tvariações\tde\ty_i\ta\tpartir\tde\tsuas\tmédias\"\"\"\n",
      "return\tsum(v\t**\t2\tfor\tv\tin\tde_mean(y))\n",
      "def\tr_squared(alpha,\tbeta,\tx,\ty):\n",
      "\"\"\"a\tfração\tda\tvariação\tem\ty\tcapturada\tpelo\tmodelo,\tque\té\tigual\ta\n",
      "1\t-\ta\tfração\tda\tvariação\tem\ty\tnão\tcapturada\tpelo\tmodelo\"\"\"\n",
      "\t\n",
      "return\n",
      "\t1.0\t-\t(sum_of_squared_errors(alpha,\tbeta,\tx,\ty)\t/\t\t\t\t\t\t\t\t\t\t\t\ttotal_sum_of_squares(y))\n",
      "r_squared(alpha,\tbeta,\tnum_friends_good,\tdaily_minutes_good)\t\t\t\t\t\t\n",
      "#\t0.329\n",
      "agora,\tnós\tescolhemos\tum\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "\tque\tminimizaram\ta\tsoma\tda\tprevisão\n",
      "quadrada\tde\terros.\tum\tmodelo\tlinear\tque\tpoderíamos\tter\tescolhido\té\t“sempre\n",
      "prever\t\n",
      "mean(y)\n",
      "”\t(correspondendo\ta\t\n",
      "alpha\t=\tmean(y)\n",
      "\te\t\n",
      "beta\t=\t0\n",
      "),\tcuja\tsoma\tdos\terros\tao\n",
      "quadrado\té\texatamente\tigual\tà\tsoma\tdos\tquadrados.\tisso\tsignifica\tum\tr²\tde\tzero,\n",
      "o\tque\tindica\tum\tmodelo\tque\t(obviamente,\tnesse\tcaso)\tnão\tpossui\tum\n",
      "desempenho\tmelhor\tdo\tque\tsimplesmente\tpredizer\ta\tmédia.\n",
      "claramente,\to\tmodelo\tdo\tmenor\tquadrado\tdeve\tao\tmenos\tser\ttão\tbom\tquando\n",
      "aquele,\to\tque\tsignifica\tque\ta\tsoma\tdos\terros\tao\tquadrado\té\t\n",
      "no\tmáximo\n",
      "\ta\tsoma\n",
      "dos\tquadrados,\to\tque\tsignifica\tque\tr²\tdeve\tser\tpelo\tmenos\tzero.\te\ta\tsoma\tdos\n",
      "erros\tao\tquadrado\tdeve\tser\tpelo\tmenos\t0,\to\tque\tsignifica\tque\tr²\tpode\tser\tno\n",
      "máximo\t1.\n",
      "quanto\tmaior\to\tnúmero,\tmelhor\tnosso\tmodelo\tse\tencaixa\taos\tdados.\taqui\n",
      "calculamos\tum\tr²\tde\t0.329,\to\tque\tnos\tdiz\tque\tnosso\tmodelo\té\tapenas\tmais\tou\n",
      "menos\tbom\tem\tajustar\tos\tdados,\te\tque\tclaramente\thá\toutros\tfatores\tem\tjogo.usando\to\tgradiente\tdescendente\n",
      "se\tescrevermos\t\n",
      "theta\t=\t[alpha,\tbeta]\n",
      ",\ttambém\tpodemos\tresolver\tisso\tusando\to\n",
      "gradiente\tdescendente:\n",
      "def\tsquared_error(x_i,\ty_i,\ttheta):\n",
      "alpha,\tbeta\t=\ttheta\n",
      "return\terror(alpha,\tbeta,\tx_i,\ty_i)\t**\t2\n",
      "def\tsquared_error_gradient(x_i,\ty_i,\ttheta):\n",
      "alpha,\tbeta\t=\ttheta\n",
      "return\t[-2\t*\terror(alpha,\tbeta,\tx_i,\ty_i),\t\t\t\t\t\t\t\t\n",
      "#\tderivada\tde\talpha\tparcial\n",
      "\t\t\t-2\t*\terror(alpha,\tbeta,\tx_i,\ty_i)\t*\tx_i]\t\t\t\n",
      "#\tderivada\tde\tbeta\tparcial\n",
      "#\tescolhe\tum\tvalor\taleatório\tpara\tcomeçar\n",
      "random.seed(0)\n",
      "theta\t=\t[random.random(),\trandom.random()]\n",
      "alpha,\tbeta\t=\tminimize_stochastic(squared_error,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsquared_error_gradient,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnum_friends_good,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdaily_minutes_good,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttheta,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t0.0001)\n",
      "print\talpha,\tbeta\n",
      "usando\tos\tmesmos\tdados\tnós\tconseguimos\talpha\t=\t22,93,\tbeta\t=\t0,905,\tque\tsão\n",
      "muito\tpróximos\tdas\trespostas\tcorretas.estimativa\tmáxima\tda\tprobabilidade\n",
      "por\tque\tescolhemos\tmínimos\tquadrados?\tuma\tjustificativa\tenvolve\ta\t\n",
      "estimativa\n",
      "máxima\tda\tprobabilidade\n",
      ".\n",
      "imagine\tque\ttemos\tum\tmodelo\tde\tdados\t\n",
      "v\n",
      "1\n",
      ",\t…,\t\n",
      "v\n",
      "n\n",
      "\tque\tvem\tde\tuma\tdistribuição\n",
      "que\tdepende\tde\talgum\tparâmetro\tdesconhecido\t\n",
      "θ\n",
      ":\n",
      "se\tnão\tsoubéssemos\tteta,\tpoderíamos\tvoltar\te\tpensar\tnessa\tquantidade\tcomo\ta\n",
      "probabilidade\n",
      "\tde\t\n",
      "θ\n",
      "\tdada\ta\tamostra:\n",
      "nessa\tabordagem,\to\t\n",
      "θ\n",
      "\tmais\tprovável\té\to\tvalor\tque\tmaximiza\tessa\tfunção\tde\n",
      "probabilidade;\tisto\té,\to\tvalor\tque\tfaz\tcom\tque\tos\tdados\tobservados\tsejam\tos\n",
      "mais\tprováveis.\tno\tcaso\tde\tuma\tdistribuição\tcontínua,\tna\tqual\ttemos\tuma\n",
      "função\tde\tdistribuição\tde\tprobabilidade\tno\tlugar\tde\tuma\tfunção\tde\tmassa\tde\n",
      "probabilidade,\tnós\tpodemos\tfazer\ta\tmesma\tcoisa.\n",
      "de\tvolta\tà\tregressão.\tuma\tsuposição\tque\tgeralmente\té\tfeita\tsobre\to\tmodelo\tde\n",
      "regressão\tsimples\té\tque\tos\terros\tde\tregressão\tsão\tnormalmente\tdistribuídos\tcom\n",
      "média\t0\te\talgum\t(conhecido)\tdesvio\tpadrão\t\n",
      "σ\n",
      ".\tse\tesse\tfor\to\tcaso,\tentão\ta\n",
      "probabilidade\tbaseada\tem\tver\tum\tpar\t\n",
      "(x_i,\ty_i)\n",
      "\té:\n",
      "a\tprobabilidade\tbaseada\tem\ttodo\to\tconjunto\tde\tdados\té\to\tproduto\tde\n",
      "probabilidades\tindividuais,\tque\té\tmaior\tprecisamente\tquando\t\n",
      "alpha\n",
      "\te\t\n",
      "beta\n",
      "\tsão\n",
      "escolhidos\tpara\tminimizar\ta\tsoma\tdos\terros\tquadrados.\tisto\té,\tnesse\tcaso,\n",
      "minimizar\ta\tsoma\tdos\terros\tquadrados\té\tequivalente\ta\tmaximizar\ta\n",
      "probabilidade\tdos\tdados\tobservados.para\tmais\tesclarecimentos\n",
      "continue\tlendo\tsobre\tregressão\tmúltipla\tdo\t\n",
      "capítulo\t15\n",
      "!capítulo\t15\n",
      "regressão\tmúltipla\n",
      "eu\tnão\tolho\tpara\tum\tproblema\te\tcoloco\tvariáveis\tque\tnão\to\tafetam\n",
      ".\n",
      "—bill\tparcells\n",
      "mesmo\tque\ta\tvice-presidente\testeja\timpressionada\tcom\tseu\tmodelo\tpreditivo,\n",
      "ela\tacha\tque\tvocê\tpode\tfazer\tmelhor.\tpara\tisso,\tvocê\tcolheu\tdados\tadicionais:\n",
      "para\tcada\tum\tdos\tseus\tusuários,\tvocê\tsabe\tquantas\thoras\tele\ttrabalha\tpor\tdia\te\tse\n",
      "ele\ttem\tum\tphd.\tvocê\tgostaria\tde\tusar\tesses\tdados\tadicionais\tpara\tmelhorar\tseu\n",
      "modelo.\n",
      "desta\tforma,\tvocê\tcria\tuma\thipótese\tde\tum\tmodelo\tlinear\tcom\tmais\tvariáveis\n",
      "independentes:\n",
      "obviamente,\tse\tum\tusuário\ttem\tphd\tnão\té\tum\tnúmero,\tmas\t—\tcomo\tfalamos\tno\n",
      "capítulo\t11\n",
      "\t—\tnós\tpodemos\tintroduzir\tuma\t\n",
      "variável\tfictícia\n",
      "\tigual\ta\t1\tpara\n",
      "usuários\tcom\tphd\te\t0\tpara\tusuários\tsem\tphd,\to\tque\té\ttão\tnumérico\tquanto\tas\n",
      "outras\tvariáveis.o\tmodelo\n",
      "lembre-se\tde\tque\tno\t\n",
      "capítulo\t14\n",
      "\tnós\tadaptamos\tum\tmodelo\tda\tforma:\n",
      "agora\timagine\tque\tcada\tentrada\t\n",
      "x\n",
      "i\n",
      "\tnão\té\tum\túnico\tnúmero\tmas\tum\tvetor\tde\t\n",
      "k\n",
      "números\n",
      "\txi1,\t…,\txik\n",
      ".\to\tmodelo\tde\tregressão\tmúltipla\tpresume\tque:\n",
      "em\tregressão\tmúltipla\to\tvetor\tde\tparâmetros\tgeralmente\té\tchamado\tde\t\n",
      "β\n",
      ".\tnós\n",
      "queremos\tque\tisso\tinclua\to\ttermo\tconstante\ttambém,\to\tque\tnós\tpodemos\tatingir\n",
      "adicionando\tuma\tcoluna\tde\tuns\taos\tnossos\tdados:\n",
      "beta\t=\t[alpha,\tbeta_1,\t...,\tbeta_k]\n",
      "e:\n",
      "x_i\t=\t[1,\tx_i1,\t...,\tx_ik]\n",
      "então\tnosso\tmodelo\té:\n",
      "def\n",
      "\tpredict(x_i,\tbeta):\n",
      "\"\"\"presume\tque\to\tprimeiro\telemento\tde\tcada\tx_i\té\t1\"\"\"\n",
      "return\n",
      "\tdot(x_i,\tbeta)\n",
      "nesse\tcaso\tem\tparticular,\tnossa\tvariável\tindependente\t\n",
      "x\n",
      "\tserá\tuma\tlista\tde\n",
      "vetores,\tcada\tum\tse\tparecendo\tcom:\n",
      "[1,\t\t\t\t\t\n",
      "#\ttermo\tconstante\n",
      "\t49,\t\t\t\t\n",
      "#\tnúmero\tde\tamigos\n",
      "\t4,\t\t\t\t\t\n",
      "#\thoras\tde\ttrabalho\tpor\tdia\n",
      "\t0]\t\t\t\t\t\n",
      "#\tnão\ttem\tphd•\n",
      "•\n",
      "mais\tsuposições\tdo\tmodelo\tdos\tmínimos\tquadrados\n",
      "há\tmais\talgumas\tsuposições\tque\tsão\texigidas\tpara\tque\tesse\tmodelo\t(e\tnossa\n",
      "solução)\tfaça\tsentido.\n",
      "a\tprimeira\té\tque\tas\tcolunas\tde\t\n",
      "x\n",
      "\tsejam\t\n",
      "linearmente\tindependentes\n",
      "\t—\tque\tnão\n",
      "haja\tcomo\tescrever\tqualquer\tum\tcomo\tuma\tsoma\tponderada\tdos\toutros.\tse\testa\n",
      "suposição\tfalhar,\té\timpossível\testimar\t\n",
      "beta\n",
      ".\tpara\tver\tisso\tem\tum\tcaso\textremo,\n",
      "imagine\tque\ttemos\tum\tcampo\textra\t\n",
      "num_acquaintances\n",
      "\tem\tnossos\tdados\tque\tpara\n",
      "cada\tusuário\tfosse\texatamente\tigual\ta\t\n",
      "num_friends\n",
      ".\n",
      "então,\tcomeçando\tcom\tqualquer\t\n",
      "beta\n",
      ",\tse\tadicionarmos\t\n",
      "qualquer\n",
      "\tquantidade\tao\n",
      "coeficiente\t\n",
      "num_friends\n",
      "\te\tsubtrair\ta\tmesma\tquantidade\tao\tcoeficiente\n",
      "num_acquaintances\n",
      ",\tas\tprevisões\tdo\tmodelo\tpermanecerão\tas\tmesmas.\to\tque\n",
      "significa\tque\tnão\thá\tcomo\tencontrar\t\n",
      "o\n",
      "\tcoeficiente\tpara\t\n",
      "num_friends\n",
      ".\t(geralmente,\n",
      "violações\ta\testa\tsuposição\tnão\tsão\ttão\tóbvias.)\n",
      "a\tsegunda\thipótese\timportante\té\tque\tas\tcolunas\tde\t\n",
      "x\n",
      "\tnão\testão\tcorrelacionadas\n",
      "com\tos\terros\t\n",
      "ε\n",
      ".\tse\tisto\tcalhar\tde\tacontecer,\tnossas\testimativas\tde\t\n",
      "beta\n",
      "\testarão\n",
      "sistematicamente\terradas.\n",
      "por\texemplo,\tno\t\n",
      "capítulo\t14\n",
      ",\tnós\tconstruímos\tum\tmodelo\tpreditivo\tem\tque\tcada\n",
      "amigo\tadicional\testava\tassociado\tcom\t0,90\tminutos\textras\tno\tsite.\n",
      "imagine\tque\ttambém\té\to\tcaso\tque:\n",
      "pessoas\tque\ttrabalham\tmais\thoras\tpassam\tmenos\ttempo\tno\tsite.\n",
      "pessoas\tcom\tmais\tamigos\ttendem\ta\ttrabalhar\tmais\thoras.\n",
      "isto\té,\timagine\tque\to\tmodelo\treal\té:\n",
      "minutos\t=\t\n",
      "α\n",
      "\t+\t\n",
      "β\n",
      "1\n",
      "\tamigos\t+\t\n",
      "β\n",
      "2\n",
      "\thoras\tde\ttrabalho\t+\t\n",
      "ε\n",
      "e\tque\thoras\tde\ttrabalho\te\tamigos\tsão\tpositivamente\tcorrelacionados.\tneste\tcaso,\n",
      "quando\tminimizarmos\tos\terros\tde\tum\tmodelo\tvariável:\n",
      "minutos\t=\n",
      "α\n",
      "\t+\t\n",
      "β\n",
      "1\n",
      "\tamigos\t+\t\n",
      "ε\n",
      "nós\tsubestimaremos\t\n",
      "β\n",
      "1\n",
      ".pense\tno\tque\taconteceria\tse\tnós\tfizéssemos\tprevisões\tusando\tum\tmodelo\tde\tuma\n",
      "única\tvariável\tcom\to\tvalor\t“real”\tde\t\n",
      "β\n",
      "1\n",
      ".\t(isto\té,\to\tvalor\tque\taparece\ta\tpartir\tda\n",
      "minimização\tde\terros\té\to\tque\tchamamos\tde\tmodelo\t“real”.)\tas\tprevisões\n",
      "tenderiam\ta\tser\tmuito\tpequenas\tpara\tusuários\tque\ttrabalham\tmuitas\thoras\te\n",
      "muito\tgrandes\tpara\tos\tque\ttrabalham\tpoucas\thoras,\tpois\t\n",
      "β\n",
      "2\n",
      "\t>\t0\te\tnós\n",
      "“esquecemos”\tde\tinclui-lo.\tporque\thoras\tde\ttrabalho\té\tpositivamente\n",
      "correlacionada\tcom\to\tnúmero\tde\tamigos,\tisto\tsignifica\tque\tas\tprevisões\ttendem\n",
      "a\tser\tmuito\tpequenas\tpara\tusuários\tcom\tmuitos\tamigos\te\tmuito\tgrandes\tpara\n",
      "usuários\tcom\tpoucos\tamigos.\n",
      "o\tresultado\tdisso\té\tque\tpodemos\treduzir\tos\terros\t(no\tmodelo\tde\túnica\tvariável)\n",
      "diminuindo\tnossa\testimativa\tde\t\n",
      "β\n",
      "1\n",
      ",\tque\tsignifica\tque\to\t\n",
      "β\n",
      "1\n",
      "\tque\tminimiza\to\terro\té\n",
      "menor\tdo\tque\to\tvalor\t“real”.\te,\tem\tgeral,\tquando\tvariáveis\tindependentes\tsão\n",
      "correlacionadas\tcom\terros\tcomo\taqui,\tnossa\tsolução\tdos\tmínimos\tquadrados\tnos\n",
      "dará\tuma\testimativa\tpolarizada\tde\t\n",
      "β\n",
      ".ajustando\to\tmodelo\n",
      "como\tfizemos\tno\tmodelo\tlinear\tsimples,\tescolheremos\t\n",
      "beta\n",
      "\tpara\tminimizar\ta\n",
      "soma\tdos\terros\tquadrados.\tencontrar\ta\tsolução\texata\tnão\té\ttão\tsimples\tde\tfazer\ta\n",
      "mão,\to\tque\tsignifica\tque\tprecisamos\tusar\to\tgradiente\tdescendente.\n",
      "começaremos\tcriando\tuma\tfunção\tde\terro\ta\tminimizar.\tpara\to\tgradiente\n",
      "descendente\taleatório,\tqueremos\tapenas\to\terro\tquadrado\tcorrespondente\ta\tuma\n",
      "simples\tprevisão:\n",
      "def\n",
      "\terror(x_i,\ty_i,\tbeta):\n",
      "return\n",
      "\ty_i\t-\tpredict(x_i,\tbeta)\n",
      "def\n",
      "\tsquared_error(x_i,\ty_i,\tbeta):\n",
      "return\n",
      "\terror(x_i,\ty_i,\tbeta)\t**\t2\n",
      "se\tvocê\tsabe\tcálculo,\tvocê\tpode\tcomputar:\n",
      "def\tsquared_error_gradient(x_i,\ty_i,\tbeta):\n",
      "\"\"\"o\tgradiente\t(com\trespeito\ta\tbeta)\n",
      "correspondente\tao\ti-ésimo\ttermo\tde\terro\tquadrado\"\"\"\n",
      "return\t[-2\t*\tx_ij\t*\terror(x_i,\ty_i,\tbeta)\n",
      "\t\t\t\t\tfor\tx_ij\tin\tx_i]\n",
      "caso\tcontrário,\tvocê\tprecisará\tacreditar\tna\tminha\tpalavra.\n",
      "neste\tmomento,\testamos\tprontos\tpara\tencontrar\to\tbeta\tótimo\tusando\to\tgradiente\n",
      "descendente\taleatório:\n",
      "def\n",
      "\testimate_beta(x,\ty):\n",
      "beta_initial\t=\t[random.random()\t\n",
      "for\n",
      "\tx_i\t\n",
      "in\n",
      "\tx[0]]\n",
      "return\n",
      "\tminimize_stochastic(squared_error,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsquared_error_gradient,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tx,\ty,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbeta_initial,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t0.001)\n",
      "random.seed(0)\n",
      "beta\t=\testimate_beta(x,\tdaily_minutes_good)\t\n",
      "#\t[30.63,\t0.972,\t-1.868,\t0.911]\n",
      "isso\tsignifica\tque\tnosso\tmodelo\tse\tparece\tcom\tisso:\n",
      "minutos\t=\t30,63\t+\t0,972\tamigos\t–\t1,868\thoras\tde\ttrabalho\t+\t0,911\tphdinterpretando\to\tmodelo\n",
      "você\tdeveria\tpensar\tnos\tcoeficientes\tdos\tmodelos\tcomo\trepresentantes\tde\n",
      "estimativas\tdos\timpactos\tde\tcada\tfator\tcom-todos-os-demais-mantidos-\n",
      "constantes.\to\trestante\tsendo\tigual,\tcada\tamigo\tadicional\tcorresponde\ta\tum\n",
      "minuto\textra\tpassado\tno\tsite\ta\tcada\tdia.\to\trestante\tsendo\tigual,\tcada\thora\n",
      "adicional\tno\ttrabalho\tde\tum\tusuário\tcorresponde\ta\taproximadamente\tdois\n",
      "minutos\tmenos\tgastos\tno\tsite\tpor\tdia.\to\trestante\tsendo\tigual,\tter\tum\tphd\té\n",
      "associado\ta\tpassar\tum\tminuto\textra\tno\tsite\ta\tcada\tdia.\n",
      "isso\tnão\tnos\tdiz\t(diretamente)\tnada\ta\trespeito\tdas\tinterações\tentre\tas\tvariáveis.\té\n",
      "possível\tque\to\tefeito\tde\thoras\tde\ttrabalho\tseja\tdiferente\tpara\tpessoas\tcom\tmuitos\n",
      "amigos\tdo\tque\tpara\tpessoas\tcom\tpoucos\tamigos.\teste\tmodelo\tnão\tcaptura\tisso.\n",
      "uma\tforma\tde\tlidar\tcom\ttal\tcaso\té\tinserir\tuma\tnova\tvariável\tque\tseja\to\t\n",
      "produto\n",
      "de\t“amigos”\te\t“horas\tde\ttrabalho\".\tisso\tefetivamente\tpermite\tque\to\tcoeficiente\n",
      "de\t“horas\tde\ttrabalho”\taumente\t(ou\tdiminua)\tconforme\to\tnúmero\tde\tamigos\n",
      "aumenta.\n",
      "ou\té\tpossível\tque\tquanto\tmais\tamigos\tvocê\ttem\tmais\ttempo\tvocê\tpasse\tno\tsite\n",
      "até\tcerto\tponto\n",
      ",\te\tapós\tisso\tmais\tamigos\tfazem\tcom\tque\tvocê\tpasse\tmenos\n",
      "tempo\tno\tsite.\t(talvez\tcom\tmuitos\tamigos\ta\texperiência\tseja\tdemais?)\tnós\n",
      "poderíamos\ttentar\tcapturar\tisso\tem\tnosso\tmodelo\tadicionando\toutra\tvariável\tque\n",
      "seja\to\t\n",
      "quadrado\n",
      "\tdo\tnúmero\tde\tamigos.\n",
      "uma\tvez\tque\tcomeçamos\ta\tadicionar\tvariáveis,\tprecisamos\tnos\tpreocupar\tse\tos\n",
      "coeficientes\tsão\t“importantes”.\tnão\thá\tlimites\tpara\tos\tnúmeros\tde\tprodutos,\n",
      "logs,\tquadrados\te\tpotências\tde\tlouis\tgrace\tque\tpodemos\tadicionar.o\tbenefício\tdo\tajuste\n",
      "mais\tuma\tvez,\tnós\tpodemos\tolhar\tpara\tr²,\tque\tagora\taumentou\tpara\t0,68:\n",
      "def\n",
      "\tmultiple_r_squared(x,\ty,\tbeta):\n",
      "sum_of_squared_errors\t=\tsum(error(x_i,\ty_i,\tbeta)\t**\t2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tx_i,\ty_i\t\n",
      "in\n",
      "\tzip(x,\ty))\n",
      "return\n",
      "\t1.0\t-\tsum_of_squared_errors\t/\ttotal_sum_of_squares(y)\n",
      "lembre-se,\tentretanto,\tque\tadicionar\tnovas\tvariáveis\ta\tuma\tregressão\tirá\n",
      "necessariamente\n",
      "\taumentar\tr².\tafinal,\to\tmodelo\tde\tregressão\tsimples\té\tapenas\to\n",
      "caso\tespecial\tdo\tmodelo\tde\tregressão\tmúltipla\tem\tque\tos\tcoeficientes\tde\t“horas\n",
      "de\ttrabalho”\te\t“phd”\tsão\tiguais\ta\t0.\to\tmelhor\tmodelo\tde\tregressão\tmúltipla\tterá\n",
      "necessariamente\tum\terro\tpelo\tmenos\ttão\tpequeno\tquanto\taquele.\n",
      "por\tisso,\tem\tregressão\tmúltipla,\tnós\ttambém\tprecisamos\tver\tos\t\n",
      "erros\tpadrões\n",
      "dos\tcoeficientes,\tque\tmedem\tquão\tcertos\testamos\tem\tnossas\testimativas\tpara\n",
      "cada\t\n",
      "β\n",
      "1\n",
      ".\ta\tregressão\tcomo\tum\ttodo\tpode\tajustar\tnossos\tdados\tmuito\tbem,\tmas\n",
      "se\talgumas\tdas\tvariáveis\tindependentes\tforem\tcorrelacionadas\t(ou\tirrelevantes),\n",
      "seus\tcoeficientes\tpodem\tnão\t\n",
      "significar\n",
      "\ttanto.\n",
      "a\tabordagem\ttípica\tpara\tmedir\testes\terros\tcomeça\tcom\toutra\tsuposição\t—\tque\n",
      "erros\t\n",
      "ε\n",
      "i\n",
      "\tsão\tvariáveis\tindependentes\taleatórias\tnormais\tcom\tmédia\t0\te\talgum\n",
      "(desconhecido)\tdesvio\tpadrão\t\n",
      "ơ\n",
      "\tcompartilhado.\tneste\tcaso,\tnós\t(ou,\tmais\n",
      "provavelmente,\tnosso\tsoftware\tde\testatística)\tpodemos\tusar\ta\tálgebra\tlinear\tpara\n",
      "encontrar\to\terro\tpadrão\tpara\tcada\tcoeficiente.\tquanto\tmaior\tfor,\tmenos\tcerteza\n",
      "tem\tnosso\tmodelo\tsobre\to\tcoeficiente.\tinfelizmente,\tnão\tpodemos\tfazer\tesse\ttipo\n",
      "de\tálgebra\tlinear\tdo\tzero.digressão:\ta\tinicialização\n",
      "imagine\tque\ttemos\tum\tmodelo\tde\t\n",
      "n\n",
      "\tpontos\tde\tdados\tgerados\tpor\talguma\n",
      "distribuição\t(desconhecida\tpor\tnós:\n",
      "data\t=\tget_sample(num_points=n)\n",
      "no\t\n",
      "capítulo\t5\n",
      ",\tescrevemos\tuma\tfunção\t\n",
      "median\n",
      "\tpara\tcomputar\ta\tmediana\tdos\n",
      "dados\tobservados,\ta\tqual\tpodemos\tusar\tcomo\testimativa\tda\tprópria\tmediana\tda\n",
      "distribuição.\n",
      "mas\tquão\tconfiantes\tpodemos\testar\tcom\trelação\tà\tnossa\testimativa?\tse\ttodos\tos\n",
      "dados\tno\texemplo\tsão\tpróximos\ta\t100,\tparece\tque\ta\tmediana\té\tpróxima\ta\t100.\n",
      "se\taproximadamente\tmetade\tdos\tdados\tno\tmodelo\tforem\tpróximos\tde\t0\te\ta\n",
      "outra\tmetade\tpróxima\tde\t200,\tentão\tnão\tpodemos\testar\ttão\tcertos\tsobre\ta\n",
      "mediana.\n",
      "se\tpudéssemos\tpegar\tnovos\tmodelos\trepetidamente,\tpoderíamos\tcomputar\ta\n",
      "mediana\tpara\tcada\te\tver\ta\tdistribuição\tdelas.\tgeralmente\tnão\tpodemos.\to\tque\n",
      "podemos\tfazer\té\tinicializar\tnovos\tconjuntos\tde\tdados\tescolhendo\t\n",
      "n\n",
      "\tpontos\tde\n",
      "dados\t\n",
      "com\tsubstituição\n",
      "\ta\tpartir\tde\tnossos\tdados\te\tentão\tcomputar\tas\tmedianas\n",
      "destes\tconjuntos\tde\tdados\tsintéticos:\n",
      "def\tbootstrap_sample(data):\n",
      "\"\"\"amostra\taleatoriamente\tlen(dados)\telementos\tcom\tsubstituição\"\"\"\n",
      "return\t[random.choice(data)\tfor\t_\tin\tdata]\n",
      "def\tbootstrap_statistic(data,\tstats_fn,\tnum_samples):\n",
      "\"\"\"avalia\tstats_fn\tem\tnum_samples\tamostra\tde\tinicialização\ta\tpartir\tdos\tdados\"\"\"\n",
      "return\t[stats_fn(bootstrap_sample(data))\n",
      "\t\t\t\tfor\t_\tin\trange(num_samples)]\n",
      "por\texemplo,\tconsidere\tos\tdois\tseguintes\tconjuntos\tde\tdados:\n",
      "#\t101\tpontos\ttodos\tmuito\tpróximos\tde\t100\n",
      "close_to_100\t=\t[99.5\t+\trandom.random()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(101)]\n",
      "#\t101\tpontos,\t50\tpróximos\tde\t0,\t50\tpróximos\tde\t200\n",
      "far_from_100\t=\t([99.5\t+\trandom.random()]\t+\n",
      "\t\t\t\t\t\t\t\t\t[random.random()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(50)]\t+\n",
      "\t\t\t\t\t\t\t\t\t[200\t+\trandom.random()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(50)])\n",
      "se\tvocê\tcomputar\ta\tmediana\tpara\tcada,\tambas\tserão\tmuitos\tpróximas\tde\t100.\n",
      "entretanto,\tse\tvocê\tolhar\tpara:bootstrap_statistic(close_to_100,\tmedian,\t100)\n",
      "você\tverá\tem\tsua\tmaioria\tnúmeros\tpróximos\tde\t100.\tenquanto\tque,\tse\tvocê\n",
      "olhar\tpara:\n",
      "bootstrap_statistic(far_from_100,\tmedian,\t100)\n",
      "você\tverá\tmuitos\tnúmeros\tpróximos\tde\t0\te\tmuitos\tpróximos\tde\t200.\n",
      "o\tdesvio\tpadrão\tdo\tprimeiro\tconjunto\tde\tmedianas\té\tpróximo\tde\t0\tenquanto\tque\n",
      "o\tdo\tsegundo\té\tpróximo\tde\t100.\teste\tcaso\textremo\tseria\tmuto\tfácil\tde\tperceber\n",
      "inspecionando\tmanualmente\tos\tdados\tmas,\tno\tgeral,\tisso\tnão\té\tverdade.erros\tpadrões\tde\tcoeficientes\tde\tregressão\n",
      "nós\tpodemos\tusar\ta\tmesma\tabordagem\tpara\tcalcular\tos\terros\tpadrões\tdos\n",
      "nossos\tcoeficientes\tde\tregressão.\tnós\trepetidamente\ttiramos\tuma\tamostra\tde\n",
      "inicialização\tdos\tnossos\tdados\te\tcalculamos\t\n",
      "beta\n",
      "\tbaseado\tnaquela\tamostra.\tse\to\n",
      "coeficiente\tcorrespondente\ta\tuma\tdas\tvariáveis\tindependentes\t(digamos\n",
      "num_friends\n",
      ")\tnão\tvariar\tmuitos\tpelos\tmodelos,\tnós\tpodemos\tficar\tconfiantes\tque\n",
      "nossa\testimativa\testá\trelativamente\tcorreta.\tse\to\tcoeficiente\tvariar\tmuito,\tnão\n",
      "podemos\tficar\ttão\tconfiantes\tassim.\n",
      "o\túnico\tdetalhe\té\tque,\tantes\tda\tamostragem,\tprecisamos\tcompactar\t(zip)\tnossos\n",
      "dados\tx\te\ty\tpara\tcertificar-nos\tde\tque\tvalores\tcorrespondentes\tde\tvariáveis\n",
      "independentes\te\tdependentes\tsejam\tamostrados\tjuntos.\tisso\tsignifica\tque\n",
      "bootstrap_sample\n",
      "\tretornará\tuma\tlista\tde\tpares\t(\n",
      "x_i,\ty_i\n",
      "),\tque\tprecisará\tse\treagrupar\tem\n",
      "x_sample\n",
      "\te\t\n",
      "y_sample\n",
      ".\n",
      "def\n",
      "\testimate_sample_beta(sample):\n",
      "\"\"\"amostra\té\tuma\tlista\tde\tpares\t(x_i,\ty_i)\"\"\"\n",
      "x_sample,\ty_sample\t=\tzip(*sample)\t\n",
      "#\ttruque\tmágico\tpara\tdescompactar\n",
      "return\n",
      "\testimate_beta(x_sample,\ty_sample)\n",
      "random.seed(0)\t\n",
      "#\tpara\tque\tvocê\tconsiga\to\tmesmo\tresultado\tque\teu\n",
      "bootstrap_betas\t=\tbootstrap_statistic(zip(x,\tdaily_minutes_good),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\testimate_sample_beta,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t100)\n",
      "e\tapós\tisso\tpodemos\tcalcular\to\tdesvio\tpadrão\tde\tcada\tcoeficiente:\n",
      "bootstrap_standard_errors\t=\t[\n",
      "standard_deviation([beta[i]\tfor\tbeta\tin\tbootstrap_betas])\n",
      "for\ti\tin\trange(4)]\n",
      "#\t[1,174,\t\t\t#\ttermo\tconstante,\t\terro\treal\t=\t1,19\n",
      "#\t\t0,079,\t\t\t#\tnum_friends,\t\t\t\t\t\terro\treal\t=\t0,080\n",
      "#\t\t0,131,\t\t\t#\tdesempregado,\t\t\t\t\terro\treal\t=\t0,127\n",
      "#\t\t0,990]\t\t\t#\tphd,\t\t\t\t\t\t\t\t\t\t\t\t\t\terro\treal\t=\t0,998\n",
      "nós\tpodemos\tusar\tisso\tpara\ttestar\thipóteses,\tcomo\t“\n",
      "β\n",
      "i\n",
      "\té\tigual\ta\tzero?”\tde\tacordo\n",
      "com\ta\thipótese\tnula\t\n",
      "β\n",
      "1\n",
      "\t=\t0\t(e\tcom\tnossas\toutras\tpremissas\tsobre\ta\tdistribuição\n",
      "de\t\n",
      "ε\n",
      "i\n",
      "),\ta\testatística:que\té\tnossa\testimativa\tde\t\n",
      "β\n",
      "1\n",
      ",\tdividida\tpela\tnossa\testimativa\tde\terro\tpadrão,\n",
      "segue\tuma\t\n",
      "distribuição\tt\tde\tstudent\n",
      "\tcom\t“\n",
      "n\t–\tk\n",
      "\tpontos\tde\tliberdade\".\n",
      "se\ttivéssemos\ta\tfunção\t\n",
      "students_t_cd\n",
      "f\tpoderíamos\tcomputar\tvalores\t\n",
      "p\n",
      "\tpara\tcada\n",
      "coeficiente\tmínimo\tquadrado\tpara\tindicar\ta\tprobabilidade\tde\tobservarmos\ttal\n",
      "valor\tse\to\tcoeficiente\treal\tfosse\tzero.\tinfelizmente,\tnós\tnão\ttemos\ttal\tfunção.\n",
      "(mas\tteríamos\tse\tnão\testivéssemos\ttrabalhando\ta\tpartir\tdo\tzero.)\n",
      "entretanto,\tconforme\tos\tgraus\tde\tliberdade\taumentam,\ta\tdistribuição\tt\tfica\tmais\n",
      "perto\tde\tum\tpadrão\tnormal.\tem\tuma\tsituação\tcomo\tessa,\tem\tque\t\n",
      "n\n",
      "\té\tmuito\n",
      "maior\tque\t\n",
      "k\n",
      ",\tnós\tpodemos\tusar\t\n",
      "normal_cdf\n",
      "\te\tainda\tnos\tsentir\tbem:\n",
      "def\tp_value(beta_hat_j,\tsigma_hat_j):\n",
      "if\tbeta_hat_j\t>\t0:\n",
      "\t\n",
      "#\tse\to\tcoeficiente\té\tpositivo,\tprecisamos\tcomputar\tduas\tvezes\ta\n",
      "\t\n",
      "#\tprobabilidade\tde\tver\tum\tvalor\tainda\t*maior*\n",
      "\t\n",
      "return\n",
      "\t2\t*\t(1\t-\tnormal_cdf(beta_hat_j\t/\tsigma_hat_j))\n",
      "else\n",
      ":\n",
      "\t\n",
      "#\tcaso\tcontrário,\tduas\tvezes\ta\tprobabilidade\tde\tver\tum\tvalor\t*menor*\n",
      "\t\n",
      "return\n",
      "\t2\t*\tnormal_cdf(beta_hat_j\t/\tsigma_hat_j)\n",
      "p_value(30.63,\t1.174)\t\t\t\n",
      "#\t~0\t\t\t(termo\tconstante)\n",
      "p_value(0.972,\t0.079)\t\t\t\n",
      "#\t~0\t\t\t(num_friends)\n",
      "p_value(-1.868,\t0.131)\t\t\n",
      "#\t~0\t\t\t(work_hours)\n",
      "p_value(0.911,\t0.990)\t\t\t\n",
      "#\t0.36\t(phd)\n",
      "(em\tuma\tsituação\tnão\tcomo\tessa,\tnós\testaríamos\tusando\tum\tprograma\n",
      "estatístico\tque\tsabe\ttanto\tcomputar\ta\tdistribuição\t\n",
      "t\n",
      "\tquanto\tos\terros\tpadrões\n",
      "exatos.)\n",
      "enquanto\ta\tmaioria\tdos\tcoeficientes\tpossuem\tvalores\t\n",
      "p\n",
      "\tpequenos\t(sugerindo\tque\n",
      "eles\trealmente\tnão\tsão\tzeros),\to\tcoeficiente\tpara\t“phd”\tnão\té\n",
      "“significantemente”\tdiferente\tde\tzero,\to\tque\ttorna\tpossível\tque\to\tcoeficiente\tde\n",
      "“phd”\tseja\taleatório.\n",
      "em\tcenários\tde\tregressão\tmais\telaborados,\tàs\tvezes\tvocê\tquer\ttestar\thipóteses\n",
      "mais\telaboradas\tsobre\tos\tdados,\tcomo\t“pelo\tmenos\tum\tde\t\n",
      "β\n",
      "1\n",
      "\tnão\té\tzero”\tou\t“\n",
      "β\n",
      "1\n",
      "é\tigual\ta\t\n",
      "β\n",
      "2\n",
      "\te\tβ\n",
      "3\n",
      "\té\tigual\ta\t\n",
      "β\n",
      "4\n",
      "”,\tque\tvocê\tpode\tfazer\tcom\tum\t\n",
      "teste\tf\n",
      ",\tque\testá\tfora\n",
      "do\tescopo\tdeste\tlivro.regularização\n",
      "na\tprática,\tvocê\tgeralmente\taplicará\tregressão\tlinear\tem\tconjuntos\tde\tdados\n",
      "com\tgrandes\tquantidades\tde\tvariáveis.\tisso\tcria\talgumas\trugas\textras.\tprimeiro,\n",
      "quanto\tmais\tvariáveis\tvocê\tusar,\tmaior\ta\tprobabilidade\tde\tvocê\tsobreajustar\tseu\n",
      "modelo\tao\tconjunto\tde\ttreinamento.\te\tsegundo,\tquanto\tmais\tcoeficientes\tnão-\n",
      "zero\tvocê\ttiver,\tmais\tdifícil\tserá\tentendê-los.\tse\to\tobjetivo\té\t\n",
      "explicar\n",
      "\talgum\n",
      "fenômeno,\tum\tmodelo\tpequeno\tcom\ttrês\tfatores\tpode\tser\tmais\tútil\tdo\tque\tum\n",
      "modelo\tum\tpouco\tmelhor\tcom\tcentenas.\n",
      "a\t\n",
      "regularização\n",
      "\té\tuma\tabordagem\tna\tqual\tnós\tadicionamos\tao\ttermo\tde\terro\n",
      "uma\tpenalidade\tque\taumenta\t\n",
      "beta\n",
      "\taumenta.\tentão\tnós\tminimizamos\to\terro\te\ta\n",
      "penalidade\tcombinadas.\tquanto\tmais\timportância\tdermos\tem\ttermos\tde\n",
      "penalidade,\tmais\tdesencorajamos\tcoeficientes\tgrandes.\n",
      "por\texemplo,\tem\t\n",
      "regressão\tde\tcumeeira\n",
      "\t(\n",
      "ridge\n",
      "),\tadicionamos\tuma\tpenalidade\n",
      "proporcional\tà\tsoma\tdos\tquadrados\tde\t\n",
      "beta_i\n",
      ".\t(exceto\tque\tnós\ttipicamente\tnão\n",
      "penalizamos\t\n",
      "beta_o\n",
      ",\to\ttermo\tconstante.)\n",
      "#\talpha\té\tum\t*hiperparâmetro*\tque\tcontrola\tquão\tsevera\ta\tpenalidade\té\n",
      "#\tàs\tvezes\té\tchamado\tde\t“lambda”\tmas\tisso\tjá\ttem\tum\tsignificado\tem\tpython\n",
      "def\n",
      "\tridge_penalty(beta,\talpha):\n",
      "return\n",
      "\talpha\t*\tdot(beta[1:],\tbeta[1:])\n",
      "def\n",
      "\tsquared_error_ridge(x_i,\ty_i,\tbeta,\talpha):\n",
      "\t\n",
      "\"\"\"estimativa\tde\terro\tmais\ta\tpenalidade\tridge\tsobre\tbeta\"\"\"\n",
      "return\terror(x_i,\ty_i,\tbeta)\t**\t2\t+\tridge_penalty(beta,\talpha)\n",
      "que\tvocê\tpode\tentão\tcolocar\to\tgradiente\tdescendente\tcomo\tsempre:\n",
      "def\tridge_penalty_gradient(beta,\talpha):\n",
      "\"\"\"gradiente\tsomente\tde\tpenalidade\tridge\"\"\"\n",
      "return\t[0]\t+\t[2\t*\talpha\t*\tbeta_j\tfor\tbeta_j\tin\tbeta[1:]]\n",
      "def\tsquared_error_ridge_gradient(x_i,\ty_i,\tbeta,\talpha):\n",
      "\"\"\"gradiente\tcorrespondente\tao\ti-ésimo\ttermo\tde\terro\tquadrado\n",
      "incluindo\ta\tpenalidade\tridge\"\"\"\n",
      "return\tvector_add(squared_error_gradient(x_i,\ty_i,\tbeta),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tridge_penalty_gradient(beta,\talpha))\n",
      "def\testimate_beta_ridge(x,\ty,\talpha):\n",
      "\"\"\"usa\to\tgradiente\tdescendente\tpara\tencaixar\tuma\tregressão\tridge\n",
      "com\tpenalidade\talfa\"\"\"\n",
      "beta_initial\t=\t[random.random()\tfor\tx_i\tin\tx[0]]return\tminimize_stochastic(partial(squared_error_ridge,\talpha=alpha),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpartial(squared_error_ridge_gradient,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\talpha=alpha),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tx,\ty,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbeta_initial,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t0.001)\n",
      "com\t\n",
      "alpha\n",
      "\tem\tzero,\tnão\thá\tpenalidade\te\tconseguimos\tos\tmesmos\tresultados\tde\n",
      "antes:\n",
      "random.seed(0)\n",
      "beta_0\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=0.0)\n",
      "#\t[30.6,\t0.97,\t-1.87,\t0.91]\n",
      "dot(beta_0[1:],\tbeta_0[1:])\t\n",
      "#\t5.26\n",
      "multiple_r_squared(x,\tdaily_minutes_good,\tbeta_0)\t\n",
      "#\t0.680\n",
      "conforme\taumentamos\t\n",
      "alpha\n",
      ",\to\tbenefício\tdo\tajuste\tpiora,\tmas\to\ttamanho\tde\t\n",
      "beta\n",
      "diminui:\n",
      "beta_0_01\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=0.01)\n",
      "#\t[30.6,\t0.97,\t-1.86,\t0.89]\n",
      "dot(beta_0_01[1:],\tbeta_0_01[1:])\t\n",
      "#\t5.19\n",
      "multiple_r_squared(x,\tdaily_minutes_good,\tbeta_0_01)\t\n",
      "#\t0.680\n",
      "beta_0_1\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=0.1)\n",
      "#\t[30.8,\t0.95,\t-1.84,\t0.54]\n",
      "dot(beta_0_1[1:],\tbeta_0_1[1:])\t\n",
      "#\t4.60\n",
      "multiple_r_squared(x,\tdaily_minutes_good,\tbeta_0_1)\t\n",
      "#\t0.680\n",
      "beta_1\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=1)\n",
      "#\t[30.7,\t0.90,\t-1.69,\t0.085]\n",
      "dot(beta_1[1:],\tbeta_1[1:])\t\n",
      "#\t3.69\n",
      "multiple_r_squared(x,\tdaily_minutes_good,\tbeta_1)\t\n",
      "#\t0.676\n",
      "beta_10\t=\testimate_beta_ridge(x,\tdaily_minutes_good,\talpha=10)\n",
      "#\t[28.3,\t0.72,\t-0.91,\t-0.017]\n",
      "dot(beta_10[1:],\tbeta_10[1:])\t#\t1.36\n",
      "multiple_r_squared(x,\tdaily_minutes_good,\tbeta_10)\t#\t0.573\n",
      "em\tparticular,\to\tcoeficiente\tem\t“phd”\tsome\tconforme\taumentamos\ta\n",
      "penalidade,\to\tque\testá\tde\tacordo\tcom\tnosso\tresultado\tanterior\tque\tnão\tfoi\n",
      "significantemente\tdiferente\tde\tzero.\n",
      "geralmente,\tvocê\tquereria\treescalar\tseus\tdados\tantes\tde\tusar\tessa\tabordagem.\tafinal,\n",
      "se\tvocê\tmuda\tanos\tde\texperiência\tpara\tséculos\tde\texperiência,\tseu\tcoeficiente\tde\n",
      "mínimo\tquadrado\taumentar\tpor\tum\tfator\tde\t100\te\tinesperadamente\tserá\tpenalizado\n",
      "muito\tmais,\tmesmo\tsendo\to\tmesmo\tmodelo.outra\tabordagem\té\ta\tregressão\tlaço\t(\n",
      "lasso\n",
      "),\tque\tusa\ta\tpenalidade:\n",
      "def\n",
      "\tlasso_penalty(beta,\talpha):\n",
      "return\n",
      "\talpha\t*\tsum(abs(beta_i)\t\n",
      "for\n",
      "\tbeta_i\t\n",
      "in\n",
      "\tbeta[1:])\n",
      "enquanto\ta\tpenalidade\tde\tcumeeira\tdiminui\tos\tcoeficientes\tno\tgeral,\ta\n",
      "penalidade\tlaço\ttende\ta\tforçar\tos\tcoeficientes\ta\tserem\tzero,\to\tque\ta\ttorna\tboa\n",
      "para\taprender\tmodelos\tesparsos.\tinfelizmente,\tnão\té\tagradável\tpara\to\tgradiente\n",
      "descendente,\to\tque\tsignifica\tque\tnós\tnão\tconseguiremos\tresolvê-la\tdo\tzero.•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "a\tregressão\tpossui\tuma\tteoria\trica\te\texpansiva.\teste\té\toutro\tassunto\tque\n",
      "você\tdeveria\tconsiderar\tler\tum\tlivro\tdidático\tou,\tpelo\tmenos,\tartigos\tdo\n",
      "wikipédia.\n",
      "scikit-learn\tpossui\tum\tmódulo\tlinear_model\t(\n",
      "http://bit.ly/1ycpg63\n",
      ")\tque\n",
      "fornece\tum\tmodelo\t\n",
      "linearregression\n",
      "\tsimilar\tao\tnosso,\tbem\tcomo\tuma\n",
      "regressão\t\n",
      "ridge\n",
      ",\tregressão\t\n",
      "lasso\n",
      "\te\toutros\ttipos\tde\tregularização.\n",
      "statsmodel\t(\n",
      "http://statsmodels.sourceforge.net\n",
      ")\té\toutro\ttipo\tde\tmódulo\n",
      "python\tque\tcontém\t(entre\toutras\tcoisas)\tmodelos\tde\tregressão\tlinear.capítulo\t16\n",
      "regressão\tlogística\n",
      "muitas\tpessoas\tdizem\tque\thá\tuma\tlinha\ttênue\tentre\ta\tgenialidade\te\ta\tloucura.\tnão\tacho\tque\texista\tuma\n",
      "linha\ttênue,\teu\tacho\tque\thá\tum\tabismo\n",
      ".\n",
      "—\n",
      "bill\tbailey\n",
      "no\t\n",
      "capítulo\t1\n",
      ",\tnós\tdemos\tuma\tpequena\tolhada\tno\tproblema\tde\ttentar\tprever\n",
      "quais\tusuários\tda\tdatasciencester\tpagavam\tpor\tcontas\tpremium.\trevisitaremos\n",
      "esse\tproblema\tneste\tcapítulo.o\tproblema\n",
      "nós\ttemos\tum\tconjunto\tde\tdados\tanônimos\tde\taproximadamente\t200\tusuários,\n",
      "contendo\to\tsalário\tde\tcada\tusuário,\tseus\tanos\tde\texperiência\tcomo\tcientistas\tde\n",
      "dados\te\tse\tpagam\tpor\tuma\tconta\tpremium\t(\n",
      "figura\t16-1\n",
      ").\tcomo\té\tcomum\tcom\n",
      "variáveis\tcategóricas,\tnós\trepresentamos\tas\tvariáveis\tdependentes\tcomo\t0\t(sem\n",
      "conta\tpremium)\tou\t1\t(conta\tpremium).\n",
      "como\tde\tcostume,\tnossos\tdados\testão\tem\tuma\tmatriz\tna\tqual\tcada\tfileira\té\tuma\n",
      "lista\t\n",
      "[experience,\tsalary,\tpaid_account]\n",
      ".\tvamos\ttransformá-la\tno\tformato\tdo\tqual\n",
      "precisamos:\n",
      "x\t=\t[[1]\t+\trow[:2]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata]\t\n",
      "#\tcada\telemento\té\t[1,\texperience,\tsalary]\n",
      "y\t=\t[row[2]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tdata]\t\t\t\t\t\t\t\t\n",
      "#\tcada\telemento\té\tpaid_account\n",
      "uma\tprimeira\ttentativa\tóbvia\té\tusar\ta\tregressão\tlinear\te\tencontrar\to\tmelhor\n",
      "modelo:\n",
      "conta\tpaga\t=\t\n",
      "β\n",
      "0\n",
      "\t+\n",
      "β\n",
      "1\n",
      "\texperiência\t+\t\n",
      "β\n",
      "2\n",
      "\tsalário\t+\t\n",
      "˚figura\t16-1.\tusuários\tpagantes\te\tnão\tpagantes\n",
      "e\tcertamente\tnão\thá\tnada\tque\tnos\timpeça\tde\tmodelar\to\tproblema\tdessa\tforma.\n",
      "os\tresultados\tsão\texibidos\tna\t\n",
      "figura\t16-2\n",
      ".\n",
      "rescaled_x\t=\trescale(x)\n",
      "beta\t=\testimate_beta(rescaled_x,\ty)\t\n",
      "#\t[0.26,\t0.43,\t-0.43]\n",
      "predictions\t=\t[predict(x_i,\tbeta)\tfor\tx_i\tin\trescaled_x]\n",
      "plt.scatter(predictions,\ty)\n",
      "plt.xlabel(\"prevista\")\n",
      "plt.ylabel(\"realizada\")\n",
      "plt.show()•\n",
      "•\n",
      "figura\t16-2.\tusando\tregressão\tlinear\tpara\tprever\tcontas\tpremium\n",
      "mas\tessa\tabordagem\tleva\ta\talguns\tproblemas\timediatos:\n",
      "nós\tgostaríamos\tque\tas\tsaídas\tda\tnossa\tprevisão\tfossem\t0\tou\t1,\tpara\n",
      "indicar\ta\tmembresia\tda\tclasse.\testaria\ttudo\tbem\tse\teles\testivessem\tentre\t0\n",
      "e\t1,\tuma\tvez\tque\tnós\tpodemos\tinterpretar\tessas\tprobabilidades\t—\tuma\n",
      "saída\tde\t0,25\tpoderia\tsignificar\t25%\tde\tchance\tde\tser\tum\tsócio\tpagante.\n",
      "mas\tsaídas\tdo\tmodelo\tlinear\tpodem\tser\tgrandes\tnúmeros\tpositivos\tou\taté\n",
      "mesmo\tnúmeros\tnegativos,\tfazendo\tcom\tque\ta\tinterpretação\tnão\tseja\n",
      "clara.\tde\tfato,\taqui\tmuitas\tdas\tnossas\tprevisões\tforam\tnegativas.\n",
      "o\tmodelo\tde\tregressão\tlinear\tpresumiu\tque\tos\terros\tnão\teram\n",
      "correlacionados\tcom\tas\tcolunas\tde\t\n",
      "x\n",
      ".\tmas\taqui,\to\tcoeficiente\tde\tregressão\n",
      "para\t\n",
      "experience\n",
      "\té\t0,43,\tindicando\tque\tmais\texperiência\tleva\ta\tmaiores\n",
      "probabilidades\tde\tuma\tconta\tpremium.\tisso\tsignifica\tque\tnosso\tmodelo\n",
      "apresenta\tvalores\tmuito\tgrandes\tpara\tpessoas\tcom\tmuita\texperiência.\tmasnós\tsabemos\tque\tos\tvalores\treais\tdevem\tser,\tno\tmáximo\t1,\to\tque\tsignifica\n",
      "que\tsaídas\tmuito\tgrandes\tcorrespondem\ta\tvalores\tnegativos\tmuito\taltos\n",
      "nos\ttermos\tde\terros.\tsendo\tesse\to\tcaso,\tnossa\testimativa\tpara\tbeta\té\n",
      "polarizada.\n",
      "o\tque\tnós\tgostaríamos\té\tque\tgrandes\tvalores\tpositivos\tde\t\n",
      "dot(x_i,\tbeta)\n",
      "correspondessem\tàs\tprobabilidades\tpróximas\ta\t1\te\tque\tgrandes\tvalores\tnegativos\n",
      "correspondessem\tàs\tprobabilidades\tpróximas\ta\t0.\tnós\tpodemos\trealizar\tisso\n",
      "aplicando\toutra\tfunção\tno\tresultado.a\tfunção\tlogística\n",
      "no\tcaso\tda\tregressão\tlogística,\tusamos\ta\t\n",
      "função\tlogística\n",
      ",\texibida\tna\t\n",
      "figura\t16-\n",
      "3\n",
      ":\n",
      "def\n",
      "\tlogistic(x):\n",
      "return\n",
      "\t1.0\t/\t(1\t+\tmath.exp(-x))\n",
      "figura\t16-3.\ta\tfunção\tlogística\n",
      "conforme\tsua\tentrada\tfica\tgrande\te\tpositiva,\tela\tse\taproxima\tcada\tvez\tmais\tde\t1.\n",
      "conforme\tsua\tentrada\tfica\tgrande\te\tnegativa,\tse\taproxima\tmais\tde\t0.\talém\n",
      "disso,\tela\ttem\ta\tpropriedade\tconveniente\tda\tsua\tderivada\tser\tdada\tpor:\n",
      "def\n",
      "\tlogistic_prime(x):\n",
      "return\n",
      "\tlogistic(x)\t*\t(1\t-\tlogistic(x))\n",
      "a\tqual\tnós\tutilizaremos\tem\tum\tinstante.\tnós\tusaremos\tisto\tpara\tajustar\tum\n",
      "modelo:em\tque\t\n",
      "f\n",
      "\té\ta\tfunção\t\n",
      "logistic\n",
      ".\n",
      "lembre-se\tque,\tpara\ta\tregressão\tlinear,\tnós\tajustamos\to\tmodelos\tminimizando\ta\n",
      "soma\tdos\terros\tquadrados,\to\tque\tacabou\tescolhendo\to\t\n",
      "β\n",
      "\tque\tmaximizou\ta\n",
      "probabilidade\tdos\tdados.\n",
      "aqui\tas\tduas\tnão\tsão\tequivalentes,\tentão\tusaremos\to\tgradiente\tdescendente\tpara\n",
      "maximizar\ta\tprobabilidade\tdiretamente.\tisso\tsignifica\tque\tprecisamos\tcalcular\ta\n",
      "função\tde\tprobabilidade\te\tseu\tgradiente.\n",
      "dado\talgum\t\n",
      "β\n",
      ",\tnosso\tmodelo\tdiz\tque\tcada\t\n",
      "y\n",
      "1\n",
      "\tdeveria\tser\tigual\ta\t1\tcom\n",
      "probabilidade\t\n",
      "f(x\n",
      "i\n",
      "\tβ)\n",
      "\te\t0\tcom\tprobabilidade\t1\t–\t\n",
      "f(x\n",
      "i\n",
      "\tβ)\n",
      ".\n",
      "o\tpdf\tpara\t\n",
      "y\n",
      "1\n",
      "\tpode\tser\tescrito\tcomo:\n",
      "se\t\n",
      "y\n",
      "1\n",
      "\té\t0,\tisso\té\tigual\ta:\n",
      "e\tse\t\n",
      "y\n",
      "1\n",
      "\té\t1,\té\tigual\ta:\n",
      "acaba\tsendo\tmais\tsimples\tmaximizar\to\t\n",
      "log\tda\tprobabilidade\n",
      ":\n",
      "porque\ta\tfunção\tlog\té\tmonotonamente\tcrescente,\tqualquer\t\n",
      "beta\n",
      "\tque\tmaximize\to\n",
      "log\tda\tprobabilidade\ttambém\tmaximiza\ta\tprobabilidade\te\tvice-versa:\n",
      "def\n",
      "\tlogistic_log_likelihood_i(x_i,\ty_i,\tbeta):\n",
      "if\n",
      "\ty_i\t==\t1:\n",
      "\t\n",
      "return\n",
      "\tmath.log(logistic(dot(x_i,\tbeta)))\n",
      "else\n",
      ":\n",
      "\t\n",
      "return\n",
      "\tmath.log(1\t-\tlogistic(dot(x_i,\tbeta)))\n",
      "se\tsupormos\tque\tpontos\tde\tdados\tdiferentes\tsão\tindependentes\tuns\tdos\toutros,\ta\n",
      "probabilidade\ttotal\té\to\tproduto\tdas\tprobabilidades\tindividuais.\to\tque\tsignifica\n",
      "que\to\tlog\ttotal\tda\tprobabilidade\té\ta\tsoma\tdas\tprobabilidades\tdos\tlog\tindividuais;def\n",
      "\tlogistic_log_likelihood(x,\ty,\tbeta):\n",
      "return\n",
      "\tsum(logistic_log_likelihood_i(x_i,\ty_i,\tbeta)\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tx_i,\ty_i\t\n",
      "in\n",
      "\tzip(x,\ty))\n",
      "um\tpouco\tde\tcálculo\tnos\tfornece\to\tgradiente:\n",
      "def\tlogistic_log_partial_ij(x_i,\ty_i,\tbeta,\tj):\n",
      "\"\"\"aqui\ti\té\to\tíndice\tdo\tponto\tde\tdados\n",
      ",\n",
      "j\té\to\tíndice\tda\tderivada\"\"\"\n",
      "\treturn\t(y_i\t-\tlogistic(dot(x_i,\tbeta)))\t*\tx_i[j]\n",
      "def\tlogistic_log_gradient_i(x_i,\ty_i,\tbeta):\n",
      "\"\"\"o\tgradiente\tdo\tlog\tda\tprobabilidade\n",
      "correspondente\tao\ti-ésimo\tponto\tde\tdados\"\"\"\n",
      "\treturn\t[logistic_log_partial_ij(x_i,\ty_i,\tbeta,\tj)\n",
      "\t\t\t\tfor\tj,\t_\tin\tenumerate(beta)]\n",
      "def\tlogistic_log_gradient(x,\ty,\tbeta):\n",
      "return\treduce(vector_add,\n",
      "\t\t\t\t\t\t\t\t\t\t[logistic_log_gradient_i(x_i,\ty_i,\tbeta)\n",
      "\t\t\t\t\t\t\t\t\t\tfor\tx_i,\ty_i\tin\tzip(x,y)])\n",
      "neste\tponto\tnós\ttemos\ttodos\tos\tpedaços\tque\tprecisamos.aplicando\to\tmodelo\n",
      "queremos\tdividir\tnossos\tdados\tem\tconjunto\tde\ttreinamento\te\tconjunto\tde\tteste:\n",
      "random.seed(0)\n",
      "x_train,\tx_test,\ty_train,\ty_test\t=\ttrain_test_split(rescaled_x,\ty,\t0.33)\n",
      "#\tqueremos\tmaximizar\to\tlog\tda\tprobabilidade\tem\tdados\tde\ttreinamento\n",
      "fn\t=\tpartial(logistic_log_likelihood,\tx_train,\ty_train)\n",
      "gradient_fn\t=\tpartial(logistic_log_gradient,\tx_train,\ty_train)\n",
      "#\tescolhemos\tum\tponto\tde\tpartida\taleatório\n",
      "beta_0\t=\t[random.random()\tfor\t_\tin\trange(3)]\n",
      "#\te\tmaximizamos\tusando\to\tgradiente\tdescendente\n",
      "beta_hat\t=\tmaximize_batch(fn,\tgradient_fn,\tbeta_0)\n",
      "como\talternativa,\tvocê\tpoderia\tusar\to\tgradiente\tdescendente\testocástico:\n",
      "beta_hat\t=\tmaximize_stochastic(logistic_log_likelihood_i,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlogistic_log_gradient_i,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tx_train,\ty_train,\tbeta_0)\n",
      "de\tqualquer\tforma,\tencontramos\taproximadamente:\n",
      "beta_hat\t=\t[-1.90,\t4.05,\t-3.87]\n",
      "esses\tsão\tos\tcoeficientes\tpara\tos\tdados\t\n",
      "rescaled\n",
      "\t(redimensionados),\tmas\tpodemos\n",
      "transformá-los\tde\tvolta\taos\tdados\toriginais:\n",
      "beta_hat_unscaled\t=\t[7.61,\t1.42,\t-0.000249]\n",
      "infelizmente,\teles\tnão\tsão\ttão\tfáceis\tde\tinterpretar\tcomo\tos\tcoeficientes\tde\n",
      "regressão\tlinear.\to\trestante\tsendo\tigual,\tum\tano\ta\tmais\tde\texperiência\tacrescenta\n",
      "1,42\tà\tentrada\tde\t\n",
      "logistic\n",
      ".\to\trestante\tsendo\tigual,\t10.000\ta\tmais\tno\tsalário\tdiminui\n",
      "2,49\tda\tentrada\tde\t\n",
      "logistic\n",
      ".\n",
      "no\tentanto,\to\timpacto\tna\tsaída\tdepende\tde\toutras\tentradas\ttambém.\tse\t\n",
      "dot\n",
      "\t\n",
      "(beta,\n",
      "x_i)\n",
      "\tjá\té\tgrande\t(correspondente\ta\tuma\tprobabilidade\tpróxima\tde\t1),\taumentá-lo\n",
      "mesmo\tque\tmuito\tnão\tpode\tafetar\tmuito\ta\tprobabilidade.\tse\tfor\tpróxima\tde\t0,\n",
      "aumentá-lo\tum\tpouco\tpode\taumentar\tbastante\ta\tprobabilidade.\n",
      "o\tque\tpodemos\tdizer\té\tque\t—\ttodo\to\trestante\tsendo\tigual\t—\tas\tpessoas\tcom\n",
      "mais\texperiência\ttêm\tmais\tprobabilidade\tde\tpagar\tpela\tassinatura.\te\ttambém,\t—\n",
      "todo\to\trestante\tsendo\tigual\t—\tas\tpessoas\tcom\tos\tsalários\tmais\taltos\tsão\tmenosprováveis\tde\tpagar\tpor\tassinaturas.\t(estava\tum\ttanto\taparente\tquando\tmontamos\n",
      "o\tgráfico\tdos\tdados.)o\tbenefício\tdo\tajuste\n",
      "nós\tainda\tnão\tutilizamos\tos\tdados\tde\tteste.\tvamos\tver\to\tque\tacontece\tse\n",
      "fizermos\ta\tprevisão\tde\t\n",
      "conta\tpaga\n",
      "\tquando\ta\tprobabilidade\texceder\t0,5:\n",
      "true_positives\t=\tfalse_positives\t=\ttrue_negatives\t=\tfalse_negatives\t=\t0\n",
      "for\n",
      "\tx_i,\ty_i\t\n",
      "in\n",
      "\tzip(x_test,\ty_test):\n",
      "predict\t=\tlogistic(dot(beta_hat,\tx_i))\n",
      "\t\n",
      "if\n",
      "\ty_i\t==\t1\t\n",
      "and\n",
      "\tpredict\t>=\t0.5:\t\t\t\n",
      "#\tpv:\tpaga\te\tprevimos\tpaga\n",
      "true_positives\t+=\t1\n",
      "elif\n",
      "\ty_i\t==\t1:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tfn:\tpaga\te\tprevimos\tnão\tpagantes\n",
      "false_negatives\t+=\t1\n",
      "elif\n",
      "\tpredict\t>=\t0.5:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tvf:\tnão\tpaga\te\tprevimos\tpagantes\n",
      "false_positives\t+=\t1\n",
      "else\n",
      ":\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tvp:\tnão\tpaga\te\tprevimos\tnão\tpaga\n",
      "true_negatives\t+=\t1\n",
      "precision\t=\ttrue_positives\t/\t(true_positives\t+\tfalse_positives)\n",
      "recall\t=\ttrue_positives\t/\t(true_positives\t+\tfalse_negatives)\n",
      "isso\tdá\tuma\tacurácia\tde\t93%\t(“quando\tprevimos\t\n",
      "conta\tpaga\testamos\tcertos\n",
      "93%\tdo\ttempo”)\te\tuma\tsensibilidade\tde\t82%\t(“quando\tum\tusuário\tpagou\tuma\n",
      "conta\te\tprevimos\t\n",
      "conta\tpaga\n",
      "\t82%\tdo\ttempo”),\tem\tque\tambos\tsão\tnúmeros\tbem\n",
      "respeitáveis.\n",
      "nós\ttambém\tpodemos\tassinalar\tas\tprevisões\tversus\tas\treais\t(\n",
      "figura\t16-4\n",
      "),\tque\n",
      "também\tmostra\tque\to\tmodelo\tfunciona\tbem:\n",
      "predictions\t=\t[logistic(dot(beta_hat,\tx_i))\t\n",
      "for\n",
      "\tx_i\t\n",
      "in\n",
      "\tx_test]\n",
      "plt.scatter(predictions,\ty_test)\n",
      "plt.xlabel(\"probabilidade\tprevista\")\n",
      "plt.ylabel(\"resultado\treal\")\n",
      "plt.title(\"regressão\tlogística\tprevista\tvs.\treal\")\n",
      "plt.show()figura\t16-4.\tregressão\tlogística\tprevista\tversus\treal\n",
      ".máquina\tde\tvetor\tde\tsuporte\n",
      "esse\tconjunto\tde\tpontos\tem\tque\t\n",
      "dot(beta_hat,\tx_i)\n",
      "\té\tigual\ta\t0\té\to\tlimite\tentre\tnossas\n",
      "classes.\tnós\tpodemos\tassinalá-lo\tpara\tver\texatamente\to\tque\tnosso\tmodelo\testá\n",
      "fazendo\t(\n",
      "figura\t16-5\n",
      ").\n",
      "esse\tlimite\té\tum\t\n",
      "hiperplano\n",
      "\tque\tdivide\to\tespaço\tde\tparâmetro\tentre\tduas\tpartes\n",
      "de\tespaço\tcorrespondentes\ta\t\n",
      "prever\tpagos\n",
      "\te\t\n",
      "prever\tnão\tpagos\n",
      ".\tnós\tencontramos\n",
      "isso\tcomo\tum\tefeito\tcolateral\tde\tencontrar\to\tmodelo\tlogístico\tmais\tprovável.\n",
      "uma\tabordagem\talternativa\tpara\ta\tclassificação\té\tapenas\tprocurar\to\thiperplano\n",
      "que\t“melhor”\tsepare\tas\tclasses\tnos\tdados\tde\ttreinamento.\tessa\té\ta\tideia\tpor\ttrás\n",
      "da\t\n",
      "máquina\tde\tvetor\tde\tsuporte\n",
      ",\tque\tencontra\to\thiperplano\tque\tmaximiza\ta\n",
      "distância\tpara\to\tponto\tmais\tpróximo\tem\tcada\tclasse\t(\n",
      "figura\t16-6\n",
      ").\n",
      "figura\t16-5.\tusuários\tpagantes\te\tnão\tpagantes\tcom\tlimite\tde\tdecisãoencontrar\ttal\thiperplano\té\tum\tproblema\tde\totimização\tque\tenvolve\ttécnicas\tque\n",
      "são\tavançadas\tdemais\tpara\tnós.\tum\tproblema\tdiferente\té\tque\tum\thiperplano\tde\n",
      "separação\tpode\tnem\tmesmo\texistir.\tem\tnosso\tconjunto\tde\tdados\t“quem\tpaga?”\n",
      "simplesmente\tnão\thá\tlinha\tque\tsepare\tperfeitamente\tos\tusuários\tpagantes\tdos\n",
      "não\tpagantes.\n",
      "nós\tpodemos,às\tvezes,\tcontornar\tessa\tsituação\ttransformando\tos\tdados\tem\tum\n",
      "espaço\tdimensional\tsuperior.\tpor\texemplo,\tconsidere\to\tsimples\tconjunto\n",
      "unidimensional\tde\tdados\texibido\tna\t\n",
      "figura\t16-7\n",
      ".\n",
      "figura\t16-6.\tum\thiperplano\tde\tseparação\n",
      "está\tclaro\tque\tnão\thá\thiperplano\tque\tsepare\texemplos\tpositivos\tdos\tnegativos.\n",
      "entretanto,\tolhe\to\tque\tacontece\tquando\tmapeamos\tesse\tconjunto\tde\tdados\tem\n",
      "duas\tdimensões\tdiferentes\tenviando\to\tponto\t\n",
      "x\n",
      "\tpara\t\n",
      "(x,\tx**2)\n",
      ".\tde\trepente,\té\n",
      "possível\tencontrar\tum\thiperplano\tque\tdivide\tos\tdados\t(\n",
      "figura\t16-8\n",
      ").isso\té\tgeralmente\tchamado\tde\t\n",
      "truque\tdo\tkernel\n",
      "\tporque,\tem\tvez\tde\tmapear\tos\n",
      "pontos\tnum\tespaço\tdimensional\tmaior\t(o\tque\tpode\tser\tcaro\tse\thouver\tmuitos\n",
      "pontos\te\to\tmapeamento\tfor\tcomplicado),\tnós\tusamos\tuma\tfunção\t“kernel”\tpara\n",
      "computar\tprodutos\tescalares\tno\tespaço\tdimensional\tmaior\te\tusá-los\tpara\n",
      "encontrar\to\thiperplano.\n",
      "figura\t16-7.\tum\tconjunto\tunidimensional\tde\tdados\tinseparável\n",
      "é\tdifícil\t(e,\tprovavelmente,\tuma\tmá\tideia)\tusar\tmáquinas\tde\tvetor\tde\tsuporte\n",
      "sem\tdepender\tde\tum\tsoftware\tespecializado\tem\totimização\tescrito\tpor\tpessoas\n",
      "com\to\tconhecimento\tapropriado,\tentão\tvamos\tdeixar\tnosso\ttratamento\taqui.figura\t16-8.\to\tconjunto\tde\tdados\tse\ttorna\tseparável\tem\tdimensões\tmaiores•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "scikit-learn\tpossui\tmodelos\tpara\tregressão\tlogística\n",
      "(\n",
      "http://bit.ly/1xkbywa\n",
      ")\te\tmáquinas\tde\tvetor\tde\tsuporte\n",
      "(\n",
      "http://bit.ly/1xkbbzj\n",
      ").\n",
      "libsvm\t(\n",
      "http://bit.ly/1xkba7t\n",
      ")\té\ta\timplementação\tde\tmáquina\tde\tvetor\tde\n",
      "suporte\tque\tscikit-learn\tusa.\tem\tseu\twebsite\thá\tuma\tvariedade\tde\n",
      "documentação\tsobre\tmáquinas\tde\tvetor\tde\tsuporte.capítulo\t17\n",
      "árvores\tde\tdecisão\n",
      "uma\tárvore\té\tum\tmistério\tincompreensível\n",
      ".\n",
      "—\n",
      "jim\twooddring\n",
      "o\tvice-presidente\tde\ttalentos\tda\tdatasciencester\tentrevistou\tum\tnúmero\tde\n",
      "candidatos\tpara\temprego\tdo\tsite,\tcom\tníveis\tde\tsucesso\tvariados.\tele\tcoletou\tum\n",
      "conjunto\tde\tdados\tcom\tvários\tatributos\t(qualitativos)\tde\tcada\tcandidato,\tbem\n",
      "como\tse\to\tcandidato\tde\tsaiu\tbem\tou\tmal\tna\tentrevista.\tvocê\tpoderia\tusar\tesses\n",
      "dados\tpara\tconstruir\tum\tmodelo\tidentificando\tquais\tcandidatos\tfarão\tboas\n",
      "entrevistas,\tpara\tque\tele\tnão\tprecise\tperder\ttempo\tfazendo\tentrevistas?\n",
      "isso\tparece\tser\tperfeito\tpara\tuma\t\n",
      "árvore\tde\tdecisão\n",
      ",\toutra\tferramente\tde\n",
      "modelagem\tde\tprevisão\tno\tkit\tde\tum\tcientista\tde\tdados.•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "o\tque\té\tuma\tárvore\tde\tdecisão?\n",
      "uma\tárvore\tde\tdecisão\tusa\tuma\testrutura\tde\tárvore\tpara\trepresentar\tum\tnúmero\n",
      "de\tpossíveis\t\n",
      "caminhos\tde\tdecisão\n",
      "\te\tum\tresultado\tpara\tcada\tcaminho.\n",
      "se\tvocê\tjá\tjogou\tvinte\tperguntas,\tjá\testá\tfamiliarizado\tcom\tárvores\tde\tdecisão.\n",
      "por\texemplo:\n",
      "“estou\tpensando\tem\tum\tanimal.”\n",
      "“ele\tpossui\tmais\tde\tcinco\tpernas?”\n",
      "“não.”\n",
      "“é\tdelicioso?”\n",
      "“não.”\n",
      "“ele\taparece\tna\tparte\tde\ttrás\tda\tmoeda\tde\tcinco\tcentavos\taustraliana?”\n",
      "“sim.”\n",
      "“é\tum\tequidna?”\n",
      "“sim!”\n",
      "isso\tcorresponde\tao\tcaminho:\n",
      "“não\tmais\tdo\tque\t5\tpernas”\t→\t“não\tdelicioso”\t→\t“na\tmoeda\tde\t5\tcentavos”\n",
      "→\t“equidna!”\n",
      "em\tuma\tidiossincrática\t(e\tnão\tmuito\tabrangente)\tárvore\tde\tdecisão\t“adivinhe\to\n",
      "animal”\t(\n",
      "figura\t17-1\n",
      ").figura\t17-1.\tuma\tárvore\tde\tdecisão\t“adivinhe\to\tanimal”\n",
      "as\tárvores\tde\tdecisão\tpossuem\tmuitas\trecomendações.\telas\tsão\tmuito\tfáceis\tde\n",
      "entender\te\tinterpretar,\te\to\tprocesso\tpor\tonde\tchegam\tnuma\tprevisão\té\n",
      "completamente\ttransparante.\tdiferente\tde\toutros\tmodelos\tque\tvimos\taté\tagora,\n",
      "as\tárvores\tde\tdecisão\tpodem\tlidar\tfacilmente\tcom\tuma\tmistura\tde\tatributos\n",
      "numéricos\t(exemplo:\tnúmero\tde\tpernas)\te\tcategóricos\t(exemplo:\tdelicioso/não\n",
      "delicioso)\te\tpodem\taté\tclassificar\tos\tdados\tpara\tos\tatributos\tque\testão\tfaltando.\n",
      "ao\tmesmo\ttempo,\tencontrar\ta\tárvore\tde\tdecisão\tperfeita\tpara\tum\tconjunto\tde\n",
      "dados\tem\ttreinamento\té\tcomputacionalmente\tum\tproblema\tmuito\tdifícil.\n",
      "(contornaremos\tisso\ttentando\tconstruir\tuma\tárvore\tboa\to\tbastante\tem\tvez\tde\n",
      "uma\tperfeita,\tapesar\tde\tque,\tpara\tuma\tboa\tparte\t\n",
      "de\tconjuntos\tde\tdados\tisso\tainda\n",
      "pode\tser\tmuito\ttrabalhoso.)\tmais\timportante,\té\tmuito\tfácil\t(e\tmuito\truim)\n",
      "construir\tárvores\tde\tdecisão\tque\tsão\t\n",
      "sobreajustadas\n",
      "\taos\tdados\tem\ttreinamento\te\n",
      "que\tnão\tgeneralizem\tbem\tpara\tdados\tdesconhecidos.\tnós\tveremos\tformas\tde\n",
      "lidar\tcom\tisso.\n",
      "a\tmaioria\tdas\tpessoas\tdividem\tárvores\tde\tdecisão\tem\t\n",
      "árvores\tde\tclassificação\n",
      "(que\tproduzem\tsaídas\tcategóricas)\te\t\n",
      "árvores\tde\tregressão\n",
      "\t(que\tproduzem\tsaídasnuméricas).\tneste\tcapítulo,\tfocaremos\tem\tárvores\tde\tclassificação\te\n",
      "trabalharemos\tcom\to\talgoritmo\tid3\tpara\taprender\tuma\tárvore\tde\tdecisão\ta\tpartir\n",
      "de\tum\tconjunto\tde\tdados\trotulados,\to\tque\ttalvez\tnos\tajude\ta\tentender\tcomo\n",
      "árvores\tde\tdecisão\trealmente\tfuncionam.\tpara\tsimplificar\tas\tcoisas,\tnos\n",
      "restringiremos\ta\tproblemas\tcom\tsaídas\tbinárias\tcomo\t“eu\tdeveria\tcontratar\tesse\n",
      "candidato?”\tou\t“eu\tdeveria\texibir\to\tanúncio\ta\tou\to\tb\tpara\tvisitantes\tdo\tsite?”\tou\n",
      "“comer\tessa\tcomida\tque\tencontrei\tna\tgeladeira\tdo\tescritório\tme\tfará\tmal?”entropia\n",
      "pra\tconstruir\tuma\tárvore\tde\tdecisão,\tprecisaremos\tdecidir\tquais\tperguntas\tfazer\n",
      "e\tem\tqual\tordem.\tem\tcada\tetapa\tde\tuma\tárvore\thá\talgumas\tpossibilidades\tque\n",
      "eliminamos\te\toutras\tque\tnão.\tapós\tter\ta\tinformação\tde\tque\tum\tanimal\tnão\n",
      "possui\tmais\tdo\tque\tcinco\tpernas,\teliminamos\ta\tpossibilidade\tde\tele\tser\tum\n",
      "gafanhoto.\tnão\teliminamos\ta\tpossibilidade\tde\tser\tum\tpato.\tcada\tpergunta\n",
      "possível\tsepara\tas\tpossibilidades\trestantes\tde\tacordo\tcom\tas\trespostas.\n",
      "nós\tgostaríamos\tde\tescolher\tperguntas\tcujas\trespostas\tnos\tdessem\tmuita\n",
      "informação\tsobre\to\tque\tnossa\tárvore\tdeveria\tprever.\tse\thouver\tuma\tsimples\n",
      "pergunta\tsim/não\tpara\tcada\trespostas\t“sim”\tsempre\tcorrespondente\ta\tsaídas\t\n",
      "true\n",
      "(verdadeiros)\te\trespostas\t“não”\ta\tsaídas\t\n",
      "false\n",
      "\t(falsos),\tessa\tseria\tuma\tpergunta\n",
      "perfeita\tpara\tfazer.\tcontrariamente,\tuma\tpergunta\tsim/não\tpara\ta\tqual\tnenhuma\n",
      "resposta\tlhe\tdá\tmuita\tinformação\tsobre\to\tque\tprevisão\tdeveria\tser\tnão\té\tuma\tboa\n",
      "escolha.\n",
      "nós\tchegamos\tnessa\tnoção\tde\t“quanta\tinformação”\tcom\t\n",
      "entropia\n",
      ".\tvocê\tjá\tdeve\n",
      "ter\tescutado\tisso\tcom\to\tsignificado\tde\tdesordem.\tnós\tusamos\tpara\trepresentar\ta\n",
      "incerteza\tassociada\tcom\tos\tdados.\n",
      "imagine\tque\ttemos\tum\tconjunto\t\n",
      "s\n",
      "\tde\tdados,\tno\tqual\tcada\tmembro\té\trotulado\n",
      "como\tpertencente\ta\tuma\tclasse\tdentre\to\tfinito\tnúmero\tde\tclasses\t\n",
      "c\n",
      "1\n",
      ",\t…,\n",
      "c\n",
      "n\n",
      ".\tse\n",
      "todos\tos\tpontos\tde\tdados\tpertencem\ta\tuma\túnica\tclasse,\tentão\tnão\thá\tincerteza\n",
      "real,\to\tque\tsignifica\tque\tdeve\thaver\tbaixa\tentropia.\tse\tos\tpontos\tde\tdados\testão\n",
      "separados\tde\tforma\tigual\tnas\tclasses,\thá\tmuita\tincerteza\te\tdeve\thaver\talta\n",
      "entropia.\n",
      "em\ttermos\tmatemáticos,\tse\t\n",
      "p\n",
      "i\n",
      "\té\ta\tproporção\tde\tdados\tdefinidos\tcomo\tclasses\t\n",
      "c\n",
      "i\n",
      ",\n",
      "nós\tdefinimos\ta\tentropia\tcomo:\n",
      "com\ta\tconvenção\t(padrão)\tde\tque\t0\tlog\t0\t=\t0.\n",
      "sem\tmuita\tpreocupação\tcom\tos\tdetalhes,\tcada\ttermo\t–\t\n",
      "p\n",
      "i\n",
      "\tlog\n",
      "2\n",
      "\t\n",
      "p\n",
      "i\n",
      "\té\tnão\tnegativo\te\n",
      "próximo\tde\tzero\tprecisamente\tquando\t\n",
      "p\n",
      "i\n",
      "\tou\té\tpróximo\tde\tzero\tou\tde\t1\t(\n",
      "figura17-2\n",
      ").\n",
      "figura\t17-2.\tum\tgráfico\tde\t–p\tlog\tp\n",
      "isso\tsignifica\tque\ta\tentropia\tserá\tpequena\tquando\tcada\t\n",
      "p\n",
      "i\n",
      "é\tpróximo\tde\t0\tou\t1\n",
      "(por\texemplo:\tquando\ta\tmaioria\tdos\tdados\testá\tem\tuma\túnica\tclasse)\te\tserá\n",
      "maior\tquando\tmuitos\tdos\t\n",
      "p\n",
      "i\n",
      "\tnão\testiverem\tpróximos\tde\t0\t(por\texemplo,\tquando\n",
      "os\tdados\testão\tespalhados\tpor\tmúltiplas\tclasses).\tesse\té\texatamente\to\n",
      "comportamento\tesperado.\n",
      "é\tmuito\tfácil\tjogar\ttudo\tisso\tem\tuma\tfunção:\n",
      "def\n",
      "\tentropy(class_probabilities):\n",
      "\"\"\"dada\tuma\tlista\tde\tprobabilidades\tde\tclasse,\tcompute\ta\tentropia\"\"\"\n",
      "return\n",
      "\tsum(-p\t*\tmath.log(p,\t2)\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\tp\t\n",
      "in\n",
      "\tclass_probabilities\n",
      "\t\t\t\t\t\t\t\n",
      "if\n",
      "\tp)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tignora\tprobabilidades\tzero\n",
      "nossos\tdados\tconsistirão\tde\tpares\t(\n",
      "input\n",
      ",\t\n",
      "label\n",
      "),\to\tque\tsignifica\tque\tprecisaremoscomputar\tsozinhos\tas\tprobabilidades\tde\tclasse.\tobserve\tque\tnão\tnos\timporta\n",
      "qual\trótulo\té\tassociada\tcom\tqual\tprobabilidade,\tapenas\tquais\tsão\tas\n",
      "probabilidades:\n",
      "def\n",
      "\tclass_probabilities(labels):\n",
      "total_count\t=\tlen(labels)\n",
      "return\n",
      "\t[count\t/\ttotal_count\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tcount\t\n",
      "in\n",
      "\tcounter(labels).values()]\n",
      "def\n",
      "\tdata_entropy(labeled_data):\n",
      "labels\t=\t[label\t\n",
      "for\n",
      "\t_,\tlabel\t\n",
      "in\n",
      "\tlabeled_data]\n",
      "probabilities\t=\tclass_probabilities(labels)\n",
      "return\n",
      "\tentropy(probabilities)a\tentropia\tde\tuma\tpartição\n",
      "o\tque\tfizemos\taté\tagora\tfoi\tcomputar\ta\tentropia\t(pense\t“incerteza”)\tde\tum\n",
      "conjunto\tde\tdados\trotulados.\tagora,\tcada\tetapa\tda\tárvore\tde\tdecisão\tenvolve\n",
      "fazer\tuma\tpergunta\tcuja\tresposta\tparticiona\tos\tdados\tem\tum\tou\t(esperamos)\n",
      "mais\tsubconjuntos.\tpor\texemplo,\tnossa\tpergunta\t“tem\tmais\tde\tcinco\tpernas?”\n",
      "divide\tanimais\tem\taqueles\tque\ttêm\tmais\tde\tcinco\tpernas\t(por\texemplo,\taranhas)\n",
      "e\tos\tque\tnão\t(por\texemplo,\tequidnas).\n",
      "da\tmesma\tforma,\tnós\tgostaríamos\tde\tter\talguma\tnoção\tde\tentropia\tque\tresulte\n",
      "em\tparticionar\tum\tconjunto\tde\tdados\tem\tuma\tcerta\tforma.\tnós\tqueremos\tuma\n",
      "divisão\tque\ttenha\tbaixa\tentropia\tse\tdividir\tos\tdados\tem\tsubconjuntos\tque\n",
      "tenham\tbaixa\tentropia\t(por\texemplo,\tsão\taltamente\tcertos)\te\talta\tentropia\tse\n",
      "possuir\tsubconjuntos\tcom\t(grandes\te\tcom)\talta\tentropia\t(por\texemplo,\tsão\n",
      "altamente\tincertos).\n",
      "por\texemplo,\tminha\tpergunta\t“moeda\tde\tcinco\tcentavos\taustraliana”\tfoi\tmuito\n",
      "boba\t(e\tbem\tsortuda!),\tà\tmedida\tque\tdividiu\tos\tanimais\trestantes\taté\taquele\n",
      "momento\tem\ts\n",
      "1\n",
      "\t=\t{equidna}\te\ts\n",
      "2\n",
      "\t=\t{o\trestante},\tem\tque\ts\t\n",
      "2\n",
      "é\tgrande\te\tpossui\n",
      "alta\tentropia.\t(s\n",
      "1\n",
      "\tnão\ttem\tentropia\tmas\trepresenta\tuma\tpequena\tfração\tdas\n",
      "“classes”\trestantes.)\n",
      "matematicamente,\tse\tdividirmos\tnossos\tdados\t\n",
      "s\n",
      "\tem\tsubconjuntos\t\n",
      "s\n",
      "1\n",
      ",…,\n",
      "s\n",
      "m\n",
      "contendo\tproporções\tde\tdados\t\n",
      "q1\n",
      ",\t…,\n",
      "q\n",
      "m\n",
      ",\tentão\tnós\tcomputamos\ta\tentropia\tda\n",
      "partição\tcomo\tuma\tsoma\tponderada:\n",
      "que\tpodemos\timplementar\tcomo:\n",
      "def\n",
      "\tpartition_entropy(subsets):\n",
      "\"\"\"encontre\ta\tentropia\tdesta\tdivisão\tde\tdados\tem\tsubconjuntos\n",
      "subconjunto\té\tuma\tlista\tde\tlistas\tde\tdados\trotulados\"\"\"\n",
      "\ttotal_count\t=\tsum(len(subset)\t\n",
      "for\n",
      "\tsubset\t\n",
      "in\n",
      "\tsubsets)\n",
      "\t\n",
      "return\n",
      "\tsum(\tdata_entropy(subset)\t*\tlen(subset)\t/\ttotal_count\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tsubset\t\n",
      "in\n",
      "\tsubsets\t)\n",
      "um\tproblema\tcom\tessa\tabordagem\té\tque\tparticionar\tpor\tum\tatributo\t(característica)com\tmuitos\tvalores\tdiferentes\tresultará\tem\tum\tentropia\tmuito\tbaixa\tdevido\tao\n",
      "sobreajuste.\tpor\texemplo,\timagine\tque\tvocê\ttrabalha\tpara\tum\tbanco\te\testá\ttentando\n",
      "construir\tuma\tárvore\tde\tdecisão\tpara\tprever\tquais\tclientes\tprovavelmente\tserão\n",
      "inadimplentes\tcom\to\tfinanciamento\tusando\talguns\tdados\thistóricos\tcomo\tseu\n",
      "conjunto\tde\ttreinamento.\timagine\tainda\tque\tos\tdados\tcontêm\to\tnúmero\tdo\tcpf\tde\n",
      "cada\tcliente.\tdividir\tem\tssn\tproduzirá\tsubconjuntos\tde\tuma\tpessoa,\tem\tque\tcada\n",
      "uma\tdelas\tnecessariamente\tpossui\tzero\tentropia.\tmas\tum\tmodelo\tque\tdepende\tde\n",
      "ssn\t\n",
      "certamente\n",
      "\tnão\tgeneraliza\talém\tdo\tconjunto\tde\ttreinamento.\tpor\tisso,\tvocê\n",
      "deveria\tevitar\t(ou\tagrupar,\tse\tapropriado)\tatributos\tcom\tmuitos\tvalores\tpossíveis\tao\n",
      "criar\tárvores\tde\tdecisão.•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "criando\tuma\tárvore\tde\tdecisão\n",
      "a\tvice-presidente\tforneceu\tdados\tdos\tentrevistados,\tque\tconsistem\tde\t(por\tsua\n",
      "especificação)\tpares\t(\n",
      "input,\tlabel\n",
      ")\tem\tque\tcada\t\n",
      "input\n",
      "\té\tum\t\n",
      "dict\n",
      "\tde\tcaracterísticas\tde\n",
      "candidatos\te\tcada\trótulo\té\t\n",
      "true\n",
      "\t(o\tcandidato\tfez\tboa\tentrevista)\tou\t\n",
      "false\n",
      "\t(o\n",
      "candidato\tfez\tentrevista\truim).\tem\tespecífico,\tvocê\tpossui\to\tnível\tde\tcada\n",
      "candidato,\tsua\tlinguagem\tfavorita,\tse\té\tativo\tno\ttwitter\te\tse\tpossui\tphd:\n",
      "inputs\t=\t[\n",
      "({'level':'senior',\t'lang':'java',\t'tweets':'no',\t'phd':'no'},\t\t\t\t\tfalse),\n",
      "({'level':'senior',\t'lang':'java',\t'tweets':'no',\t'phd':'yes'},\t\t\t\tfalse),\n",
      "({'level':'mid',\t'lang':'python',\t'tweets':'no',\t'phd':'no'},\t\t\t\t\t\ttrue),\n",
      "({'level':'junior',\t'lang':'python',\t'tweets':'no',\t'phd':'no'},\t\t\ttrue),\n",
      "({'level':'junior',\t'lang':'r',\t'tweets':'yes',\t'phd':'no'},\t\t\t\t\t\t\ttrue),\n",
      "({'level':'junior',\t'lang':'r',\t'tweets':'yes',\t'phd':'yes'},\t\t\t\t\t\tfalse),\n",
      "({'level':'mid',\t'lang':'r',\t'tweets':'yes',\t'phd':'yes'},\t\t\t\t\t\t\t\t\ttrue),\n",
      "({'level':'senior',\t'lang':'python',\t'tweets':'no',\t'phd':'no'},\t\t\tfalse),\n",
      "({'level':'senior',\t'lang':'r',\t'tweets':'yes',\t'phd':'no'},\t\t\t\t\t\t\ttrue),\n",
      "({'level':'junior',\t'lang':'python',\t'tweets':'yes',\t'phd':'no'},\t\ttrue),\n",
      "({'level':'senior',\t'lang':'python',\t'tweets':'yes',\t'phd':'yes'},\ttrue),\n",
      "({'level':'mid',\t'lang':'python',\t'tweets':'no',\t'phd':'yes'},\t\t\t\t\ttrue),\n",
      "({'level':'mid',\t'lang':'java',\t'tweets':'yes',\t'phd':'no'},\t\t\t\t\t\t\ttrue),\n",
      "({'level':'junior',\t'lang':'python',\t'tweets':'no',\t'phd':'yes'},\t\tfalse)\n",
      "]\n",
      "nossa\tárvore\tconsistirá\tde\t\n",
      "nós\tde\tdecisão\n",
      "\t(que\tfazem\tuma\tpergunta\te\n",
      "direcionam\tde\tforma\tdiferente\tdependendo\tda\tresposta)\te\t\n",
      "nós\tfolha\n",
      "\t(que\tnos\tdão\n",
      "uma\tprevisão).\tnós\ta\tconstruiremos\tusando\tum\talgoritmo\t\n",
      "id3\n",
      "\trelativamente\n",
      "simples\tque\topera\tda\tseguinte\tforma.\tdigamos\tque\tnos\tderam\talguns\tdados\n",
      "rotulados\te\tuma\tlista\tde\tcaracterísticas\tque\tdeveríamos\tconsiderar\tpara\tramificar.\n",
      "se\tos\tdados\tpossuem\ta\tmesmo\trótulo,\tcrie\tum\tnó\tfolha\tque\tprevê\tesse\n",
      "rótulo\te\tentão\tpare.\n",
      "se\ta\tlista\tde\tcaracterísticas\testá\tvazia\t(por\texemplo:\tnão\texistem\tmais\n",
      "perguntas\tpossíveis),\tcrie\tum\tnó\tfolha\tque\tprevê\to\trótulo\tmais\tcomum\te\n",
      "pare.\n",
      "caso\tcontrário,\ttente\tparticionar\tos\tdados\tpor\ttodas\tas\tcaracterísticas.\n",
      "escolha\ta\tdivisão\tcom\ta\tentropia\tde\tpartição\tmais\tbaixa.\n",
      "adicione\tum\tnó\tde\tdecisão\tbaseado\tna\tcaracterística\tescolhida.•\n",
      "retorne\ta\tcada\tsubconjunto\tparticionado\tusando\tas\tcaracterísticas\n",
      "remanescentes.\n",
      "isso\té\tconhecido\tcomo\tum\talgoritmo\t“ganancioso”\tporque,\ta\tcada\tpasso,\tele\n",
      "escolhe\ta\topção\timediatamente\tmelhor.\tdado\tum\tconjunto\tde\tdados,\tpode\texistir\n",
      "uma\tárvore\tmelhor\tcom\tum\tprimeiro\tmovimento\tpior\tde\tver.\tcaso\texista,\tesse\n",
      "algoritmo\tnão\tirá\tencontrá-la.\tcontudo,\té\trelativamente\tmais\tfácil\tde\tentender\te\n",
      "implementar,\to\tque\to\ttorna\tmuito\tbom\tpara\tcomeçar\ta\texplorar\tárvores\tde\n",
      "decisão.\n",
      "vamos\tpercorrer\tmanualmente\tesses\tpassos\tno\tconjunto\tde\tdados\tdos\n",
      "entrevistados.\to\tconjunto\tde\tdados\tpossui\trótulos\t\n",
      "true\n",
      "\te\t\n",
      "false\n",
      ",\te\tnós\ttemos\tquatro\n",
      "características\tpelas\tquais\tpodemos\tdividi-los.\tentão,\tnosso\tprimeiro\tpasso\tserá\n",
      "encontrar\ta\tpartição\tcom\ta\tmenor\tentropia.\tcomeçaremos\tescrevendo\tuma\n",
      "função\tque\tfaz\ta\tdivisão:\n",
      "def\n",
      "\tpartition_by(inputs,\tattribute):\n",
      "\"\"\"cada\tentrada\té\tum\tpar\t(attribute_dict,\tlabel)\n",
      ".\n",
      "retorna\tuma\tdict:\tattribute_value\n",
      "\t->\n",
      "inputs\"\"\"\n",
      "groups\t=\tdefaultdict(list)\n",
      "for\n",
      "\tinput\t\n",
      "in\n",
      "\tinputs:\n",
      "\t\t\t\t\t\tkey\t=\tinput[0][attribute]\t\t\n",
      "#\tpega\to\tvalor\tdo\tatributo\tespecificado\n",
      "\t\t\t\t\t\tgroups[key].append(input)\t\t\n",
      "#\tentão\tadiciona\tessa\tentrada\tà\tlista\tcorreta\n",
      "return\n",
      "\tgroups\n",
      "e\tuma\tque\tusa\tisso\tpara\tcomputar\ta\tentropia:\n",
      "def\n",
      "\tpartition_entropy_by(inputs,\tattribute):\n",
      "\"\"\"computa\ta\tentropia\tcorrespondente\tà\tpartição\tdada\"\"\"\n",
      "partitions\t=\tpartition_by(inputs,\tattribute)\n",
      "return\n",
      "\tpartition_entropy(partitions.values())\n",
      "então\tsó\tprecisamos\tencontrar\ta\tpartição\tcom\tentropia\tmínima\tpara\ttodo\to\n",
      "conjunto\tde\tdados:\n",
      "for\n",
      "\tkey\t\n",
      "in\n",
      "\t['level','lang','tweets','phd']:\n",
      "print\n",
      "\tkey,\tpartition_entropy_by(inputs,\tkey)\n",
      "#\tlevel\t0.693536138896\n",
      "#\tlang\t0.860131712855\n",
      "#\ttweets\t0.788450457308\n",
      "#\tphd\t0.892158928262\n",
      "a\tmenor\tentropia\tvem\tda\tdivisão\tbaseada\tem\t\n",
      "level\n",
      ",\tentão\tprecisamos\tfazer\tumasub-árvore\tpara\tcada\tvalor\t\n",
      "level\n",
      "\tpossível.\tcada\tcandidato\t\n",
      "mid\n",
      "\té\trotulado\tcom\t\n",
      "true\n",
      ",\n",
      "o\tque\tsignifica\tque\ta\tsub-árvore\t\n",
      "mid\n",
      "\té\tsimplesmente\tum\tnó\tfolha\tque\tprevê\t\n",
      "true\n",
      ".\n",
      "para\tcandidatos\t\n",
      "senior\n",
      ",\ttemos\tuma\tmistura\tde\t\n",
      "true\n",
      "s\te\t\n",
      "false\n",
      "s,\tlogo\tprecisamos\n",
      "dividir\tnovamente:\n",
      "senior_inputs\t=\t[(input,\tlabel)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinput,\tlabel\t\n",
      "in\n",
      "\tinputs\t\n",
      "if\n",
      "\tinput[\"level\"]\t==\t\"senior\"]\n",
      "for\n",
      "\tkey\t\n",
      "in\n",
      "\t['lang',\t'tweets',\t'phd']:\n",
      "print\n",
      "\tkey,\tpartition_entropy_by(senior_inputs,\tkey)\n",
      "#\tlang\t0.4\n",
      "#\ttweets\t0.0\n",
      "#\tphd\t0.950977500433\n",
      "isso\tnos\tmostra\tque\tnossa\tpróxima\tdivisão\tdeveria\tser\tcom\tbase\tem\t\n",
      "tweets\n",
      ",\tque\n",
      "resulta\tem\tuma\tpartição\tde\tentropia\tzero.\tpara\tos\tcandidatos\t\n",
      "senior\n",
      ",\ttweets\t“sim”\n",
      "sempre\tresultam\tem\t\n",
      "true\n",
      "\tenquanto\ttweets\t“não”\tsempre\tresultam\tem\t\n",
      "false\n",
      ".\n",
      "finalmente,\tse\tfizermos\ta\tmesma\tcoisa\tpara\tos\tcandidatos\t\n",
      "junior\n",
      ",\tdividiremos\tem\n",
      "phd\n",
      ",\tapós\to\tque\tdescobrimos\tque\tnão\tphd\tsempre\tresulta\tem\t\n",
      "true\n",
      "\te\tphd\tsempre\n",
      "resulta\tem\t\n",
      "false\n",
      ".\n",
      "a\t\n",
      "figura\t17-3\n",
      "\tmostra\ta\tárvore\tde\tdecisão\tcompleta.figura\t17-3.\ta\tárvore\tde\tdecisão\tpara\tcontratação•\n",
      "•\n",
      "•\n",
      "juntando\ttudo\n",
      "agora\tque\tvimos\tcomo\to\talgoritmo\tfunciona,\tgostaríamos\tde\timplementá-lo\tde\n",
      "forma\tmais\tgeral.\tisso\tsignifica\tque\tprecisamos\tdecidir\tcomo\tqueremos\n",
      "representar\tas\tárvores.\tusaremos\ta\trepresentação\tmais\tleve\tpossível.\tnós\n",
      "definimos\tas\t\n",
      "árvores\n",
      "\tcomo:\n",
      "true\n",
      "false\n",
      "uma\ttupla\t(\n",
      "attribute,\tsubtree_dict\n",
      ")\n",
      "aqui\t\n",
      "true\n",
      "\trepresenta\tum\tnó\tfolha\tque\tretorna\t\n",
      "true\n",
      "\tpara\tqualquer\tentrada,\t\n",
      "false\n",
      "representa\tum\tnó\tfolha\tque\tretorna\t\n",
      "false\n",
      "\tpara\tqualquer\tentrada,\te\tuma\ttupla\n",
      "representa\tum\tnó\tde\tdecisão\tque,\tpara\tqualquer\tentrada,\tencontra\tseu\tvalor\n",
      "attribute\n",
      "\te\tclassifica\ta\tentrada\tusando\ta\tsub-árvore\tcorrespondente.\n",
      "com\tessa\trepresentação,\tnossa\tárvore\tde\tcontratação\tse\tpareceria\tcom\tisso:\n",
      "('level',\n",
      "\t{'junior':\t('phd',\t{'no':\ttrue,\t'yes':\tfalse}),\n",
      "\t\t\t'mid':\ttrue,\n",
      "\t\t\t'senior':\t('tweets',\t{'no':\tfalse,\t'yes':\ttrue})})\n",
      "ainda\thá\ta\tquestão\tdo\tque\tfazer\tse\tencontrarmos\tum\tvalor\tde\tcaracterística\n",
      "inesperada\t(ou\tfaltante).\to\tque\tnossa\tárvore\tdeveria\tfazer\tse\tencontrasse\tum\n",
      "candidato\tcujo\t\n",
      "level\n",
      "\té\t“estagiário”?\tlidaremos\tcom\tesse\tcaso\tacrescentando\tuma\n",
      "chave\t\n",
      "none\n",
      "\tque\tprevê\to\trótulo\tmais\tcomum.\t(apesar\tde\tque\tisso\tseria\tuma\n",
      "péssima\tideia\tse\t\n",
      "none\n",
      "\tfosse\tna\tverdade\tum\tvalor\tque\taparecesse\tnos\tdados.)\n",
      "dada\ttal\trepresentação,\tpodemos\tclassificar\tuma\tentrada\tcom:\n",
      "def\tclassify(tree,\tinput):\n",
      "\"\"\"classifica\ta\tentrada\tusando\ta\tárvore\tde\tdecisão\tfornecida\"\"\"\n",
      "\t\n",
      "#\tse\tfor\tum\tnó\tfolha,\tretorna\tseu\tvalor\n",
      "if\ttree\tin\t[true,\tfalse]:\n",
      "\t\t\t\t\treturn\ttree\n",
      "\t\n",
      "#\tsenão,\testa\tárvore\tconsiste\tde\tuma\tcaracterística\tpara\tdividir\n",
      "#\te\tum\tdicionário\tcujas\tchaves\tsão\tvalores\tdaquela\tcaracterística\n",
      "#\te\tcujos\tvalores\tsão\tsub-árvores\tpara\tconsiderar\tdepois\n",
      "attribute,\tsubtree_dict\t=\ttreesubtree_key\t=\tinput.get(attribute)\t\t\t\n",
      "#\tnone\tse\testiver\tfaltando\tcaracterística\n",
      "if\tsubtree_key\tnot\tin\tsubtree_dict:\t\t\n",
      "#\tse\tnão\thá\tsub-árvore\tpara\tchave\n",
      ",\n",
      "\t\t\t\t\t\tsubtree_key\t=\tnone\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tusaremos\ta\tsub-árvore\tnone\n",
      "subtree\t=\tsubtree_dict[subtree_key]\t\t\n",
      "#\tescolha\ta\tsub-árvore\tapropriada\n",
      "return\tclassify(subtree,\tinput)\t\t\t\t\t\n",
      "#\te\tuse\tpara\tclassificar\ta\tentrada\n",
      "e\ttudo\to\tque\trestou\té\tconstruir\ta\trepresentação\tda\tárvore\ta\tpartir\tdos\tnossos\n",
      "dados\tem\ttreinamento:\n",
      "def\n",
      "\tbuild_tree_id3(inputs,\tsplit_candidates=none):\n",
      "\t\n",
      "#\tse\teste\té\tnosso\tprimeiro\tpasso\n",
      ",\n",
      "#\ttodas\tas\tchaves\tda\tprimeira\tentrada\tsão\tcandidatos\tdivididos\n",
      "if\tsplit_candidates\tis\tnone:\n",
      "split_candidates\t=\tinputs[0][0].keys()\n",
      "#\tconta\ttrues\te\tfalses\tnas\tentradas\n",
      "num_inputs\t=\tlen(inputs)\n",
      "num_trues\t=\tlen([label\tfor\titem,\tlabel\tin\tinputs\tif\tlabel])\n",
      "num_falses\t=\tnum_inputs\t-\tnum_trues\n",
      "if\tnum_trues\t==\t0:\treturn\tfalse\t\t\t\t\t\t\n",
      "#\tnenhum\ttrue?\tretorne\tuma\tfolha\t“false”\n",
      "if\tnum_falses\t==\t0:\treturn\ttrue\t\t\t\t\t\t\n",
      "#\tnenhum\tfalse?\tretorne\tuma\tfolha\t“true”\n",
      "if\tnot\tsplit_candidates:\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tse\tnão\thouver\tmais\tcandidatos\ta\tdividir\n",
      "return\tnum_trues\t>=\tnum_falses\t\t\t\n",
      "#\tretorne\ta\tfolha\tmajoritária\n",
      "#\tsenão,\tdivida\tcom\tbase\tna\tmelhor\tcaracterística\n",
      "best_attribute\t=\tmin(split_candidates,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tkey=partial(partition_entropy_by,\tinputs))\n",
      "partitions\t=\tpartition_by(inputs,\tbest_attribute)\n",
      "new_candidates\t=\t[a\tfor\ta\tin\tsplit_candidates\n",
      "\t\t\t\t\t\t\t\t\t\t\tif\ta\t!=\tbest_attribute]\n",
      "#\trecursivamente\tconstrói\tas\tsub-árvores\n",
      "subtrees\t=\t{\tattribute_value\t:\tbuild_tree_id3(subset,\tnew_candidates)\n",
      "\t\t\t\t\t\tfor\tattribute_value,\tsubset\tin\tpartitions.iteritems()\t}\n",
      "subtrees[none]\t=\tnum_trues\t>\tnum_falses\t\t\t\t\t\n",
      "#\tcaso\tpadrão\n",
      "return\t(best_attribute,\tsubtrees)\n",
      "na\tárvore\tque\tconstruímos,\tcada\tfolha\tconsistia\tinteiramente\tde\tentradas\t\n",
      "true\n",
      "\tou\n",
      "inteiramente\tde\tentradas\t\n",
      "false\n",
      ".\tisso\tsignifica\tque\ta\tárvore\tprevê\tperfeitamente\tem\n",
      "um\tconjunto\tde\tdados\tem\ttreinamento.\tmas\tnós\ttambém\tpodemos\taplicar\tisso\ta\n",
      "novos\tdados\tque\tnão\testavam\tno\tconjunto\tde\ttreinamento:\n",
      "tree\t=\tbuild_tree_id3(inputs)\n",
      "classify(tree,\t{\t\"level\"\t:\t\"junior\",\t\t\t\t\t\t\t\t\t\t\t\"lang\"\t:\t\"java\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\"tweets\"\t:\t\"yes\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\"phd\"\t:\t\"no\"}\t)\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\ttrue\n",
      "classify(tree,\t{\t\"level\"\t:\t\"junior\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\"lang\"\t:\t\"java\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\"tweets\"\t:\t\"yes\",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\"phd\"\t:\t\"yes\"}\t)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tfalse\n",
      "e\ttambém\tem\tdados\tcom\tvalores\tfaltando\tou\tinesperados:\n",
      "classify(tree,\t{\t\"level\"\t:\t\"intern\"\t}\t)\t\n",
      "#\ttrue\n",
      "classify(tree,\t{\t\"level\"\t:\t\"senior\"\t}\t)\t\n",
      "#\tfalse\n",
      "como\tnosso\tobjetivo\tera\tdemonstrar\t\n",
      "como\n",
      "\tconstruir\tuma\tárvore,\tnós\tconstruímos\ta\n",
      "árvore\tusado\ttodo\to\tconjunto\tde\tdados.\tcomo\tsempre,\tse\trealmente\testivéssemos\n",
      "tentando\tcriar\tum\tbom\tmodelo\tpara\talguma\tcoisa,\tnós\tteríamos\t(coletado\tmais\tdados\n",
      "e)\tdividido\tos\tdados\tem\tsubconjuntos\tde\ttreinamento/validação/teste.florestas\taleatórias\n",
      "levando\tem\tconsideração\tcomo\tárvores\tde\tdecisão\tpodem\tse\tajustar\tquase\n",
      "perfeitamente\ta\tseus\tdados\tem\ttreinamento,\tnão\tnos\tsurpreende\tque\telas\ttendem\n",
      "a\tsobreajustar.\tuma\tforma\tde\tevitar\tisso\té\ta\ttécnica\tchamada\t\n",
      "florestas\n",
      "aleatórias\n",
      ",\tna\tqual\tpodemos\tconstruir\tvárias\tárvores\tde\tdecisão\te\tdeixá-las\n",
      "escolher\tcomo\tclassificar\tentradas:\n",
      "def\n",
      "\tforest_classify(trees,\tinput):\n",
      "votes\t=\t[classify(tree,\tinput)\t\n",
      "for\n",
      "\ttree\t\n",
      "in\n",
      "\ttrees]\n",
      "vote_counts\t=\tcounter(votes)\n",
      "return\n",
      "\tvote_counts.most_common(1)[0][0]\n",
      "nosso\tprocesso\tde\tconstrução\tde\tárvores\tera\tdeterminista,\tentão\tcomo\n",
      "conseguimos\tárvores\taleatórias?\n",
      "uma\tparte\tenvolve\tdados\t\n",
      "inicialização\n",
      "\t(lembre-se\tde\t“digressão:\ta\n",
      "inicialização”,\tna\tpágina\t183).\tem\tvez\tde\ttreinar\tcada\tárvore\tem\ttodas\tas\n",
      "entradas\tno\tconjunto\tde\ttreinamento,\tnós\ttreinamos\tcada\tárvore\tno\tresultado\tde\n",
      "bootstrap_sample\n",
      "(\n",
      "inputs\n",
      ").\tuma\tvez\tque\tcada\tárvore\té\tconstruída\tusando\tdados\n",
      "diferentes,\tcada\tárvore\tserá\tdiferente\tda\toutra.\t(um\tbenefício\té\tque\tusar\tdados\n",
      "não-amostrados\tpara\ttestar\tcada\tárvore\té\tum\tmétodo\tjusto,\to\tque\tsignifica\tque\n",
      "você\tpode\tcontinuar\tusando\ttodos\tos\tdados\tcomo\to\tconjunto\tde\ttreinamento\tse\n",
      "você\tsouber\tmedir\trendimento.)\testa\ttécnica\té\tconhecida\tcomo\t\n",
      "bootstrap\n",
      "aggregating\n",
      "\tou\t\n",
      "bagging\n",
      "\t(empacotamento).\n",
      "uma\tsegunda\tforma\tenvolve\tmudar\tcomo\tescolhemos\ta\tforma\tcomo\t\n",
      "best_attribute\n",
      "divide-se.\tem\tvez\tde\tolhar\tpara\ttodos\tos\tatributos\tremanescentes,\tnós\tprimeiro\n",
      "escolhemos\tum\tsubconjunto\taleatório\te\to\tdividimos\tno\tque\tfor\tmelhor:\n",
      "#\tse\tjá\thá\tcandidatos\to\tbastante,\tolhe\tpara\ttodos\teles\n",
      "if\tlen(split_candidates)\t<=\tself.num_split_candidates:\n",
      "sampled_split_candidates\t=\tsplit_candidates\n",
      "#\tsenão\tescolha\tuma\tamostra\taleatória\n",
      "else:\n",
      "sampled_split_candidates\t=\trandom.sample(split_candidates,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tself.num_split_candidates)\n",
      "#\tagora\tescolha\ta\tmelhor\tcaracterística\ta\tpartir\tapenas\tdaqueles\tcandidatos\n",
      "best_attribute\t=\tmin(sampled_split_candidates,key=partial(partition_entropy_by,\tinputs))\n",
      "partitions\t=\tpartition_by(inputs,\tbest_attribute)\n",
      "esse\té\tum\texemplo\te\tuma\ttécnica\tmais\tampla\tchamada\t\n",
      "ensemble\tlearning\n",
      "\tna\n",
      "qual\tcombinamos\tvários\t\n",
      "weak\tlearners\n",
      "\t(tipicamente\tmodelos\tde\talta\n",
      "polarização,\te\tbaixa\tvariância)\tpara\tproduzir\tum\tmodelo\tforte\tglobal.\n",
      "florestas\taleatórias\tsão\tum\tdos\tmodelos\tmais\tpopulares\te\tversáteis\tdisponíveis.•\n",
      "•\n",
      "para\tmaiores\tesclarecimentos\n",
      "scikit-learn\tpossui\tmuitos\tmodelos\tde\tárvores\tde\tdecisão\n",
      "(\n",
      "http://bit.ly/1ycpmuq\n",
      ").\ttambém\tpossui\tum\tmódulo\t\n",
      "ensemble\n",
      "(\n",
      "http://bit.ly/1ycpom1\n",
      ")\n",
      "\tque\tinclui\t\n",
      "randomforestclassifier\n",
      "\te\toutros\tmétodos.\n",
      "nós\tquase\tnão\tarranhamos\ta\tsuperfície\tdo\ttópico\tde\tárvores\tde\tdecisão\te\n",
      "seus\talgoritmos.\ta\twikipédia\t(\n",
      "http://bit.ly/1ycpn1j\n",
      ")\té\tum\tbom\tponto\tde\n",
      "partida\tpara\tuma\texplicação\tmais\tampla.capítulo\t18\n",
      "redes\tneurais\n",
      "eu\tgosto\tde\tcoisas\tsem\tsentido;\telas\tacordam\tas\tcélulas\tdo\tcérebro\n",
      ".\n",
      "—dr.\tseuss\n",
      "uma\t\n",
      "rede\tneural\tartificial\n",
      "\t(ou\trede\tneural)\té\tum\tmodelo\tpreditivo\tmotivado\tpela\n",
      "forma\tcomo\to\tcérebro\tfunciona.\tpense\tno\tcérebro\tcomo\tuma\tcoleção\tde\n",
      "neurônios\tconectados.\tcada\tneurônio\tolha\tpara\ta\tsaída\tde\toutros\tneurônios\tque\n",
      "o\talimentam,\tfaz\tum\tcálculo\te\tentão\tele\tdispara\t(se\to\tcálculo\texceder\talgum\n",
      "limite)\tou\tnão\t(se\tnão\texceder).\n",
      "redes\tneurais\tartificiais\tconsistem\tde\tneurônios\tartificiais,\tque\tdesenvolvem\n",
      "cálculos\tsimilares\tsobre\tsuas\tentradas.\tredes\tneurais\tpodem\tresolver\tuma\n",
      "variedade\tde\tproblemas\tcomo\treconhecimento\tde\tcaligrafia\te\tdetecção\tfacial,\te\n",
      "elas\tsão\tmuito\tusadas\tem\t\n",
      "deep\tlearning\n",
      "\t(aprendizado\tprofundo),\tuma\tdas\n",
      "subáreas\tmais\tpopulares\tde\tdata\tscience.\tentretanto,\ta\tmaioria\tdas\tredes\tneurais\n",
      "são\t“caixas-pretas”\t—\tinspecionar\tseus\tdetalhes\tnão\tlhe\tfornece\tmuito\n",
      "entendimento\tde\t\n",
      "como\n",
      "\telas\testão\tresolvendo\tum\tproblema.\te\tgrandes\tredes\n",
      "neurais\tpodem\tser\tdifíceis\tde\ttreinar.\tpara\ta\tmaioria\tdos\tproblemas\tque\tvocê\n",
      "encontrará\tcomo\tum\tcientista\tde\tdados,\telas\tprovavelmente\tnão\tsão\ta\tmelhor\n",
      "opção.\talgum\tdia,\tquando\tvocê\testiver\ttentando\tconstruir\tuma\tinteligência\n",
      "artificial\tpara\ttornar\treal\ta\tsingularidade,\telas\tpodem\tser.perceptrons\n",
      "a\trede\tneural\tmais\tsimples\té\ta\t\n",
      "perceptron\n",
      ",\tque\taproxima\tum\túnico\tneurônio\n",
      "com\t\n",
      "n\n",
      "\tentradas\tbinárias.\tela\tcomputa\ta\tsoma\tponderada\tde\tsuas\tentradas\te\n",
      "“dispara”\tse\tessa\tsoma\tfor\tzero\tou\tmaior:\n",
      "def\n",
      "\tstep_function(x):\n",
      "return\n",
      "\t1\t\n",
      "if\n",
      "\tx\t>=\t0\t\n",
      "else\n",
      "\t0\n",
      "def\n",
      "\tperceptron_output(weights,\tbias,\tx):\n",
      "\"\"\"retorna\t1\tse\ta\tperceptron\t'disparar',\t0\tse\tnão\"\"\"\n",
      "calculation\t=\tdot(weights,\tx)\t+\tbias\n",
      "return\n",
      "\tstep_function(calculation)\n",
      "perceptron\té\tsimplesmente\ta\tdistinção\tentre\tespaços\tseparados\tpelo\thiperplano\n",
      "de\tpontos\t\n",
      "x\n",
      ",\tpelo\tqual:\n",
      "dot(weights,x)\t+\tbias\t==\t0\n",
      "com\tpesos\tpropriamente\tescolhidos,\tperceptrons\tpodem\tsolucionar\talguns\n",
      "problemas\tsimples\t(\n",
      "figura\t18-1\n",
      ").\tpor\texemplo,\tpodemos\tcriar\tuma\t\n",
      "porta\tand\n",
      "(que\tretorna\t1\tse\tambas\tentradas\tforem\t1\tmas\tretorna\t0\tse\tuma\tdas\tentradas\tfor\n",
      "0)\tcom:\n",
      "weights\t=\t[2,\t2]\n",
      "bias\t=\t-3\n",
      "se\tambas\tas\tentradas\tforem\t1,\to\tcálculo\t(\n",
      "calculation\n",
      ")\tserá\tigual\ta\t2\t+\t2\t–\t3\t=\t1,\te\ta\n",
      "saída\tserá\t1.\tse\tapenas\tuma\tdas\tentradas\tfor\t1,\to\t\n",
      "cálculo\n",
      "\tserá\tigual\ta\t2\t+\t0\t–\t3\t=\t–\n",
      "1,\te\ta\tsaída\tserá\t0.\te\tse\tambas\tentradas\tforem\t0,\to\t\n",
      "cálculo\n",
      "\tserá\t–3\te\ta\tsaída\tserá\t0.\n",
      "similarmente,\tpoderíamos\tconstruir\tuma\t\n",
      "porta\tor\n",
      "\tcom:\n",
      "weights\t=\t[2,\t2]\n",
      "bias\t=\t-1figura\t18-1.\tespaço\tde\tdecisão\tpara\tum\tperceptron\tde\tduas\tentradas\n",
      "e\tpoderíamos\tconstruir\tuma\t\n",
      "porta\tnot\n",
      "\t(que\tteria\tuma\tentrada\te\tconverteria\t1\n",
      "para\t0\te\t0\tpara\t1)\tcom:\n",
      "weights\t=\t[-2]\n",
      "bias\t=\t1\n",
      "entretanto,\texistem\talguns\tproblemas\tque\tsimplesmente\tnão\tpodem\tser\n",
      "resolvidos\tcom\tapenas\tum\tperceptron.\tpor\texemplo,\tnão\timporta\to\tquanto\tvocê\n",
      "tente,\tvocê\tnão\tpode\tusar\tum\tperceptron\tpara\tconstruir\tum\ta\t\n",
      "porta\txor\n",
      "\tcom\n",
      "saída\t1\tse\texatamente\tuma\tde\tsuas\tentradas\tfor\t1\tou\tentão\t0.\té\taí\tque\n",
      "começamos\ta\tprecisar\tde\tredes\tneurais\tmais\tcomplicadas.\n",
      "claro,\tvocê\tnão\tprecisa\tda\taproximação\tde\tum\tneurônio\tpara\tconstruir\tuma\n",
      "porta\tlógica:\n",
      "and_gate\t=\tmin\n",
      "or_gate\t=\tmax\n",
      "xor_gate\t=\t\n",
      "lambda\n",
      "\tx,\ty:\t0\t\n",
      "if\n",
      "\tx\t==\ty\t\n",
      "else\n",
      "\t1como\tneurônios\treais,\tneurônios\tartificiais\tcomeçam\ta\tficar\tmais\tinteressantes\n",
      "quando\tvocê\tcomeça\ta\tconectá-los.redes\tneurais\tfeed-forward\n",
      "a\ttopologia\tdo\tcérebro\té\tdemasiadamente\tcomplicada,\tentão\té\tnormal\taproximá-\n",
      "la\tcom\tuma\trede\tneural\t\n",
      "feed-forward\n",
      "\tidealizada\tque\tconsiste\tde\t\n",
      "camadas\n",
      "discretas\tde\tneurônios,\tcada\tuma\tconectada\tà\tseguinte.\tisso\ttipicamente\tenvolve\n",
      "uma\tcamada\tde\tentrada\t(que\trecebe\tentradas\te\tas\ttransmite\tsem\tmodificações),\n",
      "uma\tou\tmais\t“camadas\tocultas”\t(em\tque\tcada\tuma\tconsiste\tde\tneurônios\tque\n",
      "pegam\tsaídas\tda\tcamada\tanterior,\tfazem\talgum\tcálculo\te\tpassam\to\tresultado\n",
      "para\ta\tpróxima\tcamada),\te\tuma\tcamada\tde\tsaída\t(que\tproduz\tas\tsaídas\tfinais).\n",
      "assim\tcomo\to\tperceptron,\tcada\tneurônio\t(não\tde\tentrada)\tpossui\to\tpeso\n",
      "correspondente\ta\tcada\tuma\tde\tsuas\tentradas\te\tuma\tpolarização\t(tendência).\tpara\n",
      "simplificar\tnossa\trepresentação,\tadicionaremos\ta\tpolarização\t(bias)\tno\tfinal\tdo\n",
      "nosso\tvetor\tde\tpesos\te\tdaremos\ta\tcada\tneurônio\tuma\t\n",
      "entrada\tpolarizada\n",
      "\tque\té\n",
      "sempre\tigual\ta\t1.\n",
      "como\tcom\to\tperceptron,\tpara\tcada\tneurônio\tsomaremos\tos\tprodutos\tde\tsuas\n",
      "entradas\te\tseus\tpesos.\tmas\taqui,\tem\tvez\tde\tgerar\t\n",
      "step_function\n",
      "\taplicada\tàquele\n",
      "produto,\texibiremos\tuma\taproximação\tsuave\tda\tfunção\tstep.\tusaremos\ta\tfunção\n",
      "sigmoid\n",
      "\t(\n",
      "figura\t18-2\n",
      "):\n",
      "def\n",
      "\tsigmoid(t):\n",
      "return\n",
      "\t1\t/\t(1\t+\tmath.exp(-t))figura\t18-2.\ta\tfunção\tsigmoid\n",
      "por\tque\tusar\t\n",
      "sigmoid\n",
      "\tem\tvez\tde\tuma\tmais\tsimples\t\n",
      "step_function\n",
      "?\tpara\ttreinar\tuma\n",
      "rede\tneural,\tprecisaremos\tusar\tcálculo,\te\tpara\tusar\tcálculo,\tprecisaremos\tde\n",
      "funções\t\n",
      "suaves\n",
      ".\ta\tfunção\tstep\tnão\té\tcontínua,\te\tsigmoid\té\tuma\tboa\taproximação\n",
      "suave\tdela.\n",
      "você\tdeve\tse\tlembrar\tde\t\n",
      "sigmoid\n",
      "\tdo\t\n",
      "capítulo\t16\n",
      ",\tonde\tera\tchamada\tde\t\n",
      "logistic\n",
      ".\n",
      "tecnicamente,\t“sigmoid”\tse\trefere\tao\t\n",
      "formato\n",
      "\tda\tfunção,\t“logística”\ta\testa\tfunção\n",
      "específica\tembora\tas\tpessoas\tgeralmente\tusem\tos\ttermos\tindistintamente.\n",
      "nós\tpodemos\tentão\tcalcular\ta\tsaída\tcomo:\n",
      "def\n",
      "\tneuron_output(weights,\tinputs):\n",
      "return\n",
      "\tsigmoid(dot(weights,\tinputs))\n",
      "dada\tessa\tfunção,\tnós\tpodemos\trepresentar\tum\tneurônio\tsimplesmente\tcomouma\tlista\tde\tpesos\tcujo\ttamanho\té\tmais\tdo\tque\to\tnúmero\tde\tentradas\tdaquele\n",
      "neurônio\t(por\tcausa\tdo\tpeso\tbias).\tentão,\tpodemos\trepresentar\tuma\trede\tneural\n",
      "como\tuma\tlista\tde\t\n",
      "camadas\n",
      "\t(não\tde\tentrada),\tem\tque\tcada\tcamada\té\tapenas\tuma\n",
      "lista\tde\tneurônios\tnaquela\tcamada.\n",
      "isto\té,\trepresentaremos\tuma\trede\tneural\tcomo\tuma\tlista\t(camadas)\tde\tlistas\n",
      "(neurônios)\tde\tlistas\t(pesos).\n",
      "dada\ttal\trepresentação,\tusar\ta\trede\tneural\té\tbem\tsimples:\n",
      "def\tfeed_forward(neural_network,\tinput_vector):\n",
      "\"\"\"recebe\ta\trede\tneural\n",
      "(representada\tcomo\tuma\tlista\tde\tlistas\tde\tlistas\tde\tpesos)\n",
      "e\tretorna\ta\tsaída\ta\tpartir\tda\tentrada\ta\tse\tpropagar\"\"\"\n",
      "outputs\t=\t[]\n",
      "#\tprocessa\tuma\tcamada\tpor\tvez\n",
      "for\tlayer\tin\tneural_network:\n",
      "input_with_bias\t=\tinput_vector\t+\t[1]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tadiciona\tuma\tentrada\tpolarizada\n",
      "output\t=\t[neuron_output(neuron,\tinput_with_bias)\t\t\n",
      "#\tcomputa\ta\tsaída\n",
      "\t\tfor\tneuron\tin\tlayer]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpara\tcada\tneurônio\n",
      "outputs.append(output)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\te\tmemoriza\n",
      "#\tentão\ta\tentrada\tpara\ta\tpróxima\tcamada\té\ta\tsaída\tdesta\n",
      "input_vector\t=\toutput\n",
      "return\toutputs\n",
      "agora\té\tfácil\tconstruir\ta\tporta\txor\tque\tnão\tpodíamos\tconstruir\tcom\tum\túnico\n",
      "perceptron.\tsó\tprecisamos\tajustar\tos\tpesos\tpara\tque\t\n",
      "neuron_output\n",
      "s\tseja\tbem\n",
      "próximo\tde\t0\tou\tde\t1:\n",
      "xor_network\t=\t[\n",
      "#\tcamada\toculta\n",
      "\t\t\t\t\t\t\t\t[[20,\t20,\t-30],\t\t\t\t\t\t\t\n",
      "#\tneurônio\t'and'\n",
      "\t\t\t\t\t\t\t\t\t[20,\t20,\t-10]],\t\t\t\t\t\t\n",
      "#\tneurônio\t'or'\n",
      "\t\t\t\t\t\t\t\t\n",
      "#\toutput\tlayer\n",
      "\t\t\t\t\t\t\t\t\t[[-60,\t60,\t-30]]]\t\t\t\t\n",
      "#\tneurônio\t'segunda\tentrada\n",
      ",\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tmas\tnão\ta\tprimeira\tentrada'\n",
      "for\tx\tin\t[0,\t1]:\n",
      "for\ty\tin\t[0,\t1]:\n",
      "#\tfeed_forward\tproduz\tas\tsaídas\tpara\ttodos\tos\tneurônios\n",
      "#\tfeed_forward[-1]\té\ta\tsaída\tda\tcamada\tde\tsaída\tde\tneurônios\n",
      "print\tx,\ty,\tfeed_forward(xor_network,[x,\ty])[-1]\n",
      "#\t0\t0\t[9.38314668300676e-14]\n",
      "#\t0\t1\t[0.9999999999999059]#\t1\t0\t[0.9999999999999059]\n",
      "#\t1\t1\t[9.383146683006828e-14]\n",
      "ao\tusar\tuma\tcamada\toculta,\tpodemos\ttransmitir\ta\tsaída\tde\tum\tneurônio\t“and”\te\n",
      "a\tsaída\tde\tum\tneurônio\t“or”\tem\tum\tneurônio\t“segunda\tentrada\tmas\tnão\tprimeira\n",
      "entrada”.\to\tresultado\té\tuma\trede\tque\trealiza\t“or,\tmas\tnão\tand”,\tque\té\n",
      "precisamente\txor\t(\n",
      "figura\t18-3\n",
      ").\n",
      "figura\t18-3.\tuma\trede\tneural\tpara\txor1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "5.\n",
      "backpropagation\n",
      "geralmente\tnós\tnão\tconstruímos\tredes\tneurais\tmanualmente.\tisso\tse\tdá,\tem\n",
      "parte,\tporque\tas\tusamos\tpara\tresolver\tproblemas\tmuito\tmaiores\t—\tum\tproblema\n",
      "de\treconhecimento\tda\timagem\tpode\tenvolver\tdezenas\tou\tmilhares\tde\tneurônios.\n",
      "e\tem\tparte\tporque\tnós\tgeralmente\tnão\tconseguimos\t“raciocinar”\tsobre\to\tque\n",
      "neurônios\tdeveriam\tser.\n",
      "em\tvez\tdisso,\tnós\tusamos\tdados\tpara\t\n",
      "treinar\n",
      "\tredes\tneurais.\tuma\tabordagem\n",
      "popular\té\tum\talgoritmo\tchamado\t\n",
      "backpropagation\n",
      "\tque\tpossui\tsemelhanças\tcom\n",
      "o\talgoritmo\tgradiente\tdescendente\tque\tvimos\tanteriormente.\n",
      "imagine\tque\ttemos\tum\tconjunto\tde\ttreinamento\tque\tconsiste\tde\tvetores\tde\n",
      "entradas\te\tcorrespondentes\tvetores\talvos\tde\tsaída.\tpor\texemplo,\tem\tnosso\n",
      "exemplo\tanterior\t\n",
      "xor_network\n",
      ",\to\tvetor\tde\tentrada\t\n",
      "[1,0]\n",
      "\tcorrespondia\tao\talvo\tde\tsaída\n",
      "[1]\n",
      ".\te\timagine\tque\tnossa\trede\ttem\talgum\tconjunto\tde\tpesos.\tnós\tajustamos\tos\n",
      "pesos\tusando\to\tseguinte\talgoritmo:\n",
      "execute\t\n",
      "feed_forward\n",
      "\tem\tum\tvetor\tde\tentrada\tpara\tproduzir\tsaídas\tde\ttodos\n",
      "os\tneurônios\tna\trede.\n",
      "isso\tresulta\tem\tum\terro\tpara\tcada\tneurônio\tde\tsaída\t—\ta\tdiferença\tentre\n",
      "sua\tsaída\te\tseu\talvo.\n",
      "compute\to\tgradiente\tpara\tesse\terro\tcomo\tuma\tfunção\tde\tpesos\tde\n",
      "neurônios\te\tajuste\tseus\tpesos\tna\tdireção\tque\tmais\tdiminui\to\terro.\n",
      "“propague”\tesses\terros\tde\tsaída\tde\tvolta\tpara\tinferir\terros\tpara\tas\tcamadas\n",
      "ocultas.\n",
      "compute\tos\tgradientes\tdesses\terros\te\tajuste\tos\tpesos\tda\tcamada\toculta\tda\n",
      "mesma\tmaneira.\n",
      "tipicamente,\tnós\texecutamos\to\talgoritmo\tmuitas\tvezes\tpara\ttodo\to\tnosso\n",
      "conjunto\tde\ttreinamento\taté\tque\ta\trede\tconvirja:\n",
      "def\tbackpropagate(network,\tinput_vector,\ttargets):\n",
      "hidden_outputs,\toutputs\t=\tfeed_forward(network,\tinput_vector)\n",
      "#\ta\tsaída\t*\t(1\t–\toutput)\té\tda\tderivada\tda\tsigmoid\n",
      "output_deltas\t=\t[output\t*\t(1\t-\toutput)\t*\t(output\t-\ttarget)\n",
      "\t\t\t\tfor\toutput,\ttarget\tin\tzip(outputs,\ttargets)]#\tajusta\tos\tpesos\tpara\ta\tcamada\tde\tsaída,\tum\tneurônio\tpor\tvez\n",
      "for\ti,\toutput_neuron\tin\tenumerate(network[-1]):\n",
      "#\tfoca\tno\ti-ésimo\tneurônio\tda\tcamada\tde\tsaída\n",
      "for\tj,\thidden_output\tin\tenumerate(hidden_outputs\t+\t[1]):\n",
      "#\tajusta\to\tj-ésimo\tpeso\tbaseado\tem\tambos\n",
      "#\to\tdelta\tdeste\tneurônio\te\tsua\tj-ésima\tentrada\n",
      "output_neuron[j]\t-=\toutput_deltas[i]\t*\thidden_output\n",
      "#\terros\tde\tbackpropagation\tpara\ta\tcamada\toculta\n",
      "hidden_deltas\t=\t[hidden_output\t*\t(1\t-\thidden_output)\t*\n",
      "\t\t\t\tdot(output_deltas,\t[n[i]\tfor\tn\tin\toutput_layer])\n",
      "\t\t\tfor\ti,\thidden_output\tin\tenumerate(hidden_outputs)]\n",
      "#\tajusta\tos\tpesos\tpara\ta\tcamada\toculta,\tum\tneurônio\tpor\tvez\n",
      "for\ti,\thidden_neuron\tin\tenumerate(network[0]):\n",
      "for\tj,\tinput\tin\tenumerate(input_vector\t+\t[1]):\n",
      "hidden_neuron[j]\t-=\thidden_deltas[i]\t*\tinput\n",
      "isso\té\tpraticamente\tescrever\texplicitamente\to\terro\tao\tquadrado\tcomo\tuma\n",
      "função\tde\tpesos\te\tusar\ta\tfunção\t\n",
      "minimize_stochastic\n",
      "\tque\tconstruímos\tno\t\n",
      "capítulo\t8\n",
      ".\n",
      "neste\tcaso,\tescrever\texplicitamente\ta\tfunção\tgradiente\tacaba\tsendo\tum\ttipo\tde\n",
      "dor.\tse\tvocê\tsabe\tcálculo\te\ta\tregra\tda\tcadeia,\tos\tdetalhes\tmatemáticos\tsão\n",
      "relativamente\tdiretos,\tmas\tmanter\ta\tnotação\tdireta\t(“a\tderivada\tparcial\tda\tfunção\n",
      "de\terro\tdo\tpeso\tque\taquele\tneurônio\ti\tatribui\tà\tentrada\tvinda\tdo\tneurônio\tj”)\tnão\n",
      "é\ttão\tdivertido.exemplo:\tderrotando\tum\tcaptcha\n",
      "para\tcertificar\tque\tpessoas\tque\testão\tse\tregistrando\tem\tseu\tsite\tsão\trealmente\n",
      "pessoas,\ta\tvice-presidente\tda\tgerência\tde\tprodutos\tquer\tque\tvocê\timplemente\n",
      "um\tcaptcha\t(completely\tautomated\tpublic\tturing\ttest\tto\ttell\tcomputers\tand\n",
      "humans\tapart)\tcomo\tparte\tdo\tprocesso\tde\tregistro.\tem\tparticular,\tele\tgostaria\n",
      "de\texibir\taos\tusuários\tuma\timagem\tde\tum\tdígito\te\texigir\tque\teles\tforneçam\n",
      "aquele\tdígito\tpara\tprovar\tque\tsão\thumanos.\n",
      "ele\tnão\tacreditou\tquando\tvocê\tdisse\tque\tcomputadores\tpodem\tfacilmente\n",
      "resolver\tesse\tproblema,\tentão\tvocê\tdecide\tconvencê-lo\tcriando\tum\tprograma\n",
      "que\tfaça\tisso.\n",
      "representaremos\tcada\tdígito\tcomo\tuma\timagem\t5\t×\t5:\n",
      "nossa\trede\tneural\tquer\tque\tuma\tentrada\tseja\tum\tvetor\tde\tnúmeros.\tentão\n",
      "transformaremos\tcada\timagem\tem\tum\tvetor\tde\ttamanho\t25,\tcujos\telementos\tsão\n",
      "1\t(“este\tpixel\testá\tna\timagem”)\tou\t0\t(“este\tpixel\tnão\testá\tna\timagem”).\n",
      "por\texemplo,\to\tdígito\tzero\tseria\trepresentado\tcomo:\n",
      "zero_digit\t=\t[1,1,1,1,1,\n",
      "\t\t\t\t1,0,0,0,1,\n",
      "\t\t\t\t1,0,0,0,1,\n",
      "\t\t\t\t1,0,0,0,1,\n",
      "\t\t\t\t1,1,1,1,1]\n",
      "nós\tqueremos\tque\tnossa\tsaída\tindique\tqual\tdígito\ta\trede\tneural\tpensa\tque\té,\n",
      "então\tprecisaremos\tde\t10\tsaídas.\ta\tsaída\tcorreta\tpara\to\tdígito\t4,\tpor\texemplo,\n",
      "seria:\n",
      "[0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0]\n",
      "então,\tpresumindo\tque\tnossas\tentradas\testão\tordenadas\tcorretamente\tde\t0\ta\t9,\n",
      "nossos\talvos\tserão:targets\t=\t[[1\t\n",
      "if\n",
      "\ti\t==\tj\t\n",
      "else\n",
      "\t0\t\n",
      "for\n",
      "\ti\t\n",
      "in\n",
      "\trange(10)]\n",
      "\t\t\t\t\n",
      "for\n",
      "\tj\t\n",
      "in\n",
      "\trange(10)]\n",
      "para\tque\t(por\texemplo)\t\n",
      "targets[4]\n",
      "\tseja\ta\tsaída\tcorreta\tpara\to\tdígito\t4.\n",
      "nesse\tponto\testamos\tprontos\tpara\tconstruir\tnossa\trede\tneural:\n",
      "random.seed(0)\t\t\t\t\t\n",
      "#\tpara\tpegar\tresultados\trepetidos\n",
      "input_size\t=\t25\t\t\t\t\n",
      "#\tcada\tentrada\té\tum\tvetor\tde\ttamanho\t25\n",
      "num_hidden\t=\t5\t\t\t\t\t\n",
      "#\tteremos\t5\tneurônios\tna\tcamada\toculta\n",
      "output_size\t=\t10\t\t\t\n",
      "#\tprecisamos\tde\t10\tsaídas\tpara\tcada\tentrada\n",
      "#\tcada\tneurônio\toculto\ttem\tum\tpeso\tpor\tentrada,\tmais\tum\tpeso\tbias\n",
      "hidden_layer\t=\t[[random.random()\t\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(input_size\t+\t1)]\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(num_hidden)]\n",
      "#\tcada\tneurônio\tde\tsaída\ttem\tum\tpeso\tpor\tneurônio\toculto,\tmais\to\tpeso\tbias\n",
      "output_layer\t=\t[[random.random()\t\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(num_hidden\t+\t1)]\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(output_size)]\n",
      "#\ta\trede\tcomeça\tcom\tpesos\taleatórios\n",
      "network\t=\t[hidden_layer,\toutput_layer]\n",
      "e\tpodemos\ttreinar\to\talgoritmo\tbackpropagation:\n",
      "#\t10.000\titerações\tparecem\tser\to\tsuficiente\tpara\tconvergir\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(10000):\n",
      "for\n",
      "\tinput_vector,\ttarget_vector\t\n",
      "in\n",
      "\tzip(inputs,\ttargets):\n",
      "backpropagate(network,\tinput_vector,\ttarget_vector)\n",
      "isso\tfunciona\tbem\tno\tconjunto\tde\ttreinamento,\tobviamente:\n",
      "def\n",
      "\tpredict(input):\n",
      "return\n",
      "\tfeed_forward(network,\tinput)[-1]\n",
      "predict(inputs[7])\n",
      "#\t[0.026,\t0.0,\t0.0,\t0.018,\t0.001,\t0.0,\t0.0,\t0.967,\t0.0,\t0.0]\n",
      "o\tque\tindica\tque\ta\tsaída\tde\tneurônio\tde\tdígito\t7\tproduz\t0,97,\tenquanto\tque\n",
      "todas\tas\toutras\tsaídas\tde\tneurônios\tproduzem\tnúmeros\tmuito\tpequenos.\n",
      "mas\ttambém\tpodemos\taplicar\tisso\ta\tdígitos\tdesenhados\tdiferentes,\tcomo\tmeu\t3\n",
      "estilizado:\n",
      "predict([0,1,1,1,0,\t\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "\t\t0,0,0,1,1,\t\t\t\t\n",
      "#\t...@@\n",
      "\t\t0,0,1,1,0,\t\t\t\t\n",
      "#\t..@@\n",
      ".\n",
      "\t\t0,0,0,1,1,\t\t\t\t\n",
      "#\t...@@\n",
      "\t\t0,1,1,1,0])\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "#\t[0.0,\t0.0,\t0.0,\t0.92,\t0.0,\t0.0,\t0.0,\t0.01,\t0.0,\t0.12]a\trede\tainda\tpensa\tque\tele\tparece\tcom\tum\t3,\tenquanto\tmeu\t8\testilizado\trecebe\n",
      "votos\tpara\tser\tum\t5,\tum\t8\te\tum\t9:\n",
      "predict([0,1,1,1,0,\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "\t\t1,0,0,1,1,\t\t\t\n",
      "#\t@..@@\n",
      "\t\t0,1,1,1,0,\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "\t\t1,0,0,1,1,\t\t\t\n",
      "#\t@..@@\n",
      "\t\t0,1,1,1,0])\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "#\t[0.0,\t0.0,\t0.0,\t0.0,\t0.0,\t0.55,\t0.0,\t0.0,\t0.93,\t1.0]\n",
      "ter\tum\tconjunto\tde\ttreinamento\tmaior\tprovavelmente\tajudaria.\n",
      "embora\ta\toperação\tda\trede\tnão\tseja\texatamente\ttransparente,\tpodemos\n",
      "inspecionar\tos\tpesos\tda\tcamada\toculta\tpara\tentender\to\tque\testão\treconhecendo.\n",
      "podemos\tassinalar\tos\tpesos\tpara\tcada\tneurônio\tcomo\tuma\tgrade\t5\t×\t5\n",
      "correspondente\tàs\tentradas\t5\t×\t5.\n",
      "na\tvida\treal,\tvocê\tprovavelmente\tmarcaria\tpesos\tzero\tcomo\tbrancos,\tcom\tpesos\n",
      "maiores\tpositivos\tmais\te\tmais\t(digamos)\tverdes\te\tnegativos\tcom\t(digamos)\n",
      "vermelho.\tinfelizmente,\té\tmuito\tdifícil\tfazer\tisso\tem\tum\tlivro\tpreto\te\tbranco.\n",
      "em\tvez\tdisso,\tmarcaremos\tpesos\tzero\tcom\tbranco\te\tpesos\tmais\te\tmais\tdistantes\n",
      "de\tzero\tcada\tvez\tmais\tescuros.\te\tusaremos\thachurado\tpara\tindicar\tpesos\n",
      "negativos.\n",
      "para\tfazer\tisso,\tusaremos\t\n",
      "pyplot.imshow\n",
      ",\tque\tnão\tvimos\tantes.\tcom\tisso,\tpodemos\n",
      "assinalar\timagens\tpixel\tpor\tpixel.\tnormalmente\tisso\tnão\té\tusado\tpara\tdata\n",
      "science,\tmas\taqui\té\tuma\tboa\tescolha:\n",
      "import\tmatplotlib\n",
      "weights\t=\tnetwork[0][0]\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tprimeiro\tneurônio\tna\tcamada\toculta\n",
      "abs_weights\t=\tmap(abs,\tweights)\t\t\t\t\t\n",
      "#\ta\tescuridão\tdepende\tsomente\tdo\tvalor\tabsoluto\n",
      "grid\t=\t[abs_weights[row:(row+5)]\t\t\t\t\t\t\n",
      "#\ttransforma\tos\tpesos\tem\tuma\tgrade\t5x5\n",
      "\t\t\t\tfor\trow\tin\trange(0,25,5)]\t\t\t\t\t\n",
      "#\t[pesos[0:5],\t…,\tpesos[20:25]]\n",
      "ax\t=\tplt.gca()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpara\tusar\thachuras,\tprecisamos\tde\teixos\n",
      "ax.imshow(grid,\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\taqui\to\tmesmo\tque\tplt.imshow\n",
      "cmap=matplotlib.cm.binary,\t\t\n",
      "#\tuse\ta\tescala\tde\tcores\tpreto\te\tbranco\n",
      "interpolation='none')\t\t\t\t\t\t\t\n",
      "#\tassinala\tblocos\tcomo\tblocos\n",
      "def\tpatch(x,\ty,\thatch,\tcolor):\n",
      "\"\"\"retorna\tum\tobjeto\tmatplotlib\t'patch'\tcom\ta\tlocalização\n",
      "especificada,\tpadrão\tde\thachuras\te\tcor\"\"\"\n",
      "return\tmatplotlib.patches.rectangle((x\t-\t0.5,\ty\t-\t0.5),\t1,\t1,\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thatch=hatch,\tfill=false,\tcolor=color)\n",
      "#\thachuras\tpesos\tnegativos\n",
      "for\ti\tin\trange(5):\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tlinha\n",
      "for\tj\tin\trange(5):\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcoluna\n",
      "if\tweights[5*i\t+\tj]\t<\t0:\t\t\t\t\t\t\t\n",
      "#\tlinha\ti,\tcoluna\tj\t=\tpesos[5*i\t+\tj]\n",
      "#\tadiciona\thachuras\tpreto\te\tbrancas,\tvisíveis\tsejam\tclaras\tou\tescuras\n",
      "ax.add_patch(patch(j,\ti,\t'/',\t\"white\"))\n",
      "ax.add_patch(patch(j,\ti,\t'\\\\',\t\"black\"))\n",
      "plt.show()\n",
      "figura\t18-4.\tpesos\tpara\ta\tcamada\toculta\n",
      "na\t\n",
      "figura\t18-4\n",
      ",\tpodemos\tver\tque\to\tprimeiro\tneurônio\toculto\tpossui\tgrandes\n",
      "pesos\tpositivos\tna\tcoluna\tda\tesquerda\te\tno\tcentro\tda\tfileira\tno\tmeio,\tenquanto\n",
      "possui\tgrandes\tpesos\tnegativos\tna\tcoluna\tda\tdireita.\t(e\tvocê\tpode\tver\tque\tpossui\n",
      "grandes\tbias\tnegativos,\to\tque\tsignifica\tque\tnão\tdisparará\ta\tnão\tser\tque\tconsiga\n",
      "precisamente\tas\tentradas\tpositivas\tque\testá\t“procurando”.)\n",
      "sem\tdúvidas,\tnessas\tentradas,\tele\tfaz\to\tque\tesperamos:\n",
      "left_column_only\t=\t[1,\t0,\t0,\t0,\t0]\t*\t5\n",
      "print\n",
      "\tfeed_forward(network,\tleft_column_only)[0][0]\t\n",
      "#\t1.0\n",
      "center_middle_row\t=\t[0,\t0,\t0,\t0,\t0]\t*\t2\t+\t[0,\t1,\t1,\t1,\t0]\t+\t[0,\t0,\t0,\t0,\t0]\t*\t2\n",
      "print\n",
      "\tfeed_forward(network,\tcenter_middle_row)[0][0]\t\n",
      "#\t0.95\n",
      "right_column_only\t=\t[0,\t0,\t0,\t0,\t1]\t*\t5\n",
      "print\n",
      "\tfeed_forward(network,\tright_column_only)[0][0]\t\n",
      "#\t0.0\n",
      "similarmente,\to\tneurônio\toculto\tdo\tmeio\tparece\t“gostar”\tde\tlinhas\thorizontais\n",
      "mas\tnão\tde\tlinhas\tdiagonais,\te\to\túltimo\tneurônio\toculto\tparece\t“gostar”\tda\n",
      "fileira\tdo\tcentro\tmas\tnão\tda\tcoluna\tdo\tmeio.\t(é\tdifícil\tde\tinterpretar\tos\toutros\n",
      "dois\tneurônios.)\n",
      "o\tque\tacontece\tquando\texecutamos\tmeu\t3\testilizado\tna\trede?my_three\t=\t[0,1,1,1,0,\t\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "\t\t0,0,0,1,1,\t\t\t\t\n",
      "#\t...@@\n",
      "\t\t0,0,1,1,0,\t\t\t\t\n",
      "#\t..@@\n",
      ".\n",
      "\t\t0,0,0,1,1,\t\t\t\t\n",
      "#\t...@@\n",
      "\t\t0,1,1,1,0]\t\t\t\t\n",
      "#\t.@@@\n",
      ".\n",
      "hidden,\toutput\t=\tfeed_forward(network,\tmy_three)\n",
      "as\tsaídas\t\n",
      "hidden\n",
      "\tsão:\n",
      "0.121080\t\t#\tfrom\tnetwork[0][0],\tprovavelmente\texcedido\tpor\t(1,\t4)\n",
      "0.999979\t\t#\tfrom\tnetwork[0][1],\tgrandes\tcontribuições\tde\t(0,\t2)\te\t(2,2)\n",
      "0.999999\t\t#\tfrom\tnetwork[0][2],\tpositivo\tem\ttodos\tos\tlugares\tmenos\t(3,4)\n",
      "0.999992\t\t#\tfrom\tnetwork[0][3],\tmais\tuma\tvez\tgrandes\tcontribuições\tde\t(0,2)\te\t(2,2)\n",
      "0.000000\t\t#\tfrom\tnetwork[0][4],\tnegativo\tou\tzero\tem\ttodos\tos\tlugares,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmenos\tna\tfileira\tdo\tcentro\n",
      "que\tentra\tno\tneurônio\tde\tsaída\t“three”(três)\tcom\tpesos\t\n",
      "network[-1][3]:\n",
      "-11.61\t#\tpeso\tpara\toculto[0]\n",
      "\t-2.17\t#\tpeso\tpara\toculto[1]\n",
      "\t\t9.31\t#\tpeso\tpara\toculto[2]\n",
      "\t-1.38\t#\tpeso\tpara\toculto[3]\n",
      "-11.47\t#\tpeso\tpara\toculto[4]\n",
      "-\t1.92\t#\tpeso\tda\tentrada\tpolarizada\n",
      "de\tmodo\tque\to\tneurônio\tcompute:\n",
      "sigmoid(.121\t*\t-11.61\t+\t1\t*\t-2.17\t+\t1\t*\t9.31\t-\t1.38\t*\t1\t-\t0\t*\t11.47\t-\t1.92)\n",
      "que\té\t0,92,\tcomo\tvimos.\tna\tessência,\ta\tcamada\toculta\testá\tcomputando\tcinco\n",
      "divisões\tdiferentes\tde\tespaço\tdimensional\t25,\tmapeando\tcada\tentrada\n",
      "dimensional\t25\tpara\tcinco\tnúmeros.\te\tentão\tcada\tneurônio\tde\tsaída\tolha\tapenas\n",
      "para\tos\tresultados\tdaquelas\tcinco\tdivisões.\n",
      "como\tvimos,\t\n",
      "my_three\n",
      "\tcai\tlevemente\tna\tparte\t“inferior”\tda\tpartição\t0\t(isto\té,\n",
      "apenas\tativa\tlevemente\to\tneurônio\toculto\t0),\tlonge\tda\tparte\t“superior”\tdas\n",
      "partições\t1,\t2\te\t3\t(isto\té,\tativa\tfortemente\taqueles\tneurônios\tocultos),\te\tlonge\tda\n",
      "parte\tinferior\tda\tpartição\t4\t(isto\té,\tnão\tativa\tnenhum\tneurônio).\n",
      "e\tcada\tum\tdos\t10\tneurônios\tde\tsaída\tusa\tapenas\taquelas\tcinco\tativações\tpara\n",
      "decidir\tse\t\n",
      "my_\tthree\n",
      "\té\tseu\tdígito\tou\tnão.•\n",
      "•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "a\tcoursera\ttem\tum\tcurso\tgratuito\tsobre\tneural\tnetworks\tfor\tmachine\n",
      "learning\t(\n",
      "https://www.coursera.org/course/neuralnets\n",
      ").\to\túltimo\tcurso\tfoi\n",
      "em\t2012,\tmas\tos\tmateriais\tdo\tcurso\tainda\testão\tdisponíveis.\n",
      "michael\tnielsen\testá\tescrevendo\tum\tlivro\tonline\tgratuito\tsobre\tneural\n",
      "networks\tand\tdeep\tlearning\n",
      "(\n",
      "http://neuralnetworksanddeeplearning.com\n",
      "/\n",
      ").\tquando\tvocê\tler\teste\tlivro,\n",
      "ele\tjá\tdeve\tter\tterminado.\n",
      "pybrain\t(\n",
      "http://pybrain.org\n",
      ")\té\tuma\tbiblioteca\tpython\tsimples\tde\trede\n",
      "neural.\n",
      "pylearn2\t(\n",
      "http://deeplearning.net/software/pylearn2\n",
      "/\n",
      ")\té\tuma\tbiblioteca\tde\n",
      "rede\tneural\tmuito\tmais\tavançada\t(e\tmuito\tmais\tdifícil\tde\tusar).capítulo\t19\n",
      "agrupamento\n",
      "onde\ttínhamos\ttais\tagrupamentos\n",
      "nos\ttornou\tnobremente\tselvagens,\tnão\tinsanos\n",
      "—robert\therrick\n",
      "a\tmaioria\tdos\talgoritmos\tneste\tlivro\tsão\to\tque\té\tconhecido\tpor\taprendizado\n",
      "supervisionado,\tno\tque\tcomeçam\tcom\tum\tconjunto\tde\tdados\t\n",
      "rotulados\n",
      "\te\tos\n",
      "usam\tcomo\tbase\tpara\tfazer\tprevisões\tsobre\tnovos\tdados,\tnão\trotulados.\n",
      "agrupamento,\tentretanto,\té\tum\texemplo\tde\taprendizado\tnão\tsupervisionado,\tem\n",
      "que\tnós\ttrabalhamos\tcom\tdados\tcompletamente\tnão\trotulados\t(ou\tno\tqual\tnosso\n",
      "dado\tpossui\trótulo\tmas\tnós\to\tignoramos).a\tideia\n",
      "quando\tvocê\tolha\tpara\talguma\tfonte\tde\tdados\té\tnormal\tque\tos\tdados,\tde\talguma\n",
      "forma,\tformem\t\n",
      "agrupamentos\n",
      ".\tum\tconjunto\tde\tdados\tque\tmostre\tonde\n",
      "milionários\tmoram\tprovavelmente\tpossui\tagrupamentos\tem\tlugares\tcomo\n",
      "beverly\thills\te\tmanhattan.\tum\tconjunto\tde\tdados\tque\tmostre\tquantas\thoras\tas\n",
      "pessoas\ttrabalham\tsemanalmente\tprovavelmente\tpossui\tum\tagrupamento\tpor\n",
      "volta\tde\t40\t(e\tse\tfor\ttirado\tde\tum\testado\tcom\tleis\texigindo\tbenefícios\tespeciais\n",
      "para\tpessoas\tque\ttrabalham\tpelo\tmenos\t20\thoras\tpor\tsemana,\tprovavelmente\tterá\n",
      "outro\tagrupamento\tpor\tvolta\tde\t19).\tum\tconjunto\tde\tdados\tdemográficos\tde\n",
      "eleitores\tregistrados\tprovavelmente\tforma\tuma\tvariedade\tde\tagrupamentos\t(por\n",
      "exemplo:\t“mães\tde\tpraticantes\tde\tfutebol”,\t“aposentados\tentediados”,\t“jovens\n",
      "desempregados”)\tque\tpesquisadores\tde\topinião\tpública\te\tconsultores\tpolíticos\n",
      "devem\tconsiderar\trelevantes.\n",
      "diferente\tde\talguns\tdos\tproblemas\tque\tvimos,\tgeralmente\tnão\thá\tagrupamento\n",
      "“correto”.\tum\tesquema\tde\tagrupamento\talternativo\tpode\tagrupar\talguns\tdos\n",
      "“jovens\tdesempregados”\tcom\t“estudantes\tde\tpós-graduação”,\toutros\tcom\n",
      "“moradores\tdo\tporão\tdos\tpais”.\tnenhum\tesquema\té\tnecessariamente\tmais\n",
      "correto\t—\tpelo\tcontrário,\tcada\tum\té\tmelhor\tno\tque\tdiz\trespeito\tà\tsua\tprópria\n",
      "métrica\t“quão\tbons\tsão\tos\tagrupamentos?”\n",
      "além\tdisso,\tos\tagrupamentos\tnão\tse\trotulam\tsozinhos.\tvocê\tterá\tque\tfazer\tisso\n",
      "vendo\tos\tdados\tcontidos\tem\tcada\tum.1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "o\tmodelo\n",
      "para\tnós,\tcada\tentrada\t(\n",
      "input\n",
      ")\tserá\tum\tvetor\tem\tespaço\tdimensional\t\n",
      "d\n",
      "\t(que\n",
      "representaremos\tcomo\tuma\tlista\tde\tnúmeros).\tnosso\tobjetivo\tserá\tidentificar\n",
      "agrupamentos\tde\tentradas\tsimilares\te,às\tvezes,\tencontrar\tum\tvalor\n",
      "representativo\tpara\tcada\tagrupamento.\n",
      "por\texemplo,\tcada\tentrada\tpoderia\tser\t(um\tvetor\tnumérico\tque\tde\talguma\tforma\n",
      "representa)\to\ttítulo\tde\tum\tpost\tde\tum\tblog,\tem\tcujo\tcaso\to\tobjetivo\tpoderia\tser\n",
      "encontrar\tagrupamentos\tde\tposts\tsimilares,\ttalvez\tpara\tentender\tsobre\to\tque\n",
      "nossos\tusuários\testão\tfalando\tno\tblog.\tou\timagine\tque\ttemos\tuma\timagem\n",
      "contendo\tmilhares\tde\tcores\t\n",
      "(red,\tgreen,\tblue)\n",
      "\te\tque\tnós\tprecisamos\ttirar\tuma\tcópia\n",
      "de\tuma\tversão\tde\t10\tcores\tdela.\to\tagrupamento\tnos\tajuda\ta\tescolher\t10\tcores\n",
      "que\tminimizarão\to\t“erro\tde\tcor”\ttotal.\n",
      "um\tdos\tmétodos\tde\tagrupamento\tmais\tsimples\té\ta\t\n",
      "k-means\n",
      ",\tna\tqual\tum\tnúmero\n",
      "de\tagrupamentos\t\n",
      "k\n",
      "é\tescolhido\tantecipadamente,\tdepois\tdo\tque\to\tobjetivo\té\n",
      "particionar\tas\tentradas\tem\tconjuntos\ts\n",
      "1\n",
      ",…,\t\n",
      "s\n",
      "k\n",
      "\tde\tuma\tforma\tque\tminimize\ta\n",
      "soma\ttotal\tdas\tdistâncias\tquadradas\tde\tcada\tponto\tpara\ta\tmédia\tde\tseu\n",
      "agrupamento\tdesignado.\n",
      "há\tmuitas\tformas\tde\tdefinir\tpontos\t\n",
      "n\n",
      "\tpara\tagrupamentos\t\n",
      "k\n",
      ",\to\tque\tsignifica\tque\n",
      "encontrar\to\tmelhor\tagrupamento\té\tum\tproblema\tbem\tdifícil.\tnós\taceitaremos\n",
      "um\talgoritmo\titerativo\tque\tusualmente\tencontra\tum\tbom\tagrupamento:\n",
      "comece\tcom\tum\tconjunto\tde\t\n",
      "k-means\n",
      ",\tque\tsão\tpontos\tem\tespaço\n",
      "dimensional\t\n",
      "d\n",
      ".\n",
      "associe\tcada\tponto\tcom\ta\tmédia\t(k-means)\tmais\tpróxima.\n",
      "se\tnenhuma\tassociação\tde\tponto\tde\tatribuição\tmudou,\tpare\te\tmantenha\tos\n",
      "agrupamentos.\n",
      "se\talguma\tassociação\tmudar,\tcompute\tnovamente\tas\tmédias\te\tvolte\tao\n",
      "passo\t2.\n",
      "usando\ta\tfunção\t\n",
      "vector_mean\n",
      "\tdo\t\n",
      "capítulo\t4\n",
      ",\té\tbem\tfácil\tcriar\tuma\tclasse\tque\tfaça\n",
      "isso:\n",
      "class\tkmeans:\"\"\"executa\tagrupamentos\tk-means\"\"\"\n",
      "def\t__init__(self,\tk):\n",
      "self.k\t=\tk\t\t\t\t\t\t\t\t\t\t\n",
      "#\tnúmero\tde\tagrupamentos\n",
      "self.means\t=\tnone\t\t\t\n",
      "#\tponto\tmédio\tde\tagrupamentos\n",
      "def\tclassify(self,\tinput):\n",
      "\"\"\"retorna\to\tíndice\tdo\tagrupamento\tmais\tpróximo\tda\tentrada\"\"\"\n",
      "return\tmin(range(self.k),\n",
      "\t\t\tkey=lambda\ti:\tsquared_distance(input,\tself.means[i]))\n",
      "def\ttrain(self,\tinputs):\n",
      "#\tescolha\tpontos\tk\taleatórios\tcomo\tmédia\tinicial\n",
      "self.means\t=\trandom.sample(inputs,\tself.k)\n",
      "assignments\t=\tnone\n",
      "while\ttrue:\n",
      "#\tencontre\tnovas\tassociações\n",
      "new_assignments\t=\tmap(self.classify,\tinputs)\n",
      "#\tse\tnenhuma\tassociação\tmudou,\tterminamos\n",
      ".\n",
      "if\tassignments\t==\tnew_assignments:\n",
      "\t\t\t\t\treturn\n",
      "#\tsenão,\tmantenha\tas\tnovas\tassociações\n",
      ",\n",
      "assignments\t=\tnew_assignments\n",
      "#\te\tcompute\tnovas\tmédias,\tbaseado\tnas\tnovas\tassociações\n",
      "for\ti\tin\trange(self.k):\n",
      "#\tencontre\ttodos\tos\tpontos\tassociados\tao\tagrupamento\ti\n",
      "i_points\t=\t[p\tfor\tp,\ta\tin\tzip(inputs,\tassignments)\tif\ta\t==\ti]\n",
      "\t\t\t\t\t\t\n",
      "#\tcertifique-se\tque\ti_points\tnão\testá\tvazio\n",
      ",\n",
      "#\tpara\tnão\tdividir\tpor\t0\n",
      "if\ti_points:\n",
      "\t\t\t\tself.means[i]\t=\tvector_mean(i_points)\n",
      "vamos\tver\tcomo\tisso\tfunciona.exemplo:\tencontros\n",
      "para\tcelebrar\to\tcrescimento\tda\tdatasciencester,\ta\tvice-presidente\tde\n",
      "recompensas\tpara\tusuário\tquer\torganizar\tvários\tencontros\tpresenciais\tpara\tos\n",
      "usuários\tde\tsua\tcidade\tnatal,\tcompletos\tcom\tcerveja,\tpizza\te\tcamisetas\n",
      "datasciencester.\tvocê\tsabe\ta\tlocalização\tde\ttodos\tos\tseus\tusuários\tlocais\t(\n",
      "figura\n",
      "19-1\n",
      "),\te\tela\tgostaria\tque\tvocê\tescolhesse\tlocais\tde\tencontro\tpara\tque\tfique\tmais\n",
      "fácil\tpara\ttodos\tcomparecerem.\n",
      "dependendo\tde\tcomo\tvocê\tenxerga,\tverá\tdois\tou\ttrês\tagrupamentos.\t(é\tfácil\n",
      "fazer\tisso\tvisualmente\tporque\tos\tdados\testão\tapenas\tem\tduas\tdimensões.\tcom\n",
      "mais\tdimensões,\tseria\tmais\tdifícil\tde\tvisualizar.)\n",
      "primeiro\timagine\tque\tela\tpossui\torçamento\to\tsuficiente\tpara\ttrês\tencontros.\n",
      "você\tvai\taté\tseu\tcomputador\te\ttenta\tisso:\n",
      "random.seed(0)\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpara\tque\tvocê\tconsiga\tos\tmesmos\n",
      "clusterer\t=\tkmeans(3)\t\t\t\t\n",
      "#\tresultados\tque\teu\n",
      "clusterer.train(inputs)\n",
      "print\tclusterer.meansfigura\t19-1:\tas\tlocalizações\tdos\tusuários\tde\tsua\tcidade\tnatal\n",
      "você\tencontra\ttrês\tagrupamentos\tcentralizados\tem\t[-45,4],\t[-16,10],\te\t[18,20],\te\n",
      "você\tprocura\tlocais\tde\tencontro\tperto\tdessas\tlocalizações\t(\n",
      "figura\t19-2\n",
      ").\n",
      "você\tmostra\tisso\tà\tvice-presidente,\tque\to\tinforma\tque\tagora\tela\tsó\ttem\n",
      "orçamento\tpara\t\n",
      "dois\n",
      "\tencontros.\n",
      "“sem\tproblemas”,\tvocê\tdiz:\n",
      "random.seed(0)\n",
      "clusterer\t=\tkmeans(2)\n",
      "clusterer.train(inputs)\n",
      "print\n",
      "\tclusterer.meansfigura\t19-2:\tas\tlocalizações\tde\tusuários\tagrupadas\tem\ttrês\tagrupamentos\n",
      "como\texibido\tna\t\n",
      "figura\t19-3\n",
      ",\tum\tencontro\tainda\tdeveria\testar\tperto\t[18,20],\n",
      "mas\tagora\to\toutro\tdeve\testar\tperto\t[-26,-5].figura\t19-3:\tas\tlocalizações\tde\tusuários\tagrupadas\tem\tdois\tagrupamentosescolhendo\tk\n",
      "no\texemplo\tanterior,\ta\tescolha\tde\t\n",
      "k\n",
      "\tfoi\tlevada\tpor\tfatores\tfora\tdo\tnosso\tcontrole.\n",
      "no\tgeral,\tesse\tnão\tseria\to\tcaso.\thá\tuma\tgrande\tvariedade\tde\tcaminhos\tpara\n",
      "escolher\tum\t\n",
      "k\n",
      ".\tuma\tque\té\trazoavelmente\tfácil\tde\tentender\tenvolve\tmarcar\ta\n",
      "soma\tdos\terros\tao\tquadrado\t(entre\tcada\tponto\te\ta\tmédia\tde\tseu\tagrupamento)\n",
      "como\tuma\tfunção\tde\t\n",
      "k\n",
      "\te\tolhar\tpara\tonde\to\tgráfico\t“dobra”:\n",
      "def\tsquared_clustering_errors(inputs,\tk):\n",
      "\"\"\"encontra\to\terro\tao\tquadrado\ttotal\tde\tk-means\tagrupando\tas\tentradas\"\"\"\n",
      "clusterer\t=\tkmeans(k)\n",
      "clusterer.train(inputs)\n",
      "means\t=\tclusterer.means\n",
      "assignments\t=\tmap(clusterer.classify,\tinputs)\n",
      "return\tsum(squared_distance(input,\tmeans[cluster])\n",
      "\t\t\t\tfor\tinput,\tcluster\tin\tzip(inputs,\tassignments))\n",
      "#\tagora\tfaça\to\tgráfico\tde\t1\taté\tlen(inputs)\tagrupamentos\n",
      "ks\t=\trange(1,\tlen(inputs)\t+\t1)\n",
      "errors\t=\t[squared_clustering_errors(inputs,\tk)\t\n",
      "for\n",
      "\tk\t\n",
      "in\n",
      "\tks]\n",
      "plt.plot(ks,\terrors)\n",
      "plt.xticks(ks)\n",
      "plt.xlabel(\"k\")\n",
      "plt.ylabel(\"total\tde\terros\tao\tquadrado\")\n",
      "plt.title(\"erro\ttotal\tvs.\tnúmero\tde\tagrupamentos\")\n",
      "plt.show()figura\t19-4.\tescolhendo\tum\tk\n",
      "olhando\tpara\ta\t\n",
      "figura\t19-4\n",
      ",\tesse\tmétodo\tcoincide\tcom\tsua\tvisão\toriginal\tque\t3\n",
      "é\to\tnúmero\t“certo”\tde\tagrupamentos.1.\n",
      "2.\n",
      "exemplo:\tagrupando\tcores\n",
      "a\tvice-presidente\tda\tswag\tcriou\tadesivos\tatraentes\tdatasciencester\tque\teles\n",
      "gostariam\tque\tvocê\tentregasse\tnos\tencontros.\tinfelizmente,\tsua\timpressora\tde\n",
      "adesivos\tpode\timprimir\tno\tmáximo\tcinco\tcores\tpor\tadesivo.\te\tcomo\ta\tvice-\n",
      "presidente\tde\tarte\testá\tde\tlicença,\ta\tvice-presidente\tda\tswag\tperguntou\tse\thá\n",
      "alguma\tforma\tde\tvocê\tmodificar\to\tdesign\tpara\tque\tcontenha\tcinco\tcores.\n",
      "as\timagens\tde\tcomputador\tpodem\tser\trepresentadas\tcomo\tum\tarray\tde\tpixels\tde\n",
      "duas\tdimensões,\tonde\tcada\tpixel\tpossui\tum\tvetor\tde\ttrês\tdimensões\t\n",
      "(red,\tgreen,\tblue)\n",
      "indicando\tsua\tcor.\n",
      "criar\tuma\tversão\tde\tcinco\tcores\tda\timagem\trequer:\n",
      "escolher\tcinco\tcores\n",
      "designar\tuma\tdestas\tcores\tpara\tcada\tpixel\n",
      "essa\té\tuma\texcelente\ttarefa\tpara\tagrupar\ta\tk-means,\tque\tpode\tparticionar\tos\n",
      "pixels\tem\tcinco\tagrupamentos\tem\tum\tespaço\tvermelho,\tverde\te\tazul.\tse\tentão\n",
      "recolorirmos\tos\tpixels\tem\tcada\tagrupamento\tpara\ta\tcor\tmédia,\tterminamos.\n",
      "para\tcomeçar,\tprecisaremos\tde\tuma\tmaneira\tde\tcarregar\tuma\timagem\tem\n",
      "python.\tpodemos\tfazer\tisso\tcom\t\n",
      "matplotlib:\n",
      "path_to_png_file\t=\tr\"c:\\images\\image.png\"\t\t\t\t\n",
      "#\tonde\tsua\timagem\testá\n",
      "import\tmatplotlib.image\tas\tmpimg\n",
      "img\t=\tmpimg.imread(path_to_png_file)\n",
      "por\ttrás\tdas\tcenas,\t\n",
      "img\n",
      "\té\tum\tarray\tnumpy,\tmas\tpara\tnossos\tobjetivos,\tpodemos\n",
      "tratá-lo\tcomo\tuma\tlista\tde\tlistas\tde\tlistas.\n",
      "img[i][j]\té\to\tpixel\tna\ti-ésima\tlinha\te\tna\tcoluna\tj-ésima,\te\tcada\tpixel\té\tuma\tlista\n",
      "[red,\tgreen,\tblue]\n",
      "\tde\tnúmeros\tentre\t0\te\t1\tindicando\ta\tcor\tpara\taquele\tpixel\n",
      "(\n",
      "http://en.wikipedia.org/wiki/rgb_color_model\n",
      "):\n",
      "top_row\t=\timg[0]\n",
      "top_left_pixel\t=\ttop_row[0]\n",
      "red,\tgreen,\tblue\t=\ttop_left_pixel\n",
      "em\tparticular,\tpodemos\tconseguir\tuma\tlista\testável\tpara\ttodos\tos\tpixels,\tcomo:pixels\t=\t[pixel\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\timg\t\n",
      "for\n",
      "\tpixel\t\n",
      "in\n",
      "\trow]\n",
      "e\tentão\tabastecê-las\tao\tnosso\tagrupamento:\n",
      "clusterer\t=\tkmeans(5)\n",
      "clusterer.train(pixels)\t\t\t\t\n",
      "#\tisso\tpode\tdemorar\tum\tpouco\n",
      "uma\tvez\tterminado,\tapenas\tconstruímos\tuma\timagem\tnova\tcom\to\tmesmo\n",
      "formato:\n",
      "def\trecolor(pixel):\n",
      "cluster\t=\tclusterer.classify(pixel)\t\t\t\t\t\t\t\t\n",
      "#\tíndice\tdo\tagrupamento\tmais\tpróximo\n",
      "return\tclusterer.means[cluster]\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tponto\tmédio\tdo\tagrupamento\tmais\tpróximo\n",
      "new_img\t=\t[[recolor(pixel)\tfor\tpixel\tin\trow]\t\t\t\n",
      "#\trecolore\testa\tlinha\tde\tpixels\n",
      "for\trow\tin\timg]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tpara\tcada\tlinha\tna\timagem\n",
      "e\texibe\tusando\t\n",
      "plt.imshow():\n",
      "plt.imshow(new_img)\n",
      "plt.axis('off')\n",
      "plt.show()\n",
      "é\tdifícil\texibir\tos\tresultados\tde\tcores\tem\tum\tlivro\tpreto\te\tbranco,\tmas\ta\t\n",
      "figura\n",
      "19-5\n",
      "\tmostra\tversões\tem\tescala\tde\tcinza\tde\tuma\timagem\tem\tcores\te\ta\tsaída\tpara\n",
      "usar\tesse\tprocesso\tpara\treduzi-la\tpara\tcinco\tcores:\n",
      "figura\t19-5.\timagem\toriginal\te\tsua\tdescoloração\tde\tmédia\t51.\n",
      "2.\n",
      "agrupamento\thierárquico\tbottom-up\n",
      "uma\tabordagem\talternativa\tpara\tagrupamento\té\t“criar”\tagrupamentos\tbottom-\n",
      "up.\tpodemos\tfazer\tisso\tda\tseguinte\tforma:\n",
      "faça\tde\tcada\tentrada\tseu\tpróprio\tagrupamento\tde\tum.\n",
      "enquanto\thouver\tmúltiplos\tagrupamentos\tsobrando\tencontre\tos\tdois\n",
      "agrupamentos\tmais\tpróximos\te\tos\tjunte.\n",
      "no\tfinal,\tteremos\tum\tagrupamento\tgigante\tcontendo\ttodas\tas\tentradas.\tse\n",
      "quisermos\tacompanhar\ta\tordem\tde\tjunção,\tpodemos\trecriar\tqualquer\tnúmero\tde\n",
      "agrupamentos\tdesfazendo\tjunções.\tpor\texemplo,\tse\tquisermos\ttrês\n",
      "agrupamentos,\tpodemos\tsimplesmente\tdesfazer\tas\tduas\túltimas\tjunções.\n",
      "nós\tusaremos\tuma\trepresentação\tmuito\tsimples\tde\tagrupamento.\tnossos\tvalores\n",
      "estarão\tem\tagrupamentos\t\n",
      "folha\n",
      ",\tque\trepresentaremos\tcomo\ttuplas\tde\t1:\n",
      "leaf1\t=\t([10,\t20],)\t\t\t\n",
      "#\tpara\tfazer\tuma\ttupla\tde\t1\tvocê\tprecisa\tde\tvírgulas\n",
      "leaf2\t=\t([30,\t-15],)\t\t\n",
      "#\tsenão\tpython\tinterpreta\tos\tparênteses\tcomo\tparênteses\n",
      "usaremos\testes\tpara\tcriar\tagrupamentos\t\n",
      "fundidos\n",
      ",\tos\tquais\trepresentaremos\n",
      "como\ttuplas\tde\t2\t(ordem\tde\tjunção,\tfilhos):\n",
      "merged\t=\t(1,\t[leaf1,\tleaf2])\n",
      "falaremos\tda\tordem\tde\tjunção\tdaqui\ta\tpouco,\tmas,\tenquanto\tisso,\tvamos\tcriar\n",
      "algumas\tfunções\tauxiliares:\n",
      "def\n",
      "\tis_leaf(cluster):\n",
      "\"\"\"um\tagrupamento\té\tuma\tfolha\tse\ttiver\ttamanho\t1\"\"\"\n",
      "return\n",
      "\tlen(cluster)\t==\t1\n",
      "def\n",
      "\tget_children(cluster):\n",
      "\"\"\"retorna\tos\tdois\tfilhos\tdesse\tagrupamento\tse\tfor\tum\tagrupamento\tfundido;\n",
      "cria\tuma\texceção\tse\tfor\tum\tagrupamento\tfolha\"\"\"\n",
      "if\n",
      "\tis_leaf(cluster):\n",
      "raise\ttypeerror\n",
      "(\"um\tagrupamento\tfolha\tnão\ttem\tfilhos\")\n",
      "else\n",
      ":\n",
      "return\n",
      "\tcluster[1]\n",
      "def\n",
      "\tget_values(cluster):\n",
      "\"\"\"retorna\to\tvalor\tneste\tagrupamento\t(se\tfor\tum\tagrupamento\tfolha)\n",
      "ou\ttodos\tos\tvalores\tnos\tagrupamentos\tfolha\tabaixo\tdele\t(se\tnão\tfor)\"\"\"\n",
      "if\n",
      "\tis_leaf(cluster):return\n",
      "\tcluster\t\t\t\t\t\t\n",
      "#\tjá\té\tuma\ttupla\tde\t1\tcontendo\tvalor\n",
      "else\n",
      ":\n",
      "return\n",
      "\t[value\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tchild\t\n",
      "in\n",
      "\tget_children(cluster)\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tvalue\t\n",
      "in\n",
      "\tget_values(child)]\n",
      "a\tfim\tde\tfundir\tos\tagrupamentos\tmais\tpróximos,\tprecisamos\tde\talguma\tnoção\n",
      "de\tdistância\tentre\tagrupamentos.\tusaremos\ta\tdistância\t\n",
      "mínima\n",
      "\tentre\telementos\n",
      "de\tdois\tagrupamentos,\tque\tfunde\tos\tdois\tagrupamentos\tmais\tpróximos\t(mas,\tàs\n",
      "vezes,\tproduzirá\tgrandes\tagrupamentos\tem\tcadeia\tque\tnão\tsão\ttão\tpróximos).\tse\n",
      "quiséssemos\tajustar\tdois\tagrupamentos\tesféricos,\tusaríamos\ta\tdistância\t\n",
      "máxima\n",
      ",\n",
      "pois\tela\tfunde\tdois\tagrupamentos\tque\tse\tencaixam\tna\tmenor\tbola.\tambas\n",
      "escolhas\tsão\tcomuns,\tassim\tcomo\té\ta\tdistância\t\n",
      "média:\n",
      "def\n",
      "\tcluster_distance(cluster1,\tcluster2,\tdistance_agg=min):\n",
      "\"\"\"computa\ttodas\tas\tdistâncias\tentre\tcluster1\te\tcluster2\n",
      "e\taplica\t_distance_agg_\tna\tlista\tresultante\"\"\"\n",
      "return\n",
      "\tdistance_agg([distance(input1,\tinput2)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinput1\t\n",
      "in\n",
      "\tget_values(cluster1)\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinput2\t\n",
      "in\n",
      "\tget_values(cluster2)])\n",
      "usaremos\ta\tordem\tde\tjunção\tpara\tacompanhar\ta\tordem\tque\tfizemos\to\n",
      "agrupamento.\tnúmeros\tmenores\trepresentarão\tjunções\t\n",
      "tardias\n",
      ".\tisso\tsignifica\tque\n",
      "quando\tquisermos\tdesfazer\ta\tjunção\tde\tagrupamentos,\to\tfazemos\tda\tmenor\tpara\n",
      "a\tmaior\tjunção.\tcomo\tagrupamentos\tfolha\tnunca\tforam\tfundidos,\tiremos\tatribuir\n",
      "infinito\t(inf)\ta\teles:\n",
      "def\tget_merge_order(cluster):\n",
      "if\tis_leaf(cluster):\n",
      "return\tfloat('inf')\n",
      "else:\n",
      "return\tcluster[0]\t\t\t\n",
      "#\ta\tordem\tde\tjunção\té\to\tprimeiro\telemento\tde\ttupla\tde\t2\n",
      "agora\testamos\tprontos\tpara\tcriar\to\talgoritmo\tde\tagrupamentos:\n",
      "def\tbottom_up_cluster(inputs,\tdistance_agg=min):\n",
      "#\tcomeça\tcom\tcada\tentrada\tcomo\tum\tagrupamento\tfolha\t/\ttupla\tde\t1\n",
      "clusters\t=\t[(input,)\tfor\tinput\tin\tinputs]\n",
      "#\tenquanto\ttivermos\tmais\tde\tum\tagrupamento\tfolha\trestante…\n",
      "while\tlen(clusters)\t>\t1:\n",
      "#\tencontra\tos\tdois\tagrupamentos\tmais\tpróximos\n",
      "c1,\tc2\t=\tmin([(cluster1,\tcluster2)\n",
      "\t\t\t\tfor\ti,\tcluster1\tin\tenumerate(clusters)\n",
      "\t\t\t\tfor\tcluster2\tin\tclusters[:i]],\n",
      "\t\t\t\tkey=lambda\t(x,\ty):\tcluster_distance(x,\ty,\tdistance_agg))•\n",
      "•\n",
      "•\n",
      "•\n",
      "#\tremove-os\tda\tlista\tde\tagrupamentos\n",
      "clusters\t=\t[c\tfor\tc\tin\tclusters\tif\tc\t!=\tc1\tand\tc\t!=\tc2]\n",
      "#\tfaz\ta\tjunção\tdeles,\tusando\ta\tordem\tde\tjunção\t=\tnúmeros\tde\tagrupamentos\trestantes\n",
      "merged_cluster\t=\t(len(clusters),\t[c1,\tc2])\n",
      "#\te\tadiciona\ta\tjunção\tdeles\n",
      "clusters.append(merged_cluster)\n",
      "#\tquando\tsobrar\tapenas\tum\tagrupamento,\tretorne-o\n",
      "return\tclusters[0]\n",
      "seu\tuso\té\tbem\tsimples:\n",
      "base_cluster\t=\tbottom_up_cluster(inputs)\n",
      "isso\tproduz\tum\tagrupamento\tcuja\trepresentação\testranha\té:\n",
      "para\tcada\tagrupamento\tfundido,\teu\talinhei\tseus\tfilhos\tverticalmente.\tse\n",
      "dissermos\t“agrupamento\t0”\tpara\to\tagrupamento\tcom\tordem\tde\tjunção\t0,\tvocê\n",
      "pode\tinterpretar\tcomo:\n",
      "agrupamento\t0\té\ta\tjunção\tdo\tagrupamento\t1\te\tdo\tagrupamento\t2.\n",
      "agrupamento\t1\té\ta\tjunção\tdo\tagrupamento\t3\te\tdo\tagrupamento\t16.\n",
      "agrupamento\t16\té\ta\tjunção\tda\tfolha\n",
      "[11,\t15]\n",
      "\te\tda\tfolha\n",
      "[13,\t13]\n",
      ".\n",
      "e\tassim\tpor\tdiante…\n",
      "como\ttínhamos\t20\tentradas,\tforam\tnecessárias\t19\tjunções\tpara\tconseguir\tesseagrupamento.\ta\tprimeira\tjunção\tcriou\to\tagrupamento\t18\tcombinando\tas\tfolhas\n",
      "[19,\t28]\n",
      "\te\t\n",
      "[21,\t27]\n",
      ".\te\ta\túltima\tjunção\tcriou\to\tagrupamento\t0.\n",
      "no\tentanto,\tgeralmente\tnão\tqueremos\trepresentações\truins\tcomo\tessa.\t(mesmo\n",
      "que\tesse\tpossa\tser\tum\texercício\tinteressante\tpara\tcriar\tvisualizações\tamigáveis\n",
      "ao\tusuário\tde\thierarquia\tde\tagrupamento.)\tem\tvez\tdisso,\tvamos\tescrever\tuma\n",
      "função\tque\tgera\tqualquer\tnúmero\tde\tagrupamentos\tdesfazendo\to\tnúmero\n",
      "apropriado\tde\tjunções:\n",
      "def\tgenerate_clusters(base_cluster,\tnum_clusters):\n",
      "#\tcomece\tcom\tuma\tlista\tapenas\tcom\to\tagrupamento\tbase\n",
      "clusters\t=\t[base_cluster]\n",
      "#\tdesde\tque\tainda\tnão\ttenhamos\tagrupamentos\to\tsuficiente…\n",
      "while\tlen(clusters)\t<\tnum_clusters:\n",
      "#\tescolha\to\tque\tfoi\tfundido\tpor\túltimo\n",
      "next_cluster\t=\tmin(clusters,\tkey=get_merge_order)\n",
      "#\tremova-o\tda\tlista\n",
      "clusters\t=\t[c\tfor\tc\tin\tclusters\tif\tc\t!=\tnext_cluster]\n",
      "#\te\tadicione\tseus\tfilhos\tà\tlista,\tisto\té,\tdesfaça\ta\tfunção\n",
      "clusters.extend(get_children(next_cluster))\n",
      "#\tuma\tvez\tque\ttemos\tagrupamentos\to\tsuficiente…\n",
      "return\tclusters\n",
      "então,\tpor\texemplo,\tse\tqueremos\tgerar\ttrês\tagrupamentos,\tsó\tprecisamos\tfazer:\n",
      "three_clusters\t=\t[get_values(cluster)\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tcluster\t\n",
      "in\n",
      "\tgenerate_clusters(base_cluster,\t3)]\n",
      "que\tpodemos\trepresentar\tfacilmente:\n",
      "for\ti,\tcluster,\tmarker,\tcolor\tin\tzip([1,\t2,\t3],\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tthree_clusters,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t['d','o','*'],\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t['r','g','b']):\n",
      "xs,\tys\t=\tzip(*cluster)\t\n",
      "#\ttruque\tmágico\tde\tdescompactar\n",
      "plt.scatter(xs,\tys,\tcolor=color,\tmarker=marker)\n",
      "#\tcoloca\tum\tnúmero\tno\tponto\tmédio\tdo\tagrupamento\n",
      "x,\ty\t=\tvector_mean(cluster)\n",
      "plt.plot(x,\ty,\tmarker='$'\t+\tstr(i)\t+\t'$',\tcolor='black')\n",
      "plt.title(\"localizações\tde\tusuários\t–\t3\tagrupamentos\tbottom-up,\tmin\")\n",
      "plt.xlabel(\"quadras\tao\tleste\tdo\tcentro\tda\tcidade\")\n",
      "plt.ylabel(\"quadras\tao\tnorte\tdo\tcentro\tda\tcidade\")\n",
      "plt.show()\n",
      "isso\tdá\tresultados\tmuito\tdiferentes\tdos\tque\ta\tk-means,\tcomo\texibido\tna\t\n",
      "figura19-6\n",
      ".\n",
      "figura\t19-6.\ttrês\tagrupamentos\tbottom-up\tusando\tdistância\tmínima\n",
      "como\tmencionamos\tanteriormente,\tisso\tse\tdá\tporque\tusar\t\n",
      "min\n",
      "\tem\t\n",
      "cluster_distance\n",
      "tende\ta\tcriar\tagrupamentos\tem\tcadeia.\tse\tusarmos\t\n",
      "max\n",
      "\tparece\t(nos\tfornece\n",
      "agrupamentos\tpróximos)\tigual\tao\tresultado\tde\tmédia\t3\t(\n",
      "figura\t19-7\n",
      ").\n",
      "a\timplementação\t\n",
      "bottom_up_clustering\n",
      "\tacima\té\trelativamente\tsimples,\tmas\ttambém\n",
      "é\tchocantemente\tineficiente.\tela\tcomputa\ta\tdistância\tentre\tcada\tpar\tde\tentrada\tem\n",
      "cada\tpasso.\tuma\timplementação\tmais\teficiente\tpoderia\tpré-computar\tas\tdistâncias\n",
      "entre\tcada\tpar\tde\tentradas\te\tentão\tdar\tuma\tolhada\tdentro\tde\t\n",
      "cluster_distance\n",
      ".\tuma\n",
      "implementação\t\n",
      "realmente\n",
      "\teficiente\ttambém\tlembraria\tde\t\n",
      "cluster_distances\n",
      "\tdo\tpasso\n",
      "anterior.figura\t19-7.\ttrês\tagrupamentos\tbottom-up\tusando\tdistância\tmáxima•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "scikit-learn\tpossui\tum\tmódulo\tcompleto\t\n",
      "sklearn.cluster\n",
      "\t(\n",
      "http://scikit-\n",
      "learn.org/stable/modules/clustering.html\n",
      ")\tque\tcontém\tvários\talgoritmos\tde\n",
      "agrupamento\tincluindo\t\n",
      "kmeans\n",
      "\te\to\talgoritmo\thierárquico\t\n",
      "ward\n",
      "\tde\n",
      "agrupamento\t(que\tusa\tum\tcritério\tdiferente\tpara\tunir\tos\tagrupamentos\tdo\n",
      "que\tos\tnossos\tmódulos).\n",
      "scipy\t(\n",
      "http://www.scipy.org\n",
      "/\n",
      ")\tpossui\tdois\tmodelos\tde\tagrupamentos\t\n",
      "scipy.\n",
      "cluster.vq\n",
      "\t(que\tfaz\ta\tk-means)\te\t\n",
      "scipy.cluster.hierarchy\n",
      "\t(que\tpossui\tuma\tvariedade\n",
      "de\talgoritmos\tde\tagrupamento\thierárquicos).capítulo\t20\n",
      "processamento\tde\tlinguagem\n",
      "natural\n",
      "eles\tforam\ta\tum\tgrande\tbanquete\tde\tlinguagens\te\troubaram\tas\tsobras\n",
      ".\n",
      "—william\tshakespeare\n",
      "processamento\tde\tlinguagem\tnatural\n",
      "\t(natural\tlanguage\tprocessing\t—\tnlp)\n",
      "refere-se\ta\ttécnicas\tcomputacionais\tenvolvendo\tlinguagem.\té\tum\tcampo\tamplo,\n",
      "mas\tveremos\talgumas\ttécnicas\tsimples\te\toutras\tnão.nuvens\tde\tpalavras\n",
      "no\t\n",
      "capítulo\t1\n",
      ",\tnós\tcomputamos\tcontagem\tde\tpalavras\tde\tinteresse\tde\tusuários.\n",
      "uma\ttécnica\tpara\tvisualizar\te\tcontar\tpalavras\té\tnuvem\tde\tpalavras,\tque\té\n",
      "artisticamente\tdesenhar\tas\tpalavras\tcom\ttamanhos\tproporcionais\tàs\tsuas\n",
      "contagens.\n",
      "no\tgeral,\tos\tcientistas\tde\tdados\tnão\tpenam\tmuito\tem\tnuvens\tde\tpalavras,\tem\n",
      "grande\tparte\tporque\ta\tcolocação\tdas\tpalavras\tnão\tsignifica\tnada\talém\tde\t“este\té\n",
      "um\tespaço\tonde\teu\tconsegui\tencaixar\tuma\tpalavra”.\n",
      "se\tvocê\tfor\tforçado\ta\tcriar\tuma\tnuvem\tde\tpalavras,\tpense\tse\tquer\tfazer\tos\teixos\n",
      "transmitirem\talguma\tcoisa.\tpor\texemplo,\timagine\tque\tpara\tcada\tcoleção\tde\n",
      "dados\tde\tjargões\trelacionados\tà\tciência\tvocê\ttenha\tdois\tnúmeros\tentre\t0\te\t100\n",
      "—\to\tprimeiro\trepresentando\ta\tfrequência\tque\tele\taparece\tem\tpostagens\tde\n",
      "empregos\te\to\tsegundo\ta\tfrequência\tque\taparece\tem\tcurrículos:\n",
      "data\t=\t[\t(\"big\tdata\",\t100,\t15),\t(\"hadoop\",\t95,\t25),\t(\"python\",\t75,\t50),\n",
      "\t\t\t\t\t\t(\"r\",\t50,\t40),\t(\"machine\tlearning\",\t80,\t20),\t(\"statistics\",\t20,\t60),\n",
      "\t\t\t\t\t\t(\"data\tscience\",\t60,\t70),\t(\"analytics\",\t90,\t3),\n",
      "\t\t\t\t\t\t(\"team\tplayer\",\t85,\t85),\t(\"dynamic\",\t2,\t90),\t(\"synergies\",\t70,\t0),\n",
      "\t\t\t\t\t\t(\"actionable\tinsights\",\t40,\t30),\t(\"think\tout\tof\tthe\tbox\",\t45,\t10),\n",
      "\t\t\t\t\t\t(\"self-starter\",\t30,\t50),\t(\"customer\tfocus\",\t65,\t15),\n",
      "\t\t\t\t\t\t(\"thought\tleadership\",\t35,\t35)]\n",
      "a\tabordagem\tnuvem\tde\tpalavras\té\tapenas\tpara\torganizar\tas\tpalavras\tna\tpágina\n",
      "usando\tuma\tfonte\tbonita\t(\n",
      "figura\t20-1\n",
      ").figura\t20-1.\tnuvem\tde\tjargões\n",
      "isso\tparece\tlegal\tmas\tnão\tnos\tdiz\tnada.\tuma\tabordagem\tmais\tinteressante\n",
      "poderia\tser\tdispersá-las\tpara\tque\ta\tposição\thorizontal\tindicasse\tpopularidade\tde\n",
      "postagens\te\ta\tvertical\tpopularidade\tde\tcurrículos,\to\tque\tproduziria\tuma\n",
      "visualização\tque\ttransmitiria\talguns\t\n",
      "insights\n",
      "\t(\n",
      "figura\t20-2\n",
      "):\n",
      "def\n",
      "\ttext_size(total):\n",
      "\"\"\"igual\ta\t8\tse\to\ttotal\tfor\t0,\t28\tse\to\ttotal\tfor\t200\"\"\"\n",
      "return\n",
      "\t8\t+\ttotal\t/\t200\t*\t20\n",
      "for\n",
      "\tword,\tjob_popularity,\tresume_popularity\t\n",
      "in\n",
      "\tdata:\n",
      "plt.text(job_popularity,\tresume_popularity,\tword,\n",
      "\t\tha='center',\tva='center',\n",
      "\t\tsize=text_size(job_popularity\t+\tresume_popularity))\n",
      "plt.xlabel(\"popularidade\tem\tpostagens\tde\tempregos\")\n",
      "plt.ylabel(\"popularidade\tem\tcurrículos\")\n",
      "plt.axis([0,\t100,\t0,\t100])\n",
      "plt.xticks([])\n",
      "plt.yticks([])\n",
      "plt.show()figura\t20-2.\tuma\tnuvem\tde\tpalavras\tmais\tsignificativa\t(se\tmenos\tatrativa)modelos\tn-gramas\n",
      "a\tvice-presidente\tde\tmarketing\tde\tpesquisa\tquer\tque\tvocê\tcrie\tmilhares\tde\n",
      "páginas\tweb\tsobre\tdata\tscience\tpara\tque\tseu\tsite\tseja\tclassificado\tno\ttopo\tdos\n",
      "resultados\tde\tpesquisa\tpara\tos\ttermos\trelacionados.\t(você\ttenta\texplicar\tque\tos\n",
      "algoritmos\tdos\tmecanismos\tde\tpesquisas\tsão\tespertos\to\tbastante\te\tque\tisso\tnão\n",
      "funcionará,\tmas\tela\tse\trecusa\ta\tescutar.)\n",
      "claro,\tela\tnão\tquer\tescrever\tmilhares\tde\tpáginas\tweb,\tnem\tquer\tpagar\tuma\n",
      "horda\tde\t“estrategistas\tde\tconteúdo”\tpara\tfazê-lo.\tem\tvez\tdisso,\tela\tpergunta\tse\n",
      "você\tpode,\tde\talguma\tforma,\tgerar\testas\tpáginas.\tpara\tfazer\tisso,\tprecisaremos\n",
      "de\talguma\tlinguagem\tde\tmodelagem.\n",
      "uma\tabordagem\té\tcomeçar\tcom\tum\tcorpo\tde\tdocumentos\te\taprender\tum\tmodelo\n",
      "estatístico\tde\tlinguagem.\tno\tnosso\tcaso,\tcomeçaremos\tcom\to\tensaio\tde\tmike\n",
      "loukidess\t“what\tis\tdata\tscience?”\t(\n",
      "http://oreil.ly/1cd6ykn\n",
      ")\n",
      "como\tno\t\n",
      "capítulo\t9\n",
      ",\tusaremos\t\n",
      "requests\n",
      "\te\t\n",
      "beautifulsoup\n",
      "\tpara\trecuperar\tos\tdados.\thá\n",
      "alguns\tproblemas\tnos\tquais\tprecisamos\tprestar\tatenção.\n",
      "o\tprimeiro\té\tque\tos\tapóstrofos\tno\ttexto\tsão\tna\tverdade\to\tcaractere\tunicode\n",
      "u”\\u2019”\n",
      ".\tcriaremos\tuma\tfunção\tauxiliar\tpara\tsubstituí-las\tpor\tapóstrofos\n",
      "normais.\n",
      "def\n",
      "\tfix_unicode(text):\n",
      "return\n",
      "\ttext.replace(u\"\n",
      "\\u2019\n",
      "\",\t\"'\")\n",
      "o\tsegundo\tproblema\té\tque\tuma\tvez\tque\tconseguirmos\to\ttexto\tda\tpágina\tda\tweb,\n",
      "vamos\tquerer\tdividi-lo\tem\tuma\tsequência\tde\tpalavras\te\tpontos\t(para\tque\n",
      "possamos\tdizer\tonde\tas\tsentenças\tterminam).\tpodemos\tfazer\tisso\tusando\n",
      "re.findall():\n",
      "from\tbs4\timport\n",
      "\tbeautifulsoup\n",
      "import\trequests\n",
      "url\t=\t\"http://radar.oreilly.com/2010/06/what-is-data-science.html\"\n",
      "html\t=\trequests.get(url).text\tsoup\t=\tbeautiful\n",
      "soup(html,\t'html5lib')\n",
      "content\t=\tsoup.find(\"div\",\t\"entry-content\")\t\t\t\t\n",
      "#\tencontra\tconteúdo\tde\tentrada\tdiv\n",
      "regex\t=\tr\"[\\w']+|[\\.]\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcombina\tuma\tpalavra\tou\tum\tpontodocument\t=\t[]\n",
      "for\n",
      "\tparagraph\t\n",
      "in\n",
      "\tcontent(\"p\"):\n",
      "words\t=\tre.findall(regex,\tfix_unicode(paragraph.text))\n",
      "document.extend(words)\n",
      "nós\tcertamente\tpoderíamos\t(e\tdeveríamos)\tlimpar\tum\tpouco\tmais\tesses\tdados.\n",
      "ainda\thá\tuma\tquantidade\tde\ttexto\textrínseco\tno\tdocumento\t(por\texemplo,\ta\n",
      "primeira\tpalavra\té\t“section”),\tnós\tdividimos\tem\tpontos\tno\tmeio\tda\tsentença\t(por\n",
      "exemplo,\tem\t“web\t2.0)\te\texistem\tlegendas\túteis\te\tlistas\tespalhadas\tpor\ttodo\n",
      "lado.\tdito\tisso,\ttrabalharemos\tcom\to\t\n",
      "document\n",
      "\tcomo\tele\testá.\n",
      "agora\tque\tnós\ttemos\to\ttexto\tcomo\tuma\tsequência\tde\tpalavras,\tnós\tpodemos\n",
      "modelar\tuma\tlinguagem\tda\tseguinte\tforma:\tdada\talguma\tpalavra\tinicial\t(como\n",
      "“book”)\tolhamos\tpara\ttodas\tas\tpalavras\tseguintes\tnos\tdocumentos\tfonte\t(aqui\n",
      "“isn't”,\t“a”,\t“shows”,\t“demonstrates”,\te\t“teaches”).\tnós\tescolhemos\n",
      "aleatoriamente\tumas\tdessas\tpara\tser\ta\tpróxima\tpalavra\te\trepetimos\to\tprocesso\n",
      "até\tchegar\tno\tponto,\tque\tsignifica\to\tfinal\tda\tsentença.\tnós\tchamamos\tisso\tde\n",
      "modelo\tbigrama\n",
      ",\tpor\tser\tdeterminado\tcompletamente\tpor\tsequências\tde\n",
      "bigramas\t(pares\tde\tpalavra)\tnos\tdados\toriginais.\n",
      "mas\te\ta\tpalavra\tinicial?\tnós\tpodemos\tapenas\tescolher\taleatoriamente\tdas\n",
      "palavras\tque\t\n",
      "seguem\n",
      "\to\tponto.\tpara\tcomeçar,\tvamos\tpré-computar\tas\tpossíveis\n",
      "transições\tde\tpalavras.\tlembre-se\tque\t\n",
      "zip\n",
      "\tpara\tquando\tqualquer\tuma\tde\tsuas\n",
      "entradas\ttermina,\tpara\tque\t\n",
      "zip(document,\tdocument[1:])\n",
      "\tnos\tdê\tprecisamente\tos\tpares\n",
      "de\telementos\tconsecutivos\tdo\tdocumento:\n",
      "bigrams\t=\tzip(document,\tdocument[1:])\n",
      "transitions\t=\tdefaultdict(list)\n",
      "for\n",
      "\tprev,\tcurrent\t\n",
      "in\n",
      "\tbigrams:\n",
      "transitions[prev].append(current)\n",
      "agora\testamos\tprontos\tpara\tgerar\tsentenças:\n",
      "def\n",
      "\tgenerate_using_bigrams():\n",
      "current\t=\t\".\"\t\t\t\n",
      "#\tisso\tsignifica\tque\ta\tpróxima\tpalavra\tcomeçará\tuma\tsentença\n",
      "result\t=\t[]\n",
      "while\ttrue:\n",
      "next_word_candidates\t=\ttransitions[current]\t\t\t\t\n",
      "#\tbigramas\t(current,\t_)\n",
      "current\t=\trandom.choice(next_word_candidates)\t\t\n",
      "#\tescolhe\tum\taleatoriamente\n",
      "result.append(current)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tanexa-o\taos\tresultados\n",
      "if\tcurrent\t==\t\".\":\treturn\t\"\t\".join(result)\t\t\t\t\t\n",
      "#\tse\t“.”\tterminamosas\tsentenças\tque\tproduz\tsão\tbesteiras,\tmas\tsão\to\ttipo\tde\tbesteira\tque\tvocê\n",
      "deveria\tcolocar\tno\tseu\tweb\tsite\tse\testá\ttentando\tfazer\tparecer\tcom\tdata\tscience.\n",
      "por\texemplo:\n",
      "você\tdeve\tsaber\tquais\tsão\tvocê\tquer\tdados\tordenar\tdados\tabastecer\tweb\tamigo\talguém\tem\n",
      "tópicos\tde\ttendência\tcomo\tos\tdados\tem\thadoop\té\tdata\tscience\trequer\tum\tlivro\tdemonstrar\tpor\n",
      "que\tvisualizações\tsão\tmas\tnós\tfazemos\tcorrelações\tmassivas\tatravés\tmuitos\tcomerciais\tdisco\n",
      "rígido\tem\tlinguagem\tpython\te\tcria\tforma\tmais\tmanejável\tfazendo\tconexões\tentão\tusa\te\tusa\tisso\n",
      "para\tresolver\tos\tdados.\n",
      "—modelo\tbigrama\n",
      "nós\tpodemos\ttornar\tas\tsentenças\tmenos\tbobas\tolhando\tpara\t\n",
      "trigrams\n",
      ",\ttrios\tde\n",
      "palavras\tconsecutivas.\t(de\tmodo\tmais\tgeral,\tvocê\tpode\tolhar\tpara\t\n",
      "n-grams\n",
      "\tcom\n",
      "n\n",
      "\tpalavras\tconsecutivas,\tmas\ttrês\tserão\to\tbastante\tpara\tnós.)\tagora\tas\ttransições\n",
      "dependerão\tdas\t\n",
      "duas\n",
      "\tpalavras\tanteriores:\n",
      "trigrams\t=\tzip(document,\tdocument[1:],\tdocument[2:])\n",
      "trigram_transitions\t=\tdefaultdict(list)\n",
      "starts\t=\t[]\n",
      "for\tprev,\tcurrent,\tnext\tin\ttrigrams:\n",
      "if\tprev\t==\t\".\":\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tse\ta\t“palavra”\tanterior\tera\tum\tponto\n",
      "starts.append(current)\t\t\t\n",
      "#\tentão\testa\té\tuma\tpalavra\tinicial\n",
      "trigram_transitions[(prev,\tcurrent)].append(next)\n",
      "note\tque\tagora\ttemos\tque\tacompanhar\tas\tpalavras\tinicias\tseparadamente.\n",
      "podemos\tgerar\tsentenças\tpraticamente\tda\tmesma\tforma:\n",
      "def\n",
      "\tgenerate_using_trigrams():\n",
      "current\t=\trandom.choice(starts)\t\t\t\t\t\n",
      "#\tescolha\tuma\tpalavra\tinicial\taleatória\n",
      "prev\t=\t\".\"\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\te\ta\tpreceda\tcom\tum\t'.'\n",
      "result\t=\t[current]\n",
      "while\n",
      "\ttrue:\n",
      "next_word_candidates\t=\ttrigram_transitions[(prev,\tcurrent)]\n",
      "next_word\t=\trandom.choice(next_word_candidates)\n",
      "prev,\tcurrent\t=\tcurrent,\tnext_word\n",
      "result.append(current)\n",
      "if\n",
      "\tcurrent\t==\t\".\":\n",
      "return\n",
      "\t\"\t\".join(result)\n",
      "isso\tproduz\tsentenças\tmelhores\tcomo:em\tretrospecto\tmapreduce\tparece\tcom\tuma\tepidemia\te\tcaso\tseja\tele\tnos\tdá\tnovos\tinsights\tem\n",
      "como\ta\teconomia\tfunciona\tisso\tnão\té\tuma\tpergunta\tnós\tpoderíamos\taté\tter\tperguntado\ta\talguns\n",
      "anos\thouve\tinstrumentação.\n",
      "—\tmodelo\ttrigrama\n",
      "claro,\telas\tparecem\tmelhor\tporque\tem\tcada\tpasso\to\tprocesso\tde\tgeração\tpossui\n",
      "menos\tescolhas\te\tem\tmuitos\tpassos\tapenas\tuma\tescolha.\tisso\tsignifica\tque\tvocê\n",
      "frequentemente\tgera\tsentenças\t(ao\tmenos\tfrases\tlongas)\tque\tforam\tvistas\n",
      "literalmente\tnos\tdados\toriginais.\tmais\tdados\tajudariam;\taté\tfuncionaria\tmelhor\n",
      "se\tvocê\tcoletasse\t\n",
      "n\n",
      "-grams\tde\tvários\tartigos\tsobre\tdata\tscience.gramáticas\n",
      "uma\tabordagem\tdiferente\tpara\tmodelar\tlinguagem\té\tcom\t\n",
      "gramáticas\n",
      ",\tregras\n",
      "para\tgerar\tsentenças\taceitáveis.\tno\tensino\tfundamental,\tvocê\tprovavelmente\n",
      "aprendeu\tsobre\tpartes\tdo\tdiscurso\te\tcomo\tcombiná-las.\tpor\texemplo,\tse\tvocê\n",
      "tinha\tum\tprofessor\tde\tinglês\tmuito\truim,\tvocê\tpode\tdizer\tque\tuma\tsentença\n",
      "necessariamente\tconsiste\tde\tum\t\n",
      "substantivo\n",
      "\tseguido\tde\tum\t\n",
      "verbo\n",
      ".\tse,\tentão,\n",
      "você\ttem\tuma\tlista\tde\tsubstantivos\te\tverbos,\tvocê\tpode\tgerar\tsentenças\tde\n",
      "acordo\tcom\ta\tregra.\n",
      "definiremos\tuma\tgramática\tum\tpouco\tmais\tcomplicada:\n",
      "grammar\t=\t{\n",
      "\"_s\"\t:\t[\"_np\t_vp\"],\n",
      "\"_np\"\t:\t[\"_n\",\n",
      "\"_a\t_np\t_p\t_a\t_n\"],\n",
      "\"_vp\"\t:\t[\"_v\",\n",
      "\"_v\t_np\"],\n",
      "\"_n\"\t:\t[\"data\tscience\",\t\"python\",\t\"regression\"],\n",
      "\"_a\"\t:\t[\"big\",\t\"linear\",\t\"logistic\"],\n",
      "\"_p\"\t:\t[\"about\",\t\"near\"],\n",
      "\"_v\"\t:\t[\"learns\",\t\"trains\",\t\"tests\",\t\"is\"]\n",
      "}\n",
      "eu\tinventei\ta\tconvenção\tde\tque\tnomes\tque\tcomecem\tcom\tsublinhados\treferem-\n",
      "se\ta\t\n",
      "regras\n",
      "\tque\tprecisam\tde\tmaior\texplicação,\te\tque\toutros\tnomes\tsão\t\n",
      "terminais\n",
      "que\tnão\tprecisam\tde\tmais\tprocessamento.\n",
      "então,\tpor\texemplo,\t“_s”\té\ta\tregra\tde\t“sentença”,\tque\tproduz\tuma\tregra\t“_np”\n",
      "(“frase\tnominal”)\tseguida\tde\tuma\tregra\t“_vp”\t(“frase\tverbal”).\n",
      "a\tregra\tda\tfrase\tverbal\tpode\tproduzir\ta\tregra\t“_v”\t(“verbo”)\tou\ta\tregra\tverbo\n",
      "seguida\tda\tregra\tfrase\tnominal.\n",
      "note\tque\ta\tregra\t“_np”\tcontém\tela\tmesma\tem\tuma\tde\tsuas\tproduções.\tas\n",
      "gramáticas\tpodem\tser\trecursivas,\to\tque\tpermite\tque\taté\tgramáticas\tinfinitas\n",
      "como\testa\tgerem\tsentenças\tinfinitamente\tdiferentes.\n",
      "como\tgeramos\tsentenças\ta\tpartir\tdesta\tgramática?\tcomeçaremos\tcom\tuma\tlista\n",
      "contendo\ta\tregra\tsentença\t\n",
      "[“_s”]\n",
      ".\te\tentão\texpandiremos\trepetidamente\tcada\tregrasubstituindo-a\tpor\tuma\tescolha\taleatória\tde\tsuas\tproduções.\tnós\tpararemos\n",
      "quando\ttivermos\tuma\tlista\tcontendo\tapenas\tterminais.\n",
      "por\texemplo,\tuma\ttal\tprogressão\tpode\tparecer\tcom:\n",
      "['_s']\n",
      "['_np','_vp']\n",
      "['_n','_vp']\n",
      "['python','_vp']\n",
      "['python','_v','_np']\n",
      "['python','trains','_np']\n",
      "['python','trains','_a','_np','_p','_a','_n']\n",
      "['python','trains','logistic','_np','_p','_a','_n']\n",
      "['python','trains','logistic','_n','_p','_a','_n']\n",
      "['python','trains','logistic','data\tscience','_p','_a','_n']\n",
      "['python','trains','logistic','data\tscience','about','_a',\t'_n']\n",
      "['python','trains','logistic','data\tscience','about','logistic','_n']\n",
      "['python','trains','logistic','data\tscience','about','logistic','python']\n",
      "como\timplementamos\tisso?\tbom,\tpara\tcomeçar,\tcriaremos\tuma\tsimples\tfunção\n",
      "auxiliar\tpara\tidentificar\tterminais:\n",
      "def\n",
      "\tis_terminal(token):\n",
      "return\n",
      "\ttoken[0]\t!=\t\"_\"\n",
      "em\tseguida,\tprecisamos\tescrever\tuma\tfunção\tpara\ttransformar\tuma\tlista\tde\n",
      "símbolos\tem\tuma\tsentença.\tprocuraremos\tpelo\tprimeiro\tsímbolo\tnão\tterminal.\n",
      "se\tnão\tconseguimos\tencontrar\tum,\tsignifica\tque\tcompletamos\ta\tsentença\te\n",
      "terminamos.\n",
      "se\tencontrarmos\tum\tnão\tterminal,\tescolhemos\taleatoriamente\tuma\tde\tsuas\n",
      "produções.\tse\tessa\tprodução\té\tum\tterminal\t(por\texemplo:\tuma\tpalavra),\tnós\n",
      "simplesmente\tsubstituímos\to\tsímbolo\tpor\tela.\tcaso\tcontrário,\tserá\tuma\n",
      "sequência\tde\tsímbolos\tnão\tterminais\tseparados\tpor\tespaço\tque\tprecisamos\n",
      "separar\t(\n",
      "split\n",
      ").\te\tentão\tencaixar\tem\tsímbolos\tatuais.\tde\tqualquer\tforma,\trepetimos\n",
      "o\tprocesso\tno\tnovo\tconjunto\tde\tsímbolos.\n",
      "colocando\ttudo\tjunto\tconseguimos:\n",
      "def\n",
      "\texpand(grammar,\ttokens):\n",
      "for\n",
      "\ti,\ttoken\t\n",
      "in\n",
      "\tenumerate(tokens):\n",
      "#\tpula\tos\tterminais\n",
      "if\n",
      "\tis_terminal(token):\t\n",
      "continue#\tse\tchegamos\taqui,\tencontramos\tum\tsímbolo\tnão\tterminal\n",
      "#\tentão\tprecisamos\tescolher\tum\tsubstituto\taleatório\n",
      "replacement\t=\trandom.choice(grammar[token])\n",
      "if\n",
      "\tis_terminal(replacement):\n",
      "tokens[i]\t=\treplacement\n",
      "else\n",
      ":\n",
      "tokens\t=\ttokens[:i]\t+\treplacement.split()\t+\ttokens[(i+1):]\n",
      "#\tagora\tchama\texpand\tda\tnova\tlista\tde\tsímbolos\n",
      "return\texpand(grammar,\ttokens)\n",
      "#\tse\tchegamos\taqui,\ttemos\ttodos\tos\tterminais\te\tacabamos\n",
      "return\ttokens\n",
      "agora\tpodemos\tcomeçar\ta\tgerar\tsentenças:\n",
      "def\n",
      "\tgenerate_sentence(grammar):\n",
      "return\n",
      "\texpand(grammar,\t[\"_s\"])\n",
      "tente\tmudar\ta\tgramática\t—\tacrescente\tmais\tpalavras,\tmais\tregras\te\tsuas\n",
      "próprias\tpartes\tdo\tdiscurso—\taté\tque\tvocê\testeja\tpronto\tpara\tgerar\ttantas\n",
      "páginas\tweb\tquanto\tsua\tempresa\tprecisa.\n",
      "as\tgramáticas\tsão\tmais\tinteressantes\tquando\tusadas\tem\toutra\tdireção.\tdada\tuma\n",
      "sentença\tpodemos\tusar\tuma\tgramática\tpara\t\n",
      "analisar\n",
      "\ta\tsentença.\tisso\tpermite\tque\n",
      "identifiquemos\tsujeitos\te\tverbos\te\tnos\tajuda\ta\tentender\ta\tsentença.\n",
      "usar\tdata\tscience\tpara\tgerar\ttexto\té\tum\ttruque\tesperto;\tusá-la\tpara\t\n",
      "entender\n",
      "\to\n",
      "texto\té\tmais\tmágico.\t(veja\t“para\tmais\tesclarecimentos”\tna\tpágina\t200\tas\n",
      "bibliotecas\tque\tvocê\tpoderia\tusar.)um\tadendo:\tamostragem\tde\tgibbs\n",
      "gerar\tamostras\tde\talgumas\tdistribuições\té\tfácil.\tnós\tpodemos\tconseguir\n",
      "variáveis\taleatórias\tuniformes\tcom:\n",
      "random.random()\n",
      "e\tvariáveis\taleatórias\tnormais\tcom:\n",
      "inverse_normal_cdf(random.random())\n",
      "mas\talgumas\tdistribuições\tsão\tmais\tdifíceis\tde\tcriar\tamostras.\ta\t\n",
      "amostragem\tde\n",
      "gibbs\n",
      "\té\tuma\ttécnica\tpara\tgerar\tamostras\tde\tdistribuições\tmultidimensionais\n",
      "quando\tapenas\tconhecemos\talgumas\tdas\tdistribuições\tcondicionais.\n",
      "por\texemplo,\timagine\tque\testá\tjogando\tdois\tdados.\tdeixe\t\n",
      "x\n",
      "\tser\to\tvalor\tdo\n",
      "primeiro\tdado\te\t\n",
      "y\n",
      "\ta\tsoma\tdos\tdados,\te\timagine\tque\tvocê\tqueria\tgerar\tmuitos\n",
      "pares\t(x,\ty).\tneste\tcaso\té\tfácil\tgerar\tamostras\tdiretamente:\n",
      "def\n",
      "\troll_a_die():\n",
      "return\n",
      "\trandom.choice([1,2,3,4,5,6])\n",
      "def\n",
      "\tdirect_sample():\n",
      "d1\t=\troll_a_die()\n",
      "d2\t=\troll_a_die()\n",
      "return\n",
      "\td1,\td1\t+\td2\n",
      "mas\timagine\tque\tvocê\tsó\tconhecia\tas\tdistribuições\tcondicionais.\ta\tdistribuição\n",
      "de\t\n",
      "y\n",
      "\tcondicionado\ta\t\n",
      "x\n",
      "\té\tfácil\t—\tse\tvocê\tsabe\to\tvalor\tde\t\n",
      "x\n",
      ",\t\n",
      "y\n",
      "\té\tigualmente\n",
      "possível\tde\tser\t\n",
      "x\n",
      "+\t1,\t\n",
      "x\n",
      "+\t2,\t\n",
      "x\n",
      "+\t3,\t\n",
      "x\n",
      "+\t4,\t\n",
      "x\n",
      "+\t5\tou\t\n",
      "x\n",
      "+\t6:\n",
      "def\n",
      "\trandom_y_given_x(x):\n",
      "\"\"\"igualmente\tpossível\tde\tser\tx\t+\t1,\tx\t+\t2,\t…,\tx\t+\t6\"\"\"\n",
      "return\n",
      "\tx\t+\troll_a_die()\n",
      "a\toutra\tdireção\té\tmais\tcomplicada.\tpor\texemplo,\tse\tvocê\tsabe\tque\t\n",
      "y\n",
      "\té\t2,\tentão\n",
      "necessariamente\t\n",
      "x\n",
      "\té\t1\t(pois\ta\túnica\tforma\tde\tdois\tdados\tsomarem\t2\té\tse\tambos\n",
      "forem\t1).\tse\tvocê\tsabe\tque\t\n",
      "y\n",
      "\té\t3,\tentão\t\n",
      "x\n",
      "\té\tigualmente\tpossível\tde\tser\t1\tou\t2.\n",
      "similarmente,\tse\t\n",
      "y\n",
      "\té\t11,\tentão\t\n",
      "x\n",
      "\ttem\tque\tser\t5\tou\t6:\n",
      "def\n",
      "\trandom_x_given_y(y):\n",
      "if\n",
      "\ty\t<=\t7:\n",
      "#\tse\to\ttotal\té\t7\tou\tmenos,\to\tprimeiro\tdado\té\tigualmente\n",
      "#\tpossível\tde\tser\t1,\t2,\t...,\t(total\t–\t1)return\n",
      "\trandom.randrange(1,\ty)\n",
      "else\n",
      ":\n",
      "#\tse\to\ttotal\té\t7\tou\tmais,\to\tprimeiro\tdado\té\tigualmente\n",
      "#\tpossível\tde\tser\t(total\t–\t6),\t(total\t–\t5),\t…,\t6\n",
      "return\n",
      "\trandom.randrange(y\t-\t6,\t7)\n",
      "a\tforma\tcomo\ta\tamostragem\tde\tgibbs\tfunciona\té\tque\tse\tcomeçamos\tcom\n",
      "qualquer\tvalor\t(válido)\tpara\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "\te\tentão\trepetida\te\talternadamente\tsubstituímos\n",
      "x\n",
      "\tpor\tum\tvalor\taleatório\tescolhido\tcondicionado\ta\t\n",
      "y\n",
      "\te\tsubstituímos\t\n",
      "y\n",
      "\tpor\tum\n",
      "valor\taleatório\tescolhido\tcondicionado\ta\t\n",
      "x\n",
      ".\tapós\tum\tnúmero\tde\titerações,\tos\n",
      "valores\tde\t\n",
      "x\n",
      "\te\t\n",
      "y\n",
      "\trepresentarão\tuma\tamostra\tde\tuma\tdistribuição\tconjunta\n",
      "incondicional:\n",
      "def\n",
      "\tgibbs_sample(num_iters=100):\n",
      "x,\ty\t=\t1,\t2\t\n",
      "#\tnão\timporta\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(num_iters):\n",
      "x\t=\trandom_x_given_y(y)\n",
      "y\t=\trandom_y_given_x(x)\n",
      "return\n",
      "\tx,\ty\n",
      "você\tpode\tverificar\tque\tisso\tfornece\tresultados\tparecidos\taos\tda\tamostra\tdireta:\n",
      "def\n",
      "\tcompare_distributions(num_samples=1000):\n",
      "counts\t=\tdefaultdict(\n",
      "lambda\n",
      ":\t[0,\t0])\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(num_samples):\n",
      "counts[gibbs_sample()][0]\t+=\t1\n",
      "counts[direct_sample()][1]\t+=\t1\n",
      "return\n",
      "\tcounts\n",
      "usaremos\tessa\ttécnica\tna\tpróxima\tseção.•\n",
      "•\n",
      "•\n",
      "•\n",
      "modelagem\tde\ttópicos\n",
      "quando\tconstruímos\tnossa\trecomendação\tcientistas\tde\tdados\tque\tvocê\tdeveria\n",
      "conhecer\tno\t\n",
      "capítulo\t1\n",
      ",\tnós\tsimplesmente\tprocuramos\tcombinações\texatas\tdos\n",
      "interesses\tdeclarados\tdas\tpessoas.\n",
      "uma\tabordagem\tmais\tsofisticada\tpara\tentender\tcomo\tos\tinteresses\tdos\tnossos\n",
      "usuários\tpode\tser\ttentar\tidentificar\tos\t\n",
      "tópicos\n",
      "\tque\tsustentam\tesses\ttópicos.\tuma\n",
      "técnica\tchamada\t\n",
      "análise\tlatente\tde\tdirichlet\n",
      "\t(latent\tdirichlet's\tanalysis\t–\n",
      "lda)\té\tcomumente\tusada\tpara\tidentificar\ttópicos\tcomuns\tem\tuma\tcoleção\tde\n",
      "documentos.\taplicaremos\tisso\ta\tdocumentos\tque\tconsistem\tem\tinteresses\tde\n",
      "cada\tusuário.\n",
      "a\tlda\tpossui\talgumas\tsemelhanças\tcom\to\tclassificador\tnaive\tbayes\tque\n",
      "construímos\tno\t\n",
      "capítulo\t13\n",
      ",\tno\tque\tassume\tum\tmodelo\tprobabilístico\tpara\n",
      "documentos.\tnós\tmaquiaremos\tos\tdetalhes\tmatemáticos\tpesados,\tmas\tpara\n",
      "nossos\tobjetivos\to\tmodelo\tpresume\tque:\n",
      "há\tum\tnúmero\tfixo\t\n",
      "k\n",
      "\tde\ttópicos.\n",
      "existe\tuma\tvariável\taleatória\tque\tatribui\ta\tcada\ttópico\tuma\tprobabilidade\n",
      "de\tdistribuição\tassociada\tàs\tpalavras.\tvocê\tdeveria\tpensar\tnessa\n",
      "distribuição\tcomo\ta\tprobabilidade\tde\tver\ta\tpalavra\t\n",
      "w\n",
      "\tdado\to\ttópico\t\n",
      "k\n",
      ".\n",
      "ainda\thá\toutra\tvariável\taleatória\tque\tatribui\ta\tcada\tdocumento\ta\n",
      "probabilidade\tde\tdistribuição\tde\ttópicos.\tvocê\tdeveria\tpensar\tnessa\n",
      "distribuição\tcomo\tuma\tmistura\tde\ttópicos\tno\tdocumento\t\n",
      "d\n",
      ".\n",
      "cada\tpalavra\tem\tum\tdocumento\tfoi\tgerada\tprimeiro\tpela\tescolha\taleatória\n",
      "de\tum\ttópico\t(da\tdistribuição\tde\ttópicos\tdo\tdocumento)\te\tentão\tuma\n",
      "palavra\t(da\tdistribuição\tde\tpalavras\tdos\ttópicos).\n",
      "nós\ttemos\tuma\tcoleção\tde\t\n",
      "documents\n",
      "\tem\tque\tcada\tuma\té\tuma\t\n",
      "list\n",
      "\tde\tpalavras.\te\n",
      "temos\tuma\tcoleção\tcorrespondente\tde\t\n",
      "document_topics\n",
      "\tque\tatribui\tum\ttópico\t(um\n",
      "número\tentre\t0\te\t\n",
      "k\n",
      "\t–\t1)\ta\tcada\tpalavra\tem\tcada\tdocumento.\n",
      "para\tque\ta\tquinta\tpalavra\tno\tquarto\tdocumento\tseja:\n",
      "documents[3][4]e\to\ttópico\tde\tonde\taquela\tpalavra\tfoi\tescolhida:\n",
      "document_topics[3][4]\n",
      "isso\texplicitamente\tdefine\ta\tdistribuição\tde\ttópicos\tde\tcada\tdocumento\te\n",
      "implicitamente\tdefine\ta\tdistribuição\tde\tpalavras\tde\tcada\ttópico.\n",
      "nós\tpodemos\testimar\ta\tprobabilidade\tde\to\ttópico\t1\tproduzir\tuma\tcerta\tpalavra\n",
      "comparando\tquantas\tvezes\to\ttópico\t1\tproduz\t\n",
      "qualquer\n",
      "\tpalavra.\tda\tmesma\n",
      "forma,\tquando\tconstruímos\tum\tfiltro\tpara\tspam\tno\t\n",
      "capítulo\t13\n",
      ",\tcomparamos\n",
      "quantas\tvezes\tuma\tpalavra\taparecia\tem\tspams\tcom\to\tnúmero\ttotal\tde\tpalavras\n",
      "que\taparecem\tem\tspams.\n",
      "apesar\tde\tesses\ttópicos\tserem\tapenas\tnúmeros,\tpodemos\tdar\ta\teles\tnomes\n",
      "descritivos\tolhando\tpara\tas\tpalavras\tnas\tquais\teles\tcolocam\tmais\tpeso.\tnós\tsó\n",
      "precisamos\tgerar\tde\talguma\tforma\to\t\n",
      "document_topics\n",
      ".\té\taqui\tque\ta\tamostragem\tde\n",
      "gibbs\tentra\tem\tação.\n",
      "nós\tcomeçamos\tatribuindo\ta\tcada\tpalavra\tem\tcada\tdocumento\tum\ttópico\n",
      "completamente\taleatório.\tentão\tpassamos\tpor\tcada\tdocumento,\tuma\tpalavra\tpor\n",
      "vez.\tpara\taquela\tpalavra\te\tdocumento,\tnós\tconstruímos\tpesos\tpara\tcada\ttópico\n",
      "que\tdependem\tda\tdistribuição\t(atual)\tde\ttópicos\tnaquele\tdocumento\te\tda\n",
      "distribuição\t(atual)\tde\tpalavras\tpara\taquele\ttópico.\tentão,\tusamos\ttais\tpesos\tpara\n",
      "amostrar\tum\tnovo\ttópico\tpara\taquela\tpalavra.\tse\titerarmos\tesse\tprocesso\tmuitas\n",
      "vezes,\tacabaremos\tcom\tuma\tamostra\tconjunta\tda\tdistribuição\ttópico-palavra\te\n",
      "da\tdistribuição\tdocumento-tópico.\n",
      "para\tcomeçar,\tprecisaremos\tde\tuma\tfunção\tpara\tescolher\taleatoriamente\tum\n",
      "índice\tbaseado\tno\tconjunto\tarbitrário\tde\tpesos:\n",
      "def\n",
      "\tsample_from(weights):\n",
      "\"\"\"retorna\ti\tcom\tprobabilidade\tde\tweights[i]\t/\tsum(weights)\"\"\"\n",
      "total\t=\tsum(weights)\n",
      "rnd\t=\ttotal\t*\trandom.random()\t\t\t\t\t\t\n",
      "#\tuniforme\tentre\t0\te\ttotal\n",
      "for\n",
      "\ti,\tw\t\n",
      "in\n",
      "\tenumerate(weights):\n",
      "rnd\t-=\tw\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tretorna\to\tmenor\ti\ttal\tque\n",
      "if\n",
      "\trnd\t<=\t0:\t\n",
      "return\n",
      "\ti\t\t\t\t\t\t\t\t\t\t\n",
      "#\tweights\t[0]\t+\t…\t+\tweights[i]\t>=\trnd\n",
      "por\texemplo,\tse\tvocê\tdá\tpesos\t\n",
      "[1,\t1,\t3]\n",
      "\tentão\tum\tquinto\tdo\ttempo\tele\tretornará\t0,\n",
      "um\tquinto\tdo\ttempo\tele\tretornará\t1\te\ttrês\tquintos\tdo\ttempo\tretornará\t2.nossos\tdocumentos\tsão\tos\tinteresses\tde\tnossos\tusuários,\tque\tparecem\tcom:\n",
      "documents\t=\t[\n",
      "[\"hadoop\",\t\"big\tdata\",\t\"hbase\",\t\"java\",\t\"spark\",\t\"storm\",\t\"cassandra\"],\n",
      "[\"nosql\",\t\"mongodb\",\t\"cassandra\",\t\"hbase\",\t\"postgres\"],\n",
      "[\"python\",\t\"scikit-learn\",\t\"scipy\",\t\"numpy\",\t\"statsmodels\",\t\"pandas\"],\n",
      "[\"r\",\t\"python\",\t\"statistics\",\t\"regression\",\t\"probability\"],\n",
      "[\"machine\tlearning\",\t\"regression\",\t\"decision\ttrees\",\t\"libsvm\"],\n",
      "[\"python\",\t\"r\",\t\"java\",\t\"c++\",\t\"haskell\",\t\"programming\tlanguages\"],\n",
      "[\"statistics\",\t\"probability\",\t\"mathematics\",\t\"theory\"],\n",
      "[\"machine\tlearning\",\t\"scikit-learn\",\t\"mahout\",\t\"neural\tnetworks\"],\n",
      "[\"neural\tnetworks\",\t\"deep\tlearning\",\t\"big\tdata\",\t\"artificial\tintelligence\"],\n",
      "[\"hadoop\",\t\"java\",\t\"mapreduce\",\t\"big\tdata\"],\n",
      "[\"statistics\",\t\"r\",\t\"statsmodels\"],\n",
      "[\"c++\",\t\"deep\tlearning\",\t\"artificial\tintelligence\",\t\"probability\"],\n",
      "[\"pandas\",\t\"r\",\t\"python\"],\n",
      "[\"databases\",\t\"hbase\",\t\"postgres\",\t\"mysql\",\t\"mongodb\"],\n",
      "[\"libsvm\",\t\"regression\",\t\"support\tvector\tmachines\"]\n",
      "]\n",
      "e\ttentaremos\tencontrar\t\n",
      "k\t=\t4\ttópicos\n",
      ".\n",
      "para\tcalcular\tos\tpesos\tda\tamostragem,\tprecisaremos\tacompanhar\tvárias\n",
      "contagens.\tprimeiro\tvamos\tcriar\tas\testruturas\tde\tdados\tpara\telas.\n",
      "quantas\tvezes\tcada\ttópico\té\tatribuído\ta\tcada\tdocumento:\n",
      "#\tuma\tlista\tde\tcontadores,\tuma\tpara\tcada\tdocumento\n",
      "document_topic_counts\t=\t[counter()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\tdocuments]\n",
      "quantas\tvezes\tcada\tpalavra\té\tatribuída\tpara\tcada\ttópico:\n",
      "#\tuma\tlista\tde\tcontadores,\tuma\tpara\tcada\ttópico\n",
      "topic_word_counts\t=\t[counter()\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(k)]\n",
      "o\tnúmero\ttotal\tde\tpalavras\tatribuídas\ta\tcada\ttópico:\n",
      "#\tuma\tlista\tde\tnúmeros,\tuma\tpara\tcada\ttópico\n",
      "topic_counts\t=\t[0\t\n",
      "for\n",
      "\t_\t\n",
      "in\n",
      "\trange(k)]\n",
      "o\tnúmero\ttotal\tde\tpalavras\tcontidas\tem\tcada\tdocumento:\n",
      "#\tuma\tlista\tde\tnúmeros,\tuma\tpara\tcada\tdocumento\n",
      "document_lengths\t=\tmap(len,\tdocuments)\n",
      "o\tnúmero\tde\tpalavras\tdistintas:\n",
      "distinct_words\t=\tset(word\t\n",
      "for\n",
      "\tdocument\t\n",
      "in\n",
      "\tdocuments\t\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument)w\t=\tlen(distinct_words)\n",
      "e\to\tnúmero\tde\tdocumentos:\n",
      "d\t=\tlen(documents)\n",
      "por\texemplo,\tuma\tvez\tque\tpopulamos\testes,\tpodemos\tencontrar\to\tnúmero\tde\n",
      "palavras\tem\t\n",
      "documents[3]\n",
      "\tassociado\tcom\to\ttópico\t1\tcomo:\n",
      "document_topic_counts[3][1]\n",
      "e\tpodemos\tencontrar\to\tnúmero\tde\tvezes\tque\t\n",
      "nlp\n",
      "\té\tassociado\tcom\to\ttópico\t2\n",
      "como:\n",
      "topic_word_counts[2][\"nlp\"]\n",
      "agora\testamos\tprontos\tpara\tdefinir\tnossas\tfunções\tde\tprobabilidade\tcondicional.\n",
      "como\tno\t\n",
      "capítulo\t13\n",
      ",\tcada\tuma\tpossui\tum\ttermo\tsuavizador\tque\tgarante\tque\n",
      "todo\ttópico\tpossua\tuma\tchance\tdiferente\tde\tzero\tde\tser\tescolhido\tem\tqualquer\n",
      "documento\te\tque\tcada\tpalavra\tpossua\tuma\tchance\tdiferente\tde\tzero\tde\tser\n",
      "escolhida\tem\tqualquer\ttópico:\n",
      "def\tp_topic_given_document(topic,\td,\talpha=0.1):\n",
      "\"\"\"a\tfração\tde\tpalavras\tno\tdocumento\t_d_\n",
      "que\tsão\tatribuídas\ta\t_topic_\t(mais\talguma\tcoisa)\"\"\"\n",
      "return\t((document_topic_counts[d][topic]\t+\talpha)\t/\n",
      "\t\t\t\t(document_lengths[d]\t+\tk\t*\talpha))\n",
      "def\tp_word_given_topic(word,\ttopic,\tbeta=0.1):\n",
      "\"\"\"a\tfração\tde\tpalavras\tatribuídas\ta\t_topic_\n",
      "que\té\tigual\ta\t_\tword\t_\t(mais\talguma\tcoisa)\"\"\"\n",
      "return\t((topic_word_counts[topic][word]\t+\tbeta)\t/\n",
      "\t\t\t\t(topic_counts[topic]\t+\tw\t*\tbeta))\n",
      "usaremos\testes\tpara\tcriar\tpesos\tpara\tatualizar\tos\ttópicos:\n",
      "def\ttopic_weight(d,\tword,\tk):\n",
      "\"\"\"dado\tum\tdocumento\te\tuma\tpalavra\tnaquele\tdocumento\n",
      ",\n",
      "retorne\to\tpeso\tpara\to\tk-ésimo\ttópico\"\"\"\n",
      "return\n",
      "\tp_word_given_topic(word,\tk)\t\t\t*\tp_topic_given_document(k,\td)\n",
      "def\n",
      "\tchoose_new_topic(d,\tword):\n",
      "return\n",
      "\tsample_from([topic_weight(d,\tword,\tk)\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tk\t\n",
      "in\n",
      "\trange(k)])existem\tsólidos\tmotivos\tmatemáticos\tpara\to\tporquê\tde\t\n",
      "topic_weight\n",
      "\tter\tsido\n",
      "definido\tde\ttal\tforma,\tmas\tseus\tdetalhes\tnos\tlevariam\tmuito\tfora\tdo\tescopo.\n",
      "felizmente,\tfaz\tsentido\tque\t—\tdada\tuma\tpalavra\te\tseu\tdocumento\t—\ta\n",
      "probabilidade\tde\tescolha\tde\tqualquer\ttópico\tdependa\tde\tquão\tprovável\taquele\n",
      "tópico\té\tpara\to\tdocumento\te\tquão\tprovável\taquela\tpalavra\té\tpara\to\ttópico.\n",
      "isso\té\ttodo\to\tmaquinário\tdo\tqual\tprecisamos.\tcomeçamos\tatribuindo\tcada\n",
      "palavra\ta\tum\ttópico\taleatório\te\tpopulando\tnossos\tcontadores\tapropriadamente:\n",
      "random.seed(0)\n",
      "document_topics\t=\t[[random.randrange(k)\t\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\tdocument]\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tdocument\t\n",
      "in\n",
      "\tdocuments]\n",
      "for\n",
      "\td\t\n",
      "in\n",
      "\trange(d):\n",
      "for\n",
      "\tword,\ttopic\t\n",
      "in\n",
      "\tzip(documents[d],\tdocument_topics[d]):\n",
      "document_topic_counts[d][topic]\t+=\t1\n",
      "topic_word_counts[topic][word]\t+=\t1\n",
      "topic_counts[topic]\t+=\t1\n",
      "nosso\tobjetivo\té\tconseguir\tuma\tamostra\tauxiliar\tda\tdistribuição\ttópicos-\n",
      "palavras\te\tda\tdistribuição\tdocumentos-tópicos.\tnós\tfazemos\tisso\tusando\tuma\n",
      "forma\tde\tamostragem\tde\tgibbs\tque\tusa\tprobabilidades\tcondicionais\tdefinidas\n",
      "previamente:\n",
      "for\titer\tin\trange(1000):\n",
      "for\td\tin\trange(d):\n",
      "for\ti,\t(word,\ttopic)\tin\tenumerate(zip(documents[d],\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdocument_topics[d])):\n",
      "#\tremova\testa\tpalavra\t/\ttópico\tda\tcontagem\n",
      "#\tpara\tque\tnão\tinfluencie\tnos\tpesos\n",
      "document_topic_counts[d][topic]\t-=\t1\n",
      "topic_word_counts[topic][word]\t-=\t1\n",
      "topic_counts[topic]\t-=\t1\n",
      "document_lengths[d]\t-=\t1\n",
      "#\tescolha\tum\tnovo\ttópico\tbaseado\tnos\tpesos\n",
      "new_topic\t=\tchoose_new_topic(d,\tword)\n",
      "document_topics[d][i]\t=\tnew_topic\n",
      "#\ta\tagora\tcoloque-o\tde\tvolta\tnas\tcontas\n",
      "document_topic_counts[d][new_topic]\t+=\t1\n",
      "topic_word_counts[new_topic][word]\t+=\t1\n",
      "topic_counts[new_topic]\t+=\t1\n",
      "document_lengths[d]\t+=\t1\n",
      "o\tque\tsão\tos\ttópicos?\teles\tsão\tapenas\tnúmeros\t0,\t1,\t2,\te\t3.\tse\tquisermos\tnomespara\teles\ttemos\tque\tfazer\tisso\tnós\tmesmos.\tvamos\tver\tas\tpalavras\tcom\tmaiores\n",
      "pesos\tpara\tcada\ttópico\t(\n",
      "tabela\t20-1\n",
      "):\n",
      "for\n",
      "\tk,\tword_counts\t\n",
      "in\n",
      "\tenumerate(topic_word_counts):\n",
      "for\n",
      "\tword,\tcount\t\n",
      "in\n",
      "\tword_counts.most_common():\n",
      "if\n",
      "\tcount\t>\t0:\t\n",
      "print\n",
      "\tk,\tword,\tcount\n",
      "tabela\t20-1.\tpalavras\tmais\tcomuns\tpor\ttópico\n",
      "baseado\tnisso\teu\tprovavelmente\tatribuiria\tnomes\tde\ttópicos:\n",
      "topic_names\t=\t[\"big\tdata\te\tlinguagens\tde\tprogramação\",\n",
      "\t\t\t\t\t\t\"python\te\testatística\",\n",
      "\t\t\t\t\t\t\"bases\tde\tdados\",\n",
      "\t\t\t\t\t\t\"aprendizado\tde\tmáquina\"]\n",
      "agora\tpodemos\tver\tcomo\to\tmodelo\tatribui\ttópicos\taos\tinteresses\tde\tcada\n",
      "usuário:\n",
      "for\n",
      "\tdocument,\ttopic_counts\t\n",
      "in\n",
      "\tzip(documents,\tdocument_topic_counts):\n",
      "print\n",
      "\tdocument\n",
      "for\n",
      "\ttopic,\tcount\t\n",
      "in\n",
      "\ttopic_counts.most_common():\n",
      "if\n",
      "\tcount\t>\t0:\n",
      "print\n",
      "\ttopic_names[topic],\tcount,\n",
      "print\n",
      "que\tnos\tdá:\n",
      "['hadoop',\t'big\tdata',\t'hbase',\t'java',\t'spark',\t'storm',\t'cassandra']\n",
      "big\tdata\te\tlinguagem\tde\tprogramação\t4\tbases\tde\tdados\t3\n",
      "['nosql',\t'mongodb',\t'cassandra',\t'hbase',\t'postgres']\n",
      "bases\tde\tdados\t5\n",
      "['python',\t'scikit-learn',\t'scipy',\t'numpy',\t'statsmodels',\t'pandas']\n",
      "python\te\testatística\t5\taprendizado\tde\tmáquina\t1\n",
      "e\tassim\tpor\tdiante.\tdados\tos\t“e”\tque\tprecisamos\tem\talguns\tde\tnossos\tnomes\tde\n",
      "tópicos,\té\tpossível\tque\tusemos\tmais\ttópicos,\tembora\tseja\tprovável\tque\tnãotenhamos\tdados\to\tsuficiente\tpara\taprendê-los\tcom\tsucesso.•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "natural\tlanguage\ttoolkit\t(\n",
      "http://www.nltk.org\n",
      "/\n",
      ")\té\tuma\tbiblioteca\tpopular\n",
      "de\tferramentas\tnlp\tpara\tpython.\tela\tpossui\tseu\tpróprio\tlivro\tcompleto\n",
      "(\n",
      "http://www.nltk.org/book\n",
      "/\n",
      "),\tque\testá\tdisponível\tpara\tleitura\tonline.\n",
      "gensim\t(\n",
      "http://radimrehurek.com/gensim\n",
      "/\n",
      ")\té\tuma\tbiblioteca\tpython\tpara\n",
      "modelagem\tde\ttópicos,\tque\té\tuma\taposta\tmelhor\tdo\tque\tnosso\tmodelo\ta\n",
      "partir\tdo\tzero.capítulo\t21\n",
      "análise\tde\trede\n",
      "suas\tconexões\ta\ttodas\tas\tcoisas\tao\tseu\tredor,\tliteralmente,\tdefinem\tquem\tvocê\té\n",
      ".\n",
      "—\n",
      "aaron\to'connell\n",
      "muitos\tproblemas\tde\tdados\tinteressantes\tpodem\tser\tlucrativos\tpensando\tem\n",
      "termos\tde\t\n",
      "redes\n",
      ",\tconsistentes\tde\t\n",
      "nós\n",
      "\tde\talgum\ttipo\te\t\n",
      "vínculos\n",
      "\tque\tas\tjuntam.\n",
      "por\texemplos,\tseus\tamigos\tdo\tfacebook\tformam\tos\tnós\tde\tuma\trede\tcujos\n",
      "vínculos\tsão\trelações\tde\tamizade.\tum\texemplo\tmenos\tóbvio\té\ta\tprópria\tworld\n",
      "wide\tweb,\tcom\tcada\tpágina\tsendo\tum\tnó\te\tcada\thiperlink\tde\tuma\tpágina\tpara\n",
      "outra\tum\tvínculo.\n",
      "amizade\tde\tfacebook\té\tmútua\t—\tse\teu\tsou\tseu\tamigo\tno\tfacebook,\tvocê\n",
      "necessariamente\té\tmeu\tamigo.\tnesse\tcaso,\tdizemos\tque\tos\tvínculos\tsão\t\n",
      "não\n",
      "direcionados\n",
      ".\thiperlinks\tnão\tsão\t—\tmeu\twebsite\tpossui\tlinks\tpara\n",
      "whitehouse.gov,\tmas\t(por\trazões\tinexplicáveis)\twhitehouse.gov\tse\trecusa\ta\tter\n",
      "link\tpara\to\tmeu\twebsite.\tnós\tchamamos\tesses\ttipos\tde\tvínculos\tde\t\n",
      "direcionados\n",
      ".\n",
      "veremos\tos\tdois\ttipos\tde\tredes.centralidade\tde\tintermediação\n",
      "no\t\n",
      "capítulo\t1\n",
      ",\tnós\tcomputamos\tos\tconectores\tchave\tna\trede\tdatasciencester\n",
      "contando\to\tnúmero\tde\tamigos\tque\tcada\tusuário\ttinha.\tagora\tnós\ttemos\n",
      "maquinário\to\tsuficiente\tpara\tver\toutras\tabordagens.\tlembre-se\tde\tque\ta\trede\n",
      "(\n",
      "figura\t21-1\n",
      ")\tenglobava\tusuários:\n",
      "users\t=\t[\n",
      "{\t\"id\":\t0,\t\"name\":\t\"hero\"\t},\n",
      "{\t\"id\":\t1,\t\"name\":\t\"dunn\"\t},\n",
      "{\t\"id\":\t2,\t\"name\":\t\"sue\"\t},\n",
      "{\t\"id\":\t3,\t\"name\":\t\"chi\"\t},\n",
      "{\t\"id\":\t4,\t\"name\":\t\"thor\"\t},\n",
      "{\t\"id\":\t5,\t\"name\":\t\"clive\"\t},\n",
      "{\t\"id\":\t6,\t\"name\":\t\"hicks\"\t},\n",
      "{\t\"id\":\t7,\t\"name\":\t\"devin\"\t},\n",
      "{\t\"id\":\t8,\t\"name\":\t\"kate\"\t},\n",
      "{\t\"id\":\t9,\t\"name\":\t\"klein\"\t}\n",
      "]\n",
      "e\tamizades:\n",
      "friendships\t=\t[(0,\t1),\t(0,\t2),\t(1,\t2),\t(1,\t3),\t(2,\t3),\t(3,\t4),\n",
      "\t\t\t\t\t(4,\t5),\t(5,\t6),\t(5,\t7),\t(6,\t8),\t(7,\t8),\t(8,\t9)]\n",
      "figura\t21-1.\ta\trede\tdatasciencester\n",
      "nós\ttambém\tadicionamos\tlistas\tde\tamigos\tpara\tcada\tdict\tde\tusuário:\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "user[\"friends\"]\t=\t[]\n",
      "for\n",
      "\ti,\tj\t\n",
      "in\n",
      "\tfriendships:1.\n",
      "2.\n",
      "3.\n",
      "#\tisso\tfunciona\tporque\tusers[i]\té\to\tusuário\tcuja\tid\té\ti\n",
      "users[i][\"friends\"].append(users[j])\t\n",
      "#\tadiciona\ti\tcomo\tamigo\tde\tj\n",
      "users[j][\"friends\"].append(users[i])\t\n",
      "#\tadiciona\tj\tcomo\tamigo\tde\ti\n",
      "quando\tcomeçamos,\testávamos\tinsatisfeitos\tcom\tnossa\tnoção\tde\t\n",
      "grau\tde\n",
      "centralidade\n",
      ",\tque\tnão\tconcordava\tcom\tnossa\tintuição\tsobre\tquem\teram\tos\n",
      "conectores-chave\tda\trede.\n",
      "uma\talternativa\tmétrica\té\t\n",
      "centralidade\tde\tintermediação\n",
      ",\tque\tidentifica\tpessoas\n",
      "que\tfrequentemente\testão\tno\tmenor\tcaminho\tentre\tpares\tde\toutras\tpessoas.\ta\n",
      "centralidade\tde\tintermediação\tde\tnó\t\n",
      "i\n",
      "\té\tcomputada\tadicionando\tpara\tcada\toutro\n",
      "par\tde\tnós\tj\te\tk,\ta\tproporção\tdos\tcaminhos\tmais\tcurtos\tentre\to\tnó\tj\te\to\tnó\tk\tque\n",
      "passa\tpor\ti.\n",
      "isto\té,\tpara\tentender\ta\tcentralidade\tde\tintermediação\tde\tthor,\tprecisamos\n",
      "computar\ttodos\tos\tcaminhos\tmais\tcurtos\tentre\ttodos\tos\tpares\tde\tpessoas\tque\tnão\n",
      "são\tthor.\te\tentão\tprecisaremos\tcontar\tquantos\tdesses\tcaminhos\tmais\tcurtos\n",
      "passam\tpor\tthor.\tpor\texemplo,\to\túnico\tcaminho\tmais\tcurto\tentre\tchi\t(\n",
      "id\t3\n",
      ")\te\n",
      "clive\t(\n",
      "id\t5\n",
      ")\tpassa\tpor\tthor,\tenquanto\tnenhum\tdos\tdois\tcaminhos\tmais\tcurtos\n",
      "entre\thero\t(\n",
      "id\t0\n",
      ")\te\tchi\t(\n",
      "id\t3\n",
      ")\tpassa.\n",
      "portanto,\tcomo\tprimeiro\tpasso,\tprecisaremos\tdescobrir\tos\tcaminhos\tmais\tcurtos\n",
      "entre\ttodos\tos\tpares\tde\tpessoas.\texistem\talguns\talgoritmos\tbem\tsofisticados\tpara\n",
      "fazer\tisso\teficientemente,\tmas\t(como\tquase\tsempre\tacontece)\tusaremos\tum\n",
      "menos\teficiente\te\tmais\tfácil\tde\tentender.\n",
      "este\talgoritmo\t(uma\timplementação\tde\tbusca\tem\tlargura)\té\tum\tdos\tmais\n",
      "complicados\tneste\tlivro,\tentão\tfalaremos\tcuidadosamente\tsobre\tele:\n",
      "nosso\tobjetivo\té\tuma\tfunção\tque\tpega\t\n",
      "from_user\n",
      "\te\tencontra\t\n",
      "todos\n",
      "\tos\n",
      "caminhos\tmais\tcurtos\tpara\ttodos\tos\toutros\tusuários.\n",
      "representaremos\tum\tcaminho\tcomo\tuma\t\n",
      "list\n",
      "\tde\tids\tde\tusuários.\tcomo\n",
      "todo\tcaminho\tcomeça\tem\t\n",
      "from_user\n",
      ",\tnão\tincluiremos\tseu\tid\tna\tlista.\tisso\n",
      "significa\tque\to\ttamanho\tda\tlista\trepresentando\to\tcaminho\tserá\to\tpróprio\n",
      "tamanho\tdo\tcaminho.\n",
      "manteremos\tum\tdicionário\t\n",
      "shortest_paths_to\n",
      "\tonde\tas\tchaves\tsão\tids\tde\n",
      "usuários\te\tos\tvalores\tsão\tlistas\tde\tcaminhos\tque\tterminam\tno\tusuário\tcom\n",
      "o\tid\tespecificado.\tse\texiste\tum\túnico\tmenor\tcaminho,\ta\tlista\tconterá4.\n",
      "5.\n",
      "6.\n",
      "7.\n",
      "8.\n",
      "apenas\taquele\tcaminho.\tse\texistem\tmúltiplos\tcaminhos\tmenores,\ta\tlista\n",
      "conterá\ttodos\teles.\n",
      "também\tmanteremos\tuma\tfila\t\n",
      "frontier\n",
      "\tque\tcontém\tusuários\tque\tqueremos\n",
      "explorar\tna\tordem\tem\tque\tqueremos\texplorá-los.\tos\tarmazenaremos\tem\n",
      "pares\t\n",
      "(prev_user,\tuser)\n",
      "\tpara\tque\tsaibamos\tcomo\tchegamos\ta\tcada\tum\tdeles.\n",
      "inicializaremos\ta\tlista\tcom\ttodos\tos\tvizinhos\tde\t\n",
      "from_user\n",
      ".\t(ainda\tnão\n",
      "falamos\tsobre\tfilas,\tas\tquais\tsão\testruturas\totimizadas\tde\toperações\n",
      "“adicione\tao\tfinal”\te\t“remova\tdo\tcomeço”.\tem\tpython,\telas\tsão\n",
      "implementadas\tcomo\t\n",
      "collections.deque\n",
      "\tque\tna\tverdade\té\tuma\tfila\tduplamente\n",
      "terminada.)\n",
      "à\tmedida\tque\texploramos\to\tgráfico,\tsempre\tque\tencontramos\tnovos\n",
      "vizinhos\tpara\tos\tquais\tainda\tnão\tconhecemos\tos\tcaminhos\tmais\tcurtos,\tnós\n",
      "os\tadicionamos\tao\tfinal\tda\tfila\tpara\texplorarmos\tmais\ttarde,\tcom\to\tusuário\n",
      "atual\t\n",
      "prev_user\n",
      ".\n",
      "quando\ttiramos\tum\tusuário\tda\tfila\tque\tnunca\tencontramos\tantes,\tnós,\tcom\n",
      "certeza,\tencontramos\tum\tou\tmais\tcaminhos\tmais\tcurtos\tpara\tele\t—\tcada\n",
      "menor\tcaminho\tpara\t\n",
      "prev_user\n",
      "\tcom\tum\tpasso\textra.\n",
      "quando\ttiramos\tum\tusuário\tda\tfila\tque\t\n",
      "já\n",
      "\thavíamos\tencontrado\taquele\n",
      "usuário\tantes,\tentão\tou\tencontramos\toutro\tmenor\tcaminho\t(em,\tcujo\tcaso,\n",
      "deveremos\tadicionar\to\tusuário)\tou\tencontramos\tum\tcaminho\tmaior\t(em,\n",
      "cujo\tcaso,\tnão\tdeveríamos\tadicionar\to\tusuário).\n",
      "quando\tnão\thá\tmais\tusuários\tna\tfila,\texploramos\ttodo\to\tgráfico\t(ou,\tao\n",
      "menos,\tas\tpartes\tpossíveis\tde\tserem\tanalisadas\ta\tpartir\tdo\tusuário\tcom\n",
      "quem\tiniciamos)\te\tterminamos.\n",
      "podemos\tcolocar\ttudo\tjunto\tem\tuma\t(grande)\tfunção:\n",
      "from\tcollections\timport\n",
      "\tdeque\n",
      "def\n",
      "\tshortest_paths_from(from_user):\n",
      "#\tum\tdicionário\tpara\t“user_id”\tpara\t*todos*\tos\tcaminhos\n",
      "#\tmais\tcurtos\tpara\taquele\tusuário\n",
      "shortest_paths_to\t=\t{\tfrom_user[\"id\"]\t:\t[[]]\t}\n",
      "#\tuma\tfila\tde\t(previous\tuser,\tnext\tuser)\tque\tprecisamos\tverificar\n",
      ".\n",
      "#\tcomeça\tcom\ttodos\tos\tpares\t(from_user,\tfriend_of_from_user)\n",
      "frontier\t=\tdeque((from_user,\tfriend)\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tfrom_user[\"friends\"])#\tcontinue\taté\tesvaziar\ta\tfila\n",
      "while\n",
      "\tfrontier:\n",
      "prev_user,\tuser\t=\tfrontier.popleft()\t\t\t\n",
      "#\tremova\to\tusuário\tque\té\n",
      "user_id\t=\tuser[\"id\"]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\to\tprimeiro\tna\tfila\n",
      "#\tpela\tmaneira\tcomo\testamos\tadicionando\tna\tfila\n",
      ",\n",
      "#\tnecessariamente\tjá\tconhecemos\talguns\tdos\tcaminhos\tmais\tcurtos\tpara\tprev_user\n",
      "paths_to_prev_user\t=\tshortest_paths_to[prev_user[\"id\"]]\n",
      "new_paths_to_user\t=\t[path\t+\t[user_id]\t\n",
      "for\n",
      "\tpath\t\n",
      "in\n",
      "\tpaths_to_prev_user]\n",
      "#\té\tpossível\tque\tjá\tsaibamos\tum\tmenor\tcaminho\n",
      "old_paths_to_user\t=\tshortest_paths_to.get(user_id,\t[])\n",
      "#\tqual\té\to\tmenor\tcaminho\taté\taqui\tque\tjá\tvimos\taté\tagora?\n",
      "if\n",
      "\told_paths_to_user:\n",
      "min_path_length\t=\tlen(old_paths_to_user[0])\n",
      "else\n",
      ":\n",
      "min_path_length\t=\tfloat('inf')\n",
      "#\tapenas\tmantém\tcaminhos\tque\tnão\tsão\tlongos\tdemais\te\tsão\tnovos\n",
      "new_paths_to_user\t=\t[path\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tpath\t\n",
      "in\n",
      "\tnew_paths_to_user\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "if\n",
      "\tlen(path)\t<=\tmin_path_length\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "and\n",
      "\tpath\t\n",
      "not\tin\n",
      "\told_paths_to_user]\n",
      "shortest_paths_to[user_id]\t=\told_paths_to_user\t+\tnew_paths_to_user\n",
      "#\tadd\tnever-seen\tneighbors\tto\tthe\tfrontier\n",
      "frontier.extend((user,\tfriend)\n",
      "\t\t\t\t\n",
      "for\n",
      "\tfriend\t\n",
      "in\n",
      "\tuser[\"friends\"]\n",
      "\t\t\t\t\n",
      "if\n",
      "\tfriend[\"id\"]\t\n",
      "not\tin\n",
      "\tshortest_paths_to)\n",
      "return\n",
      "\tshortest_paths_to\n",
      "agora\tpodemos\tarmazenar\tesses\t\n",
      "dicts\n",
      "\tcom\tcada\tnó:\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "user[\"shortest_paths\"]\t=\tshortest_paths_from(user)\n",
      "e\tfinalmente\testamos\tprontos\tpara\tcomputar\ta\tcentralidade\tde\tintermediação.\n",
      "para\ttodo\tpar\tde\tnós\t\n",
      "i\n",
      "\te\t\n",
      "j\n",
      ",\tconhecemos\tos\t\n",
      "n\n",
      "\tcaminhos\tmais\tcurtos\tpara\t\n",
      "i\n",
      "\te\t\n",
      "j\n",
      ".\n",
      "então,\tpara\tcada\tum\tdesses\tcaminhos,\tapenas\tadicionamos\t\n",
      "1/n\n",
      "\tà\tcentralidade\tde\n",
      "cada\tnó\tnaquele\tcaminho:\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "user[\"betweenness_centrality\"]\t=\t0.0\n",
      "for\n",
      "\tsource\t\n",
      "in\n",
      "\tusers:\n",
      "source_id\t=\tsource[\"id\"]\n",
      "for\n",
      "\ttarget_id,\tpaths\t\n",
      "in\n",
      "\tsource[\"shortest_paths\"].iteritems():\n",
      "if\n",
      "\tsource_id\t<\ttarget_id:\t\t\t\t\t\t\n",
      "#\tnão\tconta\tduas\tvezes\n",
      "\t\t\t\tnum_paths\t=\tlen(paths)\t\t\t\t\t\n",
      "#\tquantos\tcaminhos\tmais\tcurtos?\t\t\t\tcontrib\t=\t1\t/\tnum_paths\t\t\t\t\n",
      "#\tcontribuição\tpara\tcentralidade\n",
      "\t\t\t\t\n",
      "for\n",
      "\tpath\t\n",
      "in\n",
      "\tpaths:\n",
      "\t\t\t\n",
      "for\n",
      "\tid\t\n",
      "in\n",
      "\tpath:\n",
      "\t\t\t\t\t\t\t\n",
      "if\n",
      "\tid\t\n",
      "not\tin\n",
      "\t[source_id,\ttarget_id]:\n",
      "\t\t\t\t\t\t\t\t\t\t\tusers[id][\"betweenness_centrality\"]\t+=\tcontrib\n",
      "figura\t21-2.\ta\trede\tdatasciencester\tdimensionada\tpor\tcentralidade\tde\n",
      "intermediação\n",
      "como\texibido\tna\t\n",
      "figura\t21-2\n",
      ",\tos\tusuários\t0\te\t9\ttêm\tcentralidade\t0\t(porque\n",
      "nenhum\tdeles\testá\tem\tnenhum\tcaminho\tmenor\tentre\toutros\tusuários),\tmas\t3,\t4\te\n",
      "5\ttêm\taltas\tcentralidades\t(porque\ttodos\tos\ttrês\testão\tem\tmuitos\tcaminhos\n",
      "menores).\n",
      "geralmente,\tos\tnúmeros\tde\tcentralidade\tnão\tsão\tsignificativos.\to\tque\timporta\té\n",
      "como\tos\tnúmeros\tpara\tcada\tnó\tse\tcomparam\tcom\tos\tnúmeros\tdos\toutros\tnós.\n",
      "outra\tmedida\tque\tpodemos\tver\té\t\n",
      "centralidade\tde\tproximidade\n",
      ".\tprimeiro,\tpara\n",
      "cada\tusuário,\tnós\tcomputamos\tsua\t\n",
      "distância\n",
      ",\tque\té\ta\tsoma\tdos\ttamanhos\tde\tseus\n",
      "caminhos\tmais\tcurtos\tpara\tcada\toutro\tusuário.\tcomo\tjá\tcomputamos\tos\n",
      "caminhos\tmais\tcurtos\tentre\tcada\tpar\tde\tnós,\té\tfácil\tcalcular\tseus\ttamanhos.\t(se\n",
      "houver\tmúltiplos\tcaminhos\tcurtos,\ttodos\teles\tpossuem\to\tmesmo\ttamanho,\tlogo\n",
      "podemos\tanalisar\to\tprimeiro.)\n",
      "def\n",
      "\tfarness(user):\n",
      "\"\"\"a\tsoma\tdos\ttamanhos\tdos\tcaminhos\tmais\tcurtos\tpara\tcada\toutro\tusuário\"\"\"\n",
      "return\n",
      "\tsum(len(paths[0])\n",
      "\t\t\t\t\n",
      "for\n",
      "\tpaths\t\n",
      "in\n",
      "\tuser[\"shortest_paths\"].values())após\tisso\ttemos\tpouquíssimo\ttrabalho\tpara\tcomputar\ta\tcentralidade\tde\n",
      "proximidade\t(\n",
      "figura\t21-3\n",
      "):\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "user[\"closeness_centrality\"]\t=\t1\t/\tfarness(user)\n",
      "figura\t21-3.\ta\trede\tdatasciencester\tdimensionada\tpor\tcentralidade\tde\n",
      "proximidade\n",
      "há\tbem\tmenos\tvariação\taqui\t—\tmesmo\tos\tnós\tcentrais\tainda\testão\tbem\tlonge\n",
      "dos\tnós\tnos\tarredores.\n",
      "como\tvimos,\tcomputar\tos\tcaminhos\tmais\tcurtos\tdá\tuma\tcerta\tchateação.\tpor\n",
      "isso,\tcentralidades\tde\tintermediação\te\tde\tproximidade\tnão\tsão\tusadas\tcom\n",
      "frequência\tem\tgrandes\tredes.\ta\tcentralidade\tmenos\tintuitiva\t(mas\tmais\tfácil\tde\n",
      "computar),\t\n",
      "centralidade\tde\tvetor\tpróprio\n",
      "\té\tusada\tcom\tmais\tfrequência.centralidade\tde\tvetor\tpróprio\n",
      "para\tfalar\tsobre\tcentralidade\tde\tvetor\tpróprio,\ttemos\tque\tfalar\tsobre\tvetores\n",
      "próprios,\te\tpara\tfalar\tsobre\tvetores\tpróprios,\ttemos\tque\tfalar\tsobre\tmultiplicação\n",
      "de\tmatrizes.\n",
      "multiplicação\tde\tmatrizes\n",
      "se\t\n",
      "a\n",
      "\té\tuma\tmatriz\t\n",
      "n\n",
      "1\n",
      "\tx\tk\n",
      "1\n",
      "\te\tb\té\tuma\tmatriz\t\n",
      "n\n",
      "2\n",
      "\t×\t\n",
      "k\n",
      "2\n",
      ",\te\tse\t\n",
      "k\n",
      "1\n",
      "\t=\tn\n",
      "2\n",
      "\tentão\to\tproduto\n",
      "ab\n",
      "\tdeles\té\ta\tmatriz\t\n",
      "n\n",
      "1\n",
      "\t×\t\n",
      "k\n",
      "2\n",
      "\tcuja\tentrada\t(i,j)\té:\n",
      "que\té\tapenas\to\tproduto\tdot\tda\ti-ésima\tlinha\tde\t\n",
      "a\n",
      "\tcom\ta\tj-ésima\tcoluna\tde\t\n",
      "b\n",
      "(também\tchamados\tde\tvetores)\n",
      ":\n",
      "def\n",
      "\tmatrix_product_entry(a,\tb,\ti,\tj):\n",
      "return\n",
      "\tdot(get_row(a,\ti),\tget_column(b,\tj))\n",
      "depois\tdo\tquê,\ttemos:\n",
      "def\n",
      "\tmatrix_multiply(a,\tb):\n",
      "n1,\tk1\t=\tshape(a)\n",
      "n2,\tk2\t=\tshape(b)\n",
      "if\n",
      "\tk1\t!=\tn2:\n",
      "\t\t\t\t\n",
      "raise\tarithmeticerror\n",
      "(\"formatos\tincompatíveis!\")\n",
      "return\n",
      "\tmake_matrix(n1,\tk2,\tpartial(matrix_product_entry,\ta,\tb))\n",
      "note\tque,\tse\t\n",
      "a\n",
      "\té\tuma\tmatriz\t\n",
      "n\n",
      "\t×\t\n",
      "k\n",
      "\te\t\n",
      "b\n",
      "\té\tuma\tmatriz\t\n",
      "k\n",
      "\t×\t1,\tentão\t\n",
      "ab\n",
      "\té\tuma\tmatriz\n",
      "n\n",
      "\t×\t1.\tse\ttratamos\tum\tvetor\tcomo\tuma\tmatriz\tde\tuma\tcoluna,\tpodemos\tpensar\n",
      "em\t\n",
      "a\n",
      "\tcomo\tuma\tfunção\tque\tmapeia\tvetores\tdimensionais\t\n",
      "k\n",
      "\tpara\tvetores\n",
      "dimensionais\t\n",
      "n\n",
      ",\tem\tque\ta\tfunção\té\tapenas\ta\tmultiplicação\tda\tmatriz.\n",
      "anteriormente,\trepresentamos\tvetores\tapenas\tcomo\tlistas,\tmas\tnão\tsão\ta\tmesma\n",
      "coisa:\n",
      "v\t=\t[1,\t2,\t3]\n",
      "v_as_matrix\t=\t[[1],\n",
      "\t\t\t\t\t[2],\n",
      "\t\t\t\t\t[3]]\n",
      "então\tprecisaremos\tde\talgumas\tfunções\tauxiliares\tpara\tconverter\tde\tum\tladopara\to\toutro\tas\tduas\trepresentações:\n",
      "def\n",
      "\tvector_as_matrix(v):\n",
      "\"\"\"retorna\to\tvetor\tv\t(representado\tcomo\tuma\tlista)\tcomo\tuma\tmatriz\tn\t×\t1\"\"\"\n",
      "return\n",
      "\t[[v_i]\t\n",
      "for\n",
      "\tv_i\t\n",
      "in\n",
      "\tv]\n",
      "def\n",
      "\tvector_from_matrix(v_as_matrix):\n",
      "\"\"\"retorna\ta\tmatriz\tn\tx\t1\tcomo\tuma\tlista\tde\tvalores\"\"\"\n",
      "return\n",
      "\t[row[0]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tv_as_matrix]\n",
      "e\tapós\tpodemos\tdefinir\ta\toperação\tde\tmatriz\tusando\tmatrix_multiply:\n",
      "def\n",
      "\tmatrix_operate(a,\tv):\n",
      "v_as_matrix\t=\tvector_as_matrix(v)\n",
      "product\t=\tmatrix_multiply(a,\tv_as_matrix)\n",
      "return\n",
      "\tvector_from_matrix(product)\n",
      "quando\t\n",
      "a\n",
      "\té\tuma\tmatriz\t\n",
      "quadrada\n",
      ",\testa\toperação\tmapeia\tvetores\tdimensionais\t\n",
      "n\n",
      "para\toutros\tvetores\tdimensionais\t\n",
      "n\n",
      ".\té\tpossível\tque,\tpara\talguma\tmatriz\t\n",
      "a\n",
      "\te\tvetor\n",
      "v\n",
      ",\tquando\t\n",
      "a\n",
      "\topera\tem\t\n",
      "v\n",
      "\tconseguimos\tum\tmúltiplo\tde\t\n",
      "v\n",
      ".\tisso\té,\to\tresultado\té\tum\n",
      "vetor\tque\taponta\tpara\ta\tmesma\tdireção\tque\t\n",
      "v\n",
      ".\tquando\tisso\tacontece\t(e\tquando,\n",
      "além\tdisso,\t\n",
      "v\n",
      "\tnão\té\tum\tvetor\tde\tzeros),\tnós\tchamamos\t\n",
      "v\n",
      "\tde\t\n",
      "vetor\tpróprio\n",
      "(autovetor)\n",
      "\tde\t\n",
      "a\n",
      ".\te\tchamamos\to\tmultiplicador\tde\t\n",
      "valor\tpróprio\t(autovalor)\n",
      ".\n",
      "uma\tpossível\tmaneira\tde\tencontrar\to\tvetor\tpróprio\tde\t\n",
      "a\n",
      "\té\tescolher\tum\tvetor\n",
      "inicial\t\n",
      "v\n",
      ",\taplicar\t\n",
      "matrix_operate\n",
      ",\treescalar\to\tresultado\tpara\tter\tmagnitude\t1\te\trepetir\n",
      "até\to\tprocesso\tconvergir:\n",
      "def\n",
      "\tfind_eigenvector(a,\ttolerance=0.00001):\n",
      "guess\t=\t[random.random()\t\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\ta]\n",
      "while\n",
      "\ttrue:\n",
      "result\t=\tmatrix_operate(a,\tguess)\n",
      "length\t=\tmagnitude(result)\n",
      "next_guess\t=\tscalar_multiply(1/length,\tresult)\n",
      "if\n",
      "\tdistance(guess,\tnext_guess)\t<\ttolerance:\n",
      "return\n",
      "\tnext_guess,\tlength\t\n",
      "#\tvetor\tpróprio,\tvalor\tpróprio\n",
      "guess\t=\tnext_guess\n",
      "por\tconstrução,\to\t\n",
      "guess\n",
      "\tretornado\té\tum\tvetor\ttal\tque,\tquando\tvocê\taplica\n",
      "matrix_operate\n",
      "\ta\tele\te\to\treescala\tpara\tter\ttamanho\t1,\tvocê\trecebe\tde\tvolta\t(um\tvetor\n",
      "muito\tpróximo\ta)\tele\tmesmo.\to\tque\tsignifica\tque\tele\té\tum\tvetor\tpróprio.\n",
      "nem\ttodas\tas\tmatrizes\tde\tnúmeros\treais\tpossuem\tvetores\te\tvalores\tpróprios.\tpor\n",
      "exemplo,\ta\tmatriz:rotate\t=\t[[\t0,\t1],\n",
      "\t\t[-1,\t0]]\n",
      "gira\tvetores\ta\t90\tgraus\tno\tsentido\thorário,\to\tque\tsignifica\tque\to\túnico\tvetor\tque\n",
      "ela\tmapeia\tpara\tum\tmúltiplo\tem\tescala\tde\tsi\tmesmo\té\tum\tvetor\tde\tzeros.\tse\n",
      "você\ttentou\t\n",
      "find_eigenvector(rotate)\n",
      "\tele\tpoderia\trodar\tpara\tsempre.\taté\tmesmo\n",
      "matrizes\tcom\tvetores\tpróprios\tpodem,\tàs\tvezes,\tficar\tpresas\tem\tciclos.\n",
      "considere\ta\tmatriz:\n",
      "flip\t=\t[[0,\t1],\n",
      "\t\t\t\t[1,\t0]]\n",
      "essa\tmatriz\tmapeia\tqualquer\tvetor\t\n",
      "[x,\ty]\n",
      "\tpara\t\n",
      "[y,\tx]\n",
      ".\tisso\tsignifica\tque,\tpor\n",
      "exemplo,\t\n",
      "[1,\t1]\n",
      "\té\tum\tvetor\tpróprio\tcom\tvalor\tpróprio\t1.\tentretanto,\tse\tvocê\n",
      "começa\tcom\tum\tvetor\taleatório\tcom\tcoordenadas\tdeferentes,\t\n",
      "find_eigenvector\n",
      "\tirá\n",
      "repetidamente\ttrocar\tas\tcoordenadas\tpara\tsempre.\tbibliotecas\tque\tnão\tsão\tdo\n",
      "zero\tcomo\tnumpy\tusam\tmétodos\tdiferentes\tque\tfuncionariam\tnesse\tcaso.\n",
      "todavia,\tquando\t\n",
      "find_eigenvector\n",
      "\tretorna\tum\tresultado,\ttal\tresultado\té\tsem\tdúvidas\n",
      "um\tvetor\tpróprio.\n",
      "centralidade\n",
      "como\tisso\tnos\tajuda\ta\tentender\ta\trede\tdatasciencester?\n",
      "para\tcomeçar,\tprecisaremos\trepresentar\tas\tconexões\tem\tnossa\trede\tcomo\n",
      "adjacency_matrix\n",
      ",\tcuja\tentrada\t(i,j)th\tou\té\t1\t(se\tusuários\t\n",
      "i\n",
      "\te\t\n",
      "j\n",
      "\tforem\tamigos)\tou\t0\t(se\n",
      "não\tforem):\n",
      "def\n",
      "\tentry_fn(i,\tj):\n",
      "return\n",
      "\t1\t\n",
      "if\n",
      "\t(i,\tj)\t\n",
      "in\n",
      "\tfriendships\t\n",
      "or\n",
      "\t(j,\ti)\t\n",
      "in\n",
      "\tfriendships\t\n",
      "else\n",
      "\t0\n",
      "n\t=\tlen(users)\n",
      "adjacency_matrix\t=\tmake_matrix(n,\tn,\tentry_fn)\n",
      "a\tcentralidade\tde\tvetor\tpróprio\tpara\tcada\tusuário\té\ta\tentrada\tcorrespondente\n",
      "àquele\tusuário\tno\tvetor\tpróprio\tretornado\tpor\tfind_eigenvector\t(\n",
      "figura\t21-4\n",
      "):\n",
      "por\tmotivos\ttécnicos\tque\testão\talém\tdo\tescopo\tdeste\tlivro,\tqualquer\tmatriz\tadjacente\n",
      "diferente\tde\tzero\tnecessariamente\tpossui\tum\tvetor\tpróprio\tpara\ttodas\taquelas\tcujos\n",
      "valores\tnão\tsão\tnegativos.\te\tfelizmente\tpara\tnós,\tpara\tessa\t\n",
      "adjacency_matrix\n",
      "\tnossa\n",
      "função\t\n",
      "find_eigenvector\n",
      "\to\tencontra.eigenvector_centralities,\t_\t=\tfind_eigenvector(adjacency_matrix)\n",
      "figura\t21-4.\ta\trede\tdatasciencester\tdimensionada\tpor\tcentralidade\tde\tvetor\n",
      "próprio\n",
      "usuários\tcom\talta\tcentralidade\tde\tvetor\tpróprio\tdeveriam\tser\taqueles\tque\ttêm\n",
      "muitas\tconexões\te\tconexões\tcom\tpessoas\tque\ttêm\talta\tcentralidade.\n",
      "aqui\tos\tusuários\t1\te\t2\tsão\tos\tmais\tcentrais,\tpois\tambos\tpossuem\ttrês\tconexões\n",
      "com\tpessoas\tque\tsão\taltamente\tcentrais.\tconforme\tnos\tafastamos\tdeles,\tas\n",
      "centralidades\tdas\tpessoas\tgradualmente\tdiminuem.\n",
      "em\tuma\trede\tpequena\tassim,\ta\tcentralidade\tdo\tvetor\tpróprio\tcomporta-se\tde\n",
      "forma\tinstável.\tse\tvocê\ttentar\tadicionar\tou\tremover\tlinks,\tdescobrirá\tque\n",
      "pequenas\tmodificações\tna\trede\tpodem\tmudar\tdramaticamente\tos\tnúmeros\tde\n",
      "centralidade.\tem\tuma\trede\tmaior\tesse\tnão\tseria\to\tcaso.\n",
      "nós\tainda\tnão\tchegamos\tno\tporquê\tde\tum\tvetor\tpróprio\tpoder\tlevar\ta\tuma\n",
      "noção\trazoável\tde\tcentralidade.\tser\tum\tvetor\tpróprio\tsignifica\tque\tse\tvocê\n",
      "computa:\n",
      "matrix_operate(adjacency_matrix,\teigenvector_centralities)\n",
      "o\tresultado\té\tum\tmúltiplo\tescalar\tde\t\n",
      "eigen_vector_centralities\n",
      ".\n",
      "se\tvocê\tolhar\tcomo\ta\tmultiplicação\tde\tmatriz\tfunciona,\t\n",
      "matrix_operate\n",
      "\tproduz\tum\n",
      "vetor\tcujo\ti-ésimo\telemento\té:\n",
      "dot(get_row(adjacency_matrix,\ti),\teigenvector_centralities)\n",
      "que\té\tprecisamente\ta\tsoma\tdas\tcentralidades\tde\tvetor\tpróprio\tde\toutros\tusuários1.\n",
      "2.\n",
      "conectados\tao\tusuário\t\n",
      "i\n",
      ".\n",
      "em\toutras\tpalavras,\tas\tcentralidades\tde\tvetor\tpróprio\tsão\tnúmeros,\tum\tpor\n",
      "usuário,\ttal\tque\tcada\tvalor\tde\tusuário\té\tum\tmúltiplo\tconstante\tda\tsoma\tdos\n",
      "valores\tde\tseus\tvizinhos.\tneste\tcaso,\tcentralidade\tsignifica\testar\tconectado\ta\n",
      "pessoas\tque\tsão\telas\tmesmas\tcentrais.\tquanto\tmais\tvocê\testiver\tdiretamente\n",
      "conectado\ta\tnós\tcom\tcentralidade,\tmais\tcentral\tvocê\té.\tisso\té\tuma\tdefinição\n",
      "circular—vetores\tpróprios\tsão\tuma\tforma\tde\tsair\tdo\tcírculo.\n",
      "outra\tmaneira\tde\tentender\tisso\té\tpensar\tno\tquê\t\n",
      "find_eigenvector\n",
      "\testá\tfazendo\taqui.\n",
      "ele\tcomeça\tatribuindo\tcada\tnó\ta\tuma\tcentralidade\taleatória.\tentão\trepete\tos\tdois\n",
      "passos\ta\tseguir\taté\to\tprocesso\tconvergir:\n",
      "dá\ta\tcada\tnó\tum\tnovo\tvalor\tde\tcentralidade\tque\té\tigual\ta\tsoma\tdos\tvalores\n",
      "das\tcentralidades\t(antigas)\tde\tseus\tvizinhos.\n",
      "reescala\to\tvetor\tde\tcentralidades\tpara\tter\tmagnitude\t1.\n",
      "embora\ta\tmatemática\tpor\ttrás\tdisso\tpareça\tum\ttanto\topaca\tno\tinício,\to\tcálculo\té\n",
      "relativamente\tdireto\t(diferente\tde\tcentralidade\tpor\tintermediação)\te\té\tmuito\tfácil\n",
      "de\tfazer\tem\tgráficos\tmuito\tgrandes.gráficos\tdirecionados\te\tpagerank\n",
      "datasciencester\tnão\testá\tconseguindo\tdeslanchar,\tentão\ta\tvice-presidente\tde\n",
      "rendimentos\tconsidera\ttrocar\tde\tum\tmodelo\tde\tamizade\tpara\tum\tmodelo\tde\n",
      "aprovação.\tacontece\tque\tninguém\tparticularmente\tse\timporta\tquais\tcientistas\tde\n",
      "dados\tsão\t\n",
      "amigos\n",
      "\tum\tdo\toutro,\tmas\trecrutadores\tse\timportam\tmuito\tcom\tquais\n",
      "cientistas\tde\tdados\tsão\trespeitados\tpor\toutros\tcientistas.\n",
      "nesse\tnovo\tmodelo,\tacompanharemos\tas\taprovações\t\n",
      "(source,\ttarget)\n",
      "\tque\tnão\n",
      "representam\tmais\tum\trelacionamento\trecíproco,\tmas\tsim\tque\t\n",
      "source\n",
      "\taprove\t\n",
      "target\n",
      "como\tum\texcelente\tcientista\tde\tdados\t(\n",
      "figura\t21-5\n",
      ").\tprecisaremos\tconsiderar\n",
      "esta\tassimetria:\n",
      "endorsements\t=\t[(0,\t1),\t(1,\t0),\t(0,\t2),\t(2,\t0),\t(1,\t2),\n",
      "\t\t\t\t\t\t(2,\t1),\t(1,\t3),\t(2,\t3),\t(3,\t4),\t(5,\t4),\n",
      "\t\t\t\t\t\t(5,\t6),\t(7,\t5),\t(6,\t8),\t(8,\t7),\t(8,\t9)]\n",
      "for\tuser\tin\tusers:\n",
      "user[\"endorses\"]\t=\t[]\t\t\t\t\t\t\t\n",
      "#\tadiciona\tuma\tlista\tpara\tacompanhar\taprovações\tdadas\n",
      "user[\"endorsed_by\"]\t=\t[]\t\t\t\t\n",
      "#\tadiciona\toutra\tpara\tcompanhar\taprovações\trecebidas\n",
      "for\tsource_id,\ttarget_id\tin\tendorsements:\n",
      "users[source_id][\"endorses\"].append(users[target_id])\n",
      "users[target_id][\"endorsed_by\"].append(users[source_id])\n",
      "figura\t21-5.\ta\trede\tdatasciencester\tde\taprovações\n",
      "após\to\tque\tpodemos\tfacilmente\tencontrar\tos\tcientistas\tde\tdados\tmais\taprovados\n",
      "(\n",
      "most_\tendorsed\n",
      ")\te\tvender\ttoda\tessa\tinformação\tpara\tos\trecrutadores:\n",
      "endorsements_by_id\t=\t[(user[\"id\"],\tlen(user[\"endorsed_by\"]))\n",
      "\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers]1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "sorted(endorsements_by_id,\n",
      "\t\t\t\tkey=\n",
      "lambda\n",
      "\t(user_id,\tnum_endorsements):\tnum_endorsements,\n",
      "\t\t\t\treverse=true)\n",
      "entretanto,\t“número\tde\taprovações”\té\tuma\tmétrica\tfácil\tde\tmanipular.\ttudo\tque\n",
      "você\tprecisa\tfazer\té\tcriar\tcontas\tfalsas\te\tfazer\tcom\tque\telas\to\taprovem.\tou\n",
      "combinar\tcom\tseus\tamigos\tpara\taprovarem\tuns\taos\toutros\t(o\tque\tparece\tque\tos\n",
      "usuários\t0,\t1\te\t2\tfizeram).\n",
      "uma\tmétrica\tmelhor\tpara\tlevar\tem\tconsideração\té\t\n",
      "quem\n",
      "\taprova\tvocê.\n",
      "aprovações\tde\tpessoas\tcom\tmuitas\taprovações\tdeveriam\tde\talguma\tforma\n",
      "contar\tmais\tdo\tque\taprovações\tde\tpessoas\tcom\tpoucas\taprovações.\tessa\té\ta\n",
      "essência\tdo\talgoritmo\tpagerank,\tusado\tpelo\tgoogle\tpara\tordenar\tweb\tsites\n",
      "baseados\tem\tquais\toutros\tsites\testão\tconectados\ta\teles,\tquais\ta\testes\te\tpor\taí\tvai.\n",
      "(se\tisso\tmais\tou\tmenos\to\tlembra\tda\tideia\tpor\ttrás\tda\tcentralidade\tde\tvetor\n",
      "próprio,\tvocê\testá\tcerto.)\n",
      "uma\tversão\tsimplificada\tse\tparece\tcom\tisto:\n",
      "há\tum\ttotal\tde\t1.0\t(ou\t100%)\tde\tpagerank\tna\trede.\n",
      "inicialmente\teste\tpagerank\té\tigualmente\tdistribuído\tpelos\tnós.\n",
      "a\tcada\tpasso,\tuma\tgrande\tfração\tdo\tpagerank\tdo\tnó\té\tdistribuída\n",
      "igualmente\tentre\tos\tseus\tlinks\tde\tsaída.\n",
      "a\tcada\tpasso,\to\tresto\tde\tpagerank\tdo\tnó\té\tdistribuído\tigualmente\tentre\n",
      "todos\tos\tnós.\n",
      "def\n",
      "\tpage_rank(users,\tdamping\t=\t0.85,\tnum_iters\t=\t100):\n",
      "#\tinicialmente\tdistribui\tpagerank\tigualmente\n",
      "num_users\t=\tlen(users)\n",
      "pr\t=\t{\tuser[\"id\"]\t:\t1\t/\tnum_users\t\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers\t}\n",
      "#\testa\té\ta\tpequena\tfração\tde\tpagerank\n",
      "#\tque\tcada\tnó\trecebe\ta\tcada\titeração\n",
      "base_pr\t=\t(1\t-\tdamping)\t/\tnum_users\n",
      "for\n",
      "\t__\t\n",
      "in\n",
      "\trange(num_iters):\n",
      "next_pr\t=\t{\tuser[\"id\"]\t:\tbase_pr\t\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers\t}\n",
      "for\n",
      "\tuser\t\n",
      "in\n",
      "\tusers:\n",
      "#\tdistribui\tpagerank\tpara\tlinks\tde\tsaída\n",
      "links_pr\t=\tpr[user[\"id\"]]\t*\tdamping\n",
      "for\n",
      "\tendorsee\t\n",
      "in\n",
      "\tuser[\"endorses\"]:\n",
      "\t\t\t\tnext_pr[endorsee[\"id\"]]\t+=\tlinks_pr\t/\tlen(user[\"endorses\"])pr\t=\tnext_pr\n",
      "return\tpr\n",
      "pagerank\t(\n",
      "figura\t21-6\n",
      ")\tidentifica\to\tusuário\t4\t(thor)\tcomo\to\tcientista\tde\tdados\n",
      "com\tmais\tclassificações.\n",
      "figura\t21-6.\ta\trede\tdatasciencester\tdimensionada\tpor\tpagerank\n",
      "mesmo\tque\tele\ttenha\tmenos\taprovações\t(2)\tdo\tque\tusuários\t0,\t1\te\t2,\tas\n",
      "aprovações\tdele\tcarregam\tclassificações\tde\tsuas\taprovações.\talém\tdisso,\tambos\n",
      "apoiadores\tapoiaram\tapenas\tele,\to\tque\tsignifica\tque\tele\tnão\tprecisou\tdividir\ta\n",
      "classificação\tcom\tmais\tninguém.•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "há\tmuitas\toutras\tnoções\tde\tcentralidade\n",
      "(\n",
      "http://en.wikipedia.org/wiki/centrality\n",
      ")\talém\tdas\tque\tusamos\t(mas\tessas\n",
      "são\tas\tmais\tpopulares).\n",
      "networkx\t(\n",
      "http://networkx.github.io\n",
      "/\n",
      ")\té\tuma\tbiblioteca\tpython\tpara\n",
      "análise\tde\trede.\tela\tpossui\tfunções\tpara\tcomputar\tcentralidades\te\n",
      "visualizar\tgráficos.\n",
      "gephi\t(\n",
      "http://gephi.github.io\n",
      "/\n",
      ")\té\tuma\tferramenta\tde\tvisualização\n",
      "amada/odiada\tde\trede\tbaseada\tna\tferramenta\tde\tvisualização\tgui.capítulo\t22\n",
      "sistemas\trecomendadores\n",
      "oh\tnatureza,\tnatureza,\tpor\tque\tés\ttão\tdesonesta,\tpara\tenviares\thomens\tcom\tfalsas\n",
      "recomendações\tpara\to\tmundo!\n",
      "—henry\tfielding\n",
      "outro\tproblema\tde\tdados\tcomum\té\tproduzir\talgum\ttipo\tde\t\n",
      "recomendação\n",
      ".\ta\n",
      "netflix\trecomenda\tfilmes\tque\tvocê\tpoderia\tquerer\tassistir.\ta\tamazon\n",
      "recomenda\tprodutos\tque\tvocê\tpoderia\tquerer\tcomprar.\to\ttwitter\trecomenda\n",
      "usuários\tpara\tvocê\tseguir.\tneste\tcapítulo,\tveremos\tvárias\tformas\tde\tusar\tdados\n",
      "para\tfazer\trecomendações.\n",
      "em\tparticular,\tveremos\to\tconjunto\tde\tdados\tde\t\n",
      "users_interests\n",
      "\tque\tusamos\n",
      "anteriormente:\n",
      "users_interests\t=\t[\n",
      "[\"hadoop\",\t\"big\tdata\",\t\"hbase\",\t\"java\",\t\"spark\",\t\"storm\",\t\"cassandra\"],\n",
      "[\"nosql\",\t\"mongodb\",\t\"cassandra\",\t\"hbase\",\t\"postgres\"],\n",
      "[\"python\",\t\"scikit-learn\",\t\"scipy\",\t\"numpy\",\t\"statsmodels\",\t\"pandas\"],\n",
      "[\"r\",\t\"python\",\t\"statistics\",\t\"regression\",\t\"probability\"],\n",
      "[\"machine\tlearning\",\t\"regression\",\t\"decision\ttrees\",\t\"libsvm\"],\n",
      "[\"python\",\t\"r\",\t\"java\",\t\"c++\",\t\"haskell\",\t\"programming\tlanguages\"],\n",
      "[\"statistics\",\t\"probability\",\t\"mathematics\",\t\"theory\"],\n",
      "[\"machine\tlearning\",\t\"scikit-learn\",\t\"mahout\",\t\"neural\tnetworks\"],\n",
      "[\"neural\tnetworks\",\t\"deep\tlearning\",\t\"big\tdata\",\t\"artificial\tintelligence\"],\n",
      "[\"hadoop\",\t\"java\",\t\"mapreduce\",\t\"big\tdata\"],\n",
      "[\"statistics\",\t\"r\",\t\"statsmodels\"],\n",
      "[\"c++\",\t\"deep\tlearning\",\t\"artificial\tintelligence\",\t\"probability\"],\n",
      "[\"pandas\",\t\"r\",\t\"python\"],\n",
      "[\"databases\",\t\"hbase\",\t\"postgres\",\t\"mysql\",\t\"mongodb\"],\n",
      "[\"libsvm\",\t\"regression\",\t\"support\tvector\tmachines\"]\n",
      "]e\tpensaremos\tsobre\to\tproblema\tde\trecomendar\tnovos\tinteresses\tpara\tum\tusuário\n",
      "baseado\tem\tseus\tinteresses\tatuais\tespecíficos.curadoria\tmanual\n",
      "antes\tda\tinternet,\tquando\tvocê\tprecisava\tde\trecomendações\tde\tlivros,\tvocê\tia\n",
      "até\ta\tbiblioteca\tonde\tum\tbibliotecário\testava\tdisponível\tpara\tsugerir\tlivros\tque\n",
      "fossem\trelevantes\ta\tseus\tinteresses\tou\tsimilares\ta\tlivros\tque\tvocê\tgostou.\n",
      "dado\tum\tnúmero\tlimitado\tde\tusuários\te\tinteresses\tda\tdatasciencester,\tseria\tfácil\n",
      "para\tvocê\tpassar\tuma\ttarde\trecomendando\tinteresses\tpara\tcada\tusuário.\tmas\tesse\n",
      "método\tnão\tescala\tparticularmente\tbem\te\té\tlimitado\tpor\tseu\tconhecimento\n",
      "pessoal\te\timaginação.\t(não\tque\teu\testeja\tsugerindo\tque\tseu\tconhecimento\n",
      "pessoal\te\timaginação\tsejam\tlimitados.)\tentão\tvamos\tpensar\tsobre\to\tque\n",
      "podemos\tfazer\tcom\t\n",
      "dados\n",
      ".recomendando\to\tque\té\tpopular\n",
      "uma\tabordagem\tfácil\té\tsimplesmente\trecomendar\to\tque\té\tpopular:\n",
      "popular_interests\t=\tcounter(interest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser_interests\t\n",
      "in\n",
      "\tusers_interests\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinterest\t\n",
      "in\n",
      "\tuser_interests).most_common()\n",
      "que\tse\tparece\tcom:\n",
      "[('python',\t4),\n",
      "\t\t('r',\t4),\n",
      "\t\t('java',\t3),\n",
      "\t\t('regression',\t3),\n",
      "\t\t('statistics',\t3),\n",
      "\t\t('probability',\t3),\n",
      "\t\t\n",
      "#\n",
      "\t...\n",
      "]\n",
      "tendo\tcomputado\tisso,\tpodemos\tapenas\tsugerir\ta\tum\tusuário\tos\tinteresses\tmais\n",
      "populares\tpelos\tquais\tele\tainda\tnão\testá\tinteressado:\n",
      "def\n",
      "\tmost_popular_new_interests(user_interests,\tmax_results=5):\n",
      "suggestions\t=\t[(interest,\tfrequency)\n",
      "\t\t\t\n",
      "for\n",
      "\tinterest,\tfrequency\t\n",
      "in\n",
      "\tpopular_interests\n",
      "\t\t\t\n",
      "if\n",
      "\tinterest\t\n",
      "not\tin\n",
      "\tuser_interests]\n",
      "return\n",
      "\tsuggestions[:max_results]\n",
      "então,\tse\tvocê\té\to\tusuário\t1,\tcom\tinteresses:\n",
      "[\"nosql\",\t\"mongodb\",\t\"cassandra\",\t\"hbase\",\t\"postgres\"]\n",
      "recomendaríamos\ta\tvocê:\n",
      "most_popular_new_interests(users_interests[1],\t5)\n",
      "#\t[('python',\t4),\t('r',\t4),\t('java',\t3),\t('regression',\t3),\t('statistics',\t3)]\n",
      "se\tvocê\tfor\to\tusuário\t3,\tque\tjá\testá\tinteressado\tem\tmuitas\tdessas\tcoisas,\tvocê\n",
      "receberia:\n",
      "[('java',\t3),\n",
      "\t('hbase',\t3),\n",
      "\t('big\tdata',\t3),\n",
      "\t('neural\tnetworks',\t2),\n",
      "\t('hadoop',\t2)]\n",
      "claro,\t“muitas\tpessoas\tsão\tinteressadas\tem\tpython\tentão\tvocê\ttambém\tdeveriaser”\tnão\té\tuma\tfrase\tde\tvenda\tmuito\tpersuasiva.\tse\talguém\té\tnovo\tem\tnosso\tsite\n",
      "e\tnão\tsabemos\tnada\tsobre\tele,\tisso\té\tbasicamente\to\tmelhor\tque\tpodemos\tfazer.\n",
      "veremos\tcomo\tpodemos\tmelhorar\tbaseando\tas\trecomendações\tde\tcada\tusuário\n",
      "em\tseus\tinteresses.filtragem\tcolaborativa\tbaseada\tno\tusuário\n",
      "uma\tforma\tde\tlevar\tem\tconsideração\tos\tinteresses\tdo\tusuário\té\tprocurar\n",
      "usuários\tque\tsão\t\n",
      "similares\n",
      "\ta\tele\te\tentão\tsugerir\tas\tcoisas\tnas\tquais\taqueles\n",
      "usuários\tsão\tinteressados.\n",
      "para\tfazer\tisso,\tprecisaremos\tde\tuma\tmaneira\tde\tmedir\tquão\tsimilares\tos\tdois\n",
      "usuários\tsão.\taqui\tusaremos\tuma\tmétrica\tchamada\t\n",
      "similaridade\tdo\tcosseno\n",
      ".\n",
      "dados\tdois\tvetores,\t\n",
      "v\n",
      "\te\t\n",
      "w\n",
      ",\té\tdefinida\tcomo:\n",
      "def\n",
      "\tcosine_similarity(v,\tw):\n",
      "return\n",
      "\tdot(v,\tw)\t/\tmath.sqrt(dot(v,\tv)\t*\tdot(w,\tw))\n",
      "ela\tmede\to\t“ângulo”\tentre\t\n",
      "v\n",
      "\te\t\n",
      "w\n",
      ".\tse\t\n",
      "v\n",
      "\te\t\n",
      "w\n",
      "\tapontam\tpara\ta\tmesma\tdireção,\tentão\to\n",
      "numerador\te\to\tdenominador\tsão\tiguais\te\tsua\tsimilaridade\tdo\tcosseno\té\tigual\ta\t1.\n",
      "se\t\n",
      "v\n",
      "\te\t\n",
      "w\n",
      "\tapontam\tpara\tdireções\topostas,\tsua\tsimilaridade\tdo\tcosseno\té\tigual\ta\t–1.\n",
      "e\tse\t\n",
      "v\n",
      "\té\t0\tsempre\tque\t\n",
      "w\n",
      "\tnão\té\t(e\tvice-versa)\tentão\t\n",
      "dot(v,\tw)\n",
      "\té\t0\te\tsua\tsimilaridade\n",
      "do\tcosseno\tserá\t0.\n",
      "quando\taplicamos\tisso\ta\tvetores\tde\t0s\te\t1s,\tcada\tvetor\tv\trepresentando\tos\n",
      "interesses\tde\tum\tusuário.\tv[i]\tserá\t1\tse\to\tusuário\té\tespecificado\tcom\to\ti-ésimo\n",
      "interesse,\te\t0\tse\tnão.\tda\tmesma\tforma,\t“usuários\tsimilares”\tsignificará\t“usuários\n",
      "cujos\tvetores\tde\tinteresses\tquase\tapontam\tpara\ta\tmesma\tdireção”.\tusuários\tcom\n",
      "interesses\tidênticos\tterão\tsimilaridade\t1.\tusuários\tcom\tinteresses\tnão\tidênticos\n",
      "terão\tsimilaridade\t0.\tsenão,\ta\tsimilaridade\tficará\tno\tmeio,\tcom\tnúmeros\n",
      "próximos\ta\t1\tindicando\t“muito\tsimilar”\te\tnúmeros\tpróximos\tde\t0\tindicando\n",
      "“não\tmuito\tsimilar\".\n",
      "um\tbom\tlugar\tpara\tcomeçar\té\tjuntar\tos\tinteresses\tconhecidos\te\t(implicitamente)\n",
      "atribuir\tíndices\ta\teles.\tpodemos\tfazer\tisso\tusando\tum\tconjunto\tde\tcompreensão\n",
      "para\tencontrar\tos\tinteresses\túnicos,\tcolocá-los\tem\tuma\tlista\te\tordená-los.\to\n",
      "primeiro\tinteresse\tna\tlista\tresultante\tserá\to\tinteresse\t0\te\tpor\taí\tvai:\n",
      "unique_interests\t=\tsorted(list({\tinterest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser_interests\t\n",
      "in\n",
      "\tusers_interests\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinterest\t\n",
      "in\n",
      "\tuser_interests\t}))\n",
      "isso\tnos\tdá\tuma\tlista\tque\tcomeça:\n",
      "['big\tdata',\t'c++',\n",
      "\t'cassandra',\n",
      "\t'hbase',\n",
      "\t'hadoop',\n",
      "\t'haskell',\n",
      "\t\n",
      "#\n",
      "\t...\n",
      "]\n",
      "em\tseguida,\tqueremos\tproduzir\tum\tvetor\t“interesse”\tde\t0s\te\t1s\tpara\tcada\n",
      "usuário.\tnós\tsó\tprecisamos\titerar\tpela\tlista\t\n",
      "unique_interests\n",
      ",\tsubstituindo\tum\t1\tse\to\n",
      "usuário\tpossui\tcada\tinteresse,\te\t0\tse\tnão:\n",
      "def\tmake_user_interest_vector(user_interests):\n",
      "\"\"\"dada\tuma\tlista\tde\tinteresses,\tproduza\tum\tvetor\tcujo\t\n",
      "i-ésimo\n",
      "\telemento\té\t1\n",
      "se\tunique_interests[i]\testá\tna\tlista,\t0\"\"\"\n",
      "return\t[1\tif\tinterest\tin\tuser_interests\telse\t0\n",
      "\t\t\t\t\t\t\t\tfor\tinterest\tin\tunique_interests]\n",
      "após\tisso,\tpodemos\tcriar\tuma\tmatriz\tde\tinteresses\tde\tusuário\tsimplesmente\n",
      "mapeando\t(\n",
      "map_ping\n",
      ").\testa\tfunção\tcontra\ta\tlista\tde\tlistas\tde\tinteresses:\n",
      "user_interest_matrix\t=\tmap(make_user_interest_vector,\tusers_interests)\n",
      "agora\t\n",
      "user_interest_matrix[i][j]\n",
      "\té\tigual\ta\t1\tse\to\tusuário\t\n",
      "i\n",
      "\tespecificou\to\tinteresse\t\n",
      "j\n",
      ",\te\t0\n",
      "se\tnão.\n",
      "por\ttermos\tum\tpequeno\tconjunto\tde\tdados,\tnão\té\tum\tproblema\tcomputar\tas\n",
      "similaridades\tem\tpares\tentre\ttodos\tos\tnossos\tusuários:\n",
      "user_similarities\t=\t[[cosine_similarity(interest_vector_i,\tinterest_vector_j)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinterest_vector_j\t\n",
      "in\n",
      "\tuser_interest_matrix]\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tinterest_vector_i\t\n",
      "in\n",
      "\tuser_interest_matrix]\n",
      "e\tdepois,\n",
      "user_similarities[i][j]\n",
      "\tnos\tdá\ta\tsimilaridade\tentre\t\n",
      "i\n",
      "\te\t\n",
      "j\n",
      ".\n",
      "por\texemplo,\t\n",
      "user_similarities[i]\n",
      "\té\t0,57,\tporque\taqueles\tdois\tusuários\tdemonstram\n",
      "interesse\tem\tcomum\tem\thadoop,\tjava\te\tbig\tdata.\tpor\toutro\tlado,\t\n",
      "user_similarities[0]\n",
      "[8]\n",
      "\té\tsomente\t0,19,\tporque\tos\tusuários\t0\te\t8\tdemonstram\tapenas\tum\tinteresse\tem\n",
      "comum:\tbig\tdata;\n",
      "especificamente,\t\n",
      "user_similarities[i]\n",
      "\té\tum\tvetor\tde\tsimilaridades\tdo\tusuário\t\n",
      "i\n",
      "\tpara\n",
      "cada\toutro\tusuário.\tpodemos\tusar\tisso\tpara\tescrever\tuma\tfunção\tque\tencontra\tos\n",
      "usuários\tmais\tsimilares\ta\tum\tusuário\tespecífico.\tnos\tcertificaremos\tde\tnão\n",
      "incluir\to\tpróprio\tusuário,\tnem\tqualquer\toutro\tusuário\tcom\tsimilaridade\t0.\teordenaremos\tos\tresultados\tdo\tmais\tsimilar\tpara\to\tmenos:\n",
      "def\tmost_similar_users_to(user_id):\n",
      "pairs\t=\t[(other_user_id,\tsimilarity)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tencontra\toutros\n",
      "\t\t\tfor\tother_user_id,\tsimilarity\tin\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tusuários\tcom\n",
      "\t\t\t\t\t\tenumerate(user_similarities[user_id])\t\t\t\t\t\t\t\t\t\n",
      "#\tsimilaridade\n",
      "\t\t\tif\tuser_id\t!=\tother_user_id\tand\tsimilarity\t>\t0]\t\t\n",
      "#\tnão\tzero\n",
      "return\tsorted(pairs,\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tordena\n",
      "\t\t\tkey=lambda\t(_,\tsimilarity):\tsimilarity,\t\t\t\t\t\t\t\t\t\t\n",
      "#\tmais\tsimilares\n",
      "\t\t\treverse=true)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tprimeiro\n",
      "por\texemplo,\tse\tchamarmos\t\n",
      "most_similar_user(0)\n",
      ",\tconseguimos:\n",
      "[(9,\t0.5669467095138409),\n",
      "\t(1,\t0.3380617018914066),\n",
      "\t(8,\t0.1889822365046136),\n",
      "\t(13,\t0.1690308509457033),\n",
      "\t(5,\t0.1543033499620919)]\n",
      "como\tusamos\tisso\tpara\tsugerir\tnovos\tinteresses\tpara\tum\tusuário?\tpara\tcada\n",
      "interesse,\tpodemos\tapenas\tsomar\tsimilaridades\tde\tusuário\tdos\toutros\tusuários\n",
      "interessados:\n",
      "def\n",
      "\tuser_based_suggestions(user_id,\tinclude_current_interests=false):\n",
      "#\tsoma\tas\tsimilaridades\n",
      "suggestions\t=\tdefaultdict(float)\n",
      "for\n",
      "\tother_user_id,\tsimilarity\t\n",
      "in\n",
      "\tmost_similar_users_to(user_id):\n",
      "for\n",
      "\tinterest\t\n",
      "in\n",
      "\tusers_interests[other_user_id]:\n",
      "\tsuggestions[interest]\t+=\tsimilarity\n",
      "#\tconverte-as\tem\tuma\tlista\tordenada\n",
      "suggestions\t=\tsorted(suggestions.items(),\n",
      "\t\t\t\t\t\t\t\t\tkey=\n",
      "lambda\n",
      "\t(_,\tweight):\tweight,\n",
      "\t\t\t\t\t\t\t\t\treverse=true)\n",
      "#\te\t(talvez)\texclui\tinteresses\tjá\texistentes\n",
      "if\n",
      "\tinclude_current_interests:\n",
      "return\n",
      "\tsuggestions\n",
      "else\n",
      ":\n",
      "return\n",
      "\t[(suggestion,\tweight)\n",
      "\t\t\t\t\t\t\n",
      "for\n",
      "\tsuggestion,\tweight\t\n",
      "in\n",
      "\tsuggestions\n",
      "\t\t\t\t\t\t\n",
      "if\n",
      "\tsuggestion\t\n",
      "not\tin\n",
      "\tusers_interests[user_id]]\n",
      "se\tchamarmos\t\n",
      "user_based_suggestions(0)\n",
      ",\tos\tprimeiros\tinteresses\tsugeridos\tsão:\n",
      "[('mapreduce',\t0.5669467095138409),\n",
      "\t('mongodb',\t0.50709255283711),\n",
      "\t('postgres',\t0.50709255283711),\n",
      "\t('nosql',\t0.3380617018914066),\t('neural\tnetworks',\t0.1889822365046136),\n",
      "\t('deep\tlearning',\t0.1889822365046136),\n",
      "\t('artificial\tintelligence',\t0.1889822365046136),\n",
      "\t\t\n",
      "#\n",
      "...\n",
      "]\n",
      "essas\tparecem\tser\tsugestões\tdecentes\tpara\talguém\tque\testá\tinteressado\tem\t“big\n",
      "data”\te\tassuntos\trelacionados\ta\tbancos\tde\tdados.\t(os\tpesos\tnão\tsão\n",
      "significativos\tintrinsecamente;\tapenas\tos\tusamos\tpara\tordenar.)\n",
      "essa\tabordagem\tnão\tfunciona\tbem\tquando\to\tnúmero\tde\titens\tfica\tmuito\tgrande.\n",
      "lembre\tda\tmaldição\tda\tdimensionalidade\tdo\t\n",
      "capítulo\t12\n",
      "\t—\tem\tespaços\tde\tvetor\n",
      "de\tgrandes\tdimensões\ta\tmaioria\tdos\tvetores\testão\tdistantes\t(e\tlogo,\tapontam\n",
      "para\tdireções\tdiferentes).\tisto\té,\tquando\thá\tum\tgrande\tnúmero\tde\tinteresses,\tos\n",
      "“usuários\tmais\tsimilares”\ta\tum\tusuário\tespecífico\tpodem\tnão\tser\tsimilares\tno\n",
      "final.\n",
      "imagine\tum\tsite\tcomo\to\tda\tamazon,\tem\tque\tcompramos\tmilhares\tde\titens\tnas\n",
      "últimas\tduas\tdécadas.\tvocê\tpoderia\ttentar\tidentificar\tusuários\tsimilares\ta\tmim\n",
      "baseado\tem\tpadrões\tde\tcompras,\tmas\té\tbem\tprovável\tque\tnão\texista\tninguém\tno\n",
      "mundo\tque\tcompre\troupas\thistóricas\tcomo\tas\tminhas.\tquem\tquer\tque\tseja\tmeu\n",
      "comprador\t“mais\tsimilar”,\tprovavelmente\tnão\té\tsimilar\ta\tmim\te\tsua\tcompras\n",
      "quase\tcertamente\tdariam\trecomendações\tidiotas\tpara\tmim.filtragem\tcolaborativa\tbaseada\tem\titens\n",
      "uma\tabordagem\talternativa\té\tcomputar\tsimilaridades\tentres\tinteresses\n",
      "diretamente.\tnós\tpodemos\tgerar\tsugestões\tpara\tcada\tusuário\tagregando\n",
      "interesses\tque\tsão\tsimilares\ta\tseus\tinteresses\tatuais.\n",
      "para\tcomeçar,\tqueremos\t\n",
      "transpor\n",
      "\ta\tmatriz\tde\tinteresse\tdo\tnosso\tusuário\tpara\n",
      "que\tfileiras\tcorrespondam\ta\tinteresses\te\tcolunas\tcorrespondam\ta\tusuários:\n",
      "interest_user_matrix\t=\t[[user_interest_vector[j]\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser_interest_vector\t\n",
      "in\n",
      "\tuser_interest_matrix]\n",
      "\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tj,\t_\t\n",
      "in\n",
      "\tenumerate(unique_interests)]\n",
      "com\to\tque\tisso\tse\tparece?\ta\tlinha\t\n",
      "j\n",
      "\tde\t\n",
      "interest_user_matrix\n",
      "\té\tcoluna\t\n",
      "j\n",
      "\tde\n",
      "user_interest_matrix\n",
      ".\tisto\té,\tpossui\t1\tpara\tcada\tusuário\tcom\taquele\tinteresse\te\t0\tpara\n",
      "cada\tusuário\tsem\taquele\tinteresse.\n",
      "por\texemplo,\t\n",
      "unique_interests[0]\n",
      "\té\tbig\tdata\te\t\n",
      "interest_user_matrix[0]\n",
      "\ttambém\té:\n",
      "[1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0]\n",
      "porque\tusuários\t\n",
      "0,\t8\n",
      "\te\t\n",
      "9\n",
      "\tindicaram\tinteresse\tem\tbig\tbata.\n",
      "agora\tpodemos\tusar\tsimilaridade\tdo\tcosseno\tnovamente.\tse,\tprecisamente,\tos\n",
      "mesmos\tusuários\testão\tinteressados\tem\tdois\ttópicos,\tsuas\tsimilaridades\tserão\t1.\n",
      "se\tnenhum\tdos\tdois\tusuários\testiver\tinteressado\tem\tambos\ttópicos,\ta\n",
      "similaridade\tserá\t0:\n",
      "interest_similarities\t=\t[[cosine_similarity(user_vector_i,\tuser_vector_j)\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser_vector_j\t\n",
      "in\n",
      "\tinterest_user_matrix]\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "for\n",
      "\tuser_vector_i\t\n",
      "in\n",
      "\tinterest_user_matrix]\n",
      "por\texemplo,\tpodemos\tencontrar\tos\tinteresses\tmais\tsimilares\ta\tbig\tdata\n",
      "(interesse\t0)\tusando:\n",
      "def\n",
      "\tmost_similar_interests_to(interest_id):\n",
      "similarities\t=\tinterest_similarities[interest_id]\n",
      "pairs\t=\t[(unique_interests[other_interest_id],\tsimilarity)\n",
      "\t\t\n",
      "for\n",
      "\tother_interest_id,\tsimilarity\t\n",
      "in\n",
      "\tenumerate(similarities)\n",
      "\t\t\n",
      "if\n",
      "\tinterest_id\t!=\tother_interest_id\t\n",
      "and\n",
      "\tsimilarity\t>\t0]\n",
      "return\n",
      "\tsorted(pairs,\n",
      "\t\tkey=\n",
      "lambda\n",
      "\t(_,\tsimilarity):\tsimilarity,\n",
      "\t\treverse=true)o\tque\tsugere\tos\tseguintes\tinteresses\tsimilares:\n",
      "[('hadoop',\t0.8164965809277261),\n",
      "\t('java',\t0.6666666666666666),\n",
      "\t('mapreduce',\t0.5773502691896258),\n",
      "\t('spark',\t0.5773502691896258),\n",
      "\t('storm',\t0.5773502691896258),\n",
      "\t('cassandra',\t0.4082482904638631),\n",
      "\t('artificial\tintelligence',\t0.4082482904638631),\n",
      "\t('deep\tlearning',\t0.4082482904638631),\n",
      "\t('neural\tnetworks',\t0.4082482904638631),\n",
      "\t('hbase',\t0.3333333333333333)]\n",
      "agora\tnós\tpodemos\tcriar\trecomendações\tpara\tum\tusuário\tsomando\tas\n",
      "similaridades\tde\tinteresses\tparecidos\tcom\tos\tdele:\n",
      "def\titem_based_suggestions(user_id,\tinclude_current_interests=false):\n",
      "#\tsoma\tinteresses\tsimilares\n",
      "suggestions\t=\tdefaultdict(float)\n",
      "user_interest_vector\t=\tuser_interest_matrix[user_id]\n",
      "for\tinterest_id,\tis_interested\tin\tenumerate(user_interest_vector):\n",
      "if\tis_interested\t==\t1:\n",
      "similar_interests\t=\tmost_similar_interests_to(interest_id)\n",
      "for\tinterest,\tsimilarity\tin\tsimilar_interests:\n",
      "\t\t\t\t\t\tsuggestions[interest]\t+=\tsimilarity\n",
      "#\tordena\tpor\tpeso\n",
      "suggestions\t=\tsorted(suggestions.items(),\n",
      "\t\t\t\t\t\t\t\t\tkey=lambda\t(_,\tsimilarity):\tsimilarity,\n",
      "\t\t\t\t\t\t\t\t\treverse=true)\n",
      "if\tinclude_current_interests:\n",
      "return\tsuggestions\n",
      "else:\n",
      "return\t[(suggestion,\tweight)\n",
      "\t\t\t\t\t\tfor\tsuggestion,\tweight\tin\tsuggestions\n",
      "\t\t\t\t\t\tif\tsuggestion\tnot\tin\tusers_interests[user_id]]\n",
      "para\to\tusuário\t0,\tisso\tgera\tas\tseguintes\t(aparentemente\trazoáveis)\n",
      "recomendações:\n",
      "[('mapreduce',\t1.861807319565799),\n",
      "\t('postgres',\t1.3164965809277263),\n",
      "\t('mongodb',\t1.3164965809277263),\n",
      "\t('nosql',\t1.2844570503761732),\n",
      "\t('programming\tlanguages',\t0.5773502691896258),\n",
      "\t('mysql',\t0.5773502691896258),\n",
      "\t('haskell',\t0.5773502691896258),\t('databases',\t0.5773502691896258),\n",
      "\t('neural\tnetworks',\t0.4082482904638631),\n",
      "\t('deep\tlearning',\t0.4082482904638631),\n",
      "\t('c++',\t0.4082482904638631),\n",
      "\t('artificial\tintelligence',\t0.4082482904638631),\n",
      "\t('python',\t0.2886751345948129),\n",
      "\t('r',\t0.2886751345948129)]•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "crab\t(\n",
      "http://muricoca.github.io/crab\n",
      "/\n",
      ")\té\tum\tframework\tpara\tconstrução\tde\n",
      "sistemas\trecomendadores\tem\tpython.\n",
      "graphlab\ttambém\tpossui\tferramentas\trecomendadoras\n",
      "(\n",
      "http://bit.ly/1mf9tsy\n",
      ").\n",
      "o\tprêmio\tnetflix\t(\n",
      "http://www.netflixprize.com\n",
      ")\tfoi\tuma\tcompetição\n",
      "famosa\tpara\tconstruir\tum\tmelhor\tsistema\tpara\trecomendar\tfilmes\tpara\n",
      "usuários\tnetflix.capítulo\t23\n",
      "bases\tde\tdados\te\tsql\n",
      "a\tmemória\té\ta\tmelhor\tamiga\te\ta\tpior\tinimiga\tdo\thomem\n",
      ".\n",
      "—\tgilbert\tparker\n",
      "os\tdados\tdos\tquais\tvocê\tprecisará\tgeralmente\testarão\tem\t\n",
      "bases\tde\tdados\n",
      ",\n",
      "usando\tsistemas\tfeitos\tpara\tarmazenar\te\tconsultar\tdados\teficientemente.\ta\tmaior\n",
      "parte\tdesses\tsistemas\tde\tbancos\tde\tdados\tsão\t\n",
      "relacionais\n",
      ",como\toracle,\tmysql\n",
      "e\tsql\tserver,\tque\tarmazenam\tdados\tem\t\n",
      "tabelas\n",
      "\te\tsão\ttipicamente\tconsultados\n",
      "usando\tstructured\tquery\tlanguage\t(sql),\tuma\tlinguagem\tdeclarativa\tpara\n",
      "manipular\tdados.\n",
      "sql\té\tuma\tparte\tessencial\tdo\tkit\tde\tferramentas\tdo\tcientista\tde\tdados.\tneste\n",
      "capítulo,\tcriaremos\tnotquiteabase,\tuma\timplementação\tpython\tde\talgo\tque\n",
      "não\té\texatamente\tum\tbanco\tde\tdados.\ttambém\tcobriremos\to\tbásico\tde\tsql\n",
      "enquanto\tmostramos\tcomo\tele\ttrabalham\tem\tnosso\tnão\texatamente\tbanco\tde\n",
      "dados,\tque\ta\tforma\tmais\t“do\tzero”\tque\tpude\tpensar\tpara\tajudar\ta\tentender\to\tque\n",
      "tais\tfuncionalidades\tbásicas\testão\tfazendo.\tminha\tesperança\té\tque\tresolver\n",
      "problemas\tem\tnotquiteabase\ttrará\tuma\tboa\tnoção\tde\tcomo\tvocê\tpode\tresolver\n",
      "os\tmesmos\tproblemas\tusando\tsql.create\ttable\te\tinsert\n",
      "uma\tbase\tde\tdados\trelacional\té\tuma\tcoleção\tde\ttabelas\t(e\tde\trelacionamentos\n",
      "entre\telas).\tuma\ttabela\té\tuma\tsimples\tcoleção\tde\tlinhas,\tnão\tdiferente\tdas\n",
      "matrizes\tcom\tas\tquais\ttrabalhamos.\tentretanto,\tuma\ttabela\ttambém\tpossui\n",
      "associação\tcom\tum\t\n",
      "esquema\n",
      "\tfixo\tconstituído\tpor\tnomes\te\ttipos\tde\tcolunas.\n",
      "por\texemplo,\timagine\tum\tconjunto\tde\tdados\t\n",
      "users\n",
      "\tcontendo\tpara\tcada\tusuário\tseu\n",
      "user_\tid\n",
      ",\t\n",
      "name\n",
      "\te\t\n",
      "num_friends\n",
      ":\n",
      "users\t=\t[[0,\t\"hero\",\t0],\n",
      "\t\t[1,\t\"dunn\",\t2],\n",
      "\t\t[2,\t\"sue\",\t3],\n",
      "\t\t[3,\t\"chi\",\t3]]\n",
      "em\tsql,\tpoderíamos\tcriar\tessa\ttabela\tcom:\n",
      "create\ttable\n",
      "\tusers\t(\n",
      "user_id\tint\t\n",
      "not\tnull\n",
      ",\n",
      "name\tvarchar(200),\n",
      "num_friends\tint);\n",
      "note\tque\tespecificamos\tque\t\n",
      "user_id\n",
      "\te\t\n",
      "num_friends\n",
      "\tdevem\tser\tinteiros\t(e\tque\t\n",
      "user_id\n",
      "não\tpode\tser\t\n",
      "null\n",
      ",\to\tque\tindica\tum\tvalor\tfaltando\te\té\tcomo\tnosso\t\n",
      "none\n",
      ")\te\tque\n",
      "nome\tdeveria\tser\tuma\tcadeia\tde\tcaracteres\tde\ttamanho\t200\tou\tmenor.\n",
      "notquiteabase\tnão\tleva\ttipos\tem\tconsideração\tmas\tse\tcomporta\tcomo\tse\n",
      "levasse.\n",
      "sql\té\tquase\tcompletamente\tinsensível\ta\tendentação\te\tcapitalização.\to\testilo\tde\n",
      "endentação\te\tcapitalização\taqui\té\to\tmeu\tfavorito.\tse\tvocê\tcomeça\ta\taprender\tsql,\n",
      "você\tcertamente\tencontrará\toutros\texemplos\testilizados\tdiferentemente.\n",
      "você\tpode\tinserir\tas\tlinhas\tcom\tdeclarações\tinsert:\n",
      "insert\tinto\n",
      "\tusers\t(user_id,\tname,\tnum_friends)\t\n",
      "values\n",
      "\t(0,\t'hero',\t0);\n",
      "note\ttambém\tque\tdeclarações\tsql\tprecisam\tterminar\tcom\tponto\tde\tvírgula\te\n",
      "que\tsql\trequer\taspa\túnica\tpara\tsuas\tstrings.\n",
      "em\tnotquiteabase\tvocê\tcriará\tuma\t\n",
      "table\n",
      "\tsimplesmente\tespecificando\tos\tnomesde\tsuas\tcolunas.\te\tpara\tinserir\tuma\tlinha,\tvocê\tusará\to\tmétodo\t\n",
      "insert()\n",
      "\tda\ttabela,\n",
      "que\tpega\tuma\t\n",
      "list\n",
      "\tde\tvalores\tde\tlinha\tque\tprecisam\testar\tna\tmesma\tordem\tdos\n",
      "nomes\tda\tcoluna\tda\ttabela.\n",
      "nos\tbastidores,\tarmazenaremos\tcada\tlinha\tcomo\tum\t\n",
      "dict\n",
      "\t(dicionário)\tde\tnomes\n",
      "de\tcolunas\tpara\tvalores.\tum\tbanco\tde\tdados\treal\tjamais\tusaria\ttal\trepresentação\n",
      "mas\tfazê-la\ttornará\tnotquiteabase\tmais\tfácil\tde\ttrabalhar:\n",
      "class\ttable\n",
      ":\n",
      "def\n",
      "\t__init__(self,\tcolumns):\n",
      "self.columns\t=\tcolumns\n",
      "self.rows\t=\t[]\n",
      "def\n",
      "\t__repr__(self):\n",
      "\"\"\"bela\trepresentação\tda\ttabela:\tcolunas\te\tentão\tlinhas\"\"\"\n",
      "return\n",
      "\tstr(self.columns)\t+\t\"\n",
      "\\n\n",
      "\"\t+\t\"\n",
      "\\n\n",
      "\".join(map(str,\tself.rows))\n",
      "def\n",
      "\tinsert(self,\trow_values):\n",
      "if\n",
      "\tlen(row_values)\t!=\tlen(self.columns):\n",
      "raise\ttypeerror\n",
      "(\"wrong\tnumber\tof\telements\")\n",
      "row_dict\t=\tdict(zip(self.columns,\trow_values))\n",
      "self.rows.append(row_dict)\n",
      "por\texemplo,\tpoderíamos\tconfigurar:\n",
      "users\t=\ttable([\"user_id\",\t\"name\",\t\"num_friends\"])\n",
      "users.insert([0,\t\"hero\",\t0])\n",
      "users.insert([1,\t\"dunn\",\t2])\n",
      "users.insert([2,\t\"sue\",\t3])\n",
      "users.insert([3,\t\"chi\",\t3])\n",
      "users.insert([4,\t\"thor\",\t3])\n",
      "users.insert([5,\t\"clive\",\t2])\n",
      "users.insert([6,\t\"hicks\",\t3])\n",
      "users.insert([7,\t\"devin\",\t2])\n",
      "users.insert([8,\t\"kate\",\t2])\n",
      "users.insert([9,\t\"klein\",\t3])\n",
      "users.insert([10,\t\"jen\",\t1])\n",
      "se\tagora\tvocê\timprimir\t\n",
      "users\n",
      ",\tverá:\n",
      "['user_id',\t'name',\t'num_friends']\n",
      "{'user_id':\t0,\t'name':\t'hero',\t'num_friends':\t0}\n",
      "{'user_id':\t1,\t'name':\t'dunn',\t'num_friends':\t2}\n",
      "{'user_id':\t2,\t'name':\t'sue',\t'num_friends':\t3}\n",
      "...•\n",
      "•\n",
      "•\n",
      "•\n",
      "update\n",
      "às\tvezes,\tvocê\tprecisa\tatualizar\tos\tdados\tque\tjá\testão\tno\tbanco\tde\tdados.\tpor\n",
      "exemplo,\tse\tdunn\tpossuir\toutro\tamigo,\tvocê\tpode\tprecisar\tfazer\tisso:\n",
      "update\n",
      "\tusers\n",
      "set\n",
      "\tnum_friends\t=\t3\n",
      "where\n",
      "\tuser_id\t=\t1;\n",
      "os\tatributos-chave\tsão:\n",
      "qual\ttabela\tatualizar\n",
      "quais\tlinhas\tatualizar\n",
      "quais\tcampos\tatualizar\n",
      "quais\tdeveriam\tser\tos\tnovos\tvalores\n",
      "adicionaremos\tum\tmétodo\t\n",
      "update\n",
      "\tsimilar\tem\tnotquiteabase.\tseu\tprimeiro\n",
      "argumento\tserá\tum\t\n",
      "dict\n",
      "\tcujas\tchaves\tsão\tcolunas\tpara\tatualizar\te\tcujos\tvalores\n",
      "são\tos\tnovos\tvalores\tpara\taqueles\tcampos.\te\tseu\tsegundo\targumento\té\tum\n",
      "predicado\tque\tretorna\t\n",
      "true\n",
      "\tpara\tlinhas\tque\tdeveriam\tser\tatualizadas,\t\n",
      "false\n",
      "\tse\tnão:\n",
      "def\n",
      "\tupdate(self,\tupdates,\tpredicate):\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tself.rows:\n",
      "if\n",
      "\tpredicate(row):\n",
      "for\n",
      "\tcolumn,\tnew_value\t\n",
      "in\n",
      "\tupdates.iteritems():\n",
      "row[column]\t=\tnew_value\n",
      "e\tapós\tisso\tpodemos\tsimplesmente\tfazer:\n",
      "users.update({'num_friends'\t:\t3},\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\testabelece\tnum_friends\t=\t3\n",
      "\t\t\t\n",
      "lambda\n",
      "\trow:\trow['user_id']\t==\t1)\t\t\n",
      "#\tem\tlinhas\tonde\tuser_id\t==\t1delete\n",
      "há\tduas\tformas\tde\texcluir\tlinhas\tde\tuma\ttabela\tem\tsql.\ta\tforma\tperigosa\n",
      "apaga\ttodas\tas\tlinhas\tda\ttabela:\n",
      "delete\tfrom\n",
      "\tusers;\n",
      "a\tforma\tmenos\tperigosa\tadiciona\tuma\tcláusula\t\n",
      "where\n",
      "\te\tapenas\tapaga\tas\tcolunas\n",
      "que\tatendem\ta\tuma\tcerta\tcondição:\n",
      "delete\tfrom\n",
      "\tusers\t\n",
      "where\n",
      "\tuser_id\t=\t1;\n",
      "é\tfácil\tacrescentar\tessa\tfuncionalidade\ta\tnossa\t\n",
      "table\n",
      ":\n",
      "def\n",
      "\tdelete(self,\tpredicate=\n",
      "lambda\n",
      "\trow:\ttrue):\n",
      "\"\"\"apaga\ttodas\tas\tlinhas\tque\tcombinam\tcom\to\tpredicado\n",
      "ou\ttodas\tas\tlinhas\tse\tnão\thá\tpredicado\"\"\"\n",
      "self.rows\t=\t[row\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tself.rows\t\n",
      "if\tnot\n",
      "(predicate(row))]\n",
      "se\tvocê\tforneceu\tuma\tfunção\t\n",
      "predicate\n",
      "\t(por\texemplo,\tcláusula\t\n",
      "where\n",
      "),\tisso\tapaga\n",
      "apenas\tas\tlinhas\tque\ta\tsatisfazem.\tse\tnão\tforneceu\tuma,\to\tpredicado\tpadrão\n",
      "sempre\tretorna\t\n",
      "true\n",
      "\te\tvocê\tapagará\ttodas\tas\tlinhas.\n",
      "por\texemplo:\n",
      "users.delete(\n",
      "lambda\n",
      "\trow:\trow[\"user_id\"]\t==\t1)\t\t\t\n",
      "#\tapaga\tlinhas\tcom\tuser_id\t==\t1\n",
      "users.delete()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tapaga\ttodas\tas\tlinhas•\n",
      "•\n",
      "select\n",
      "tipicamente\tvocê\tnão\tinspeciona\tuma\ttabela\tsql\tdiretamente.\tem\tvez\tdisso,\n",
      "você\ta\tconsulta\tcom\tuma\tdeclaração\t\n",
      "select\n",
      ":\n",
      "select\t*\tfrom\tusers;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "--\tbusca\ttodo\to\tconteúdo\n",
      "select\t*\tfrom\tusers\tlimit\t2;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "--\tbusca\tas\tduas\tprimeiras\tlinhas\n",
      "select\tuser_id\tfrom\tusers;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "--\tbusca\tsomente\tcolunas\tespecíficas\n",
      "select\tuser_id\tfrom\tusers\twhere\tname\t=\t'dunn';\t\t\t\n",
      "--\tbusca\tsomente\tlinhas\tespecíficas\n",
      "você\ttambém\tpode\tusar\tdeclarações\t\n",
      "select\n",
      "\tpara\tcalcular\tcampos:\n",
      "select\tlength\n",
      "(name)\t\n",
      "as\n",
      "\tname_length\t\n",
      "from\n",
      "\tusers;\n",
      "nós\tdaremos\ta\tnossa\tclasse\t\n",
      "table\n",
      "\tum\tmétodo\t\n",
      "select()\n",
      "\tque\tretorna\tuma\tnova\t\n",
      "table\n",
      ".\to\n",
      "método\taceita\tdois\targumentos\topcionais:\n",
      "keep_columns\n",
      "\tespecifica\to\tnome\tdas\tcolunas\tque\tvocê\tquer\tmanter\tno\n",
      "resultado.\tse\tvocê\tnão\tfornecê-la,\to\tresultado\tcontém\ttodas\tas\tcolunas.\n",
      "additional_columns\n",
      "\té\tum\tdicionário\tcujas\tchaves\tsão\tnovos\tnomes\tde\tcolunas\te\n",
      "cujos\tvalores\tsão\tfunções\tespecificando\tcomo\tcomputar\tos\tvalores\tde\n",
      "novas\tcolunas.\n",
      "se\tvocê\tnão\tfornecer\tnenhum\tdos\tdois,\tvocê\tsimplesmente\treceberia\tuma\tcópia\n",
      "da\ttabela:\n",
      "def\n",
      "\tselect(self,\tkeep_columns=none,\tadditional_columns=none):\n",
      "if\n",
      "\tkeep_columns\t\n",
      "is\n",
      "\tnone:\t\t\t\t\t\t\t\t\t\t\n",
      "#\tse\tnenhuma\tcoluna\tespecificada\n",
      ",\n",
      "keep_columns\t=\tself.columns\t\t\t\n",
      "#\tretorna\ttodas\tas\tcolunas\n",
      "if\n",
      "\tadditional_columns\t\n",
      "is\n",
      "\tnone:\n",
      "additional_columns\t=\t{}\n",
      "#\tnova\ttabela\tpara\tresultados\n",
      "result_table\t=\ttable(keep_columns\t+\tadditional_columns.keys())\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\tself.rows:\n",
      "new_row\t=\t[row[column]\t\n",
      "for\n",
      "\tcolumn\t\n",
      "in\n",
      "\tkeep_columns]\n",
      "for\n",
      "\tcolumn_name,\tcalculation\t\n",
      "in\n",
      "\tadditional_columns.iteritems():\n",
      "\tnew_row.append(calculation(row))\n",
      "result_table.insert(new_row)\n",
      "return\n",
      "\tresult_table\n",
      "nosso\t\n",
      "select()\n",
      "\tretorna\tuma\tnova\ttabela,\tenquanto\to\ttípico\t\n",
      "sql\tselect()\n",
      "\tapenasproduz\talgum\ttipo\tde\tresultado\ttransitório\t(a\tmenos\tque\tvocê\texplicitamente\n",
      "insira\tos\tresultados\tna\ttabela).\n",
      "nós\ttambém\tprecisaremos\tdos\tmétodos\t\n",
      "where()\n",
      "\te\t\n",
      "limit()\n",
      ".\tambos\tsão\tbem\tsimples:\n",
      "def\n",
      "\twhere(self,\tpredicate=\n",
      "lambda\n",
      "\trow:\ttrue):\n",
      "\"\"\"retorna\tapenas\tas\tlinhas\tque\tsatisfazem\to\tpredicado\tfornecido\"\"\"\n",
      "where_table\t=\ttable(self.columns)\n",
      "where_table.rows\t=\tfilter(predicate,\tself.rows)\n",
      "return\n",
      "\twhere_table\n",
      "def\n",
      "\tlimit(self,\tnum_rows):\n",
      "\"\"\"retorna\tapenas\tas\tprimeiras\tlinhas\tnum_rows\"\"\"\n",
      "limit_table\t=\ttable(self.columns)\n",
      "limit_table.rows\t=\tself.rows[:num_rows]\n",
      "return\n",
      "\tlimit_table\n",
      "e\tdepois\tpodemos\tfacilmente\tconstruir\tequivalentes\tnotquiteabase\tàs\n",
      "declarações\tsql\tprecedentes:\n",
      "#\tselect\t*\tfrom\tusers;\n",
      "users.select()\n",
      "#\tselect\t*\tfrom\tusers\tlimit\t2;\n",
      "users.limit(2)\n",
      "#\tselect\tuser_id\tfrom\tusers;\n",
      "users.select(keep_columns=[\"user_id\"])\n",
      "#\tselect\tuser_id\tfrom\tusers\twhere\tname\t=\t'dunn';\n",
      "users.where(\n",
      "lambda\n",
      "\trow:\trow[\"name\"]\t==\t\"dunn\")\t\\\n",
      "\t\t.select(keep_columns=[\"user_id\"])\n",
      "#\tselect\tlength(name)\tas\tname_length\tfrom\tusers;\n",
      "def\n",
      "\tname_length(row):\t\n",
      "return\n",
      "\tlen(row[\"name\"])\n",
      "users.select(keep_columns=[],\n",
      "\t\t\tadditional_columns\t=\t{\t\"name_length\"\t:\tname_length\t})\n",
      "observe\tque\t—\tdiferente\tdo\tresto\tdo\tlivro\t—\taqui\teu\tuso\tbarra\tinvertida\t\\\tpara\n",
      "continuar\tdeclarações\tem\tmúltiplas\tlinhas.\tacredito\tque\tisso\ttorna\ta\tpesquisa\tde\n",
      "notquiteabase\tmais\tfácil\tde\tler\tdo\tque\tqualquer\toutra\tforma.group\tby\n",
      "outra\toperação\tsql\tcomum\té\t\n",
      "group\tby\n",
      ",\tque\tagrupa\tlinhas\tcom\tvalores\n",
      "idênticos\tem\tcolunas\tespecificadas\te\tproduz\tvalores\tagregados\tcomo\t\n",
      "min\n",
      "\te\t\n",
      "max\n",
      "e\t\n",
      "count\n",
      "\te\t\n",
      "sum\n",
      ".\tisso\tdeveria\trelembrar\tvocê\tda\tfunção\t\n",
      "group_by\n",
      "\tde\t“manipulando\n",
      "dados”\tna\tpágina\t129.\n",
      "por\texemplo,\tvocê\tpode\tquerer\tencontrar\to\tnúmero\tde\tusuários\te\to\tmenor\t\n",
      "user_id\n",
      "para\tcada\tpossível\ttamanho\tde\tnome:\n",
      "select\tlength\n",
      "(name)\t\n",
      "as\n",
      "\tname_length,\n",
      "\t\n",
      "min\n",
      "(user_id)\t\n",
      "as\n",
      "\tmin_user_id,\n",
      "\t\n",
      "count\n",
      "(*)\t\n",
      "as\n",
      "\tnum_users\n",
      "from\n",
      "\tusers\n",
      "group\tby\tlength\n",
      "(name);\n",
      "cada\tcampo\tque\tselecionamos\tcom\t\n",
      "select\n",
      "\tprecisa\testar\tna\tcláusula\t\n",
      "group\tby\n",
      "\t(o\n",
      "que\t\n",
      "name_\tlength\n",
      "\té)\tou\tser\tuma\tcomputação\tagregada\t(o\tque\t\n",
      "min_user_id\n",
      "\te\t\n",
      "num_users\n",
      "são).\n",
      "sql\ttambém\tsuporta\tuma\tcláusula\t\n",
      "having\n",
      "\tque\tse\tcomporta\tde\tforma\tsimilar\ta\n",
      "cláusula\t\n",
      "where\n",
      "\tcom\texceção\tde\tseu\tfiltro,\tque\té\taplicado\taos\tagregados\n",
      "(enquanto\tque\tum\twhere\tfiltraria\ttodas\tas\tlinhas\tantes\tmesmo\tda\tagregação\n",
      "começar).\n",
      "você\tpode\tquerer\tsaber\to\tnúmero\tmédio\tde\tamigos\tde\tusuários\tcujos\tnomes\n",
      "começam\tcom\tletras\tespecíficas\tmas\tapenas\tver\tos\tresultados\tpara\tletras\tcom\n",
      "média\tcorrespondente\tmaior\tque\t1.\t(sim,\talguns\tdesses\texemplos\tsão\n",
      "maquinados.)\n",
      "select\n",
      "\tsubstr(name,\t1,\t1)\t\n",
      "as\n",
      "\tfirst_letter,\n",
      "\t\n",
      "avg\n",
      "(num_friends)\t\n",
      "as\n",
      "\tavg_num_friends\n",
      "from\n",
      "\tusers\n",
      "group\tby\n",
      "\tsubstr(name,\t1,\t1)\n",
      "having\tavg\n",
      "(num_friends)\t>\t1;\n",
      "(funções\tpara\ttrabalhar\tcom\tstrings\tvariam\tpelas\timplementações\tsql;\talguns\n",
      "bancos\tde\tdados\tusam\tsubstring\tou\toutra\tcoisa.)\n",
      "você\ttambém\tpode\tcomputar\to\ttotal\tde\tagregados.\tneste\tcaso,\tvocê\tabandona\to1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "group\tby:\n",
      "select\tsum\n",
      "(user_id)\t\n",
      "as\n",
      "\tuser_id_sum\n",
      "from\n",
      "\tusers\n",
      "where\n",
      "\tuser_id\t>\t1;\n",
      "para\tacrescentar\tessa\tfuncionalidade\tàs\t\n",
      "tables\n",
      "\tnotquiteabase,\tadicionaremos\tum\n",
      "método\t\n",
      "group_by()\n",
      ".\tele\tusa\tos\tnomes\tdas\tcolunas\tque\tqueremos\tagrupar,\tum\n",
      "dicionário\tde\tfunções\tde\tagregação\tque\tvocê\tquer\texecutar\tem\tcada\tgrupo\te\tum\n",
      "predicado\t\n",
      "having\n",
      "\tque\topera\tem\tmúltiplas\tlinhas.\n",
      "os\tseguintes\tpassos\tsão\trealizados:\n",
      "cria\t\n",
      "defaultdict\n",
      "\tpara\tmapear\t\n",
      "tuples\n",
      "\t(de\tagrupação\tpor\tvalores)\tpara\tlinhas\n",
      "(contendo\tagrupação\tpor\tvalores).\tlembre-se\tde\tque\tnão\tpode\tusar\tlistas\n",
      "como\tchaves\t\n",
      "dict;\n",
      "\tvocê\ttem\tque\tusar\ttuplas.\n",
      "itera\tpelas\tlinhas\tda\ttabela,\tpopulando\to\t\n",
      "defaultdict\n",
      ".\n",
      "cria\tuma\tnova\ttabela\tcom\tas\tcolunas\tde\tsaída\tcorretas.\n",
      "itera\tpor\t\n",
      "defaultdict\n",
      "\te\tpopula\ta\ttabela\tde\tsaída,\taplicando\to\tfiltro\t\n",
      "having\n",
      ",\tse\n",
      "houver.\n",
      "(um\tbanco\tde\tdados\treal\tquase\tcertamente\tfaria\tisso\tde\tuma\tforma\tmais\n",
      "eficiente.)\n",
      "def\tgroup_by(self,\tgroup_by_columns,\taggregates,\thaving=none):\n",
      "grouped_rows\t=\tdefaultdict(list)\n",
      "#\tpopula\tgrupos\n",
      "for\trow\tin\tself.rows:\n",
      "key\t=\ttuple(row[column]\tfor\tcolumn\tin\tgroup_by_columns)\n",
      "grouped_rows[key].append(row)\n",
      "#\ttabela\tresultante\tcom\tcolunas\tgroup_by\te\tagregados\n",
      "result_table\t=\ttable(group_by_columns\t+\taggregates.keys())\n",
      "for\tkey,\trows\tin\tgrouped_rows.iteritems():\n",
      "if\thaving\tis\tnone\tor\thaving(rows):\n",
      "new_row\t=\tlist(key)\n",
      "for\taggregate_name,\taggregate_fn\tin\taggregates.iteritems():\n",
      "\t\t\t\tnew_row.append(aggregate_fn(rows))\n",
      "result_table.insert(new_row)\n",
      "return\tresult_table\n",
      "novamente,\tdeixe-me\tver\tcomo\tfaríamos\to\tequivalente\tàs\tdeclarações\tsqlprecedentes.\tas\tmétricas\t\n",
      "name_length\n",
      "\tsão:\n",
      "def\n",
      "\tmin_user_id(rows):\t\n",
      "return\n",
      "\tmin(row[\"user_id\"]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\trows)\n",
      "stats_by_length\t=\tusers\t\\\n",
      ".select(additional_columns={\"name_length\"\t:\tname_length})\t\\\n",
      ".group_by(group_by_columns=[\"name_length\"],\n",
      "\t\t\taggregates={\t\"min_user_id\"\t:\tmin_user_id,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\"num_users\"\t:\tlen\t})\n",
      "as\tmétricas\t\n",
      "first_letter:\n",
      "def\n",
      "\tfirst_letter_of_name(row):\n",
      "return\n",
      "\trow[\"name\"][0]\t\n",
      "if\n",
      "\trow[\"name\"]\t\n",
      "else\n",
      "\t\"\"\n",
      "def\n",
      "\taverage_num_friends(rows):\n",
      "return\n",
      "\tsum(row[\"num_friends\"]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\trows)\t/\tlen(rows)\n",
      "def\n",
      "\tenough_friends(rows):\n",
      "return\n",
      "\taverage_num_friends(rows)\t>\t1\n",
      "avg_friends_by_letter\t=\tusers\t\\\n",
      ".select(additional_columns={'first_letter'\t:\tfirst_letter_of_name})\t\\\n",
      ".group_by(group_by_columns=['first_letter'],\n",
      "\t\t\taggregates={\t\"avg_num_friends\"\t:\taverage_num_friends\t},\n",
      "\t\t\thaving=enough_friends)\n",
      "e\t\n",
      "user_id_sum\n",
      "\té:\n",
      "def\n",
      "\tsum_user_ids(rows):\t\n",
      "return\n",
      "\tsum(row[\"user_id\"]\t\n",
      "for\n",
      "\trow\t\n",
      "in\n",
      "\trows)\n",
      "user_id_sum\t=\tusers\t\\\n",
      ".where(\n",
      "lambda\n",
      "\trow:\trow[\"user_id\"]\t>\t1)\t\\\n",
      ".group_by(group_by_columns=[],\n",
      "\t\t\taggregates={\t\"user_id_sum\"\t:\tsum_user_ids\t})order\tby\n",
      "frequentemente,\tvocê\tdesejará\tordenar\tseus\tresultados.\tpor\texemplo,\tvocê\tpode\n",
      "querer\tsaber\t(alfabeticamente)\tos\tdois\tprimeiros\tnomes\tde\tseus\tusuários:\n",
      "select\n",
      "\t*\t\n",
      "from\n",
      "\tusers\n",
      "order\tby\n",
      "\tname\n",
      "limit\n",
      "\t2;\n",
      "isso\té\tfácil\tde\timplementar\tusando\tnosso\tmétodo\t\n",
      "order_by()\n",
      "\tque\tpega\tuma\tfunção\n",
      "order:\n",
      "def\n",
      "\torder_by(self,\torder):\n",
      "new_table\t=\tself.select()\t\t\t\t\t\t\t\n",
      "#\tcria\tuma\tcópia\n",
      "new_table.rows.sort(key=order)\n",
      "return\n",
      "\tnew_table\n",
      "que\tpodemos\tusar\tcomo\tsegue:\n",
      "friendliest_letters\t=\tavg_friends_by_letter\t\\\n",
      ".order_by(\n",
      "lambda\n",
      "\trow:\t-row[\"avg_num_friends\"])\t\\\n",
      ".limit(4)\n",
      "o\t\n",
      "order\tby\n",
      "\tdo\tsql\tpermite\tque\tvocê\tespecifique\t\n",
      "asc\n",
      "\t(ascendente)\te\t\n",
      "desc\n",
      "(descendentes)\tpara\tcada\tcampo;\taqui\tteríamos\tque\tcolocar\tisso\tem\tnossa\tfunção\n",
      "order.join\n",
      "os\tbancos\tde\tdados\trelacionais\tsão\tfrequentemente\t\n",
      "normalizados\n",
      ",\to\tque\n",
      "significa\tque\tele\tsão\torganizados\tpara\tminimizar\tredundâncias.\tpor\texemplo,\n",
      "quando\ttrabalhamos\tcom\tinteresses\tde\tnossos\tusuários\tem\tpython\tpodemos\n",
      "apenas\tdar\ta\tcada\tusuário\tuma\tlista\tcontendo\tseus\tinteresses.\n",
      "tabelas\tsql\ttipicamente\tnão\tpodem\tconter\tlistas,\tentão\ta\tsolução\ttípica\té\tcriar\n",
      "uma\tsegunda\ttabela\t\n",
      "user_interests\n",
      "\tusando\to\trelacionamento\tum-para-muitos\tentre\n",
      "user_ids\n",
      "\te\tinteresses.\tem\tsql\tvocê\tpoderia\tfazer:\n",
      "create\ttable\n",
      "\tuser_interests\t(\n",
      "user_id\tint\t\n",
      "not\tnull\n",
      ",\n",
      "interest\tvarchar(100)\t\n",
      "not\tnull\n",
      ");\n",
      "mas\tem\tnotquiteabase\tvocê\tcriaria\ta\ttabela:\n",
      "user_interests\t=\ttable([\"user_id\",\t\"interest\"])\n",
      "user_interests.insert([0,\t\"sql\"])\n",
      "user_interests.insert([0,\t\"nosql\"])\n",
      "user_interests.insert([2,\t\"sql\"])\n",
      "user_interests.insert([2,\t\"mysql\"])\n",
      "ainda\thá\tmuita\tredundância\t—\to\t“sql”\tinteressado\testá\tarmazenado\tem\tdois\n",
      "lugares\tdiferentes.\tem\tum\tbanco\tde\tdados\treal\tvocê\ttalvez\tarmazenasse\t\n",
      "user_id\n",
      "\te\n",
      "interest_id\n",
      "\tna\ttabela\t\n",
      "user_interests\n",
      ",\te\tentão\tcriaria\tuma\tterceira\ttabela\t\n",
      "interests\n",
      "mapeando\t\n",
      "interest_id\n",
      "\tpara\t\n",
      "interest\n",
      "\ta\tfim\tde\tarmazenar\tcada\tnome\tde\tinteresse\tapenas\n",
      "uma\tvez.\taqui,\teles\tapenas\ttornariam\tnossos\texemplos\tmais\tcomplicados\tainda.\n",
      "quando\tnossos\tdados\testão\tem\tdiferentes\ttabelas,\tcomo\tos\tanalisamos?\tfazendo\n",
      "a\tjunção\tdas\tduas\ttabelas.\t\n",
      "join\n",
      "\tcombina\tlinhas\tna\ttabela\tà\tesquerda\tcom\tlinhas\n",
      "correspondentes\tna\ttabela\tda\tdireita,\tonde\to\tsignificado\tde\t“correspondente”\té\n",
      "baseado\tem\tcomo\tespecificamos\ta\tjunção.\n",
      "por\texemplo,\tpara\tencontrar\tusuários\tinteressados\tem\tsql\tvocê\tconsultaria:\n",
      "select\n",
      "\tusers.name\n",
      "from\n",
      "\tusers\n",
      "join\n",
      "\tuser_interests\n",
      "on\n",
      "\tusers.user_id\t=\tuser_interests.user_id\n",
      "where\n",
      "\tuser_interests.interest\t=\t'sql'join\n",
      "\tdiz\tque,\tpara\tcada\tlinha\tem\t\n",
      "user\n",
      ",\tdeveríamos\tver\to\t\n",
      "user_id\n",
      "\te\tassociar\ta\tlinha\n",
      "com\tcada\tlinha\tem\t\n",
      "user_interests\n",
      "\tcontendo\to\tmesmo\tuser_id.\n",
      "note\tque\ttivemos\tque\tespecificar\tquais\ttabelas\tusar\t\n",
      "join\n",
      "\te\tquais\tcolunas\tjuntar.\n",
      "este\té\tum\t\n",
      "inner\tjoin\n",
      ",\tque\tretorna\tas\tcombinações\tde\tlinhas\t(e\tapenas\tas\n",
      "combinações\tde\tlinhas)\tque\tcorrespondem\tde\tacordo\tcom\to\tcritério\tde\tjunção\n",
      "especificado.\n",
      "também\thá\to\t\n",
      "left\tjoin\n",
      ",\tque\t—\talém\tdas\tcombinações\tde\tlinhas\tcorrespondentes\n",
      "—\tretorna\tuma\tlinha\tpara\tcada\tlinha\tda\ttabela\tà\tesquerda\tsem\tlinhas\n",
      "correspondentes\t(nesse\tcaso,\tos\tcampos\tque\tdeveriam\tvir\tda\ttabela\ta\tdireita\n",
      "seriam\ttodos\t\n",
      "null\n",
      ").\n",
      "usando\tum\t\n",
      "left\tjoin\n",
      ",\té\tfácil\tcontar\to\tnúmero\tde\tinteresses\tde\tcada\tusuário:\n",
      "select\n",
      "\tusers.id,\t\n",
      "count\n",
      "(user_interests.interest)\t\n",
      "as\n",
      "\tnum_interests\n",
      "from\n",
      "\tusers\n",
      "left\tjoin\n",
      "\tuser_interests\n",
      "on\n",
      "\tusers.user_id\t=\tuser_interests.user_id\n",
      "left\tjoin\n",
      "\tcertifica\tque\tusuários\tsem\tinteresses\tainda\tterão\tlinhas\tno\tconjunto\tde\n",
      "dados\tunidos\t(com\tvalores\t\n",
      "null\n",
      "\tpara\tcampos\tprovenientes\tde\t\n",
      "user_interests\n",
      "),\te\n",
      "count\n",
      "\tapenas\tconta\tvalores\tque\tnão\tsão\t\n",
      "null.\n",
      "a\timplementação\t\n",
      "join()\n",
      "\tde\tnotquiteabase\tserá\tmais\trestritiva\t—\tela\n",
      "simplesmente\tfaz\ta\tjunção\tde\tduas\ttabelas\tem\tquaisquer\tcolunas\tque\telas\ttenham\n",
      "em\tcomum.\tmesmo\tassim,\tnão\té\ttrivial\tescrever:\n",
      "def\tjoin(self,\tother_table,\tleft_join=false):\n",
      "join_on_columns\t=\t[c\tfor\tc\tin\tself.columns\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "#\tcolunas\tem\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif\tc\tin\tother_table.columns]\t\t\t\t\t\t\t\n",
      "#\tambas\tas\ttabelas\n",
      "additional_columns\t=\t[c\tfor\tc\tin\tother_table.columns\t\t\n",
      "#\tcolunas\tapenas\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif\tc\tnot\tin\tjoin_on_columns]\t\t\t\t\n",
      "#\tna\ttabela\tà\tdireita\n",
      "#\ttodas\tas\tcolunas\tda\ttabela\tà\tesquerda\t+\tadditional_columns\tda\ttabela\tà\tdireita\n",
      "join_table\t=\ttable(self.columns\t+\tadditional_columns)\n",
      "for\trow\tin\tself.rows:\n",
      "def\tis_join(other_row):\n",
      "return\tall(other_row[c]\t==\trow[c]\tfor\tc\tin\tjoin_on_columns)\n",
      "other_rows\t=\tother_table.where(is_join).rows\n",
      "#\tcada\tlinha\tque\tcorresponda\ta\testa\tproduz\tuma\tlinha\tresultado\n",
      "for\tother_row\tin\tother_rows:join_table.insert([row[c]\tfor\tc\tin\tself.columns]\t+\n",
      "\t\t\t\t\t\t\t\t\t\t[other_row[c]\tfor\tc\tin\tadditional_columns])\n",
      "#\tse\tnenhuma\tlinha\tcorresponde\te\thá\tum\tleft\tjoin,\tsaída\tcom\tnone\n",
      "if\tleft_join\tand\tnot\tother_rows:\n",
      "join_table.insert([row[c]\tfor\tc\tin\tself.columns]\t+\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[none\t\n",
      "for\n",
      "\tc\t\n",
      "in\n",
      "\tadditional_columns])\n",
      "return\n",
      "\tjoin_table\n",
      "então,\tpodemos\tencontrar\tusuários\tinteressados\tem\tsql\tcom:\n",
      "sql_users\t=\tusers\t\\\n",
      ".join(user_interests)\t\\\n",
      ".where(\n",
      "lambda\n",
      "\trow:\trow[\"interest\"]\t==\t\"sql\")\t\\\n",
      ".select(keep_columns=[\"name\"])\n",
      "e\tconseguimos\tpegar\ta\tcontagem\tde\tinteresses\tcom:\n",
      "def\tcount_interests(rows):\n",
      "\"\"\"conta\tquantas\tlinhas\tnão\ttêm\tdiferente\tde\tinteresse\tnone\"\"\"\n",
      "return\tlen([row\tfor\trow\tin\trows\tif\trow[\"interest\"]\tis\tnot\tnone])\n",
      "user_interest_counts\t=\tusers\t\\\n",
      ".join(user_interests,\tleft_join=true)\t\\\n",
      ".group_by(group_by_columns=[\"user_id\"],\n",
      "\t\t\t\t\t\taggregates={\"num_interests\"\t:\tcount_interests\t})\n",
      "em\tsql\ttambém\thá\tum\t\n",
      "right\tjoin\n",
      ",\tque\tmantêm\tlinhas\tda\ttabela\ta\tdireita\tsem\n",
      "correspondentes\te\tum\t\n",
      "full\torder\tjoin\n",
      ",\tque\tmantêm\tlinhas\tde\tambas\ttabelas\tque\n",
      "não\tpossuem\tcorrespondentes.\tnão\timplementaremos\tnenhuma\tdessas.subconsultas\n",
      "em\tsql,\tvocê\tpode\tselecionar\t(\n",
      "select\n",
      ")\tde\t(e\tjuntar\t(\n",
      "join\n",
      "))\ta\tpartir\tde\tresultados\n",
      "de\tconsultas\tcomo\tse\telas\tfossem\ttabelas.\tentão,\tse\tvocê\tquiser\tencontrar\to\n",
      "menor\tuser_id\tde\talguém\tinteressado\tem\tsql,\tvocê\tpoderia\tusar\tuma\n",
      "subconsulta.\t(claro,\tvocê\tpoderia\tfazer\to\tmesmo\tcálculo\tusando\t\n",
      "join\n",
      ",\tmas\tnão\n",
      "ilustraria\tsubconsultas.)\n",
      "select\tmin\n",
      "(user_id)\t\n",
      "as\n",
      "\tmin_user_id\t\n",
      "from\n",
      "(\n",
      "select\n",
      "\tuser_id\t\n",
      "from\n",
      "\tuser_interests\t\n",
      "where\n",
      "\tinterest\t=\t'sql')\tsql_interests;\n",
      "da\tforma\tcomo\tcriamos\tnotquiteabase,\tconseguimos\tisso\tde\tgraça.\tnossos\n",
      "resultados\tde\tconsulta\tsão\ttabelas.\n",
      "likes_sql_user_ids\t=\tuser_interests\t\\\n",
      ".where(\n",
      "lambda\n",
      "\trow:\trow[\"interest\"]\t==\t\"sql\")\t\\\n",
      ".select(keep_columns=['user_id'])\n",
      "likes_sql_user_ids.group_by(group_by_columns=[],\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\taggregates={\t\"min_user_id\"\t:\tmin_user_id\t})índices\n",
      "para\tencontrar\tlinhas\tcontendo\tum\tvalor\tespecífico\t(digamos,\tem\tque\t\n",
      "name\n",
      "\té\n",
      "“hero”),\tnotquiteabase\tprecisa\tinspecionar\tcada\tlinha\tna\ttabela.\tse\ta\ttabela\n",
      "possui\tmuitas\tlinhas,\tisso\tpode\tdemorar\tmuito.\n",
      "de\tmaneira\tparecida,\tnosso\talgoritmo\t\n",
      "join\n",
      "\té\textremamente\tineficiente.\tpara\tcada\n",
      "linha\tna\ttabela\ta\tesquerda,\tele\tinspeciona\tcada\tlinha\tna\ttabela\ta\tdireita\tpara\tver\n",
      "se\té\tuma\tcombinação.\tcom\tduas\tgrandes\ttabelas\tisso\tpode\tdemorar\teternamente.\n",
      "também,\tvocê\tgeralmente\tgostaria\tde\taplicar\trestrições\ta\talgumas\tde\tsuas\n",
      "colunas.\tpor\texemplo,\tna\ttabela\t\n",
      "users\n",
      "\tvocê\tprovavelmente\tnão\tquer\tpermitir\tque\n",
      "dois\tusuários\tdiferentes\ttenham\to\tmesmo\t\n",
      "user_id\n",
      ".\n",
      "índices\tresolvem\ttodos\tesses\tproblemas.\tse\ta\ttabela\t\n",
      "user_interests\n",
      "\ttivesse\tum\tíndice\n",
      "em\t\n",
      "user_id\n",
      ",\tum\talgoritmo\t\n",
      "join\n",
      "\tpoderia\tencontrar\tcombinações\tdiretamente\tem\tvez\n",
      "de\tpesquisar\ta\ttabela\ttoda.\tse\ta\ttabela\t\n",
      "users\n",
      "\ttivesse\tum\t“único”\tíndice\tem\t\n",
      "user_id\n",
      ",\n",
      "você\treceberia\tum\terro\tse\ttentasse\tinserir\tuma\tcópia.\n",
      "cada\ttabela\tem\tum\tbanco\tde\tdados\tpode\tter\tum\tou\tmais\tíndices,\to\tque\tpermite\n",
      "que\tvocê\trapidamente\tencontre\tlinhas\tpor\tcolunas-chave,\teficientemente\tjunte\n",
      "tabelas\te\texecute\trestrições\túnicas\tem\tcolunas\tou\tcombinações\tde\tcolunas.\n",
      "planejar\te\tusar\tíndices\tbem\té\tum\ttipo\tde\tarte\tnegra\t(o\tque\tvaria\tdependendo\tdo\n",
      "banco\tde\tdados\tespecífico),\tmas\tse\tvocê\tfaz\tmuito\ttrabalho\tde\tbanco\tde\tdados,\n",
      "vale\ta\tpena\taprender.otimização\tde\tconsulta\n",
      "lembre-se\tda\tconsulta\t(consulta)\tpara\tencontrar\ttodos\tos\tusuários\tinteressados\n",
      "em\tsql:\n",
      "select\n",
      "\tusers.name\n",
      "from\n",
      "\tusers\n",
      "join\n",
      "\tuser_interests\n",
      "on\n",
      "\tusers.user_id\t=\tuser_interests.user_id\n",
      "where\n",
      "\tuser_interests.interest\t=\t'sql'\n",
      "em\tnotquiteabase\texiste\t(pelo\tmenos)\tduas\tmaneiras\tdiferentes\tpara\tescrever\n",
      "esta\tconsul-ta.\tvocê\tpoderia\tfiltrar\ta\ttabela\t\n",
      "user_interests\n",
      "\tfazendo\ta\tjunção:\n",
      "user_interests\t\\\n",
      ".where(\n",
      "lambda\n",
      "\trow:\trow[\"interest\"]\t==\t\"sql\")\t\\\n",
      ".join(users)\t\\\n",
      ".select([\"name\"])\n",
      "ou\tpoderia\tfiltrar\tos\tresultados\tda\tjunção:\n",
      "user_interests\t\\\n",
      ".join(users)\t\\\n",
      ".where(\n",
      "lambda\n",
      "\trow:\trow[\"interest\"]\t==\t\"sql\")\t\\\n",
      ".select([\"name\"])\n",
      "você\tacabaria\tcom\tos\tmesmos\tresultados\tde\tqualquer\tforma,\tmas\tfiltrar\tantes\tde\n",
      "juntar\té\tquase\tcertamente\tmais\teficiente,\tporque\tneste\tcaso\t\n",
      "join\n",
      "\ttem\tmenos\tlinhas\n",
      "para\toperar.\n",
      "em\tsql,\tvocê\tnão\tse\tpreocuparia\tcom\tisso\tno\tgeral.\tvocê\t“declara”\tos\n",
      "resultados\tque\tquer\te\tdeixa\tpara\to\tmotor\tde\tconsulta\texecutá-los\t(e\tusar\tíndices\n",
      "eficientemente).nosql\n",
      "uma\ttendência\trecente\tem\tbancos\tde\tdados\testá\tdirecionada\ta\tbancos\tde\tdados\n",
      "não\trelacionais\t“nosql”,\tque\tnão\trepresentam\tdados\tem\ttabelas.\tpor\texemplo,\n",
      "mongodb\té\tum\tfamoso\tbanco\tde\tdados\tsem\tdiagrama\tcujos\telementos\tsão\n",
      "arbitrariamente\tdocumentos\tjson\tcomplexos\tem\tvez\tde\tlinhas.\n",
      "existem\tbancos\tde\tdados\tde\tcolunas\tque\tarmazenam\tdados\tem\tcolunas\tem\tvez\n",
      "de\tlinhas\t(bons\tquando\tos\tdados\ttêm\tmuitas\tcolunas\tmas\tas\tconsultas\tprecisam\n",
      "de\tpoucas\tdelas),\tarmazenados\tvalores-chave\tque\tsão\totimizados\tpara\n",
      "recuperarem\tvalores\túnicos\t(complexos)\tpor\tsuas\tchaves,\tbancos\tde\tdados\tpara\n",
      "armazenar\te\tcriar\tgráficos\ttransversais,\tbancos\tde\tdados\tque\tsão\totimizados\tpara\n",
      "rodar\tem\tmúltiplos\tdatacenters,\tbancos\tde\tdados\tque\tsão\tfeitos\tpara\trodar\tna\n",
      "memória,\tbancos\tde\tdados\tpara\tarmazenar\tdados\tsérie\ttemporal\te\tcentenas\tde\n",
      "outros.\n",
      "a\tnovidade\tde\tamanhã\tpode\tainda\tnem\texistir,\tentão\teu\tnão\tposso\tfazer\tnada\n",
      "além\tde\tinformar\tque\tnosql\texiste.\tentão\tagora\tvocê\tsabe.\tele\texiste.•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "se\tvocê\tgostaria\tde\tfazer\tdownload\tde\tum\tbanco\tde\tdados\trelacional\tpara\n",
      "brincar,\tsqlite\t(\n",
      "http://www.sqlite.org\n",
      ")\té\trápido\te\tpequeno,\tenquanto\n",
      "mysql\t(\n",
      "http://www.mysql.com\n",
      ")\te\tpostgresql\n",
      "(\n",
      "http://www.postgresql.org\n",
      ")\tsão\tmaiores\te\tmais\tcomplicados.\ttodos\tsão\n",
      "gratuitos\te\tpossuem\tuma\tgrande\tdocumentação.\n",
      "se\tvocê\tquiser\texplorar\tnosql,\tmongodb\t(\n",
      "http://www.mongodb.org\n",
      ")\té\n",
      "bem\tsimples\tpara\tcomeçar,\to\tque\tpode\tser\tuma\tbenção\tou\tuma\tmaldição.\n",
      "ele\ttambém\ttem\tuma\tboa\tdocumentação.\n",
      "o\tartigo\tsobre\tnosql\tno\twikipédia\t(\n",
      "http://en.wikipedia.org/wiki/nosql\n",
      ")\n",
      "quase\tcertamente\tpossui\tlinks\tpara\tbancos\tde\tdados\tque\tnem\texistiam\n",
      "quando\teste\tlivro\tfoi\tescrito.1.\n",
      "2.\n",
      "3.\n",
      "capítulo\t24\n",
      "mapreduce\n",
      "o\tfuturo\tjá\tchegou.\tsó\tnão\tfoi\tdistribuído\tigualmente\tainda\n",
      ".\n",
      "—william\tgibson\n",
      "mapreduce\té\tum\tmodelo\tde\tprogramação\tpara\trealizar\tprocessamento\tparalelo\n",
      "em\tgrandes\tconjuntos\tde\tdados.\tembora\tseja\tuma\ttécnica\tpoderosa,\tsua\tbase\té\n",
      "relativamente\tsimples.\n",
      "imagine\tque\ttemos\tuma\tcoleção\tde\titens\tque\tgostaríamos\tde\tprocessar.\tpor\n",
      "exemplo,\tos\titens\tpodem\tser\tlogs\tde\tweb\tsite,\ttextos\tde\tlivros\tvariados,\tarquivos\n",
      "de\timagens\tou\tqualquer\toutra\tcoisa.\tuma\tversão\tbásica\tdo\talgoritmo\n",
      "mapreduce\tconsiste\tdos\tseguintes\tpassos:\n",
      "use\tuma\tfunção\t\n",
      "mapper\n",
      "\tpara\ttransformar\tcada\titem\tem\tzero\tou\tmais\tpares\n",
      "chave-valor.\t(é\tchamado\tcom\tfrequência\tde\tfunção\t\n",
      "map\n",
      ",\tporém\tjá\texiste\n",
      "uma\tfunção\tpython\tchamada\t\n",
      "map\n",
      "\te\tnão\tdevemos\tconfundir\tas\tduas.)\n",
      "junte\ttodos\tos\tpares\tcom\tchaves\tidênticas.\n",
      "use\tuma\tfunção\t\n",
      "reducer\n",
      "\tem\tcada\tcoleção\tde\tvalores\tagrupados\tpara\tproduzir\n",
      "valores\tde\tsaída\tpara\ta\tchave\tcorrespondente.\n",
      "isso\ttudo\té\tum\tpouco\tabstrato,\tentão\tvamos\tver\tum\texemplo\tespecífico.\thá\n",
      "poucas\tregras\tabsolutas\tde\tdata\tscience\tmas\tuma\tdelas\té\tque\tseu\tprimeiro\n",
      "exemplo\tmapreduce\tdeve\tenvolver\tcontagem\tde\tpalavras.exemplo:\tcontagem\tde\tpalavras\n",
      "datasciencester\tcresceu\tpara\tmilhões\tde\tusuários!\tisso\té\tótimo\tpara\ta\tsegurança\n",
      "do\tseu\temprego\tmas\tdificulta\tum\tpouco\ta\tanálise\tde\trotina.\n",
      "por\texemplo,\ta\tvice-presidente\tde\tconteúdo\tquer\tque\tvocê\tsaiba\tsobre\to\tque\tas\n",
      "pessoas\testão\tfalando\tem\tsuas\tatualizações\tde\tstatus.\tcomo\tprimeira\ttentativa,\n",
      "você\tdecide\tcontar\tas\tpalavras\tque\taparecem,\tpara\tque\tvocê\tpossa\tpreparar\tum\n",
      "relato\tsobre\tos\tmais\tfrequentes.\n",
      "quando\tvocê\ttinha\tpoucas\tcentenas\tde\tusuários\tisso\tera\tsimples\tde\tfazer:\n",
      "def\n",
      "\tword_count_old(documents):\n",
      "\"\"\"contagem\tde\tpalavras\tsem\tusar\tmapreduce\"\"\"\n",
      "return\n",
      "\tcounter(word\n",
      "for\n",
      "\tdocument\t\n",
      "in\n",
      "\tdocuments\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\ttokenize(document))\n",
      "com\tmilhões\tde\tusuários,\to\tconjunto\tde\t\n",
      "documents\n",
      "\t(atualizações\tde\tstatus)\té\tmuito\n",
      "grande\tpara\tcaber\tno\tseu\tcomputador.\tse\tvocê\tpuder\tencaixar\tisso\tno\tmodelo\n",
      "mapreduce,\tpode\tusar\talguma\tinfraestrutura\t“big\tdata”\tque\tseus\tengenheiros\n",
      "implementaram.\n",
      "primeiro,\tqueremos\tuma\tfunção\tque\ttransforme\tum\tdocumento\tem\tuma\n",
      "sequência\tde\tpares\tchave-valor.\tnós\tqueremos\tque\tnossa\tsaída\tseja\tagrupada\tpor\n",
      "palavra,\to\tque\tsignifica\tque\tas\tchaves\tdeveriam\tser\tpalavras.\te\tpara\tcada\n",
      "palavra,\tapenas\temitiremos\to\tvalor\t1\tpara\tindicar\tque\teste\tpar\tcorresponde\ta\n",
      "uma\tocorrência\tda\tpalavra:\n",
      "def\n",
      "\twc_mapper(document):\n",
      "\"\"\"para\tcada\tpalavra\tno\tdocumento,\temite\t(word,\t1)\"\"\"\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\ttokenize(document):\n",
      "yield\n",
      "\t(word,\t1)\n",
      "pulando\to\tpasso\t2\tpor\tenquanto,\timagine\tque\tpara\talguma\tpalavra\tnós\tcoletamos\n",
      "uma\tlista\tde\tcontas\tcorrespondentes\tàs\tque\temitimos.\tentão\tpara\tproduzir\ta\n",
      "contagem\ttotal\tpara\taquela\tpalavra,\tapenas\tprecisamos:\n",
      "def\n",
      "\twc_reducer(word,\tcounts):\n",
      "\"\"\"soma\tas\tcontagens\tpara\tuma\tpalavra\"\"\"\n",
      "yield\n",
      "\t(word,\tsum(counts))retornando\tao\tpasso\t2,\tagora\tprecisamos\tcoletar\tos\tresultados\tde\t\n",
      "wc_mapper\n",
      "\te\n",
      "fornecê-los\ta\t\n",
      "wc_reducer\n",
      ".\tvamos\tpensar\tsobre\to\tque\tfaríamos\tem\tapenas\tum\n",
      "computador:\n",
      "def\n",
      "\tword_count(documents):\n",
      "\"\"\"conta\tas\tpalavras\tnos\tdocumentos\tde\tsaída\tusando\tmapreduce\"\"\"\n",
      "#\tlugar\tpara\tarmazenar\tvalores\tagrupados\n",
      "\tcollector\t=\tdefaultdict(list)\n",
      "for\n",
      "\tdocument\t\n",
      "in\n",
      "\tdocuments:\n",
      "for\n",
      "\tword,\tcount\t\n",
      "in\n",
      "\twc_mapper(document):\n",
      "collector[word].append(count)\n",
      "return\n",
      "\t[output\n",
      "for\n",
      "\tword,\tcounts\t\n",
      "in\n",
      "\tcollector.iteritems()\n",
      "for\n",
      "\toutput\t\n",
      "in\n",
      "\twc_reducer(word,\tcounts)]\n",
      "imagine\tque\ttemos\ttrês\tdocumentos\t\n",
      "[“data\tscience”,\t“big\tdata”,\t“science\tfiction”]\n",
      ".\n",
      "então\t\n",
      "wc_mapper\n",
      "\taplicado\tao\tprimeiro\tdocumento\tdá\tpreferência\taos\tdois\tpares\n",
      "(“data”,\t1)\n",
      "\te\t\n",
      "(“science”,\t1)\n",
      ".\tdepois\tque\tnós\tpassamos\tpor\ttodos\tos\ttrês\tdocumentos,\to\n",
      "collector\n",
      "\tcontém\n",
      "{\t\"data\"\t:\t[1,\t1],\n",
      "\t\t\t\"science\"\t:\t[1,\t1],\n",
      "\t\t\t\"big\"\t:\t[1],\n",
      "\t\t\t\"fiction\"\t:\t[1]\t}\n",
      "então\t\n",
      "wc_reducer\n",
      "\tproduz\ta\tconta\tpara\tcada\tpalavra:\n",
      "[(\"data\",\t2),\t(\"science\",\t2),\t(\"big\",\t1),\t(\"fiction\",\t1)]•\n",
      "•\n",
      "•\n",
      "•\n",
      "por\tque\tmapreduce?\n",
      "como\tmencionado\tanteriormente,\to\tprincipal\tbenefício\tde\tmapreduce\té\tque\tele\n",
      "permite\tque\tdistribuamos\tcomputações\tmovendo\to\tprocessamento\taos\tdados.\n",
      "imagine\tque\tqueremos\tcontar\tpalavras\tem\tbilhões\tde\tdocumentos.\n",
      "nossa\tabordagem\toriginal\t(não\tmapreduce)\trequer\tque\ta\tmáquina\tque\testá\n",
      "fazendo\to\tprocessamento\ttenha\tacesso\ta\ttodos\tos\tdocumentos.\tisso\tsignifica\tque\n",
      "todos\tos\tdocumentos\tprecisam\tviver\tna\tmáquina\tou\tser\ttransferidos\tpara\tela\n",
      "durante\to\tprocessamento.\tmais\timportante,\tsignifica\tque\ta\tmáquina\tpode\tapenas\n",
      "processar\tum\tdocumento\tpor\tvez.\n",
      "possivelmente,\tele\tprocessa\taté\talguns\tpor\tvez\tse\ttiver\tmúltiplos\tnúcleos\te\tse\to\n",
      "código\tfor\treescrito\tpara\tlevar\tvantagem\tsobre\teles.\tmas\tmesmo\tassim,\ttodos\tos\n",
      "documentos\tainda\ttêm\tque\tchegar\tnaquela\tmáquina.\n",
      "imagine\tagora\tque\tnossos\tbilhões\tde\tdocumentos\testão\tespalhados\tpor\t100\n",
      "máquinas.\tcom\ta\tinfraestrutura\tcerta,\tpodemos\tfazer\to\tseguinte:\n",
      "faça\ta\tmáquina\trodar\to\tmapeador\t(\n",
      "mapper\n",
      ")\tem\tseus\tdocumentos,\n",
      "produzindo\tmuitos\tpares\t(chave-valor).\n",
      "distribua\taqueles\tpares\t(chave,\tvalor)\tem\tum\tnúmero\tde\tmáquinas\n",
      "redutoras,\tcertificando\tque\tos\tpares\tcorrespondentes\ta\tqualquer\tchave\n",
      "terminem\tna\tmesma\tmáquina.\n",
      "faça\tcada\tmáquina\tredutora\tagrupar\tos\tpares\tpor\tchave\te\tentão\trodar\to\n",
      "redutor\tem\tcada\tconjunto\tde\tvalores.\n",
      "retorne\tcada\tpar\t(chave,\tsaída).\n",
      "o\tque\té\texcelente\tnisso\té\tque\tele\tescala\thorizontalmente.\tse\tdobrarmos\to\n",
      "número\tde\tmáquinas\t(ignorando\tcertos\tcustos\tfixos\tde\trodar\to\tsistema\n",
      "mapreduce),\tentão\tnossa\tcomputação\tdeveria\trodar\taproximadamente\tduas\n",
      "vezes\tmais\trápido.\tcada\tmáquina\tmapeadora\tprecisará\tfazer\tapenas\tmetade\tdo\n",
      "trabalho\t(assumindo\tque\thá\tchaves\tdistintas\to\tsuficiente\tpara\tdistribuir\tainda\n",
      "mais\to\ttrabalho\tdo\tredutor)\te\to\tmesmo\té\tverdade\tpara\tmáquinas\tredutoras.mapreduce\tmais\tgeneralizado\n",
      "se\tvocê\tpensar\tnisso\tpor\tum\tminuto,\ttodo\to\tcódigo\tespecífico\tpara\tcontagem\tde\n",
      "palavra\tno\texemplo\tanterior\testá\tcontido\tnas\tfunções\t\n",
      "wc_mapper\n",
      "\te\t\n",
      "wc_reducer\n",
      ".\tisso\n",
      "significa\tque\tcom\talgumas\tmudanças\tnós\ttemos\tum\tframework\tmuito\tmais\tgeral\n",
      "(que\tainda\troda\tem\tuma\túnica\tmáquina):\n",
      "def\n",
      "\tmap_reduce(inputs,\tmapper,\treducer):\n",
      "\"\"\"roda\tmapreduce\tnas\tentradas\tusando\tmapper\te\treducer\"\"\"\n",
      "collector\t=\tdefaultdict(list)\n",
      "for\n",
      "\tinput\t\n",
      "in\n",
      "\tinputs:\n",
      "for\n",
      "\tkey,\tvalue\t\n",
      "in\n",
      "\tmapper(input):\n",
      "collector[key].append(value)\n",
      "return\n",
      "\t[output\n",
      "for\n",
      "\tkey,\tvalues\t\n",
      "in\n",
      "\tcollector.iteritems()\n",
      "for\n",
      "\toutput\t\n",
      "in\n",
      "\treducer(key,values)]\n",
      "e\tentão\tpodemos\tcontar\tpalavras\tsimplesmente\tusando:\n",
      "word_counts\t=\tmap_reduce(documents,\twc_mapper,\twc_reducer)\n",
      "isso\tnos\tdá\ta\tflexibilidade\tde\tresolver\tuma\tgrande\tvariedade\tde\tproblemas.\n",
      "antes\tde\tcontinuarmos,\tobserve\tque\t\n",
      "wc_reducer\n",
      "\testá\tapenas\tsomando\tos\tvalores\n",
      "correspondentes\ta\tcada\tchave.\tesse\ttipo\tde\tagregação\té\ttão\tcomum\tque\tvale\ta\n",
      "pena\tabstrair:\n",
      "def\n",
      "\treduce_values_using(aggregation_fn,\tkey,\tvalues):\n",
      "\"\"\"reduz\tum\tpar\tchave-valor\taplicando\taggregation_fn\taos\tvalores\"\"\"\n",
      "yield\n",
      "\t(key,\taggregation_fn(values))\n",
      "def\n",
      "\tvalues_reducer(aggregation_fn):\n",
      "\"\"\"transforma\tuma\tfunção\t(valores\n",
      "\t->\t\n",
      "saída)\tem\tuma\tredutora\n",
      "que\tmapeia\t(chave,\tvalor)\n",
      "\t->\t\n",
      "(chave,\tsaída)\"\"\"\n",
      "return\n",
      "\tpartial(reduce_values_using,\taggregation_fn)\n",
      "após\to\tque\tpodemos\tfacilmente\tcriar:\n",
      "sum_reducer\t=\tvalues_reducer(sum)\n",
      "max_reducer\t=\tvalues_reducer(max)\n",
      "min_reducer\t=\tvalues_reducer(min)\n",
      "count_distinct_reducer\t=\tvalues_reducer(\n",
      "lambda\n",
      "\tvalues:\tlen(set(values)))\n",
      "e\tassim\tpor\tdiante.•\n",
      "•\n",
      "•\n",
      "exemplo:\tanalisando\tatualizações\tde\tstatus\n",
      "a\tvice-presidente\tde\tconteúdo\tficou\timpressionada\tcom\ta\tcontagem\tde\tpalavras\n",
      "e\tpergunta\to\tque\tmais\tvocê\tpode\taprender\tdas\tatualizações\tde\tstatus\tdas\tpessoas.\n",
      "você\tconsegue\textrair\tum\tconjunto\tde\tdados\tde\tatualizações\tde\tstatus\tque\tse\n",
      "parecem\tcom:\n",
      "{\"id\":\t1,\n",
      "\t\t\"username\"\t:\t\"joelgrus\",\n",
      "\t\t\"text\"\t:\t\"is\tanyone\tinterested\tin\ta\tdata\tscience\tbook?\",\n",
      "\t\t\"created_at\"\t:\tdatetime.datetime(2013,\t12,\t21,\t11,\t47,\t0),\n",
      "\t\t\"liked_by\"\t:\t[\"data_guy\",\t\"data_gal\",\t\"mike\"]\t}\n",
      "digamos\tque\tprecisamos\tdescobrir\tque\tdia\tda\tsemana\tas\tpessoas\tmais\tfalam\n",
      "sobre\tdata\tscience.\tpara\tdescobrir\tisso,\tapenas\tcontaremos\tquantas\tatualizações\n",
      "de\tdata\tscience\texistem\tem\tcada\tdia.\tisso\tsignifica\tque\tprecisaremos\tagrupar\tpor\n",
      "dia\tda\tsemana,\tentão\tessa\té\tnossa\tchave.\te\tse\temitirmos\tum\tvalor\tde\t\n",
      "1\n",
      "\tpara\tcada\n",
      "atualização\tque\tcontém\t“data\tscience”,\tnós\tpodemos\tsimplesmente\tconseguir\ta\n",
      "soma\ttotal\tusando\t\n",
      "sum:\n",
      "def\tdata_science_day_mapper(status_update):\n",
      "\"\"\"produz\t(day_of_week,\t1)\tse\tstatus_update\tcontém\t“data\tscience\"\t\"\"\"\n",
      "if\t\"data\tscience\"\tin\tstatus_update[\"text\"].lower():\n",
      "day_of_week\t=\tstatus_update[\"created_at\"].weekday()\n",
      "yield\t(day_of_week,\t1)\n",
      "data_science_days\t=\tmap_reduce(status_updates,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdata_science_day_mapper,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsum_reducer)\n",
      "como\tum\texemplo\tum\tpouco\tdiferente,\timagine\tque\tprecisamos\tdescobrir\ta\n",
      "palavra\tmais\tcomum\tque\tcada\tusuário\tcoloca\tem\tsuas\tatualizações\tde\tstatus.\thá\n",
      "três\tabordagens\tpossíveis\tque\tsurgem\tna\tmente\tpara\t\n",
      "mapper:\n",
      "coloque\to\tnome\tde\tusuário\tna\tchave;\tcoloque\tas\tpalavras\te\tcontagens\tnos\n",
      "valores.\n",
      "coloque\ta\tpalavra\tna\tchave;\tcoloque\tos\tnomes\tde\tusuários\tnos\tvalores.\n",
      "coloque\to\tnome\tde\tusuário\te\tpalavra\tna\tchave;\tcoloque\tas\tcontagens\tnos\n",
      "valores.\n",
      "se\tvocê\tpensar\tum\tpouco\tmais\tsobre\tisso,\tnós\tdefinitivamente\tqueremos\tagruparpor\t\n",
      "username\n",
      ",\tporque\tnós\tqueremos\tconsiderar\tas\tpalavras\tde\tcada\tpessoa\n",
      "separadamente.\te\tnós\tnão\tqueremos\tagrupar\tpor\tpalavra,\tjá\tque\tnosso\tredutor\n",
      "precisará\tver\ttodas\tas\tpalavras\tpara\tcada\tpessoa\tpara\tdescobrir\tqual\té\ta\tmais\n",
      "popular.\tisso\tsignifica\tque\ta\tprimeira\topção\té\ta\topção\tcerta:\n",
      "def\n",
      "\twords_per_user_mapper(status_update):\n",
      "user\t=\tstatus_update[\"username\"]\n",
      "for\n",
      "\tword\t\n",
      "in\n",
      "\ttokenize(status_update[\"text\"]):\n",
      "yield\n",
      "\t(user,\t(word,\t1))\n",
      "def\tmost_popular_word_reducer(user,\twords_and_counts):\n",
      "\"\"\"dada\tuma\tsequência\tde\tpares\t(palavra,\tcontagem)\n",
      ",\n",
      "retorna\ta\tpalavra\tcom\ta\tmaior\tcontagem\ttotal\"\"\"\n",
      "word_counts\t=\tcounter()\n",
      "for\tword,\tcount\tin\twords_and_counts:\n",
      "word_counts[word]\t+=\tcount\n",
      "word,\tcount\t=\tword_counts.most_common(1)[0]\n",
      "yield\t(user,\t(word,\tcount))\n",
      "user_words\t=\tmap_reduce(status_updates,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twords_per_user_mapper,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmost_popular_word_reducer)\n",
      "ou\tpoderíamos\tdescobrir\to\tnúmero\tde\tdiferentes\tcurtições\tde\tstatus\tpara\tcada\n",
      "usuário:\n",
      "def\n",
      "\tliker_mapper(status_update):\n",
      "user\t=\tstatus_update[\"username\"]\n",
      "for\n",
      "\tliker\t\n",
      "in\n",
      "\tstatus_update[\"liked_by\"]:\n",
      "yield\n",
      "\t(user,\tliker)\n",
      "distinct_likers_per_user\t=\tmap_reduce(status_updates,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tliker_mapper,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcount_distinct_reducer)exemplo:\tmultiplicação\tde\tmatriz\n",
      "lembre-se\tde\t“multiplicação\tde\tmatriz”\tna\tpágina\t260\tque\tdada\tuma\tmatriz\ta\n",
      "m\n",
      "\t×\t\n",
      "n\n",
      "\te\tuma\tmatriz\tb\t\n",
      "m\n",
      "\t×\t\n",
      "k\n",
      ",\tpodemos\tmultiplicá-las\tpara\tformar\tuma\tmatriz\tc\n",
      "m\n",
      "\t×\t\n",
      "k\n",
      ",\tem\tque\to\telemento\tde\t\n",
      "c\n",
      "\tna\tfileira\t\n",
      "i\n",
      "\te\tcoluna\t\n",
      "j\n",
      "\té\tdado\tpor:\n",
      "como\tvimos,\tuma\tforma\t“natural”\tde\trepresentar\tuma\tmatriz\t\n",
      "m\n",
      "\t×\t\n",
      "n\n",
      "\té\tcom\tuma\n",
      "lista\tde\tlistas,\tonde\to\telemento\ta\n",
      "ij\n",
      "\té\to\telemento\tj-ésimo\tda\tlista\ti-ésima.\n",
      "mas\tgrandes\tmatrizes,\tàs\tvezes,\tsão\t\n",
      "esparsas\n",
      ",\to\tque\tsignifica\tque\ta\tmaioria\tde\n",
      "seus\telementos\tsão\tiguais\ta\tzero.\tpara\tgrandes\tmatrizes\tesparsas,\tuma\tlista\tde\n",
      "listas\tpode\tser\tuma\trepresentação\tinútil.\tuma\trepresentação\tmais\tcompacta\té\n",
      "uma\tlista\tde\t\n",
      "tuples\t(name,\ti,\tj,\tvalue)\n",
      "\tonde\t\n",
      "name\n",
      "\tidentifica\ta\tmatriz\te\tonde\t\n",
      "i\n",
      ",\t\n",
      "j\n",
      ",\t\n",
      "value\n",
      "indica\ta\tlocalização\tcom\tvalor\tnão\tzero.\n",
      "por\texemplo,\tuma\tmatriz\tbilhão\tx\tbilhão\tpossui\tum\t\n",
      "quintilhão\n",
      "\tde\tentradas,\tque\n",
      "não\tseriam\tfáceis\tde\tarmazenar\tem\tum\tcomputador.\tmas\tse\thá\tapenas\talgumas\n",
      "entradas\tnão\tzero\tem\tcada\tfileira,\tessa\trepresentação\talternativa\té\tmuito\tmenor.\n",
      "dado\tesse\ttipo\tde\trepresentação,\tpodemos\tusar\tmapreduce\tpara\texecutar\ta\n",
      "multiplicação\tde\tmatriz\tde\tuma\tmaneira\tdistribuída.\n",
      "para\tmotivar\tnosso\talgoritmo,\tnote\tque\tcada\telemento\ta\n",
      "ij\n",
      "\té\tusado\tapenas\tpara\n",
      "computar\telementos\tde\t\n",
      "c\n",
      "\tna\tfileira\t\n",
      "i\n",
      ",\te\tcada\telemento\tb\n",
      "ij\n",
      "\té\tusado\tapenas\tpara\n",
      "computar\tos\telementos\tde\t\n",
      "c\n",
      "\tna\tcoluna\t\n",
      "j\n",
      ".\tnosso\tobjetivo\tserá\tpara\tcada\tsaída\tdo\n",
      "nosso\t\n",
      "reducer\n",
      "\tser\tuma\tentrada\túnica\tde\t\n",
      "c\n",
      ",\to\tque\tsignifica\tque\tprecisaremos\tque\n",
      "nosso\t\n",
      "mapper\n",
      "\temita\tchaves\tidentificando\tuma\túnica\tentrada\tde\t\n",
      "c\n",
      ".\tisso\tsugere\to\n",
      "seguinte:\n",
      "def\tmatrix_multiply_mapper(m,\telement):\n",
      "\"\"\"m\té\ta\tdimensão\tcomum\t(colunas\tde\ta,\tlinhas\tde\tb)\n",
      "elemento\té\tuma\ttupla\t(matrix_name,\ti,\tj,\tvalue)\"\"\"\n",
      "name,\ti,\tj,\tvalue\t=\telement\n",
      "if\tname\t==\t\"a\":\n",
      "#\ta_ij\té\ta\tj-ésima\tentrada\tna\tsoma\tde\tcada\tc_ik,\tk=1..m\n",
      "for\tk\tin\trange(m):\n",
      "\t\n",
      "#\tagrupada\tcom\toutras\tentradas\tpara\tc_ik\tyield((i,\tk),\t(j,\tvalue))\n",
      "else:\n",
      "#\tb_ij\té\ta\ti-ésima\tentrada\tna\tsoma\tde\tcada\tc_kj\n",
      "for\tk\tin\trange(m):\n",
      "\t\n",
      "#\tagrupada\tcom\toutras\tentradas\tpara\tc_k\n",
      "\tyield((k,\tj),\t(i,\tvalue))\n",
      "def\tmatrix_multiply_reducer(m,\tkey,\tindexed_values):\n",
      "results_by_index\t=\tdefaultdict(list)\n",
      "for\tindex,\tvalue\tin\tindexed_values:\n",
      "\tresults_by_index[index].append(value)\n",
      "#\tsoma\ttodos\tos\tprodutos\tdas\tposições\tcom\tdois\tresultados\n",
      "sum_product\t=\tsum(results[0]\t*\tresults[1]\n",
      "\t\t\t\t\t\tfor\tresults\tin\tresults_by_index.values()\n",
      "\t\t\t\t\t\tif\tlen(results)\t==\t2)\n",
      "if\tsum_product\t!=\t0.0:\n",
      "yield\t(key,\tsum_product)\n",
      "por\texemplo,\tse\tvocê\ttivesse\tas\tduas\tmatrizes\n",
      "a\t=\t[[3,\t2,\t0],\n",
      "\t\t[0,\t0,\t0]]\n",
      "b\t=\t[[4,\t-1,\t0],\n",
      "\t\t[10,\t0,\t0],\n",
      "\t\t[0,\t0,\t0]]\n",
      "você\tpoderia\treescrevê-las\tcomo\ttuplas:\n",
      "entries\t=\t[(\"a\",\t0,\t0,\t3),\t(\"a\",\t0,\t1,\t2),\n",
      "\t\t\t\t(\"b\",\t0,\t0,\t4),\t(\"b\",\t0,\t1,\t-1),\t(\"b\",\t1,\t0,\t10)]\n",
      "mapper\t=\tpartial(matrix_multiply_mapper,\t3)\n",
      "reducer\t=\tpartial(matrix_multiply_reducer,\t3)\n",
      "map_reduce(entries,\tmapper,\treducer)\t#\t[((0,\t1),\t-3),\t((0,\t0),\t32)]\n",
      "isso\tnão\té\tinteressante\tem\tmatrizes\tpequenas\tmas\tse\tvocê\ttivesse\tmilhões\tde\n",
      "fileiras\te\tmilhões\tde\tcolunas,\tisso\tpoderia\tajudar\tmuito.um\tadendo:\tcombinadores\n",
      "uma\tcoisa\tque\tvocê\tprovavelmente\tnotou\té\tque\tmuitos\tdos\tnossos\tmapeadores\n",
      "parecem\tincluir\tum\tmonte\tde\tinformação\textra.\tpor\texemplo,\tao\tcontar\tpalavras,\n",
      "em\tvez\tde\temitir\t\n",
      "(word,\t1)\n",
      "\te\tsomar\tos\tvalores,\tpoderíamos\temitir\t\n",
      "(word,\tnone)\n",
      "\te\n",
      "apenas\tpegar\to\ttamanho.\n",
      "uma\trazão\tpela\tqual\tnão\tfizemos\tisso\té\tque,\tna\tconfiguração\tdistribuída,\tàs\n",
      "vezes\tqueremos\tusar\t\n",
      "combinadores\n",
      "\tpara\treduzir\ta\tquantidade\tde\tdados\tque\ttêm\n",
      "que\tser\ttransferidos\tde\tmáquina\tpara\tmáquina.\tse\tuma\tde\tnossas\tmáquinas\n",
      "mapeadoras\tvêm\ta\tpalavra\t“data”\t500\tvezes,\tpodemos\tdizer\tpara\tela\tcombinar\n",
      "500\tinstâncias\tde\t\n",
      "(“data”,\t1)\n",
      "\tem\tuma\túnica\t\n",
      "(“data”,\t500)\n",
      "\tantes\tde\tentregar\tpara\ta\n",
      "máquina\tredutora.\tisso\tresulta\tem\tmuito\tmenos\tdados\tsendo\tmovidos,\to\tque\n",
      "pode\tdeixar\tnosso\talgoritmo\tainda\tmais\trápido.\n",
      "pela\tforma\tcomo\tescrevemos\tnosso\tredutor,\tele\tlidaria\tcom\tesses\tdados\n",
      "combinados\tcorretamente.\t(se\ttivéssemos\tescrito\tusando\t\n",
      "len\n",
      ",\tnão\tfaria.)•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "para\tmais\tesclarecimentos\n",
      "o\tsistema\tmapreduce\tmais\tusado\té\thadoop\t(\n",
      "http://hadoop.apache.org\n",
      "),\n",
      "que\ttem\tmérito\tem\tmuitos\tlivros.\thá\tvárias\tdistribuições\tcomerciais\te\tnão\n",
      "comerciais\te\tum\tgrande\tecossistema\tde\tferramentas\trelacionadas\ta\n",
      "hadoop.\n",
      "para\tusá-lo,\tvocê\tdeve\tconfigurar\tseu\tpróprio\t\n",
      "cluster\n",
      "\t(ou\tencontrar\talguém\n",
      "que\tdeixe\tvocê\tusar\to\tdele),\to\tque\tnão\té\tnecessariamente\tuma\ttarefa\tpara\n",
      "os\tfracos\tde\tcoração.\tmapeadores\te\tredutores\thadoop\tsão\tcomumente\n",
      "escritos\tem\tjava,\tembora\texista\tuma\tfacilidade\tconhecida\tcomo\t“hadoop\n",
      "streaming”\tque\tlhe\tpermite\tescrevê-las\tem\toutras\tlinguagens\t(incluindo\n",
      "python).\n",
      "a\tamazon\toferece\tum\tserviço\telastic\tmapreduce\n",
      "(\n",
      "http://aws.amazon.com/elasticmapreduce\n",
      "/\n",
      ")\tque\tpode\tcriar\te\tdestruir\n",
      "clusters,\tcobrando\tde\tvocê\tapenas\tpelo\ttempo\tque\tvocê\tos\tutiliza.\n",
      "mrjob\té\tum\tpacote\tpython\tpara\tinterface\tcom\thadoop\t(ou\telastic\n",
      "mapreduce).\n",
      "trabalhos\thadoop\tsão\ttipicamente\tde\talta\tlatência,\to\tque\tos\ttorna\tuma\n",
      "escolha\truim\tpara\tanálises\tem\t“tempo\treal”.\thá\tvárias\tferramentas\tde\n",
      "“tempo\treal”\t\n",
      "construídas\tsobre\thadoop,\tmas\ttambém\thá\tmuito\n",
      "frameworks\talternativos\tque\testão\tficando\tmais\tpopulares.\tdois\tdos\tmais\n",
      "populares\tsão\tspark\t(\n",
      "http://spark.apache.org\n",
      "/\n",
      ")\te\tstorm\n",
      "(\n",
      "http://storm.incubator.apache.org\n",
      "/\n",
      ").\n",
      "agora\té\tbem\tprovável\tque\ta\tnovidade\tdo\tdia\tseja\talgum\tframework\tque\n",
      "nem\texistia\tquando\teste\tlivro\tfoi\tescrito.\tvocê\tterá\tque\tdescobrir\tsozinho.capítulo\t25\n",
      "vá\tem\tfrente\te\tpratique\tdata\tscience\n",
      "e\tagora,\tmais\tuma\tvez,\teu\tordeno\ta\tminha\thedionda\tprole\tque\tsiga\tem\tfrente\te\tprospere\n",
      ".\n",
      "—mary\tshelley\n",
      "para\tonde\tvocê\tvai\tdaqui?\tsupondo\tque\teu\tnão\tassustei\tvocê\tcom\tdata\tscience,\n",
      "há\tum\tgrande\tnúmero\tde\tcoisas\tque\tvocê\tdeveria\taprender\tem\tseguida.ipython\n",
      "nós\tmencionamos\tipython\t(\n",
      "http://ipython.org\n",
      "/\n",
      ")\tanteriormente\tno\tlivro.\tele\n",
      "fornece\tum\tshell\tcom\tmuito\tmais\tfuncionalidades\tdo\tque\to\tshell\tpadrão\tpython\n",
      "e\tadiciona\t“funções\tmágicas”\tque\tpermitem\tque\tvocê\t(dentre\toutras\tcoisas)\n",
      "copie\te\tcole\to\tcódigo\t(que\té\tnormalmente\tcomplicado\tpela\tcombinação\tde\n",
      "formatação\tcom\tlinhas\tvazias\te\tespaços\tem\tbrancos)\te\trode\tscripts\tde\tdentro\tdo\n",
      "shell.\n",
      "tornar-se\tum\tespecialista\tem\tipython\tfacilitará\tmais\ta\tsua\tvida.\t(até\tmesmo\n",
      "aprender\tum\tpouquinho\tde\tipython\ttornará\tsua\tvida\tmuito\tmais\tfácil.)\n",
      "além\tdo\tmais,\tele\tpermite\tque\tvocê\tcrie\t“cadernos”\tcombinando\ttexto,\tcódigo\n",
      "python\tvivo\te\tvisualizações\tque\tvocê\tpode\tcompartilhar\tcom\toutras\tpessoas,\tou\n",
      "apenas\tmanter\tcomo\tum\tdiário\tdo\tque\tvocê\tfez\t(\n",
      "figura\t25-1\n",
      ").\n",
      "figura\t25-1.\tum\tcaderno\tipythonmatemática\n",
      "ao\tlongo\tdo\tlivro,\tnós\texploramos\tálgebra\tlinear\t(\n",
      "capítulo\t4\n",
      "),\testatística\n",
      "(\n",
      "capítulo\t5\n",
      "),\tprobabilidade\t(\n",
      "capítulo\t6\n",
      ")\te\taspectos\tvariados\tdo\taprendizado\tde\n",
      "máquina.\n",
      "para\tser\tum\tbom\tcientista\tde\tdados,\tvocê\tdeve\tsaber\tmuito\tmais\tsobre\tesses\n",
      "tópicos\te\teu\tencorajo\tvocê\ta\ttentar\testudar\tcada\tum\tdeles,\tusando\tos\tlivros\n",
      "recomendados\tao\tfinal\tdos\tcapítulos,\tseus\tlivros\tpreferidos,\tcursos\tonline\tou\taté\n",
      "mesmo\tcursos\tpresenciais.não\tdo\tzero\n",
      "implementar\tcoisas\t“do\tzero”\té\tótimo\tpara\tentender\tcomo\telas\tfuncionam.\tmas\n",
      "geralmente\tnão\té\tótimo\tem\tperformance\t(a\tnão\tser\tque\tvocê\tos\testeja\n",
      "implementando\tespecificamente\tcom\tperformance\tem\tmente),\tfacilidade\tde\tuso,\n",
      "resposta\trápida\tou\ttratamento\tde\terros.\n",
      "na\tprática,\tvocê\tvai\tquerer\tusar\tbibliotecas\tbem\tprojetadas\tque\timplementem\n",
      "solidamente\tos\tessenciais.\t(minha\tproposta\toriginal\tpara\teste\tlivro\tenvolvia\tuma\n",
      "segunda\tmetade\t“agora\tvamos\taprender\tas\tbibliotecas”\tque\ta\to'reilly,\n",
      "felizmente,\tvetou.)\n",
      "numpy\n",
      "numpy\t(\n",
      "http://www.numpy.org\n",
      ")\t(para\t“numeric\tpython”)\tfornece\tfacilidades\n",
      "para\tfazer\tcomputação\tcientífica\t“real”.\tele\tcontém\tarrays\tque\tdesempenham\n",
      "melhor\tdo\tque\tnossos\tvetores\t\n",
      "list\n",
      ",\tmatrizes\tque\tdesempenham\tmelhor\tdo\tque\n",
      "nossas\tmatrizes\t\n",
      "list-of-list\n",
      "\te\tvárias\tfunções\tnuméricas\tpara\ttrabalhar\tcom\teles.\n",
      "numpy\té\tum\tpilar\tpara\tmuitas\toutras\tbibliotecas,\to\tque\ttorna\tseu\tconhecimento\n",
      "especialmente\tvalioso.\n",
      "pandas\n",
      "pandas\t(\n",
      "http://pandas.pydata.org\n",
      ")\tfornece\testruturas\tde\tdados\tadicionais\tpara\n",
      "trabalhar\tcom\tconjuntos\tde\tdados\tem\tpython.\tsua\tabstração\tprimária\té\to\n",
      "dataframe\n",
      ",\tque\té\tconceitualmente\tsimilar\tà\tclasse\t\n",
      "notquiteabase\ttable\n",
      "\tque\n",
      "construímos\tno\t\n",
      "capítulo\t23\n",
      ",\tmas\tcom\tmuito\tmais\tfuncionalidades\te\tmelhor\n",
      "performance.\n",
      "se\tvocê\tusar\tpython\tpara\tanalisar,\tdividir,\tagrupar\tou\tmanipular\tconjuntos\tde\n",
      "dados,\t\n",
      "pandas\n",
      "\tuma\tferramenta\tde\tvalor\tinestimável.\n",
      "scikit-learn\n",
      "scikit-learn\t(\n",
      "http://scikit-learn.org\n",
      ")\tprovavelmente\té\ta\tbiblioteca\tmais\tpopular\n",
      "para\tfazer\taprendizado\tde\tmáquina\tem\tpython.\tela\tcontém\ttodos\tos\tmodelos\tqueimplementamos\te\tmuitos\tmais\tque\tnão\tusamos.\tem\tum\tproblema\treal,\tvocê\n",
      "jamais\tconstruiria\tuma\tárvore\tde\tdecisão\tdo\tzero;\tvocê\tfaria\t\n",
      "scikit-learn\n",
      "\tfazer\to\n",
      "trabalho\tpesado.\tem\tum\tproblema\treal,\tvocê\tjamais\tescreveria\tum\talgoritmo\tde\n",
      "otimização\tà\tmão;\tvocê\tcontaria\tque\t\n",
      "scikit-learn\n",
      "\tjá\testivesse\tusando\tum\tmuito\tbom.\n",
      "sua\tdocumentação\tcontém\tmuitos\texemplos\t(\n",
      "http://scikit-\n",
      "learn.org/stable/auto_examples\n",
      "/\n",
      ")\tdo\tque\tpode\tfazer\t(e\to\tque\to\taprendizado\tde\n",
      "máquina\tpode\tfazer).\n",
      "visualização\n",
      "os\tgráficos\t\n",
      "matplotlib\n",
      "\tque\tcriamos\tforam\tlimpos\te\tfuncionais\tmas\tnão\n",
      "particularmente\testilosos\t(e\tnada\tinterativos).\tse\tvocê\tquiser\tse\taprofundar\tem\n",
      "visualização\tde\tdados,\tvocê\tpossui\tmuitas\topções.\n",
      "a\tprimeira\té\texplorar\tmais\t\n",
      "matplotlib\n",
      ",\tcujas\tcaracterísticas\tnós\tjá\tfalamos.\tseu\tweb\n",
      "site\tcontém\tmuitos\texemplos\t(\n",
      "http://matplotlib.org/examples\n",
      "/\n",
      ")\tde\tsuas\n",
      "funcionalidades\te\tuma\tgaleria\t(\n",
      "http://matplotlib.org/gallery.html\n",
      ")\tde\talguns\tde\n",
      "seus\texemplos\tmais\tinteressantes.\tse\tvocê\tquiser\tcriar\tvisualizações\testáticas,\n",
      "este\té,\tprovavelmente,\tseu\tpróximo\tpasso.\n",
      "você\ttambém\tdeveria\tverificar\tseaborn,\tque\té\tuma\tbiblioteca\tque\t(dentre\toutras\n",
      "coisas)\ttorna\t\n",
      "matplotlib\n",
      "\tmais\tatraente.\n",
      "se\tvocê\tquiser\tcriar\tvisualizações\t\n",
      "interativas\n",
      "\tque\tvocê\tpossa\tcompartilhar\tna\n",
      "web,\ta\topção\tóbvia\té\td3.js,\tuma\tbiblioteca\tjavascript\tpara\tcriar\t“documentos\n",
      "direcionados\tpor\tdados”\t(estes\tsão\tos\ttrês\tds).\tmesmo\tque\tvocê\tnão\tsaiba\n",
      "muito\tjavascript,\té\tpossível\tpegar\texemplos\tda\tgaleria\td3\te\tajustá-los\tpara\n",
      "trabalharem\tcom\tseus\tdados.\t(bons\tcientistas\tcopiam\tda\tgaleria\td3.\tótimos\n",
      "cientistas\t\n",
      "roubam\n",
      "\tda\tgaleria\td3.)\n",
      "mesmo\tque\tvocê\tnão\ttenha\tinteresse\tem\td3,\tapenas\tdar\tuma\tolhada\tna\tgaleria\té\n",
      "bem\teducativo\tpara\tvisualização\tde\tdados.\n",
      "bokeh\té\tum\tprojeto\tque\ttraz\tfuncionalidade\tde\testilo\td3\tpara\tpython.\n",
      "r\n",
      "mesmo\tque\tvocê\tpossa\tse\tsair\tbem\tsem\taprender\tr,\tmuitos\tcientistas\tde\tdados\teprojetos\tde\tdata\tscience\tusam\tisso,\tentão\tvale\ta\tpena\tao\tmenos\tse\tfamiliarizar.\n",
      "em\tparte,\tisso\té\tpara\tque\tpossa\tentender\tpostagens\tde\tblogs\tbaseadas\tem\tr\te\n",
      "exemplos\te\tcódigo;\tem\tparte,\tisso\té\tpara\tlhe\tajudar\ta\tapreciar\ta\n",
      "(comparativamente)\telegância\tde\tpython;\te,\tem\tparte,\tisso\té\tpara\tvocê\tse\ttornar\n",
      "um\tparticipante\tmelhor\tinformado\tna\teterna\tguerra\t“r\tversus\tpython”.\n",
      "no\tmundo\tnão\tfaltam\ttutorias\tde\tr,\tcursos\tde\tr\te\tlivros\tde\tr.\teu\tescuto\tboas\n",
      "coisas\tsobre\t\n",
      "hands-on\tprogramming\twith\tr\n",
      "\te\tnão\tapenas\tporque\ttambém\té\tum\n",
      "livro\to'reilly.\t(ok,\tem\tgrande\tparte\tpor\tser\tum\tlivro\to'reilly.)•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "encontre\tdados\n",
      "se\tvocê\testá\tfazendo\tdata\tscience\tcomo\tparte\tdo\tseu\ttrabalho,\tvocê\n",
      "provavelmente\tconseguirá\tdados\tcomo\tparte\tdo\tseu\ttrabalho\t(mas\tnão\n",
      "necessariamente).\te\tse\tvocê\testiver\tfazendo\tdata\tscience\tpor\tdiversão?\tdados\n",
      "estão\tem\ttodos\tos\tlugares,\tmas\testes\tsão\talguns\tpontos\tde\tpartida:\n",
      "data.gov\té\to\tportal\tde\tdados\tdo\tgoverno.\tse\tvocê\tquiser\tdados\tde\n",
      "qualquer\tcoisa\ta\trespeito\tdo\tgoverno\t(o\tque\tparece\tser\ta\tonda\tdo\n",
      "momento)\té\tum\tbom\tlugar\tpara\tcomeçar.\n",
      "reddit\tpossui\talguns\tfóruns,\tr/datasets\te\tr/data,\tque\tsão\tlugares\tpara\n",
      "descobrir\te\tperguntar\tsobre\tdados.\n",
      "a\tamazon\tmantém\tuma\tcoleção\tde\tconjunto\tde\tdados\tpúblicos\tque\teles\n",
      "gostariam\tque\tvocê\tanalisasse\tusando\tseus\tprodutos\t(mas\tque\tvocê\tpode\n",
      "analisar\tcom\tqualquer\tproduto\tque\tquiser).\n",
      "robb\tseaton\tpossui\tuma\tlista\tde\tconjuntos\tde\tdados\tselecionados\tem\tseu\n",
      "blog.\n",
      "kaggle\té\tum\tsite\tque\tfaz\tcompetições\tde\tdata\tscience.\teu\tnunca\tconsegui\n",
      "entrar\tem\tuma\t(eu\tnão\ttenho\tum\tespírito\tmuito\tcompetitivo)\tmas\tvocê\n",
      "pode\ttentar.pratique\tdata\tscience\n",
      "dar\tuma\tolhada\tem\tcatálogos\tde\tdados\té\tbom,\tmas\tos\tmelhores\tprojetos\t(e\n",
      "produtos)\tsão\taquele\tque\tdão\tuma\tcerta\tcoceira.\testes\tforam\talguns\tque\teu\tfiz.\n",
      "hacker\tnews\n",
      "hacker\tnews\té\tum\tsite\tde\tagregação\tde\tnotícias\te\tde\tdiscussão\tsobre\tnotícias\n",
      "relacionadas\ta\ttecnologia.\tele\tcoleciona\tmuitos\tartigos,\tmuitos\tdos\tquais\tnão\tsão\n",
      "interessantes\tpara\tmim.\n",
      "muitos\tanos\tatrás,\teu\tconstruí\tum\tclassificador\tde\thistória\thacker\tnews\tpara\n",
      "prever\tse\teu\testaria\tinteressado\tou\tnão\tem\tuma\thistória.\tisso\tnão\tfoi\tmuito\tbom\n",
      "com\tos\tusuários\tde\thacker\tnews,\tque\tficaram\tmagoados\tcom\to\tfato\tde\talguém\n",
      "não\testar\tinteressado\tem\ttodas\tas\thistórias\tno\tsite.\n",
      "isso\tenvolveu\trotular\tmuitas\thistórias\t(para\tconseguir\tum\tpouco\tde\ttreinamento),\n",
      "escolher\tatributos\tde\thistórias\t(por\texemplo,\tpalavras\tem\tum\ttítulo,\te\tdomínios\n",
      "de\tlinks)\te\ttreinar\tum\tclassificador\tnaive\tbayes\tnão\tmuito\tdiferente\tdo\tnosso\n",
      "filtro\tde\tspam.\n",
      "por\trazões\tagora\tperdidas\tna\thistória,\teu\to\tconstruí\tem\truby.\taprenda\tcom\tos\n",
      "meus\terros.\n",
      "carros\tde\tbombeiros\n",
      "eu\tmoro\tem\tuma\tgrande\trua\tno\tcentro\tde\tseattle,\tentre\tuma\testação\tdo\tcorpo\tde\n",
      "bombeiros\te\ta\tmaioria\tdos\tincêndios\tda\tcidade\t(ou\té\to\tque\tparece).\tcom\to\n",
      "passar\tdos\tanos,\teu\tdesenvolvi\tum\tinteresse\trecreacional\tpelo\tcorpo\tde\n",
      "bombeiros\tde\tseattle.\n",
      "felizmente\t(de\tuma\tperspectiva\tde\tdados)\teles\tmantêm\tum\tsite\tem\ttempo\treal\n",
      "911\tque\tlista\tcada\talarme\tde\tincêndio\tcom\tos\tcarros\tde\tbombeiros\tenvolvidos.\n",
      "e\tentão,\tpara\tsatisfazer\tmeu\tinteresse,\teu\tjuntei\tmuitos\tanos\tde\tdados\tde\talarmes\n",
      "e\trealizei\tuma\tanálise\tde\trede\tsocial\tdos\tcarros\tde\tbombeiros.\tentre\toutras\n",
      "coisas,\tisso\texigiu\tque\t\n",
      "eu\tinventasse\tuma\tnoção\tde\tcentralidade\tespecífica\tde\n",
      "carro\tde\tbombeiros,\tque\teu\tchamei\tde\ttruckrank.camisetas\n",
      "eu\ttenho\tuma\tfilha\tjovem\te\tuma\tfonte\tincessante\tde\tfrustração\tpara\tmim\tdurante\n",
      "sua\tinfância\tfoi\tque\ta\tmaioria\tdas\t“blusas\tfemininas”\tsão\tsem\tgraça,\tenquanto\n",
      "“camisas\tmasculinas”\tsão\tmuito\tdivertidas.\n",
      "em\tparticular,\testava\tclaro\tpara\tmim\tque\thavia\tuma\tdiferença\tentre\tas\tcamisas\n",
      "para\tbebês\tmeninos\te\tbebês\tmeninas.\tentão,\teu\tme\tperguntei\tse\teu\tpoderia\n",
      "treinar\tum\tmodelo\tpara\treconhecer\tessas\tdiferenças.\n",
      "resultado:\teu\tpude.\n",
      "isso\tenvolveu\tfazer\tdownload\tde\timagens\tde\tcentenas\tde\tcamisas,\tminimizando-\n",
      "as\tpara\to\tmesmo\ttamanho,\ttorná-las\tem\tvetores\tde\tcores\tpixel\te\tusar\tregressão\n",
      "logística\tpara\tconstruir\tum\tclassificador.\n",
      "uma\tabordagem\tparecia\tsimples\tonde\tas\tcores\teram\tapresentadas\tem\tcada\n",
      "camisa;\tuma\tsegunda\tabordagem\tencontrou\tos\t10\tcomponentes\tprincipais\tdos\n",
      "vetores\tda\timagem\tda\tcamisa\te\tclassificou\tcada\tcamisa\tusando\tsuas\tprojeções\n",
      "em\tum\tespaço\tdimensional\t10\tabrangendo\tas\t“autocamisetas”\t(\n",
      "figura\t25-2\n",
      ").\n",
      "figura\t25-2.\tautocamisetas\tcorrespondentes\tao\tprimeiro\tcomponente\tprincipal\n",
      "e\tvocê?\n",
      "o\tque\tinteressa\tvocê?\tquais\tperguntas\ttiram\tseu\tsono?\tprocure\tpor\tum\tconjunto\n",
      "de\tdados\te\tfaça\tum\tpouco\tde\tdata\tscience.sobre\to\tautor\n",
      "joel\tgrus\n",
      "\té\tengenheiro\tde\tsoftware\tno\tgoogle.\tjá\ttrabalhou\tcomo\tcientista\tde\n",
      "dados\tem\tdiversas\tempresas.\tmora\tem\tseattle,\tonde\tregularmente\tcomparece\ta\n",
      "encontros\tde\testudos\tem\tdata\tscience.\tele\tusa\tseu\tblog\tcom\tpouca\tfrequência\tem\n",
      "joelgrus.com\n",
      "\te\tusa\to\ttwitter\to\tdia\tinteiro\tem\t\n",
      "@joelgrus\n",
      ".colophon\n",
      "o\tanimal\tna\tcapa\tde\t\n",
      "data\tscience\tdo\tzero\n",
      "\té\tum\tlagópode\tbranco\t(\n",
      "lagopus\n",
      "muta\n",
      ").\tesse\tpássaro\tde\ttamanho\tmédio\tda\tfamília\tdo\tgalo-silvestre\té\tapenas\n",
      "chamado\tde\t“lagópode”\tno\treino\tunido\te\tno\tcanadá\te\tde\t“galo\tdas\tneves”\tnos\n",
      "estados\tunidos.\to\tlagópode\tbranco\té\tsedentário,\te\tse\treproduz\tpelo\tártico\tda\n",
      "eurásia,\tna\tamérica\tdo\tnorte\te\tna\tgroenlândia.\tele\tprefere\thabitats\tdesertos\te\n",
      "isolados\tcomo\tas\tmontanhas\tda\tescócia,\tos\tpireneus,\tos\talpes,\tos\turais,\ta\n",
      "cordilheira\tpamir,\tbulgária,\tas\tmontanhas\tde\taltaian\te\tos\talpes\tjaponeses.\tele\n",
      "come\tbétulas\te\tbotões\tde\tsalgueiros,\tmas\ttambém\tse\talimenta\tde\tsementes,\n",
      "flores,\tfolhas\te\tfrutas\tvermelhas.\tos\tjovens\tlagópodes\tbrancos\tcomem\tinsetos.\n",
      "os\tlagópodes\tbrancos\tmachos\tnão\tpossuem\tos\tornamentos\ttípicos\tdo\tgalo-\n",
      "silvestre\texceto\tpela\tcrista,\te\té\tusada\tpara\tfazer\ta\tcorte\te\tdesafiar\toutros\tmachos.\n",
      "muitos\testudos\tmostraram\tque\texiste\tuma\tcorrelação\tentre\to\ttamanho\tda\tcrista\te\n",
      "os\tníveis\tde\ttestosterona\tnos\tmachos.\tsuas\tpenas\tmudam\tdo\tinverno\tpara\ta\n",
      "primavera\te\tverão,\ttrocando\tde\tbranco\tpara\tmarrom,\tfornecendo\tum\ttipo\tde\n",
      "camuflagem\tsazonal.\tos\tmachos\tem\treprodução\tpossuem\tasas\tbrancas\te\tas\n",
      "partes\tde\tcima\tcinzas\texceto\tno\tinverno,\tno\tqual\tsua\tplumagem\té\n",
      "completamente\tbranca\texceto\tpelo\tseu\trabo.\n",
      "com\tseis\tmeses\tde\tidade,\to\tlagópode\tse\ttorna\tsexualmente\tmaduro;\té\tcomum\n",
      "uma\ttaxa\tde\treprodução\tde\tseis\tgalos\tpor\ttemporada\tde\treprodução,\to\tque\tajuda\n",
      "a\tproteger\ta\tpopulação\tdos\tfatores\texternos\tcomo\ta\tcaça.\ttambém\tespanta\n",
      "muitos\tpredadores\tdevido\tao\tseu\thabitat\tremoto\te\té\tcaçado\tprincipalmente\tpelas\n",
      "águias\tdouradas.\n",
      "o\tlagópode\tbranco\té\to\tprincipal\talimento\tdos\tfestivais\tde\tcomida\tislandeses.\n",
      "caçar\to\tlagópode\tbranco\tfoi\tproibido\tem\t2003\te\t2004\tdevido\tao\tdeclínio\tde\tsua\n",
      "população.\tem\t2005,\ta\tcaça\tfoi\tliberada\tnovamente\tcom\trestrição\tem\talguns\n",
      "dias.\ttodo\to\tcomércio\tdo\tlagópode\tbranco\té\tilegal.\n",
      "muitos\tdos\tanimais\tdas\tcapas\tda\to’reilly\tsão\tanimais\tem\textinção;\ttodos\teles\n",
      "são\timportantes\tpara\to\tmundo.\tpara\taprender\tmais\tsobre\tcomo\tvocê\tpode\tajudar,\n",
      "vá\tem\t\n",
      "animals.oreilly.com\n",
      ".\n",
      "a\timagem\tda\tcapa\té\tda\t\n",
      "história\tnatural\n",
      "\tde\tcassell.\tas\tfontes\tda\tcapa\tsão\turwtypewriter\te\tguardian\tsans.\ta\tfonte\tdo\ttexto\té\ta\tadobe\tminion\tpro;\ta\tfonte\tdo\n",
      "cabeçalho\té\ta\tadobe\tmyriad\tcondensed\te\ta\tfonte\tdos\tcódigos\té\ta\tdalton\tmaag\n",
      "da\tubuntu\tmono.html,\txhtml\te\tcss\tpara\tleigos\n",
      "tittle,\ted\n",
      "9788550804200\n",
      "412\tpáginas\n",
      "compre\tagora\te\tleia\n",
      "bem\tvindo\tàs\tpossibilidades\tdesenfreadas,\tmalucas\te\tmaravilhosas\tda\tworld\n",
      "wide\tweb,\tou,\tmais,\tsimplesmente,\ta\tweb.\thtml,\txhtml\te\tcss\tpara\tleigos,\n",
      "revela\tos\tdetalhes\tdas\tlinguagens\tde\tmarcação\tque\tsão\ta\tveia\tda\tweb\t–\ta\n",
      "hypertext\tmarkup\tlanguage\t(html)\te\tsua\tprima,\txhtm,\tjunto\tcom\ta\n",
      "linguagem\tda\tcascading\tstyle\tsheet\t(css),\tusada\tpara\tfazer\tcom\tque\toutras\n",
      "coisas\tpareçam\tboas.\thtml\te\txhtml\t(usamos\t(x)html\tneste\tlivro\tpara\n",
      "fazer\treferência\tàs\tduas)\te\tcss\tsão\tusadas\tpara\tcriar\tpáginas\tweb.\taprender\ta\n",
      "usá-las\to\tcoloca\tno\tgrupo\tdos\tautores\te\tdesenvolvedores\tde\tconteúdo\tweb.\tpense\n",
      "nesse\tlivro\tcomo\tum\tguia\tamigável\te\tacessível\tpara\tdominar\t(x)html\te\tcss!\n",
      "compre\tagora\te\tleia12\tregras\tpara\ta\tvida\n",
      "peterson,\tjordan\tb.\n",
      "9788550804002\n",
      "448\tpáginas\n",
      "compre\tagora\te\tleia\n",
      "aclamado\tpsicólogo\tclínico,\tjordan\tpeterson\ttem\tinfluenciado\ta\tcompreensão\n",
      "moderna\tsobre\ta\tpersonalidade\te,\tagora,\tse\ttransformou\tem\tum\tdos\tpensadores\n",
      "públicos\tmais\tpopulares\tdo\tmundo,\tcom\tsuas\tpalestras\tsobre\ttópicos\tque\tvariam\n",
      "da\tbíblia,\tàs\trelações\tamorosas\te\tà\tmitologia,\tatraindo\tdezenas\tde\tmilhões\tde\n",
      "espectadores.\tem\tuma\tera\tde\tmudanças\tsem\tprecedentes\te\tpolarização\tda\n",
      "política,\tsua\tmensagem\tfranca\te\trevigorante\tsobre\to\tvalor\tda\tresponsabilidade\n",
      "individual\te\tda\tsabedoria\tancestral\ttem\tecoado\tem\ttodos\tos\tcantos\tdo\tmundo.\n",
      "bem-humorado,\tsurpreendente\te\tinformativo,\tdr.\tpeterson\tnos\tconta\tpor\tque\n",
      "meninos\te\tmeninas\tandando\tde\tskate\tdevem\tser\tdeixados\tem\tpaz,\tque\tterrível\n",
      "destino\taguarda\taqueles\tque\tcriticam\tcom\tmuita\tfacilidade\te\tpor\tque\tvocê\n",
      "sempre\tdeve\tacariciar\tgatos\tao\tencontrar\tum\tna\trua.\to\tque\to\tsistema\tnervoso\tdas\n",
      "humildes\tlagostas\ttem\ta\tnos\tdizer\tsobre\ta\trelação\tentre\tmanter\tas\tcostas\teretas\t(e\n",
      "os\tombros\tpara\ttrás)\te\to\tsucesso\tna\tvida?\tpor\tque\tos\tantigos\tegípcios\tveneravam\n",
      "a\tcapacidade\tde\tatenção\tcomo\tseu\tdeus\tmais\tsupremo?\tque\tterríveis\tcaminhos\n",
      "as\tpessoas\tpercorrem\tquando\tse\ttornam\tressentidas,\tarrogantes\te\tvingativas?\n",
      "neste\tlivro,\tele\toferece\tdoze\tprincípios\tprofundos\te\tpráticos\tsobre\tcomo\tviver\n",
      "uma\tvida\tcom\tsignificado.\n",
      "compre\tagora\te\tleiadesign\tthinking\n",
      "brown,\ttim\n",
      "9788550803869\n",
      "272\tpáginas\n",
      "compre\tagora\te\tleia\n",
      "este\tlivro\tintroduz\ta\tideia\tde\tdesign\tthinking,\tum\tprocesso\tcolaborativo\tque\n",
      "usa\ta\tsensibilidade\te\ta\ttécnica\tcriativa\tpara\tsuprir\tas\tnecessidades\tdas\tpessoas\n",
      "não\tsó\tcom\to\tque\té\ttecnicamente\tvisível,\tmas\tcom\tuma\testratégia\tde\tnegócios\n",
      "viável.\tem\tresumo,\to\tdesign\tthinking\tconverte\tnecessidade\tem\tdemanda.\té\n",
      "uma\tabordagem\tcentrada\tno\taspecto\thumano\tdestinada\ta\tresolver\tproblemas\te\n",
      "ajudar\tpessoas\te\torganizações\ta\tserem\tmais\tinovadoras\te\tcriativas.\tescrito\tnuma\n",
      "linguagem\tleve\te\tembasada,\teste\tnão\té\tum\tlivro\tde\tdesigners\tpara\tdesigners,\te\n",
      "sim\tuma\tobra\tpara\tlíderes\tcriativos\tque\testão\tsempre\tem\tbusca\tde\talternativas\n",
      "viáveis,\ttanto\tfuncional\tquanto\tfinanceiramente,\tpara\tos\tnegócios\te\tpara\ta\n",
      "sociedade.\tneste\tlivro,\ttim\tbrown,\tceo\tda\tcelebrada\tempresa\tde\tinovação\te\n",
      "design\tideo,\tnos\tapresenta\to\tdesign\tthinking.\to\tdesign\tnão\tse\tlimita\ta\tcriar\n",
      "objetos\telegantes\tou\tembelezar\to\tmundo\ta\tnosso\tredor.\tos\tmelhores\tdesigners\n",
      "compatibilizam\ta\texigência\tcom\ta\tutilidade,\tas\trestrições\tcom\ta\tpossibilidade\te\ta\n",
      "necessidade\tcom\ta\tdemanda.\n",
      "compre\tagora\te\tleiapai\trico,\tpai\tpobre\t-\tedição\tde\t20\tanos\n",
      "atualizada\te\tampliada\n",
      "t.\tkiyosaki,\trobert\n",
      "9788550801483\n",
      "336\tpáginas\n",
      "compre\tagora\te\tleia\n",
      "a\tescola\tprepara\tas\tcrianças\tpara\to\tmundo\treal?\tessa\té\ta\tprimeira\tpergunta\tcom\n",
      "a\tqual\to\tleitor\tse\tdepara\tneste\tlivro.\to\trecado\té\tousado\te\tdireto:\tboa\tformação\te\n",
      "notas\taltas\tnão\tbastam\tpara\tassegurar\to\tsucesso\tde\talguém.\to\tmundo\tmudou;\ta\n",
      "maioria\tdos\tjovens\ttem\tcartão\tde\tcrédito,\tantes\tmesmo\tde\tconcluir\tos\testudos,\te\n",
      "nunca\tteve\taula\tsobre\tdinheiro,\tinvestimentos,\tjuros\tetc.\tou\tseja,\teles\tvão\tpara\ta\n",
      "escola,\tmas\tcontinuam\tfinanceiramente\timproficientes,\tdespreparados\tpara\n",
      "enfrentar\tum\tmundo\tque\tvaloriza\tmais\tas\tdespesas\tdo\tque\ta\tpoupança.\tpara\to\n",
      "autor,\to\tconselho\tmais\tperigoso\tque\tse\tpode\tdar\ta\tum\tjovem\tnos\tdias\tde\thoje\té:\n",
      "\"vá\tpara\ta\tescola,\ttire\tnotas\taltas\te\tdepoisprocure\tum\ttrabalho\tseguro.\"\to\tfato\té\n",
      "que\tagora\tas\tregras\tsão\toutras,\te\tnão\texiste\tmais\temprego\tgarantido\tpara\n",
      "ninguém.\tpai\trico,\tpai\tpobre\tdemonstra\tque\ta\tquestão\tnão\té\tser\tempregado\tou\n",
      "empregador,\tmas\tter\to\tcontrole\tdo\tpróprio\tdestino\tou\tdelegá-lo\ta\talguém.\té\tessa\n",
      "a\ttese\tde\trobert\tkiyosaki\tneste\tlivro\tsubstancial\te\tvisionário.\tpara\tele,\ta\n",
      "formação\tproporcionada\tpelo\tsistema\teducacional\tnão\tprepara\tos\tjovens\tpara\to\n",
      "mundo\tque\tencontrarão\tdepois\tde\tformados.\te\tcomo\tos\tpais\tpodem\tensinar\taos\n",
      "filhos\to\tque\ta\tescola\trelega?\tessa\té\toutra\tdas\tmuitas\tperguntas\tque\to\tleitor\n",
      "encontra\tem\tpai\trico,\tpai\tpobre.\tnesse\tsentido,\ta\tproposta\tdo\tautor\té\tfacilitar\ta\n",
      "tarefa\tdos\tpais.\tquem\tentende\tde\tcontabilidade\tdeve\tesquecer\tseus\n",
      "conhecimentos\tacadêmicos,\tpois\tmuitas\tdas\tteorias\texpostas\tpor\trobert\n",
      "kiyosaki\tcontrariam\tos\tprincípios\tcontábeis\tcomumente\taceitos,\te\tapresentamuma\tvaliosa\te\tmoderna\tpercepção\tdo\tmodo\tcomo\tse\trealizam\tos\tinvestimentos.\n",
      "a\tsociedade\tsofre\tmudanças\tradicais\te,\ttalvez,\tde\tproporções\tmaiores\tdo\tque\tas\n",
      "ocorridas\tem\tséculos\tpassados.\tnão\texiste\tbola\tde\tcristal,\tmas\talgo\té\tcerto:\ta\n",
      "perspectiva\tglobal\tde\ttransformações\ttranscende\tnossa\trealidade\timediata.\n",
      "aconteça\to\tque\tacontecer,\tsó\texistem\tduas\talternativas:\tsegurança\tou\n",
      "independência\tfinanceira.\te\to\tobjetivo\tde\tpai\trico,\tpai\tpobre\té\tinstruir\to\tleitor\te\n",
      "despertar\tsua\tinteligência\tfinanceira\te\ta\tde\tseus\tfilhos.\n",
      "compre\tagora\te\tleiao\tnegócio\tdo\tséculo\txxi\n",
      "kiyosaki,\trobert\tt.\n",
      "9788550804019\n",
      "160\tpáginas\n",
      "compre\tagora\te\tleia\n",
      "você\testá\tfurioso\tcom\ta\tcorrupção\tno\tmundo\tempresarial?\tcom\to\tsistema\n",
      "financeiro\te\tos\tbancos?\tcom\to\tgoverno,\tque\tfaz\tmuito\tpelas\tcoisas\terradas\te\n",
      "pouco\tpelas\tcoisas\tcertas?\tou\testá\tzangado\tconsigo\tmesmo\tpor\tnão\tter\n",
      "conseguido\tcontrolar\tsuas\tfinanças\tantes?\ta\tvida\té\tdura.\ta\tquestão\té:\to\tque\n",
      "você\testá\tfazendo\ta\trespeito?\treclamar\te\tresmungar\tsobre\ta\teconomia\tou\n",
      "responsabilizar\tos\toutros\tnão\tsão\tatitudes\tque\tasseguram\tseu\tfuturo\tfinanceiro.\n",
      "se\tvocê\tquiser\triqueza,\tprecisa\tcriá-la.\tvocê\tprecisa\tassumir\to\tcontrole\tde\tseu\n",
      "futuro,\tcontrolando\tsua\tfonte\tde\trenda\t–\thoje!\tvocê\tprecisa\tde\tseu\tpróprio\n",
      "negócio.\testes\tpodem\tser\ttempos\tdifíceis\tpara\ta\tmaioria\tdas\tpessoas,\tmas,\tpara\n",
      "muitos\tempresários,\tsão\ttempos\tplenos\tde\tpotencial\teconômico.\tnão\tapenas\n",
      "agora\té\ta\thora\tde\tter\to\tpróprio\tnegócio,\tcomo\tnunca\thouve\tum\ttempo\tmelhor!\n",
      "compre\tagora\te\tleia\n"
     ]
    }
   ],
   "source": [
    "# remoção da pontuação\n",
    "text_sem_pontuacao = ''.join([p for p in text if p not in string.punctuation])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "688a27a5-0600-4081-8e8e-246e03ca17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'compra',\n",
       " 'deste',\n",
       " 'conteúdo',\n",
       " 'não',\n",
       " 'prevê',\n",
       " 'atendimento',\n",
       " 'e',\n",
       " 'fornecimento',\n",
       " 'de',\n",
       " 'suporte',\n",
       " 'técnico',\n",
       " 'operacional',\n",
       " 'instalação',\n",
       " 'ou',\n",
       " 'configuração',\n",
       " 'do',\n",
       " 'sistema',\n",
       " 'de',\n",
       " 'leitor',\n",
       " 'de',\n",
       " 'ebooks',\n",
       " 'em',\n",
       " 'alguns',\n",
       " 'casos',\n",
       " 'e',\n",
       " 'dependendo',\n",
       " 'da',\n",
       " 'plataforma',\n",
       " 'o',\n",
       " 'suporte',\n",
       " 'poderá',\n",
       " 'ser',\n",
       " 'obtido',\n",
       " 'com',\n",
       " 'o',\n",
       " 'fabricante',\n",
       " 'do',\n",
       " 'equipamento',\n",
       " 'eou',\n",
       " 'loja',\n",
       " 'de',\n",
       " 'comércio',\n",
       " 'de',\n",
       " 'ebooksdata',\n",
       " 'science',\n",
       " 'do',\n",
       " 'zero',\n",
       " 'copyright',\n",
       " '©',\n",
       " '2016',\n",
       " 'da',\n",
       " 'starlin',\n",
       " 'alta',\n",
       " 'editora',\n",
       " 'e',\n",
       " 'consultoria',\n",
       " 'eireli',\n",
       " 'isbn',\n",
       " '9788550803876',\n",
       " 'translated',\n",
       " 'from',\n",
       " 'original',\n",
       " 'data',\n",
       " 'science',\n",
       " 'from',\n",
       " 'scratch',\n",
       " 'by',\n",
       " 'joel',\n",
       " 'grus',\n",
       " 'copyright',\n",
       " '©',\n",
       " '2015',\n",
       " 'by',\n",
       " 'o',\n",
       " '’',\n",
       " 'reilly',\n",
       " 'media',\n",
       " 'isbn',\n",
       " '9781491901427',\n",
       " 'this',\n",
       " 'translation',\n",
       " 'is',\n",
       " 'published',\n",
       " 'and',\n",
       " 'sold',\n",
       " 'by',\n",
       " 'permission',\n",
       " 'of',\n",
       " 'o',\n",
       " '’',\n",
       " 'reilly',\n",
       " 'media',\n",
       " 'inc',\n",
       " 'the',\n",
       " 'owner',\n",
       " 'of',\n",
       " 'all',\n",
       " 'rights',\n",
       " 'to',\n",
       " 'publish',\n",
       " 'and',\n",
       " 'sell',\n",
       " 'the',\n",
       " 'same',\n",
       " 'portuguese',\n",
       " 'language',\n",
       " 'edition',\n",
       " 'published',\n",
       " 'by',\n",
       " 'starlin',\n",
       " 'alta',\n",
       " 'editora',\n",
       " 'e',\n",
       " 'consultoria',\n",
       " 'eireli',\n",
       " 'copyright',\n",
       " '©',\n",
       " '2016',\n",
       " 'by',\n",
       " 'starlin',\n",
       " 'alta',\n",
       " 'editora',\n",
       " 'e',\n",
       " 'consultoria',\n",
       " 'eireli',\n",
       " 'todos',\n",
       " 'os',\n",
       " 'direitos',\n",
       " 'estão',\n",
       " 'reservados',\n",
       " 'e',\n",
       " 'protegidos',\n",
       " 'por',\n",
       " 'lei',\n",
       " 'nenhuma',\n",
       " 'parte',\n",
       " 'deste',\n",
       " 'livro',\n",
       " 'sem',\n",
       " 'autorização',\n",
       " 'prévia',\n",
       " 'por',\n",
       " 'escrito',\n",
       " 'da',\n",
       " 'editora',\n",
       " 'poderá',\n",
       " 'ser',\n",
       " 'reproduzida',\n",
       " 'ou',\n",
       " 'transmitida',\n",
       " 'a',\n",
       " 'violação',\n",
       " 'dos',\n",
       " 'direitos',\n",
       " 'autorais',\n",
       " 'é',\n",
       " 'crime',\n",
       " 'estabelecido',\n",
       " 'na',\n",
       " 'lei',\n",
       " 'nº',\n",
       " '961098',\n",
       " 'e',\n",
       " 'com',\n",
       " 'punição',\n",
       " 'de',\n",
       " 'acordo',\n",
       " 'com',\n",
       " 'o',\n",
       " 'artigo',\n",
       " '184',\n",
       " 'do',\n",
       " 'código',\n",
       " 'penal',\n",
       " 'a',\n",
       " 'editora',\n",
       " 'não',\n",
       " 'se',\n",
       " 'responsabiliza',\n",
       " 'pelo',\n",
       " 'conteúdo',\n",
       " 'da',\n",
       " 'obra',\n",
       " 'formulada',\n",
       " 'exclusivamente',\n",
       " 'pelos',\n",
       " 'autores',\n",
       " 'marcas',\n",
       " 'registradas',\n",
       " 'todos',\n",
       " 'os',\n",
       " 'termos',\n",
       " 'mencionados',\n",
       " 'e',\n",
       " 'reconhecidos',\n",
       " 'como',\n",
       " 'marca',\n",
       " 'registrada',\n",
       " 'eou',\n",
       " 'comercial',\n",
       " 'são',\n",
       " 'de',\n",
       " 'responsabilidade',\n",
       " 'de',\n",
       " 'seus',\n",
       " 'proprietários',\n",
       " 'a',\n",
       " 'editora',\n",
       " 'informa',\n",
       " 'não',\n",
       " 'estar',\n",
       " 'associada',\n",
       " 'a',\n",
       " 'nenhum',\n",
       " 'produto',\n",
       " 'eou',\n",
       " 'fornecedor',\n",
       " 'apresentado',\n",
       " 'no',\n",
       " 'livro',\n",
       " 'edição',\n",
       " 'revisada',\n",
       " 'conforme',\n",
       " 'o',\n",
       " 'acordo',\n",
       " 'ortográfico',\n",
       " 'da',\n",
       " 'língua',\n",
       " 'portuguesa',\n",
       " 'de',\n",
       " '2009',\n",
       " 'obra',\n",
       " 'disponível',\n",
       " 'para',\n",
       " 'venda',\n",
       " 'corporativa',\n",
       " 'eou',\n",
       " 'personalizada',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'informações',\n",
       " 'fale',\n",
       " 'com',\n",
       " 'projetosaltabookscombr',\n",
       " 'produção',\n",
       " 'editorial',\n",
       " 'editora',\n",
       " 'alta',\n",
       " 'books',\n",
       " 'produtor',\n",
       " 'editorial',\n",
       " 'claudia',\n",
       " 'braga',\n",
       " 'thiê',\n",
       " 'alves',\n",
       " 'produtor',\n",
       " 'editorial',\n",
       " 'design',\n",
       " 'aurélio',\n",
       " 'corrêa',\n",
       " 'gerência',\n",
       " 'editorial',\n",
       " 'anderson',\n",
       " 'vieira',\n",
       " 'supervisão',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'editorial',\n",
       " 'sergio',\n",
       " 'de',\n",
       " 'souza',\n",
       " 'assistente',\n",
       " 'editorial',\n",
       " 'carolina',\n",
       " 'giannini',\n",
       " 'marketing',\n",
       " 'editorial',\n",
       " 'silas',\n",
       " 'amaro',\n",
       " 'marketingaltabookscombr',\n",
       " 'gerência',\n",
       " 'de',\n",
       " 'captação',\n",
       " 'e',\n",
       " 'contratação',\n",
       " 'de',\n",
       " 'obras',\n",
       " 'j',\n",
       " 'a',\n",
       " 'rugeri',\n",
       " 'autoriaaltabookscombr',\n",
       " 'vendas',\n",
       " 'atacado',\n",
       " 'e',\n",
       " 'varejo',\n",
       " 'daniele',\n",
       " 'fonseca',\n",
       " 'viviane',\n",
       " 'paiva',\n",
       " 'comercialaltabookscombrouvidoria',\n",
       " 'ouvidoriaaltabookscombr',\n",
       " 'equipe',\n",
       " 'editorial',\n",
       " 'bianca',\n",
       " 'teodoro',\n",
       " 'christian',\n",
       " 'danniel',\n",
       " 'izabelli',\n",
       " 'carvalho',\n",
       " 'jessica',\n",
       " 'carvalho',\n",
       " 'juliana',\n",
       " 'de',\n",
       " 'oliveira',\n",
       " 'renan',\n",
       " 'castro',\n",
       " 'tradução',\n",
       " 'welington',\n",
       " 'nascimento',\n",
       " 'copidesque',\n",
       " 'vivian',\n",
       " 'sbravatti',\n",
       " 'revisão',\n",
       " 'gramatical',\n",
       " 'ana',\n",
       " 'paula',\n",
       " 'da',\n",
       " 'fonseca',\n",
       " 'revisão',\n",
       " 'técnica',\n",
       " 'ronaldo',\n",
       " 'd',\n",
       " '’',\n",
       " 'avila',\n",
       " 'roenick',\n",
       " 'engenheiro',\n",
       " 'de',\n",
       " 'eletrônica',\n",
       " 'pelo',\n",
       " 'instituto',\n",
       " 'militar',\n",
       " 'de',\n",
       " 'engenharia',\n",
       " 'ime',\n",
       " 'diagramação',\n",
       " 'cláudio',\n",
       " 'frota',\n",
       " 'erratas',\n",
       " 'e',\n",
       " 'arquivos',\n",
       " 'de',\n",
       " 'apoio',\n",
       " 'no',\n",
       " 'site',\n",
       " 'da',\n",
       " 'editora',\n",
       " 'relatamos',\n",
       " 'com',\n",
       " 'a',\n",
       " 'devida',\n",
       " 'correção',\n",
       " 'qualquer',\n",
       " 'erro',\n",
       " 'encontrado',\n",
       " 'em',\n",
       " 'nossos',\n",
       " 'livros',\n",
       " 'bem',\n",
       " 'como',\n",
       " 'disponibilizamos',\n",
       " 'arquivos',\n",
       " 'de',\n",
       " 'apoio',\n",
       " 'se',\n",
       " 'aplicáveis',\n",
       " 'à',\n",
       " 'obra',\n",
       " 'em',\n",
       " 'questão',\n",
       " 'acesse',\n",
       " 'o',\n",
       " 'site',\n",
       " 'wwwaltabookscombr',\n",
       " 'e',\n",
       " 'procure',\n",
       " 'pelo',\n",
       " 'título',\n",
       " 'do',\n",
       " 'livro',\n",
       " 'desejado',\n",
       " 'para',\n",
       " 'ter',\n",
       " 'acesso',\n",
       " 'às',\n",
       " 'erratas',\n",
       " 'aos',\n",
       " 'arquivos',\n",
       " 'de',\n",
       " 'apoio',\n",
       " 'eou',\n",
       " 'a',\n",
       " 'outros',\n",
       " 'conteúdos',\n",
       " 'aplicáveis',\n",
       " 'à',\n",
       " 'obra',\n",
       " 'suporte',\n",
       " 'técnico',\n",
       " 'a',\n",
       " 'obra',\n",
       " 'é',\n",
       " 'comercializada',\n",
       " 'na',\n",
       " 'forma',\n",
       " 'em',\n",
       " 'que',\n",
       " 'está',\n",
       " 'sem',\n",
       " 'direito',\n",
       " 'a',\n",
       " 'suporte',\n",
       " 'técnico',\n",
       " 'ou',\n",
       " 'orientação',\n",
       " 'pessoalexclusiva',\n",
       " 'ao',\n",
       " 'leitor',\n",
       " 'dados',\n",
       " 'internacionais',\n",
       " 'de',\n",
       " 'catalogação',\n",
       " 'na',\n",
       " 'publicação',\n",
       " 'cip',\n",
       " 'vagner',\n",
       " 'rodolfo',\n",
       " 'crb89410',\n",
       " 'g885d',\n",
       " 'grus',\n",
       " 'joel',\n",
       " 'data',\n",
       " 'science',\n",
       " 'do',\n",
       " 'zero',\n",
       " 'recurso',\n",
       " 'eletrônico',\n",
       " 'joel',\n",
       " 'grus',\n",
       " 'traduzido',\n",
       " 'por',\n",
       " 'welington',\n",
       " 'nascimento',\n",
       " 'rio',\n",
       " 'de',\n",
       " 'janeiro',\n",
       " 'alta',\n",
       " 'books',\n",
       " '2016',\n",
       " '336',\n",
       " 'p',\n",
       " 'il',\n",
       " '38',\n",
       " 'mb',\n",
       " 'tradução',\n",
       " 'de',\n",
       " 'data',\n",
       " 'science',\n",
       " 'from',\n",
       " 'scratch',\n",
       " 'first',\n",
       " 'principles',\n",
       " 'with',\n",
       " 'python',\n",
       " 'inclui',\n",
       " 'índice',\n",
       " 'isbn',\n",
       " '9788550803876',\n",
       " 'ebook1',\n",
       " 'matemática',\n",
       " '2',\n",
       " 'programação',\n",
       " '3',\n",
       " 'análise',\n",
       " 'de',\n",
       " 'dados',\n",
       " 'i',\n",
       " 'nascimento',\n",
       " 'welington',\n",
       " 'ii',\n",
       " 'título',\n",
       " 'cdd',\n",
       " '00513',\n",
       " 'cdu',\n",
       " '0046553',\n",
       " 'rua',\n",
       " 'viúva',\n",
       " 'cláudio',\n",
       " '291',\n",
       " 'bairro',\n",
       " 'industrial',\n",
       " 'do',\n",
       " 'jacaré',\n",
       " 'cep',\n",
       " '20970031',\n",
       " 'rio',\n",
       " 'de',\n",
       " 'janeiro',\n",
       " 'rj',\n",
       " 'tels',\n",
       " '21',\n",
       " '32788069',\n",
       " '32788419',\n",
       " 'wwwaltabookscombr',\n",
       " '—',\n",
       " 'altabooksaltabookscombr',\n",
       " 'wwwfacebookcomaltabooks',\n",
       " '—',\n",
       " 'wwwinstagramcomaltabooks1',\n",
       " '2',\n",
       " 'sumário',\n",
       " 'prefácio',\n",
       " 'introdução',\n",
       " 'a',\n",
       " 'ascensão',\n",
       " 'dos',\n",
       " 'dados',\n",
       " 'o',\n",
       " 'que',\n",
       " 'é',\n",
       " 'data',\n",
       " 'science',\n",
       " 'motivação',\n",
       " 'hipotética',\n",
       " 'datasciencester',\n",
       " 'encontrando',\n",
       " 'conectoreschave',\n",
       " 'cientistas',\n",
       " 'de',\n",
       " 'dados',\n",
       " 'que',\n",
       " 'você',\n",
       " 'talvez',\n",
       " 'conheça',\n",
       " 'salários',\n",
       " 'e',\n",
       " 'experiência',\n",
       " 'contas',\n",
       " 'pagas',\n",
       " 'tópicos',\n",
       " 'de',\n",
       " 'interesse',\n",
       " 'em',\n",
       " 'diante',\n",
       " 'curso',\n",
       " 'relâmpago',\n",
       " 'de',\n",
       " 'python',\n",
       " 'o',\n",
       " 'básico',\n",
       " 'iniciando',\n",
       " 'em',\n",
       " 'python',\n",
       " 'python',\n",
       " 'zen',\n",
       " 'formatação',\n",
       " 'de',\n",
       " 'espaço',\n",
       " 'em',\n",
       " 'branco',\n",
       " 'módulos',\n",
       " 'aritmética',\n",
       " 'funções',\n",
       " 'strings',\n",
       " 'cadeias',\n",
       " 'de',\n",
       " 'caracteres',\n",
       " 'exceções',\n",
       " 'listas',\n",
       " 'tuplas',\n",
       " 'dicionários',\n",
       " 'conjuntos',\n",
       " 'controle',\n",
       " 'de',\n",
       " 'fluxo3',\n",
       " '4',\n",
       " '5',\n",
       " 'veracidade',\n",
       " 'não',\n",
       " 'tão',\n",
       " 'básico',\n",
       " 'ordenação',\n",
       " 'compreensões',\n",
       " 'de',\n",
       " 'lista',\n",
       " 'geradores',\n",
       " 'e',\n",
       " 'iteradores',\n",
       " 'aleatoriedade',\n",
       " 'expressões',\n",
       " 'regulares',\n",
       " 'programação',\n",
       " 'orientada',\n",
       " 'a',\n",
       " 'objeto',\n",
       " 'ferramentas',\n",
       " 'funcionais',\n",
       " 'enumeração',\n",
       " 'enumerate',\n",
       " 'descompactação',\n",
       " 'de',\n",
       " 'zip',\n",
       " 'e',\n",
       " 'argumentos',\n",
       " 'args',\n",
       " 'e',\n",
       " 'kwargs',\n",
       " 'bemvindo',\n",
       " 'à',\n",
       " 'datasciencester',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'visualizando',\n",
       " 'dados',\n",
       " 'matplotlib',\n",
       " 'gráficos',\n",
       " 'de',\n",
       " 'barra',\n",
       " 'gráficos',\n",
       " 'de',\n",
       " 'linhas',\n",
       " 'gráficos',\n",
       " 'de',\n",
       " 'dispersão',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'álgebra',\n",
       " 'linear',\n",
       " 'vetores',\n",
       " 'matrizes',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'estatística',\n",
       " 'descrevendo',\n",
       " 'um',\n",
       " 'conjunto',\n",
       " 'único',\n",
       " 'de',\n",
       " 'dados',\n",
       " 'tendências',\n",
       " 'centrais',\n",
       " 'dispersão',\n",
       " 'correlação',\n",
       " 'paradoxo',\n",
       " 'de',\n",
       " 'simpson',\n",
       " 'alguns',\n",
       " 'outros',\n",
       " 'pontos',\n",
       " 'de',\n",
       " 'atenção',\n",
       " 'sobre',\n",
       " 'correlação',\n",
       " 'correlação',\n",
       " 'e',\n",
       " 'causalidade',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'probabilidade',\n",
       " 'dependência',\n",
       " 'e',\n",
       " 'independência',\n",
       " 'probabilidade',\n",
       " 'condicional',\n",
       " 'teorema',\n",
       " 'de',\n",
       " 'bayes',\n",
       " 'variáveis',\n",
       " 'aleatórias',\n",
       " 'distribuições',\n",
       " 'contínuas',\n",
       " 'a',\n",
       " 'distribuição',\n",
       " 'normal',\n",
       " 'o',\n",
       " 'teorema',\n",
       " 'do',\n",
       " 'limite',\n",
       " 'central',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'hipótese',\n",
       " 'e',\n",
       " 'inferência',\n",
       " 'teste',\n",
       " 'estatístico',\n",
       " 'de',\n",
       " 'hipótese',\n",
       " 'exemplo',\n",
       " 'lançar',\n",
       " 'uma',\n",
       " 'moeda',\n",
       " 'p',\n",
       " 'values',\n",
       " 'intervalos',\n",
       " 'de',\n",
       " 'confiança',\n",
       " 'phacking',\n",
       " 'exemplo',\n",
       " 'executando',\n",
       " 'um',\n",
       " 'teste',\n",
       " 'ab',\n",
       " 'inferência',\n",
       " 'bayesiana',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'gradiente',\n",
       " 'descendente',\n",
       " 'a',\n",
       " 'ideia',\n",
       " 'por',\n",
       " 'trás',\n",
       " 'do',\n",
       " 'gradiente',\n",
       " 'descendente',\n",
       " 'estimando',\n",
       " 'o',\n",
       " 'gradiente',\n",
       " 'usando',\n",
       " 'o',\n",
       " 'gradiente',\n",
       " 'escolhendo',\n",
       " 'o',\n",
       " 'tamanho',\n",
       " 'do',\n",
       " 'próximo',\n",
       " 'passo',\n",
       " 'juntando',\n",
       " 'tudo',\n",
       " 'gradiente',\n",
       " 'descendente',\n",
       " 'estocástico',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'obtendo',\n",
       " 'dados',\n",
       " 'stdin',\n",
       " 'e',\n",
       " 'stdout',\n",
       " 'lendo',\n",
       " 'arquivos',\n",
       " 'o',\n",
       " 'básico',\n",
       " 'de',\n",
       " 'arquivos',\n",
       " 'texto',\n",
       " 'arquivos',\n",
       " 'delimitados',\n",
       " 'extraindo',\n",
       " 'dados',\n",
       " 'da',\n",
       " 'internet',\n",
       " 'html',\n",
       " 'e',\n",
       " 'sua',\n",
       " 'subsequente',\n",
       " 'pesquisa10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " 'exemplo',\n",
       " 'livros',\n",
       " 'o',\n",
       " '’',\n",
       " 'reilly',\n",
       " 'sobre',\n",
       " 'dados',\n",
       " 'usando',\n",
       " 'apis',\n",
       " 'json',\n",
       " 'e',\n",
       " 'xml',\n",
       " 'usando',\n",
       " 'uma',\n",
       " 'api',\n",
       " 'não',\n",
       " 'autenticada',\n",
       " 'encontrando',\n",
       " 'apis',\n",
       " 'exemplo',\n",
       " 'usando',\n",
       " 'as',\n",
       " 'apis',\n",
       " 'do',\n",
       " 'twitter',\n",
       " 'obtendo',\n",
       " 'credenciais',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'trabalhando',\n",
       " 'com',\n",
       " 'dados',\n",
       " 'explorando',\n",
       " 'seus',\n",
       " 'dados',\n",
       " 'explorando',\n",
       " 'dados',\n",
       " 'unidimensionais',\n",
       " 'duas',\n",
       " 'dimensões',\n",
       " 'muitas',\n",
       " 'dimensões',\n",
       " 'limpando',\n",
       " 'e',\n",
       " 'transformando',\n",
       " 'manipulando',\n",
       " 'dados',\n",
       " 'redimensionando',\n",
       " 'redução',\n",
       " 'da',\n",
       " 'dimensionalidade',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'aprendizado',\n",
       " 'de',\n",
       " 'máquina',\n",
       " 'modelagem',\n",
       " 'o',\n",
       " 'que',\n",
       " 'é',\n",
       " 'aprendizado',\n",
       " 'de',\n",
       " 'máquina',\n",
       " 'sobreajuste',\n",
       " 'e',\n",
       " 'subajuste',\n",
       " 'precisão',\n",
       " 'compromisso',\n",
       " 'entre',\n",
       " 'polarização',\n",
       " 'e',\n",
       " 'variância',\n",
       " 'recursos',\n",
       " 'extração',\n",
       " 'e',\n",
       " 'seleção',\n",
       " 'de',\n",
       " 'característica',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'k–vizinhos',\n",
       " 'mais',\n",
       " 'próximos',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'exemplo',\n",
       " 'linguagens',\n",
       " 'favoritas',\n",
       " 'a',\n",
       " 'maldição',\n",
       " 'da',\n",
       " 'dimensionalidade',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'naive',\n",
       " 'bayes',\n",
       " 'um',\n",
       " 'filtro',\n",
       " 'de',\n",
       " 'spam',\n",
       " 'muito',\n",
       " 'estúpido14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " 'um',\n",
       " 'filtro',\n",
       " 'de',\n",
       " 'spam',\n",
       " 'mais',\n",
       " 'sofisticado',\n",
       " 'implementação',\n",
       " 'testando',\n",
       " 'nosso',\n",
       " 'modelo',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'regressão',\n",
       " 'linear',\n",
       " 'simples',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'usando',\n",
       " 'o',\n",
       " 'gradiente',\n",
       " 'descendente',\n",
       " 'estimativa',\n",
       " 'máxima',\n",
       " 'da',\n",
       " 'probabilidade',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'regressão',\n",
       " 'múltipla',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'mais',\n",
       " 'suposições',\n",
       " 'do',\n",
       " 'modelo',\n",
       " 'dos',\n",
       " 'mínimos',\n",
       " 'quadrados',\n",
       " 'ajustando',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'interpretando',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'o',\n",
       " 'benefício',\n",
       " 'do',\n",
       " 'ajuste',\n",
       " 'digressão',\n",
       " 'a',\n",
       " 'inicialização',\n",
       " 'erros',\n",
       " 'padrões',\n",
       " 'de',\n",
       " 'coeficientes',\n",
       " 'de',\n",
       " 'regressão',\n",
       " 'regularização',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'regressão',\n",
       " 'logística',\n",
       " 'o',\n",
       " 'problema',\n",
       " 'a',\n",
       " 'função',\n",
       " 'logística',\n",
       " 'aplicando',\n",
       " 'o',\n",
       " 'modelo',\n",
       " 'o',\n",
       " 'benefício',\n",
       " 'do',\n",
       " 'ajuste',\n",
       " 'máquina',\n",
       " 'de',\n",
       " 'vetor',\n",
       " 'de',\n",
       " 'suporte',\n",
       " 'para',\n",
       " 'mais',\n",
       " 'esclarecimentos',\n",
       " 'árvores',\n",
       " 'de',\n",
       " 'decisão',\n",
       " 'o',\n",
       " 'que',\n",
       " 'é',\n",
       " 'uma',\n",
       " 'árvore',\n",
       " 'de',\n",
       " 'decisão',\n",
       " 'entropia',\n",
       " 'a',\n",
       " 'entropia',\n",
       " 'de',\n",
       " 'uma',\n",
       " 'partição',\n",
       " 'criando',\n",
       " 'uma',\n",
       " 'árvore',\n",
       " 'de',\n",
       " 'decisão',\n",
       " 'juntando',\n",
       " 'tudo',\n",
       " 'florestas',\n",
       " 'aleatórias18',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenização\n",
    "nltk.download('punkt')\n",
    "tokenizacao = nltk.word_tokenize(text_sem_pontuacao)\n",
    "tokenizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97fa45a8-ee72-4da8-b3ba-c5bb90fa78b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remoção das stopwords, palaras que se removidas não alteram o sentido do texto.\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e42f16c-f29e-4ba6-b4e7-24acc3975cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
     ]
    }
   ],
   "source": [
    "palavras_sem_stopwords = [p for p in tokenizacao if p not in stopwords]\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a05612-8d5e-4c64-ab4a-f61295fdcd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dados', 567),\n",
       " ('1', 538),\n",
       " ('0', 455),\n",
       " ('“', 440),\n",
       " ('”', 437),\n",
       " ('in', 433),\n",
       " ('cada', 361),\n",
       " ('def', 290),\n",
       " ('return', 290),\n",
       " ('2', 287)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#palavra com mais frequência\n",
    "frequencia = FreqDist(palavras_sem_stopwords)\n",
    "frequencia = frequencia.most_common(10)\n",
    "frequencia\n",
    "\n",
    "#saiu pontuações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2b65533-c105-4da3-b650-b021173daaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1dbdf7d7350>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gerando a wordcloud\n",
    "nuvem = WordCloud(\n",
    "    background_color = 'white',\n",
    "    stopwords = stopwords,\n",
    "    height = 1080,\n",
    "    width = 1080,\n",
    "    max_words = 100\n",
    ")\n",
    "\n",
    "nuvem.generate(text)\n",
    "#salvando imagem\n",
    "nuvem.to_file('nuvem_de_palavras_livro.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1c96c42-c5f2-4494-a147-aacfe0952646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f14d5c0b-7ab6-446c-829a-fa76e12cb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('nuvem_de_palavras_livro.jpg')\n",
    "image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
